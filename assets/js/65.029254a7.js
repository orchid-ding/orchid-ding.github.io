(window.webpackJsonp=window.webpackJsonp||[]).push([[65],{548:function(a,n,e){"use strict";e.r(n);var s=e(19),t=Object(s.a)({},(function(){var a=this,n=a.$createElement,e=a._self._c||n;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("h2",{attrs:{id:"_1、flink-table以及sql的基本介绍"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1、flink-table以及sql的基本介绍"}},[a._v("#")]),a._v(" 1、Flink table以及SQL的基本介绍")]),a._v(" "),e("blockquote",[e("p",[a._v("Apache Flink 具有两个关系型API：Table API 和SQL，用于统一流和批处理。\nTable API 是用于 Scala 和 Java 语言的查询API，允许以非常直观的方式组合关系运算符的查询，例如 select，filter 和 join。Flink SQL 的支持是基于实现了SQL标准的 Apache Calcite。无论输入是批输入（DataSet）还是流输入（DataStream），任一接口中指定的查询都具有相同的语义并指定相同的结果。\n"),a._v("\nTable API和SQL接口彼此集成，Flink的DataStream和DataSet API亦是如此。我们可以轻松地在基于API构建的所有API和库之间切换。\n​\t\t\n**注意，**到目前最新版本为止，Table API和SQL还有很多功能正在开发中。 并非[Table API，SQL]和[stream，batch]输入的每种组合都支持所有操作")])]),a._v(" "),e("h2",{attrs:{id:"_2、为什么需要sql"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2、为什么需要sql"}},[a._v("#")]),a._v(" 2、为什么需要SQL")]),a._v(" "),e("p",[a._v('​\t\tTable API 是一种关系型API，类 SQL 的API，用户可以像操作表一样地操作数据， 非常的直观和方便。\n​\t\tSQL 作为一个"人所皆知"的语言，如果一个引擎提供 SQL，它将很容易被人们接受。这已经是业界很常见的现象了。\nTable & SQL API 还有另一个职责，就是流处理和批处理统一的API层。')]),a._v(" "),e("h2",{attrs:{id:"_3、flink-table-sql编程开发"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3、flink-table-sql编程开发"}},[a._v("#")]),a._v(" 3、Flink Table  &  SQL编程开发")]),a._v(" "),e("p",[a._v("官网介绍：\nhttps://ci.apache.org/projects/flink/flink-docs-release-1.8/dev/table/")]),a._v(" "),e("p",[a._v("​\t\tFlink的tableAPI允许我们对流式处理以及批量处理都使用sql语句的方式来进行开发。只要我们知道了dataStream或者dataSet可以转换成为Table，那么我们就可以方便的从各个地方获取数据，然后转换成为Table，通过TableAPI或者SQL来实现我们的数据的处理等\nFlink的表API和SQL程序可以连接到其他外部系统来读写批处理表和流表。Table source提供对存储在外部 系统(如数据库、键值存储、消息队列或文件系统)中的数据的访问。Table Sink将表发送到外部存储系统。")]),a._v(" "),e("h3",{attrs:{id:"_3-1、读取csv文件-进行查询"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-1、读取csv文件-进行查询"}},[a._v("#")]),a._v(" 3.1、读取CSV文件，进行查询")]),a._v(" "),e("p",[a._v("需求：读取csv文件，文件内容参见课件当中的flinksql.csv文件，查询年龄大于18岁的人，并将结果写入到csv文件里面去")]),a._v(" "),e("h4",{attrs:{id:"_3-1-1-第一步-导入jar包"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-1-第一步-导入jar包"}},[a._v("#")]),a._v(" 3.1.1 第一步：导入jar包")]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-planner_2.11</artifactId>\n    <version>1.8.1</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-api-scala-bridge_2.11</artifactId>\n    <version>1.8.1</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-api-scala_2.11</artifactId>\n    <version>1.8.1</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-common</artifactId>\n    <version>1.8.1</version>\n</dependency>\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br"),e("span",{staticClass:"line-number"},[a._v("17")]),e("br"),e("span",{staticClass:"line-number"},[a._v("18")]),e("br"),e("span",{staticClass:"line-number"},[a._v("19")]),e("br"),e("span",{staticClass:"line-number"},[a._v("20")]),e("br")])]),e("h4",{attrs:{id:"_3-1-2-读取csv文件进行查询"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-2-读取csv文件进行查询"}},[a._v("#")]),a._v(" 3.1.2 读取csv文件进行查询")]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v('import org.apache.flink.core.fs.FileSystem.WriteMode\nimport org.apache.flink.streaming.api.scala.{StreamExecutionEnvironment}\nimport org.apache.flink.table.api.{Table, Types}\nimport org.apache.flink.table.api.scala.StreamTableEnvironment\nimport org.apache.flink.table.sinks.{CsvTableSink}\nimport org.apache.flink.table.sources.CsvTableSource\n\nobject FlinkStreamSQL {\n  def main(args: Array[String]): Unit = {\n    //流式sql，获取运行环境\n    val streamEnvironment: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment\n    //流式table处理环境\n    val tableEnvironment: StreamTableEnvironment = StreamTableEnvironment.create(streamEnvironment)\n    //注册我们的tableSource\n    val source: CsvTableSource = CsvTableSource.builder()\n      .field("id", Types.INT)\n      .field("name", Types.STRING)\n      .field("age", Types.INT)\n      .fieldDelimiter(",")\n      .ignoreFirstLine()\n      .ignoreParseErrors()\n      .lineDelimiter("\\r\\n")\n      .path("D:\\\\开课吧课程资料\\\\Flink实时数仓\\\\datas\\\\flinksql.csv")\n      .build()\n    //将tableSource注册成为我们的表\n    tableEnvironment.registerTableSource("user",source)\n    //查询年龄大于18岁的人\n    val result: Table = tableEnvironment.scan("user").filter("age >18")\n    //打印我们表的元数据信息===》也就是字段信息\n    //将查询出来的结果，保存到我们的csv文件里面去\n    val sink = new CsvTableSink("D:\\\\开课吧课程资料\\\\Flink实时数仓\\\\datas\\\\sink.csv","===",1,WriteMode.OVERWRITE)\n    result.writeToSink(sink)\n    streamEnvironment.execute()\n  }\n}\n')])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br"),e("span",{staticClass:"line-number"},[a._v("17")]),e("br"),e("span",{staticClass:"line-number"},[a._v("18")]),e("br"),e("span",{staticClass:"line-number"},[a._v("19")]),e("br"),e("span",{staticClass:"line-number"},[a._v("20")]),e("br"),e("span",{staticClass:"line-number"},[a._v("21")]),e("br"),e("span",{staticClass:"line-number"},[a._v("22")]),e("br"),e("span",{staticClass:"line-number"},[a._v("23")]),e("br"),e("span",{staticClass:"line-number"},[a._v("24")]),e("br"),e("span",{staticClass:"line-number"},[a._v("25")]),e("br"),e("span",{staticClass:"line-number"},[a._v("26")]),e("br"),e("span",{staticClass:"line-number"},[a._v("27")]),e("br"),e("span",{staticClass:"line-number"},[a._v("28")]),e("br"),e("span",{staticClass:"line-number"},[a._v("29")]),e("br"),e("span",{staticClass:"line-number"},[a._v("30")]),e("br"),e("span",{staticClass:"line-number"},[a._v("31")]),e("br"),e("span",{staticClass:"line-number"},[a._v("32")]),e("br"),e("span",{staticClass:"line-number"},[a._v("33")]),e("br"),e("span",{staticClass:"line-number"},[a._v("34")]),e("br"),e("span",{staticClass:"line-number"},[a._v("35")]),e("br")])]),e("h3",{attrs:{id:"_3-2、datastream与table的互相转换操作"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-2、datastream与table的互相转换操作"}},[a._v("#")]),a._v(" 3.2、DataStream与Table的互相转换操作")]),a._v(" "),e("h4",{attrs:{id:"_3-2-1-datastream转换成为table"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-1-datastream转换成为table"}},[a._v("#")]),a._v(" 3.2.1 DataStream转换成为Table")]),a._v(" "),e("p",[a._v("​\t\t我们也可以将dataStream，流式处理的数据处理成为一张表，然后通过sql语句进行查询数据，读取socket当中的数据，然后进行数据统计，统计年大于10的人数，并将结果保存到本地文件，socket发送的数据格式如下。")]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("101,zhangsan,18\n102,lisi,20\n103,wangwu,25\n104,zhaoliu,8\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br")])]),e("p",[a._v("​\t\t将DataStream转换成为Table，我们需要用到StreamExecutionEnvironment和StreamTableEnvironment这两个对象\n获取StreamTableEnvironment 对象，然后调用fromDataStream或者registerDataStream就可以将我们的DataStream转换成为Table")]),a._v(" "),e("h4",{attrs:{id:"_3-2-2-table转换成为datastream"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-2-table转换成为datastream"}},[a._v("#")]),a._v(" 3.2.2 Table转换成为DataStream")]),a._v(" "),e("p",[a._v("或者我们也可以将我们处理完成之后的Table转换成为DataStream，将Table转换成为DataStream可以有两种模式")]),a._v(" "),e("ul",[e("li",[e("p",[a._v("第一种方式：AppendMode")]),a._v(" "),e("p",[a._v("将表附加到流数据，表当中只能有查询或者添加操作，如果有update或者delete操作，那么就会失败\n只有在动态Table仅通过INSERT更改修改时才能使用此模式，即它仅附加，并且以前发出的结果永远不会更新。如果更新或删除操作使用追加模式会失败报错")])]),a._v(" "),e("li",[e("p",[a._v("第二种模式：RetraceMode")]),a._v(" "),e("p",[a._v("始终可以使用此模式。返回值是boolean类型。它用true或false来标记数据的插入和撤回，返回true代表数据插入，false代表数据的撤回")])]),a._v(" "),e("li",[e("p",[a._v("1、 第一步：代码开发\n注意：flink代码开发需要导入隐式转换包\nimport org.apache.flink.api.scala._\n对于flink tableAPI或者SQL的开发，则需要导入隐式转换包")])])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v(' import org.apache.flink.table.api._\n  import org.apache.flink.core.fs.FileSystem.WriteMode\n  import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment}\n  import org.apache.flink.table.api._\n  import org.apache.flink.api.scala._\n  import org.apache.flink.table.api.scala.StreamTableEnvironment\n  import org.apache.flink.table.sinks.CsvTableSink\n\n  object FlinkStreamSQL {\n    def main(args: Array[String]): Unit = {\n      val environment: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment\n  val streamSQLEnvironment: StreamTableEnvironment = StreamTableEnvironment.create(environment)\n  val socketStream: DataStream[String] = environment.socketTextStream("node01",9000)\n  //101,zhangsan,18\n  //102,lisi,20\n  //103,wangwu,25\n  //104,zhaoliu,8\n  val userStream: DataStream[User] = socketStream.map(x =>User(x.split(",")(0).toInt,x.split(",")(1),x.split(",")(2).toInt) )\n  //将我们的流注册成为一张表\n  streamSQLEnvironment.registerDataStream("userTable",userStream)\n  //通过sql语句的方式来进行查询\n\n  //通过表达式来进行查询\n  //使用tableAPI来进行查询\n   // val table: Table = streamSQLEnvironment.scan("userTable").filter("age > 10")\n      //使用sql方式来进行查询\n      val table: Table = streamSQLEnvironment.sqlQuery("select * from userTable")\n      val sink3 = new CsvTableSink("D:\\\\开课吧课程资料\\\\Flink实时数仓\\\\datas\\\\sink3.csv","===",1,WriteMode.OVERWRITE)\n      table.writeToSink(sink3)\n      //使用append模式将Table转换成为dataStream，不能用于sum，count，avg等操作，只能用于添加数据操作\n  val appendStream: DataStream[User] = streamSQLEnvironment.toAppendStream[User](table)\n  //使用retract模式将Table转换成为DataStream\n  val retractStream: DataStream[(Boolean, User)] = streamSQLEnvironment.toRetractStream[User](table)\n  environment.execute()\n    }\n  }\n  case class User(id:Int,name:String,age:Int)\n')])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br"),e("span",{staticClass:"line-number"},[a._v("17")]),e("br"),e("span",{staticClass:"line-number"},[a._v("18")]),e("br"),e("span",{staticClass:"line-number"},[a._v("19")]),e("br"),e("span",{staticClass:"line-number"},[a._v("20")]),e("br"),e("span",{staticClass:"line-number"},[a._v("21")]),e("br"),e("span",{staticClass:"line-number"},[a._v("22")]),e("br"),e("span",{staticClass:"line-number"},[a._v("23")]),e("br"),e("span",{staticClass:"line-number"},[a._v("24")]),e("br"),e("span",{staticClass:"line-number"},[a._v("25")]),e("br"),e("span",{staticClass:"line-number"},[a._v("26")]),e("br"),e("span",{staticClass:"line-number"},[a._v("27")]),e("br"),e("span",{staticClass:"line-number"},[a._v("28")]),e("br"),e("span",{staticClass:"line-number"},[a._v("29")]),e("br"),e("span",{staticClass:"line-number"},[a._v("30")]),e("br"),e("span",{staticClass:"line-number"},[a._v("31")]),e("br"),e("span",{staticClass:"line-number"},[a._v("32")]),e("br"),e("span",{staticClass:"line-number"},[a._v("33")]),e("br"),e("span",{staticClass:"line-number"},[a._v("34")]),e("br"),e("span",{staticClass:"line-number"},[a._v("35")]),e("br"),e("span",{staticClass:"line-number"},[a._v("36")]),e("br"),e("span",{staticClass:"line-number"},[a._v("37")]),e("br")])]),e("ul",[e("li",[a._v("2、第二步：socket发送数据")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("101,zhangsan,18\n102,lisi,20\n103,wangwu,25\n104,zhaoliu,8\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br")])]),e("h4",{attrs:{id:"_3-2-3-dataset与table的互相转换操作"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-3-dataset与table的互相转换操作"}},[a._v("#")]),a._v(" 3.2.3 DataSet与Table的互相转换操作")]),a._v(" "),e("p",[a._v("我们也可以将我们的DataSet注册成为一张表Table，然后进行查询数据，同时我们也可以将Table转换成为DataSet")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v('import org.apache.flink.api.scala._\nimport org.apache.flink.api.scala.ExecutionEnvironment\nimport org.apache.flink.core.fs.FileSystem.WriteMode\nimport org.apache.flink.table.api.scala.BatchTableEnvironment\nimport org.apache.flink.table.sinks.CsvTableSink\n\nobject FlinkBatchSQL {\n  def main(args: Array[String]): Unit = {\n    val environment: ExecutionEnvironment = ExecutionEnvironment.getExecutionEnvironment\n    val batchSQL: BatchTableEnvironment = BatchTableEnvironment.create(environment)\nval sourceSet: DataSet[String] = environment.readTextFile("D:\\\\datas\\\\dataSet.csv")\n\nval userSet: DataSet[User2] = sourceSet.map(x => {\n  println(x)\n  val line: Array[String] = x.split(",")\n  User2(line(0).toInt, line(1), line(2).toInt)\n})\n\nimport org.apache.flink.table.api._\n\nbatchSQL.registerDataSet("user",userSet)\n\n//val table: Table = batchSQL.scan("user").filter("age > 18")\n//注意：user关键字是flink当中的保留字段，如果用到了这些保留字段，需要转译\nval table: Table = batchSQL.sqlQuery("select id,name,age from `user` ")\nval sink = new CsvTableSink("D:\\\\datas\\\\batchSink.csv","===",1,WriteMode.OVERWRITE)\ntable.writeToSink(sink)\n\n//将Table转换成为DataSet\n val tableSet: DataSet[User2] = batchSQL.toDataSet[User2](table)\n\ntableSet.map(x =>x.age).print()\n\nenvironment.execute()\n }\n}\n\ncase class User2(id:Int,name:String,age:Int)\n')])])]),e("p",[a._v("更多flink定义的保留关键字段：\nhttps://ci.apache.org/projects/flink/flink-docs-release-1.8/dev/table/sql.html")]),a._v(" "),e("h4",{attrs:{id:"_3-2-4、flinksql处理kafka的json格式数据"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-4、flinksql处理kafka的json格式数据"}},[a._v("#")]),a._v(" 3.2.4、FlinkSQL处理kafka的json格式数据")]),a._v(" "),e("p",[a._v("​\t\tFlink的SQL功能也可以让我们直接读取kafka当中的数据，然后将kafka当中的数据作为我们的数据源，直接将kafka当中的数据注册成为一张表，然后通过sql来查询kafka当中的数据即可，如果kafka当中出现的是json格式的数据，那么也没关系flink也可以与json进行集成，直接解析json格式的数据\nhttps://ci.apache.org/projects/flink/flink-docs-release-1.8/dev/table/connect.html")]),a._v(" "),e("ul",[e("li",[a._v("第一步：导入jar包")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("<dependency>\n     <groupId>org.apache.flink</groupId>\n     <artifactId>flink-json</artifactId>\n     <version>1.8.1</version>\n </dependency>\n\n \x3c!--\n 前面Flink Stream与kafka整合已经导入了kafka的包，不用再导入了\n <dependency>\n     <groupId>org.apache.flink</groupId>\n     <artifactId>flink-connector-kafka-0.11_2.11</artifactId>\n     <version>1.8.1</version>\n </dependency>\n <dependency>\n     <groupId>org.apache.kafka</groupId>\n     <artifactId>kafka-clients</artifactId>\n     <version>1.1.0</version>\n </dependency>\n\n <dependency>\n     <groupId>org.slf4j</groupId>\n     <artifactId>slf4j-api</artifactId>\n     <version>1.7.25</version>\n </dependency>\n\n <dependency>\n     <groupId>org.slf4j</groupId>\n     <artifactId>slf4j-log4j12</artifactId>\n     <version>1.7.25</version>\n </dependency>\n--\x3e\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br"),e("span",{staticClass:"line-number"},[a._v("17")]),e("br"),e("span",{staticClass:"line-number"},[a._v("18")]),e("br"),e("span",{staticClass:"line-number"},[a._v("19")]),e("br"),e("span",{staticClass:"line-number"},[a._v("20")]),e("br"),e("span",{staticClass:"line-number"},[a._v("21")]),e("br"),e("span",{staticClass:"line-number"},[a._v("22")]),e("br"),e("span",{staticClass:"line-number"},[a._v("23")]),e("br"),e("span",{staticClass:"line-number"},[a._v("24")]),e("br"),e("span",{staticClass:"line-number"},[a._v("25")]),e("br"),e("span",{staticClass:"line-number"},[a._v("26")]),e("br"),e("span",{staticClass:"line-number"},[a._v("27")]),e("br"),e("span",{staticClass:"line-number"},[a._v("28")]),e("br"),e("span",{staticClass:"line-number"},[a._v("29")]),e("br"),e("span",{staticClass:"line-number"},[a._v("30")]),e("br"),e("span",{staticClass:"line-number"},[a._v("31")]),e("br")])]),e("ul",[e("li",[a._v("第二步：创建kafka的topic")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("node01执行以下命令，创建一个topic\ncd /kkb/install/kafka_2.11-1.1.0\nbin/kafka-topics.sh --create --topic kafka_source_table --partitions 3 --replication-factor 1 --zookeeper node01:2181,node02:2181,node03:2181\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br")])]),e("ul",[e("li",[a._v("第三步：使用flink查询kafka当中的数据、")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v('import org.apache.flink.api.common.typeinfo.TypeInformation\nimport org.apache.flink.core.fs.FileSystem.WriteMode\nimport org.apache.flink.streaming.api.scala.StreamExecutionEnvironment\nimport org.apache.flink.table.api.{Table, _}\nimport org.apache.flink.table.api.scala.StreamTableEnvironment\nimport org.apache.flink.table.descriptors.{Json, Kafka, Schema}\nimport org.apache.flink.table.sinks.CsvTableSink\nobject KafkaJsonSource {\n  def main(args: Array[String]): Unit = {\n    val streamEnvironment: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment\n    //隐式转换\n    //checkpoint配置\n   /* streamEnvironment.enableCheckpointing(100);\n    streamEnvironment.getCheckpointConfig.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);\n    streamEnvironment.getCheckpointConfig.setMinPauseBetweenCheckpoints(500);\n    streamEnvironment.getCheckpointConfig.setCheckpointTimeout(60000);\n    streamEnvironment.getCheckpointConfig.setMaxConcurrentCheckpoints(1);\n    streamEnvironment.getCheckpointConfig.enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);\n*/\n    val tableEnvironment: StreamTableEnvironment = StreamTableEnvironment.create(streamEnvironment)\n    val kafka: Kafka = new Kafka()\n      .version("0.11")\n      .topic("kafka_source_table")\n      .startFromLatest()\n      .property("group.id", "test_group")\n      .property("bootstrap.servers", "node01:9092,node02:9092,node03:9092")\n      \nval json: Json = new Json().failOnMissingField(false).deriveSchema()\n//{"userId":1119,"day":"2017-03-02","begintime":1488326400000,"endtime":1488327000000,"data":[{"package":"com.browser","activetime":120000}]}\nval schema: Schema = new Schema()\n  .field("userId", Types.INT)\n  .field("day", Types.STRING)\n  .field("begintime", Types.LONG)\n  .field("endtime", Types.LONG)\n tableEnvironment\n  .connect(kafka)\n  .withFormat(json)\n  .withSchema(schema)\n  .inAppendMode()\n  .registerTableSource("user_log")\n//使用sql来查询数据\nval table: Table = tableEnvironment.sqlQuery("select userId,`day` ,begintime,endtime  from user_log")\ntable.printSchema()\n//定义sink，输出数据到哪里\nval sink = new CsvTableSink("D:\\\\开课吧课程资料\\\\Flink实时数仓\\\\datas\\\\flink_kafka.csv","====",1,WriteMode.OVERWRITE)\n//注册数据输出目的地\ntableEnvironment.registerTableSink("csvSink",\n  Array[String]("f0","f1","f2","f3"),\n    Array[TypeInformation[_]](Types.INT, Types.STRING, Types.LONG, Types.LONG),sink)\n//将数据插入到数据目的地\ntable.insertInto("csvSink")\nstreamEnvironment.execute("kafkaSource")\n\t}\n}\n')])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br"),e("span",{staticClass:"line-number"},[a._v("17")]),e("br"),e("span",{staticClass:"line-number"},[a._v("18")]),e("br"),e("span",{staticClass:"line-number"},[a._v("19")]),e("br"),e("span",{staticClass:"line-number"},[a._v("20")]),e("br"),e("span",{staticClass:"line-number"},[a._v("21")]),e("br"),e("span",{staticClass:"line-number"},[a._v("22")]),e("br"),e("span",{staticClass:"line-number"},[a._v("23")]),e("br"),e("span",{staticClass:"line-number"},[a._v("24")]),e("br"),e("span",{staticClass:"line-number"},[a._v("25")]),e("br"),e("span",{staticClass:"line-number"},[a._v("26")]),e("br"),e("span",{staticClass:"line-number"},[a._v("27")]),e("br"),e("span",{staticClass:"line-number"},[a._v("28")]),e("br"),e("span",{staticClass:"line-number"},[a._v("29")]),e("br"),e("span",{staticClass:"line-number"},[a._v("30")]),e("br"),e("span",{staticClass:"line-number"},[a._v("31")]),e("br"),e("span",{staticClass:"line-number"},[a._v("32")]),e("br"),e("span",{staticClass:"line-number"},[a._v("33")]),e("br"),e("span",{staticClass:"line-number"},[a._v("34")]),e("br"),e("span",{staticClass:"line-number"},[a._v("35")]),e("br"),e("span",{staticClass:"line-number"},[a._v("36")]),e("br"),e("span",{staticClass:"line-number"},[a._v("37")]),e("br"),e("span",{staticClass:"line-number"},[a._v("38")]),e("br"),e("span",{staticClass:"line-number"},[a._v("39")]),e("br"),e("span",{staticClass:"line-number"},[a._v("40")]),e("br"),e("span",{staticClass:"line-number"},[a._v("41")]),e("br"),e("span",{staticClass:"line-number"},[a._v("42")]),e("br"),e("span",{staticClass:"line-number"},[a._v("43")]),e("br"),e("span",{staticClass:"line-number"},[a._v("44")]),e("br"),e("span",{staticClass:"line-number"},[a._v("45")]),e("br"),e("span",{staticClass:"line-number"},[a._v("46")]),e("br"),e("span",{staticClass:"line-number"},[a._v("47")]),e("br"),e("span",{staticClass:"line-number"},[a._v("48")]),e("br"),e("span",{staticClass:"line-number"},[a._v("49")]),e("br"),e("span",{staticClass:"line-number"},[a._v("50")]),e("br"),e("span",{staticClass:"line-number"},[a._v("51")]),e("br"),e("span",{staticClass:"line-number"},[a._v("52")]),e("br"),e("span",{staticClass:"line-number"},[a._v("53")]),e("br"),e("span",{staticClass:"line-number"},[a._v("54")]),e("br")])]),e("ul",[e("li",[a._v("第四步：kafka当中发送数据")])]),a._v(" "),e("p",[a._v("使用kafka命令行发送数据")]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("cd /kkb/install/kafka_2.11-1.1.0\nbin/kafka-console-producer.sh  --topic kafka_source_table --broker-list node01:9092,node02:9092,node03:9092 \n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br")])]),e("p",[a._v("发送数据格式如下：")]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v('{"userId":1119,"day":"2017-03-02","begintime":1488326400000,"endtime":1488327000000}\n{"userId":1120,"day":"2017-03-02","begintime":1488326400000,"endtime":1488327000000}\n{"userId":1121,"day":"2017-03-02","begintime":1488326400000,"endtime":1488327000000}\n{"userId":1122,"day":"2017-03-02","begintime":1488326400000,"endtime":1488327000000}\n{"userId":1123,"day":"2017-03-02","begintime":1488326400000,"endtime":1488327000000}\n')])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br")])])])}),[],!1,null,null,null);n.default=t.exports}}]);