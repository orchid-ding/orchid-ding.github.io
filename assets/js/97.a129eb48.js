(window.webpackJsonp=window.webpackJsonp||[]).push([[97],{582:function(s,a,t){"use strict";t.r(a);var n=t(19),r=Object(n.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("ul",[t("li",[t("strong",[s._v("Apache Spark™")]),s._v(" is a unified analytics engine for large-scale data processing.")]),s._v(" "),t("li",[s._v("spark是针对于大规模数据处理的统一分析引擎")])]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("\tspark是在Hadoop基础上的改进，是UC Berkeley AMP lab所开源的类Hadoop MapReduce的通用的并行计算框架，Spark基于map reduce算法实现的分布式计算，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法。\n\tspark是基于内存计算框架，计算速度非常之快，但是它仅仅只是涉及到计算，并没有涉及到数据的存储，后期需要使用spark对接外部的数据源，比如hdfs。\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("h2",{attrs:{id:"四大特性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#四大特性"}},[s._v("#")]),s._v(" 四大特性")]),s._v(" "),t("h3",{attrs:{id:"速度快"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#速度快"}},[s._v("#")]),s._v(" 速度快")]),s._v(" "),t("div",{staticClass:"language-markdown line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-markdown"}},[t("code",[t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" 运行速度提高100倍\n  "),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" Apache Spark使用最先进的DAG调度程序，查询优化程序和物理执行引擎，实现批量和流式数据的高性能。\n"),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" spark比mapreduce快的2个主要原因\n  "),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" 1、==基于内存==\n    （1）mapreduce任务后期再计算的时候，每一个job的输出结果会落地到磁盘，后续有其他的job需要依赖于前面job的输出结果，这个时候就需要进行大量的磁盘io操作。性能就比较低。\n    （2）spark任务后期再计算的时候，job的输出结果可以保存在内存中，后续有其他的job需要依赖于前面job的输出结果，这个时候就直接从内存中获取得到，避免了磁盘io操作，性能比较高\n  "),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" 2、==进程与线程==\n    （1）mapreduce任务以进程的方式运行在yarn集群中，比如程序中有100个MapTask，一个task就需要一个进程，这些task要运行就需要开启100个进程。\n    （2）spark任务以线程的方式运行在进程中，比如程序中有100个MapTask，后期一个task就对应一个线程，这里就不在是进程，这些task需要运行，这里可以极端一点：\n    只需要开启1个进程，在这个进程中启动100个线程就可以了。\n    进程中可以启动很多个线程，而开启一个进程与开启一个线程需要的时间和调度代价是不一样。 开启一个进程需要的时间远远大于开启一个线程。\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br")])]),t("h3",{attrs:{id:"易用性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#易用性"}},[s._v("#")]),s._v(" 易用性")]),s._v(" "),t("div",{staticClass:"language-markdown line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-markdown"}},[t("code",[t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("-")]),s._v(" 可以快速去编写spark程序通过 java/scala/python/R/SQL等不同语言\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("h3",{attrs:{id:"通用性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#通用性"}},[s._v("#")]),s._v(" 通用性")]),s._v(" "),t("div",{staticClass:"language-markdown line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-markdown"}},[t("code",[t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("-")]),s._v(" spark框架不在是一个简单的框架，可以把spark理解成一个=="),t("span",{pre:!0,attrs:{class:"token bold"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("**")]),t("span",{pre:!0,attrs:{class:"token content"}},[s._v("生态系统")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("**")])]),s._v("==，它内部是包含了很多模块，基于不同的应用场景可以选择对应的模块去使用\n"),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" =="),t("span",{pre:!0,attrs:{class:"token bold"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("**")]),t("span",{pre:!0,attrs:{class:"token content"}},[s._v("sparksql")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("**")])]),s._v("==\n  "),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" 通过sql去开发spark程序做一些离线分析\n"),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" =="),t("span",{pre:!0,attrs:{class:"token bold"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("**")]),t("span",{pre:!0,attrs:{class:"token content"}},[s._v("sparkStreaming")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("**")])]),s._v("==\n  "),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" 主要是用来解决公司有实时计算的这种场景\n"),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" =="),t("span",{pre:!0,attrs:{class:"token bold"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("**")]),t("span",{pre:!0,attrs:{class:"token content"}},[s._v("Mlib")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("**")])]),s._v("==\n  "),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" 它封装了一些机器学习的算法库\n"),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" =="),t("span",{pre:!0,attrs:{class:"token bold"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("**")]),t("span",{pre:!0,attrs:{class:"token content"}},[s._v("Graphx")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("**")])]),s._v("==\n  "),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" 图计算\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br")])]),t("h3",{attrs:{id:"兼容性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#兼容性"}},[s._v("#")]),s._v(" 兼容性")]),s._v(" "),t("div",{staticClass:"language-markdown line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-markdown"}},[t("code",[t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("-")]),s._v(" spark程序就是一个计算逻辑程序，这个任务要运行就需要计算资源（内存、cpu、磁盘），哪里可以给当前这个任务提供计算资源，就可以把spark程序提交到哪里去运行\n"),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" =="),t("span",{pre:!0,attrs:{class:"token bold"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("**")]),t("span",{pre:!0,attrs:{class:"token content"}},[s._v("standAlone")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("**")])]),s._v("==\n  "),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" 它是spark自带的独立运行模式，整个任务的资源分配由spark集群的老大Master负责\n"),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" =="),t("span",{pre:!0,attrs:{class:"token bold"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("**")]),t("span",{pre:!0,attrs:{class:"token content"}},[s._v("yarn")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("**")])]),s._v("==\n  "),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" 可以把spark程序提交到yarn中运行，整个任务的资源分配由yarn中的老大ResourceManager负责\n"),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token bold"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("**")]),t("span",{pre:!0,attrs:{class:"token content"}},[s._v("mesos")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("**")])]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token list punctuation"}},[s._v("*")]),s._v(" 它也是apache开源的一个类似于yarn的资源调度平台\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br")])]),t("h2",{attrs:{id:"集群架构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#集群架构"}},[s._v("#")]),s._v(" 集群架构")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://kflys.gitee.io/upic/2021/spark/spark.png#align=left&display=inline&height=362&margin=%5Bobject%20Object%5D&originHeight=362&originWidth=839&size=0&status=done&style=none&width=839",alt:""}})]),s._v(" "),t("h3",{attrs:{id:"driver"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#driver"}},[s._v("#")]),s._v(" "),t("strong",[s._v("Driver")])]),s._v(" "),t("ul",[t("li",[s._v("它会执行客户端写好的main方法，它会构建一个名叫SparkContext对象\n"),t("ul",[t("li",[s._v("该对象是所有spark程序的执行入口")])])])]),s._v(" "),t("h3",{attrs:{id:"application"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#application"}},[s._v("#")]),s._v(" "),t("strong",[s._v("Application")])]),s._v(" "),t("ul",[t("li",[s._v("就是一个spark的应用程序，它是包含了客户端的代码和任务运行的资源信息")])]),s._v(" "),t("h3",{attrs:{id:"clustermanager"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#clustermanager"}},[s._v("#")]),s._v(" "),t("strong",[s._v("ClusterManager")])]),s._v(" "),t("blockquote",[t("p",[s._v("它是给程序提供计算资源的外部服务")])]),s._v(" "),t("h4",{attrs:{id:"standalone"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#standalone"}},[s._v("#")]),s._v(" "),t("strong",[s._v("standAlone")])]),s._v(" "),t("ul",[t("li",[s._v("它是spark自带的集群模式，整个任务的资源分配由spark集群的老大Master负责")])]),s._v(" "),t("h4",{attrs:{id:"yarn"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#yarn"}},[s._v("#")]),s._v(" "),t("strong",[s._v("yarn")])]),s._v(" "),t("ul",[t("li",[s._v("可以把spark程序提交到yarn中运行，整个任务的资源分配由yarn中的老大ResourceManager负责")])]),s._v(" "),t("h4",{attrs:{id:"mesos"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mesos"}},[s._v("#")]),s._v(" "),t("strong",[s._v("mesos")])]),s._v(" "),t("ul",[t("li",[s._v("它也是apache开源的一个类似于yarn的资源调度平台。")])]),s._v(" "),t("h3",{attrs:{id:"master"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#master"}},[s._v("#")]),s._v(" "),t("strong",[s._v("Master")])]),s._v(" "),t("ul",[t("li",[s._v("它是整个spark集群的主节点，负责任务资源的分配")])]),s._v(" "),t("h3",{attrs:{id:"worker"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#worker"}},[s._v("#")]),s._v(" "),t("strong",[s._v("Worker")])]),s._v(" "),t("ul",[t("li",[s._v("它是整个spark集群的从节点，负责任务计算的节点")])]),s._v(" "),t("h3",{attrs:{id:"executor"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#executor"}},[s._v("#")]),s._v(" "),t("strong",[s._v("Executor")])]),s._v(" "),t("ul",[t("li",[s._v("它是一个进程，它会在worker节点启动该进程（计算资源）")])]),s._v(" "),t("h3",{attrs:{id:"task"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#task"}},[s._v("#")]),s._v(" "),t("strong",[s._v("Task")])]),s._v(" "),t("ul",[t("li",[s._v("spark任务是以task线程的方式运行在worker节点对应的executor进程中")])]),s._v(" "),t("h2",{attrs:{id:"启动停止"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#启动停止"}},[s._v("#")]),s._v(" 启动停止")]),s._v(" "),t("div",{staticClass:"language-markdown line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-markdown"}},[t("code",[s._v("(1) 如何恢复到上一次活着master挂掉之前的状态?\n\t在高可用模式下，整个spark集群就有很多个master，其中只有一个master被zk选举成活着的master，其他的多个master都处于standby，同时把整个spark集群的元数据信息通过zk中节点进行保存。\n\n"),t("span",{pre:!0,attrs:{class:"token code keyword"}},[s._v("\t后期如果活着的master挂掉。首先zk会感知到活着的master挂掉，下面开始在多个处于standby中的master进行选举，再次产生一个活着的master，这个活着的master会读取保存在zk节点中的spark集群元数据信息，恢复到上一次master的状态。整个过程在恢复的时候经历过了很多个不同的阶段，每个阶段都需要一定时间，最终恢复到上个活着的master的转态，整个恢复过程一般需要1-2分钟。")]),s._v("\n\n(2) 在master的恢复阶段对任务的影响?\n   a）对已经运行的任务是没有任何影响\n   \t  由于该任务正在运行，说明它已经拿到了计算资源，这个时候就不需要master。\n   b) 对即将要提交的任务是有影响\n   \t  由于该任务需要有计算资源，这个时候会找活着的master去申请计算资源，由于没有一个活着的master,该任务是获取不到计算资源，也就是任务无法运行。\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br")])]),t("h2",{attrs:{id:"示例"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#示例"}},[s._v("#")]),s._v(" 示例")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[s._v("bin/spark-submit "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n--class org.apache.spark.examples.SparkPi "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n--master spark://node01:7077 "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n--executor-memory 1G "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n--total-executor-cores "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\nexamples/jars/spark-examples_2.11-2.3.3.jar "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br")])]),t("h3",{attrs:{id:"参数说明"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#参数说明"}},[s._v("#")]),s._v(" 参数说明")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("--class：指定包含main方法的主类\n--master：指定spark集群master地址\n--executor-memory：指定任务在运行的时候需要的每一个executor内存大小\n--total-executor-cores： 指定任务在运行的时候需要总的cpu核数\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("h3",{attrs:{id:"注意"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#注意"}},[s._v("#")]),s._v(" 注意")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("spark集群中有很多个master，并不知道哪一个master是活着的master，即使你知道哪一个master是活着的master，它也有可能下一秒就挂掉，这里就可以把所有master都罗列出来\n--master spark://node01:7077,node02:7077,node03:7077\n\n后期程序会轮训整个master列表，最终找到活着的master，然后向它申请计算资源，最后运行程序。\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])])])}),[],!1,null,null,null);a.default=r.exports}}]);