(window.webpackJsonp=window.webpackJsonp||[]).push([[76],{563:function(a,s,e){"use strict";e.r(s);var t=e(19),n=Object(t.a)({},(function(){var a=this,s=a.$createElement,e=a._self._c||s;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("h2",{attrs:{id:"mapreduce编程模型"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce编程模型"}},[a._v("#")]),a._v(" MapReduce编程模型")]),a._v(" "),e("ul",[e("li",[a._v("Hadoop架构图\nHadoop由HDFS分布式存储、"),e("strong",[a._v("MapReduce分布式计算")]),a._v("、Yarn资源调度三部分组成")])]),a._v(" "),e("p",[e("img",{attrs:{src:"http://kflys.gitee.io/upic/2020/03/29/uPic/hadoop/mapreduce/assets/Image201906191834-1562922704761.png#height=426&id=ZT7xI&originHeight=426&originWidth=564&originalType=binary&ratio=1&status=done&style=none&width=564",alt:""}})]),a._v(" "),e("ul",[e("li",[a._v("MapReduce是采用一种"),e("strong",[a._v("分而治之")]),a._v("的思想设计出来的分布式计算框架")]),a._v(" "),e("li",[a._v("MapReduce由两个阶段组成：\n"),e("ul",[e("li",[a._v("Map阶段（切分成一个个小的任务）")]),a._v(" "),e("li",[a._v("Reduce阶段（汇总小任务的结果）")])])]),a._v(" "),e("li",[a._v("那什么是分而治之呢？\n"),e("ul",[e("li",[a._v("比如一复杂、计算量大、耗时长的的任务，暂且称为“大任务”；")]),a._v(" "),e("li",[a._v("此时使用单台服务器无法计算或较短时间内计算出结果时，可将此大任务切分成一个个小的任务，小任务分别在不同的服务器上"),e("strong",[a._v("并行")]),a._v("的执行")]),a._v(" "),e("li",[a._v("最终再汇总每个小任务的结果")])])])]),a._v(" "),e("p",[e("img",{attrs:{src:"http://kflys.gitee.io/upic/2020/03/29/uPic/hadoop/mapreduce/assets/Image201906251747.png#height=729&id=Orhbr&originHeight=729&originWidth=1008&originalType=binary&ratio=1&status=done&style=none&width=1008",alt:""}})]),a._v(" "),e("h3",{attrs:{id:"map阶段"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#map阶段"}},[a._v("#")]),a._v(" Map阶段")]),a._v(" "),e("ul",[e("li",[a._v("map阶段有一个关键的map()函数；")]),a._v(" "),e("li",[a._v("此函数的输入是"),e("strong",[a._v("键值对")])]),a._v(" "),e("li",[a._v("输出是一系列"),e("strong",[a._v("键值对")]),a._v("，输出写入"),e("strong",[a._v("本地磁盘")]),a._v("。")])]),a._v(" "),e("h3",{attrs:{id:"reduce阶段"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#reduce阶段"}},[a._v("#")]),a._v(" Reduce阶段")]),a._v(" "),e("ul",[e("li",[a._v("reduce阶段有一个关键的函数reduce()函数")]),a._v(" "),e("li",[a._v("此函数的输入也是键值对（即map的输出（kv对））")]),a._v(" "),e("li",[a._v("输出也是一系列键值对，结果最终写入HDFS")])]),a._v(" "),e("h3",{attrs:{id:"map-reduce"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#map-reduce"}},[a._v("#")]),a._v(" Map&Reduce")]),a._v(" "),e("p",[e("img",{attrs:{src:"http://kflys.gitee.io/upic/2020/03/29/uPic/hadoop/mapreduce/assets/Image201906251807.png#height=328&id=SOuUl&originHeight=328&originWidth=1093&originalType=binary&ratio=1&status=done&style=none&width=1093",alt:""}})]),a._v(" "),e("h2",{attrs:{id:"mapreduce编程示例"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce编程示例"}},[a._v("#")]),a._v(" MapReduce编程示例")]),a._v(" "),e("ul",[e("li",[a._v("以"),e("strong",[a._v("MapReduce的词频统计")]),a._v("为例：统计一批英文文章当中，每个单词出现的总次数")])]),a._v(" "),e("h3",{attrs:{id:"mapreduce原理图"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce原理图"}},[a._v("#")]),a._v(" MapReduce原理图")]),a._v(" "),e("p",[e("img",{attrs:{src:"http://kflys.gitee.io/upic/2020/03/29/uPic/hadoop/mapreduce/assets/Image201906271715.png#height=760&id=X2wwo&originHeight=760&originWidth=1563&originalType=binary&ratio=1&status=done&style=none&width=1563",alt:""}})]),a._v(" "),e("ul",[e("li",[a._v("Map阶段\n"),e("ul",[e("li",[a._v("假设MR的输入文件“"),e("strong",[a._v("Gone With The Wind")]),a._v("”有三个block；block1、block2、block3")]),a._v(" "),e("li",[a._v("MR编程时，每个block对应一个分片split")]),a._v(" "),e("li",[a._v("每一个split对应一个map任务（map task）")]),a._v(" "),e("li",[a._v("如图共3个map任务（map1、map2、map3）；这3个任务的逻辑一样，所以以第一个map任务（map1）为例分析")]),a._v(" "),e("li",[a._v("map1读取block1的数据；一次读取block1的一行数据；\n"),e("ul",[e("li",[a._v("产生键值对(key/value)，作为map()的参数传入，调用map()；")]),a._v(" "),e("li",[a._v("假设当前所读行是第一行")]),a._v(" "),e("li",[a._v("将当前所读行的行首相对于当前block开始处的字节偏移量作为key（0）")]),a._v(" "),e("li",[a._v("当前行的内容作为value（Dear Bear River）")])])]),a._v(" "),e("li",[a._v("map()内\n"),e("ul",[e("li",[a._v("(按需求，写业务代码)，将value当前行内容按空格切分，得到三个单词Dear | Bear | River")]),a._v(" "),e("li",[a._v("将每个单词变成键值对，输出出去(Dear, 1) | (Bear, 1) | (River, 1)；最终结果写入map任务所在节点的本地磁盘中（内里还有细节，讲到shuffle时，再细细展开）")]),a._v(" "),e("li",[a._v("block的第一行的数据被处理完后，接着处理第二行；逻辑同上")]),a._v(" "),e("li",[a._v("当map任务将当前block中所有的数据全部处理完后，此map任务即运行结束")])])]),a._v(" "),e("li",[a._v("其它的每一个map任务都是如上逻辑，不再赘述")])])]),a._v(" "),e("li",[a._v("Reduce阶段\n"),e("ul",[e("li",[a._v("reduce任务（reduce task）的个数由自己写的程序编程指定，main()内的job.setNumReduceTasks(4)指定reduce任务是4个（reduce1、reduce2、reduce3、reduce4）")]),a._v(" "),e("li",[a._v("每一个reduce任务的逻辑一下，所以以第一个reduce任务（reduce1）为例分析")]),a._v(" "),e("li",[a._v("map1任务完成后，reduce1通过网络，连接到map1，将map1输出结果中属于reduce1的分区的数据，通过网络获取到reduce1端（拷贝阶段）")]),a._v(" "),e("li",[a._v("同样也如此连接到map2、map3获取结果")]),a._v(" "),e("li",[a._v("最终reduce1端获得4个(Dear, 1)键值对；由于key键相同，它们分到同一组；")]),a._v(" "),e("li",[a._v("4个(Dear, 1)键值对，转换成[Dear, Iterable(1, 1, 1, )]，作为两个参数传入reduce()")]),a._v(" "),e("li",[a._v("在reduce()内部，计算Dear的总数为4，并将(Dear, 4)作为键值对输出")]),a._v(" "),e("li",[a._v("每个reduce任务最终输出文件（内里还有细节，讲到shuffle时，再细细展开），文件写入到HDFS")])])])]),a._v(" "),e("h3",{attrs:{id:"mr中key的作用"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mr中key的作用"}},[a._v("#")]),a._v(" MR中key的作用")]),a._v(" "),e("ul",[e("li",[e("strong",[a._v("MapReduce编程中，key有特殊的作用")]),a._v(" "),e("ul",[e("li",[a._v("①数据中，若要针对某个值进行分组、聚合时，需将此值作为MR中的reduce的输入的key")]),a._v(" "),e("li",[a._v("如当前的词频统计例子，按单词进行分组，每组中对出现次数做聚合（计算总和）；所以需要将每个单词作为reduce输入的key，MapReduce框架自动按照单词分组，进而求出每组即每个单词的总次数")]),a._v(" "),e("li",[a._v("②另外，key还具有可排序的特性，因为MR中的key类需要实现WritableComparable接口；而此接口又继承Comparable接口")]),a._v(" "),e("li",[a._v("MR编程时，要充分利用以上两点；结合实际业务需求，设置合适的key\n"),e("img",{attrs:{src:"http://kflys.gitee.io/upic/2020/03/29/uPic/hadoop/mapreduce/assets/Image201908221717.png#height=128&id=g4O4f&originHeight=128&originWidth=970&originalType=binary&ratio=1&status=done&style=none&width=970",alt:""}}),a._v(" "),e("img",{attrs:{src:"http://kflys.gitee.io/upic/2020/03/29/uPic/hadoop/mapreduce/assets/Image201908221718.png#height=109&id=cHMrz&originHeight=109&originWidth=985&originalType=binary&ratio=1&status=done&style=none&width=985",alt:""}})])])])]),a._v(" "),e("h3",{attrs:{id:"map-reduce代码"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#map-reduce代码"}},[a._v("#")]),a._v(" map - reduce代码")]),a._v(" "),e("p",[a._v("Mapper代码")]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("/**\n * 类Mapper<LongWritable, Text, Text, IntWritable>的四个泛型分别表示\n * map方法的输入的键的类型kin、值的类型vin；输出的键的类型kout、输出的值的类型vout\n * kin指的是当前所读行行首相对于split分片开头的字节偏移量,所以是long类型，对应序列化类型LongWritable\n * vin指的是当前所读行，类型是String，对应序列化类型Text\n * kout根据需求，输出键指的是单词，类型是String，对应序列化类型是Text\n * vout根据需求，输出值指的是单词的个数，1，类型是int，对应序列化类型是IntWritable\n */\npublic class WordCountMap extends Mapper<LongWritable, Text, Text, IntWritable> {\n    /**\n     * 处理分片split中的每一行的数据；针对每行数据，会调用一次map方法\n     * 在一次map方法调用时，从一行数据中，获得一个个单词word，再将每个单词word变成键值对形式(word, 1)输出出去\n     * 输出的值最终写到本地磁盘中\n     * @param key 当前所读行行首相对于split分片开头的字节偏移量\n     * @param value  当前所读行\n     */\n    public void map(LongWritable key, Text value, Context context)\n            throws IOException, InterruptedException {\n            context.write(new Text(word), new IntWritable(1));\n        }\n    }\n}\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br"),e("span",{staticClass:"line-number"},[a._v("17")]),e("br"),e("span",{staticClass:"line-number"},[a._v("18")]),e("br"),e("span",{staticClass:"line-number"},[a._v("19")]),e("br"),e("span",{staticClass:"line-number"},[a._v("20")]),e("br"),e("span",{staticClass:"line-number"},[a._v("21")]),e("br"),e("span",{staticClass:"line-number"},[a._v("22")]),e("br")])]),e("p",[a._v("Reducer代码")]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("/**\n * Reducer<Text, IntWritable, Text, IntWritable>的四个泛型分别表示\n * reduce方法的输入的键的类型kin、输入值的类型vin；输出的键的类型kout、输出的值的类型vout\n * 注意：因为map的输出作为reduce的输入，所以此处的kin、vin类型分别与map的输出的键类型、值类型相同\n * kout根据需求，输出键指的是单词，类型是String，对应序列化类型是Text\n * vout根据需求，输出值指的是每个单词的总个数，类型是int，对应序列化类型是IntWritable\n */\npublic class WordCountReduce extends Reducer<Text, IntWritable, Text, IntWritable> {\n    public void reduce(Text key, Iterable<IntWritable> values,\n                          Context context) throws IOException, InterruptedException {\n        //定义变量，用于累计当前单词出现的次数\n        int sum = 0;\n        for (IntWritable count : values) {\n            //从count中获得值，累加到sum中\n            sum += count.get();\n        }\n        //将单词、单词次数，分别作为键值对，输出\n        context.write(key, new IntWritable(sum));// 输出最终结果\n    };\n}\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br"),e("span",{staticClass:"line-number"},[a._v("17")]),e("br"),e("span",{staticClass:"line-number"},[a._v("18")]),e("br"),e("span",{staticClass:"line-number"},[a._v("19")]),e("br"),e("span",{staticClass:"line-number"},[a._v("20")]),e("br")])]),e("p",[e("strong",[a._v("2.4.3 Main程序入口")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("Job job = Job.getInstance(configuration, WordCountMain.class.getSimpleName());\n//设置job的jar包，如果参数指定的类包含在一个jar包中，则此jar包作为job的jar包； 参数class跟主类在一个工程即可；一般设置成主类\njob.setJarByClass(WordCountMain.class);\n\n//通过job设置输入/输出格式\n//MR的默认输入格式是TextInputFormat，输出格式是TextOutputFormat；所以下两行可以注释掉\n//        job.setInputFormatClass(TextInputFormat.class);\n//        job.setOutputFormatClass(TextOutputFormat.class);\n\n//设置输入/输出路径\nFileInputFormat.setInputPaths(job, new Path(args[0]));\nFileOutputFormat.setOutputPath(job, new Path(args[1]));\n\n//设置处理Map阶段的自定义的类\njob.setMapperClass(WordCountMap.class);\n//设置map combine类，减少网路传出量\njob.setCombinerClass(WordCountReduce.class);\n//设置处理Reduce阶段的自定义的类\njob.setReducerClass(WordCountReduce.class);\n\n//注意：如果map、reduce的输出的kv对类型一致，直接设置reduce的输出的kv对就行；如果不一样，需要分别设置map, reduce的输出的kv类型\n//注意：此处设置的map输出的key/value类型，一定要与自定义map类输出的kv对类型一致；否则程序运行报错\n// job.setMapOutputKeyClass(Text.class);\n// job.setMapOutputValueClass(IntWritable.class);\n\n//设置reduce task最终输出key/value的类型\n//注意：此处设置的reduce输出的key/value类型，一定要与自定义reduce类输出的kv对类型一致；否则程序运行报错\njob.setOutputKeyClass(Text.class);\njob.setOutputValueClass(IntWritable.class);\n\n// 提交作业\njob.waitForCompletion(true);\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br"),e("span",{staticClass:"line-number"},[a._v("17")]),e("br"),e("span",{staticClass:"line-number"},[a._v("18")]),e("br"),e("span",{staticClass:"line-number"},[a._v("19")]),e("br"),e("span",{staticClass:"line-number"},[a._v("20")]),e("br"),e("span",{staticClass:"line-number"},[a._v("21")]),e("br"),e("span",{staticClass:"line-number"},[a._v("22")]),e("br"),e("span",{staticClass:"line-number"},[a._v("23")]),e("br"),e("span",{staticClass:"line-number"},[a._v("24")]),e("br"),e("span",{staticClass:"line-number"},[a._v("25")]),e("br"),e("span",{staticClass:"line-number"},[a._v("26")]),e("br"),e("span",{staticClass:"line-number"},[a._v("27")]),e("br"),e("span",{staticClass:"line-number"},[a._v("28")]),e("br"),e("span",{staticClass:"line-number"},[a._v("29")]),e("br"),e("span",{staticClass:"line-number"},[a._v("30")]),e("br"),e("span",{staticClass:"line-number"},[a._v("31")]),e("br"),e("span",{staticClass:"line-number"},[a._v("32")]),e("br")])]),e("h3",{attrs:{id:"运行-查看"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#运行-查看"}},[a._v("#")]),a._v(" 运行 / 查看")]),a._v(" "),e("div",{staticClass:"language-shell line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 查看运行情况 -> job： http://node01:8088")]),a._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# outpath -> http://node01:50070")]),a._v("\nhadoop jar "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("jar path"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("main class path"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" /inpath /outpath\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br")])]),e("h2",{attrs:{id:"shuffle"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#shuffle"}},[a._v("#")]),a._v(" Shuffle")]),a._v(" "),e("p",[e("img",{attrs:{src:"http://kflys.gitee.io/upic/2020/03/29/uPic/hadoop/mapreduce/assets/Image201906280906.png#height=631&id=tRa96&originHeight=631&originWidth=1427&originalType=binary&ratio=1&status=done&style=none&width=1427",alt:""}})]),a._v(" "),e("h3",{attrs:{id:"map端"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#map端"}},[a._v("#")]),a._v(" map端")]),a._v(" "),e("ul",[e("li",[a._v("每个map任务都有一个对应的环形内存缓冲区；输出是kv对，先写入到环形缓冲区（默认大小100M），当内容占据80%缓冲区空间后，由一个后台线程将缓冲区中的数据溢出写到一个磁盘文件")]),a._v(" "),e("li",[a._v("在溢出写的过程中，map任务可以继续向环形缓冲区写入数据；但是若写入速度大于溢出写的速度，最终造成100m占满后，map任务会暂停向环形缓冲区中写数据的过程；只执行溢出写的过程；直到环形缓冲区的数据全部溢出写到磁盘，才恢复向缓冲区写入")]),a._v(" "),e("li",[a._v("后台线程溢写磁盘过程，有以下几个步骤：\n"),e("ul",[e("li",[a._v("先对每个溢写的kv对做分区；分区的个数由MR程序的reduce任务数决定；默认使用HashPartitioner计算当前kv对属于哪个分区；计算公式：(key.hashCode() & Integer.MAX_VALUE) % numReduceTasks")]),a._v(" "),e("li",[a._v("每个分区中，根据kv对的key做内存中排序；")]),a._v(" "),e("li",[a._v("若设置了map端本地聚合combiner，则对每个分区中，排好序的数据做combine操作；")]),a._v(" "),e("li",[a._v("若设置了对map输出压缩的功能，会对溢写数据压缩")])])]),a._v(" "),e("li",[a._v("随着不断的向环形缓冲区中写入数据，会多次触发溢写（每当环形缓冲区写满100m），本地磁盘最终会生成多个溢出文件")]),a._v(" "),e("li",[a._v("合并溢写文件：在map task完成之前，所有溢出文件会被合并成一个大的溢出文件；且是已分区、已排序的输出文件")]),a._v(" "),e("li",[a._v("小细节：\n"),e("ul",[e("li",[a._v("在合并溢写文件时，如果至少有3个溢写文件，并且设置了map端combine的话，会在合并的过程中触发combine操作；")]),a._v(" "),e("li",[a._v("但是若只有2个或1个溢写文件，则不触发combine操作（因为combine操作，本质上是一个reduce，需要启动JVM虚拟机，有一定的开销）")])])])]),a._v(" "),e("h3",{attrs:{id:"reduce端"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#reduce端"}},[a._v("#")]),a._v(" reduce端")]),a._v(" "),e("ul",[e("li",[a._v("reduce task会在每个map task运行完成后，通过HTTP获得map task输出中，属于自己的分区数据（许多kv对）")]),a._v(" "),e("li",[a._v("如果map输出数据比较小，先保存在reduce的jvm内存中，否则直接写入reduce磁盘")]),a._v(" "),e("li",[a._v("一旦内存缓冲区达到阈值（默认0.66）或map输出数的阈值（默认1000），则触发"),e("strong",[a._v("归并merge")]),a._v("，结果写到本地磁盘")]),a._v(" "),e("li",[a._v("若MR编程指定了combine，在归并过程中会执行combine操作")]),a._v(" "),e("li",[a._v("随着溢出写的文件的增多，后台线程会将它们合并大的、排好序的文件")]),a._v(" "),e("li",[a._v("reduce task将所有map task复制完后，将合并磁盘上所有的溢出文件")]),a._v(" "),e("li",[a._v("默认一次合并10个")]),a._v(" "),e("li",[a._v("最后一批合并，部分数据来自内存，部分来自磁盘上的文件")]),a._v(" "),e("li",[a._v("进入“归并、排序、分组阶段”")]),a._v(" "),e("li",[a._v("每组数据调用一次reduce方法")])]),a._v(" "),e("h2",{attrs:{id:"自定义partitioner"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#自定义partitioner"}},[a._v("#")]),a._v(" 自定义Partitioner")]),a._v(" "),e("ul",[e("li",[a._v("HashPartitioner")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("public class HashPartitioner<K2, V2> implements Partitioner<K2, V2> {\n  public int getPartition(K2 key, V2 value, int numReduceTasks) {\n    // numReduceTasks : reduce个数，可设置\n    return (key.hashCode() & Integer.MAX_VALUE) % numReduceTasks;\n  }\n}\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br")])]),e("h2",{attrs:{id:"自定义combiner"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#自定义combiner"}},[a._v("#")]),a._v(" 自定义Combiner")]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("// 实际上Combiner就是reduce操作，需要设置 \njob.setReducerClass(CustomReduce.class);\njob.setCombinerClass(CustomReduce.class);  // open combiner\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br")])]),e("ul",[e("li",[a._v("map端combine本地聚合（"),e("strong",[a._v("本质是reduce")]),a._v("）")]),a._v(" "),e("li",[a._v("不论运行多少次Combine操作，都不能影响最终的结果")]),a._v(" "),e("li",[a._v("并非所有的mr都适合combine操作，比如求平均值")])]),a._v(" "),e("p",[e("img",{attrs:{src:"http://kflys.gitee.io/upic/2020/03/29/uPic/hadoop/mapreduce/assets/Image201909091014.png#height=551&id=D2Dxq&originHeight=551&originWidth=1357&originalType=binary&ratio=1&status=done&style=none&width=1357",alt:""}})]),a._v(" "),e("ul",[e("li",[a._v("当每个map任务的环形缓冲区添满80%，开始溢写磁盘文件")]),a._v(" "),e("li",[a._v("此过程会分区、每个分区内按键排序、再combine操作（若设置了combine的话）、若设置map输出压缩的话则再压缩\n"),e("ul",[e("li",[a._v("在合并溢写文件时，如果至少有3个溢写文件，并且设置了map端combine的话，会在合并的过程中触发combine操作；")]),a._v(" "),e("li",[a._v("但是若只有2个或1个溢写文件，则不触发combine操作（因为combine操作，本质上是一个reduce，需要启动JVM虚拟机，有一定的开销）")])])]),a._v(" "),e("li",[a._v("combine本质上也是reduce；因为自定义的combine类继承自Reducer父类")]),a._v(" "),e("li",[a._v("map: (K1, V1) -> list(K2, V2)")]),a._v(" "),e("li",[a._v("combiner: (K2, list(V2)) -> (K2, V2)")]),a._v(" "),e("li",[a._v("reduce: (K2, list(V2)) -> (K3, V3)\n"),e("ul",[e("li",[a._v("reduce函数与combine函数通常是一样的")]),a._v(" "),e("li",[a._v("K3与K2类型相同；")]),a._v(" "),e("li",[a._v("V3与V2类型相同")]),a._v(" "),e("li",[a._v("即reduce的输入的kv类型分别与输出的kv类型相同")])])])]),a._v(" "),e("h2",{attrs:{id:"mr设置压缩"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mr设置压缩"}},[a._v("#")]),a._v(" mr设置压缩")]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v('//开启map输出进行压缩的功能\nconfiguration.set("mapreduce.map.output.compress", "true");\n//设置map输出的压缩算法是：BZip2Codec，它是hadoop默认支持的压缩算法，且支持切分\nconfiguration.set("mapreduce.map.output.compress.codec", "org.apache.hadoop.io.compress.BZip2Codec");\n//开启job输出压缩功能\nconfiguration.set("mapreduce.output.fileoutputformat.compress", "true");\n//指定job输出使用的压缩算法\nconfiguration.set("mapreduce.output.fileoutputformat.compress.codec", "org.apache.hadoop.io.compress.BZip2Codec");\n')])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br")])]),e("h2",{attrs:{id:"自定义inputformat"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#自定义inputformat"}},[a._v("#")]),a._v(" 自定义InputFormat")]),a._v(" "),e("h3",{attrs:{id:"mapreduce执行过程"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce执行过程"}},[a._v("#")]),a._v(" MapReduce执行过程")]),a._v(" "),e("p",[e("img",{attrs:{src:"http://kflys.gitee.io/upic/2020/03/29/uPic/hadoop/mapreduce/assets/Image201905211621.png#height=770&id=XVFXm&originHeight=770&originWidth=890&originalType=binary&ratio=1&status=done&style=none&width=890",alt:""}})]),a._v(" "),e("ul",[e("li",[a._v("上图也描述了mapreduce的一个完整的过程；我们主要看map任务是如何从hdfs读取分片数据的部分\n"),e("ul",[e("li",[a._v("涉及3个关键的类")]),a._v(" "),e("li",[a._v("①InputFormat输入格式类\n②InputSplit输入分片类：getSplits()\n"),e("ul",[e("li",[a._v("InputFormat输入格式类将输入文件分成一个个分片InputSplit")]),a._v(" "),e("li",[a._v("每个Map任务对应一个split分片")])])])])])]),a._v(" "),e("p",[a._v("③RecordReader记录读取器类：createRecordReader()")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("  - RecordReader（记录读取器）读取分片数据，一行记录生成一个键值对\n  - 传入map任务的map()方法，调用map()\n")])])]),e("ul",[e("li",[a._v("详细流程：\n"),e("ul",[e("li",[a._v("客户端调用InputFormat的**getSplits()**方法，获得输入文件的分片信息")])])])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("public abstract class InputFormat<K, V> {\n    public abstract List<InputSplit> getSplits(JobContext var1);\n}\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br")])]),e("ul",[e("li",[a._v("针对每个MR job会生成一个相应的app master，负责map 、 reduce任务的调度及监控执行情况")]),a._v(" "),e("li",[a._v("将分片信息传递给MR job的app master")]),a._v(" "),e("li",[a._v("app master根据分片信息，尽量将map任务尽量调度在split分片数据所在节点（"),e("strong",[a._v("移动计算不移动数据")]),a._v("）")])]),a._v(" "),e("div",{staticClass:"language-java line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-java"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("public")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("abstract")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("InputSplit")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n    "),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("public")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("abstract")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("String")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[a._v("getLocations")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br")])]),e("ul",[e("li",[a._v("有几个分片，就生成几个map任务")]),a._v(" "),e("li",[a._v("每个map任务将split分片传递给createRecordReader()方法，生成此分片对应的RecordReader")]),a._v(" "),e("li",[a._v("RecordReader用来读取分片的数据，生成记录的键值对\n"),e("ul",[e("li",[a._v("nextKeyValue()判断是否有下一个键值对，如果有，返回true；否则，返回false")]),a._v(" "),e("li",[a._v("如果返回true，调用getCurrentKey()获得当前的键")]),a._v(" "),e("li",[a._v("调用getCurrentValue()获得当前的值")])])]),a._v(" "),e("li",[a._v("map任务运行过程")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("// mapper\npublic class Mapper<KEYIN, VALUEIN, KEYOUT, VALUEOUT> {\n  \t// 1. map任务运行时，会调用run()\n    public void run(Mapper<KEYIN, VALUEIN, KEYOUT, VALUEOUT>.Context context) throws IOException, InterruptedException {\n      // 2. 首先运行一次setup()方法；只在map任务启动时，运行一次；一些初始化的工作可以在setup方法中完成；如要连接数据库之类的操作\n        this.setup(context);\n      // 3. while循环，调用context.nextKeyValue()；会委托给RecordRecord的nextKeyValue()，判断是否有下一个键值对\n      // 当读取分片尾，context.nextKeyValue()返回false；退出循环\n        while(context.nextKeyValue()) {\n          \t//4.  如果有下一个键值对，调用context.getCurrentKey()、context.getCurrentValue()获得当前的键、值的值（也是调用RecordReader的同名方法[见5]）\n            this.map(context.getCurrentKey(), context.getCurrentValue(), context);\n        }\n      \t//6. 调用cleanup()方法，只在map任务结束之前，调用一次；所以，一些回收资源的工作可在此方法中实现，如关闭数据库连接\n        this.cleanup(context);\n    }\n  // 5. - 作为参数传入map(key, value, context)，调用一次map()\n  protected void map(KEYIN key, VALUEIN value, Mapper.Context context){\n        context.write(key, value);\n    }\n}\n\n// recordReader\npublic abstract class RecordReader<KEYIN, VALUEIN> implements Closeable {\n    public abstract void initialize(InputSplit var1, TaskAttemptContext var2);\n    public abstract boolean nextKeyValue();\n    public abstract KEYIN getCurrentKey();\n    public abstract VALUEIN getCurrentValue();\n    public abstract float getProgress();\n    public abstract void close();\n}\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br"),e("span",{staticClass:"line-number"},[a._v("17")]),e("br"),e("span",{staticClass:"line-number"},[a._v("18")]),e("br"),e("span",{staticClass:"line-number"},[a._v("19")]),e("br"),e("span",{staticClass:"line-number"},[a._v("20")]),e("br"),e("span",{staticClass:"line-number"},[a._v("21")]),e("br"),e("span",{staticClass:"line-number"},[a._v("22")]),e("br"),e("span",{staticClass:"line-number"},[a._v("23")]),e("br"),e("span",{staticClass:"line-number"},[a._v("24")]),e("br"),e("span",{staticClass:"line-number"},[a._v("25")]),e("br"),e("span",{staticClass:"line-number"},[a._v("26")]),e("br"),e("span",{staticClass:"line-number"},[a._v("27")]),e("br"),e("span",{staticClass:"line-number"},[a._v("28")]),e("br"),e("span",{staticClass:"line-number"},[a._v("29")]),e("br"),e("span",{staticClass:"line-number"},[a._v("30")]),e("br")])]),e("h3",{attrs:{id:"示例代码"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#示例代码"}},[a._v("#")]),a._v(" 示例代码")]),a._v(" "),e("ul",[e("li",[a._v("小文件的优化无非以下几种方式：\n"),e("ul",[e("li",[a._v("在数据采集的时候，就将小文件或小批数据合成大文件再上传HDFS(SequenceFile方案)")]),a._v(" "),e("li",[a._v("在业务处理之前，在HDFS上使用mapreduce程序对小文件进行合并；可使用"),e("strong",[a._v("自定义InputFormat")]),a._v("实现")]),a._v(" "),e("li",[a._v("在mapreduce处理时，可采用"),e("strong",[a._v("CombineFileInputFormat")]),a._v("提高效率")])])]),a._v(" "),e("li",[a._v("自定义InputFormat")])]),a._v(" "),e("div",{staticClass:"language-java line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-java"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[a._v("/**\n * 自定义InputFormat类；\n * 泛型：\n *  键：因为不需要使用键，所以设置为NullWritable\n *  值：值用于保存小文件的内容，此处使用BytesWritable\n */")]),a._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("public")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("WholeFileInputFormat")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("extends")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("FileInputFormat")]),e("span",{pre:!0,attrs:{class:"token generics"}},[e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("NullWritable")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("BytesWritable")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n  \t "),e("span",{pre:!0,attrs:{class:"token comment"}},[a._v("// 返回false，表示输入文件不可切割")]),a._v("\n    "),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("protected")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("boolean")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[a._v("isSplitable")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("JobContext")]),a._v(" context"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Path")]),a._v(" file"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n        "),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("return")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("false")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n    "),e("span",{pre:!0,attrs:{class:"token comment"}},[a._v("// 生成读取分片split的RecordReader")]),a._v("\n    "),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("public")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("RecordReader")]),e("span",{pre:!0,attrs:{class:"token generics"}},[e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("NullWritable")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("BytesWritable")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[a._v("createRecordReader")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("InputSplit")]),a._v(" split"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("TaskAttemptContext")]),a._v(" context"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("throws")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("IOException")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("InterruptedException")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n        "),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("WholeFileRecordReader")]),a._v(" reader "),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("new")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("WholeFileRecordReader")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n      \t"),e("span",{pre:!0,attrs:{class:"token comment"}},[a._v("// split传如WholeFileRecordReader进行读取，组装value")]),a._v("\n        reader"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),e("span",{pre:!0,attrs:{class:"token function"}},[a._v("initialize")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("split"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" context"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br"),e("span",{staticClass:"line-number"},[a._v("17")]),e("br"),e("span",{staticClass:"line-number"},[a._v("18")]),e("br")])]),e("ul",[e("li",[a._v("自定义RecordReader")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("public class WholeFileRecordReader extends RecordReader<NullWritable, BytesWritable> {\n    private BytesWritable value = new BytesWritable();\n    @Override\n    public boolean nextKeyValue(){\n       value.set(splitBytes, 0, splitBytes.length);\n    }\n}\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br")])]),e("h2",{attrs:{id:"自定义outputformat"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#自定义outputformat"}},[a._v("#")]),a._v(" 自定义OutputFormat")]),a._v(" "),e("ul",[e("li",[a._v("输出结果到不同"),e("strong",[a._v("目录")])])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("public class MyOutPutFormat extends FileOutputFormat<Text, NullWritable> {\n    public RecordWriter getRecordWriter(TaskAttemptContext context){\n        // 两个输出文件路径\n        FSDataOutputStream badOut = fs.create(badPath);\n        FSDataOutputStream goodOut = fs.create(goodPath);\n        return new MyRecordWriter(badOut,goodOut);\n    }\n    static class MyRecordWriter extends RecordWriter<Text, NullWritable>{\n        public void write(Text key, NullWritable value){\n            if\n             \tgoodOut.write();\n            else\n              badOut.write();\n        }\n    }\n}\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br")])]),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("// 设置自定义的输出类\njob.setOutputFormatClass(MyOutPutFormat.class);\n// 设置一个输出目录，这个目录会输出一个success的成功标志的文件\nMyOutPutFormat.setOutputPath(job, new Path(args[1]));\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br")])]),e("h3",{attrs:{id:"二次排序"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#二次排序"}},[a._v("#")]),a._v(" 二次排序")]),a._v(" "),e("ul",[e("li",[a._v("hadoop自带的key类型无法满足需求，自定义key\n"),e("ul",[e("li",[a._v("实现WritableComparable接口")]),a._v(" "),e("li",[a._v("实现compareTo比较方法")]),a._v(" "),e("li",[a._v("实现write序列化方法")]),a._v(" "),e("li",[a._v("实现readFields反序列化方法")])])]),a._v(" "),e("li",[a._v("示例代码")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("//根据输入文件格式，定义JavaBean，作为MR时，Map的输出key类型；要求此类可序列化、可比较\npublic class Person implements WritableComparable<Person> {\n    private String name;\n    private int age;\n    private int salary;\n\n    public Person() {}\n\n    //两个Person对象的比较规则：①先比较salary，高的排序在前；②若相同，age小的在前\n    public int compareTo(Person other) {}\n\n    //序列化，将NewKey转化成使用流传送的二进制\n    public void write(DataOutput dataOutput) throws IOException {}\n\n    //使用in读字段的顺序，要与write方法中写的顺序保持一致：name、age、salary\n    public void readFields(DataInput dataInput) throws IOException {}\n}\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br"),e("span",{staticClass:"line-number"},[a._v("17")]),e("br")])]),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("job.setOutputKeyClass(Person.class);\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br")])]),e("h2",{attrs:{id:"知识点小例子"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#知识点小例子"}},[a._v("#")]),a._v(" 知识点小例子")]),a._v(" "),e("ul",[e("li",[a._v("现有一个淘宝用户订单历史记录文件；每条记录有6个字段，分别表示\n"),e("ul",[e("li",[a._v("userid、datetime、title商品标题、unitPrice商品单价、purchaseNum购买量、productId商品ID")])])]),a._v(" "),e("li",[a._v("现使用MR编程，求出每个用户、每个月消费金额最多的两笔订单，花了多少钱\n"),e("ul",[e("li",[a._v("所以得相同用户、同一个年月的数据，分到同一组")])])])]),a._v(" "),e("h3",{attrs:{id:"逻辑分析"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#逻辑分析"}},[a._v("#")]),a._v(" 逻辑分析")]),a._v(" "),e("ul",[e("li",[a._v("根据文件格式，自定义JavaBean类OrderBean\n"),e("ul",[e("li",[a._v("实现WritableComparable接口")]),a._v(" "),e("li",[a._v("包含6个字段分别对应文件中的6个字段")]),a._v(" "),e("li",[a._v("重点实现compareTo方法\n"),e("ul",[e("li",[a._v("先比较userid是否相等；若不相等，则userid升序排序")]),a._v(" "),e("li",[a._v("若相等，比较两个Bean的日期是否相等；若不相等，则日期升序排序")]),a._v(" "),e("li",[a._v("若相等，再比较总开销，降序排序")])])]),a._v(" "),e("li",[a._v("实现序列化方法write()")]),a._v(" "),e("li",[a._v("实现反序列化方法readFields()")])])]),a._v(" "),e("li",[a._v("自定义分区类\n"),e("ul",[e("li",[a._v("继承Partitioner类")]),a._v(" "),e("li",[a._v("getPartiton()实现，userid相同的，处于同一个分区")])])]),a._v(" "),e("li",[a._v("自定义Mapper类\n"),e("ul",[e("li",[a._v("输出key是当前记录对应的Bean对象")]),a._v(" "),e("li",[a._v("输出的value对应当前下单的总开销")])])]),a._v(" "),e("li",[a._v("自定义分组类\n"),e("ul",[e("li",[a._v("决定userid相同、日期（年月）相同的记录，分到同一组中，调用一次reduce()")])])]),a._v(" "),e("li",[a._v("自定义Reduce类\n"),e("ul",[e("li",[a._v("reduce()中求出当前一组数据中，开销头两笔的信息")])])]),a._v(" "),e("li",[a._v("main方法\n"),e("ul",[e("li",[a._v("job.setMapperClass")]),a._v(" "),e("li",[a._v("job.setPartitionerClass")]),a._v(" "),e("li",[a._v("job.setReducerClass")]),a._v(" "),e("li",[a._v("job.setGroupingComparatorClass")])])])]),a._v(" "),e("h3",{attrs:{id:"示例代码-2"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#示例代码-2"}},[a._v("#")]),a._v(" 示例代码")]),a._v(" "),e("ul",[e("li",[a._v("OrderBean")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("public class OrderBean implements WritableComparable<OrderBean> {\n\n    //用户ID 等字段\n    private String userid;\n    public OrderBean() {}\n   \n    //key的比较规则\n    public int compareTo(OrderBean other) {}\n    // 序列化\n    public void write(DataOutput dataOutput) throws IOException {}\n\t\t// 反序列化\n    public void readFields(DataInput dataInput) throws IOException { }\n\n    /**\n     * 使用默认分区器，那么userid相同的，落入同一分区；\n     * 另外一个方案：此处不覆写hashCode方法，而是自定义分区器，getPartition方法中，对OrderBean的userid求hashCode值%reduce任务数\n     */\n//    public int hashCode() {\n//        return this.userid.hashCode();\n//    }\n}\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br"),e("span",{staticClass:"line-number"},[a._v("17")]),e("br"),e("span",{staticClass:"line-number"},[a._v("18")]),e("br"),e("span",{staticClass:"line-number"},[a._v("19")]),e("br"),e("span",{staticClass:"line-number"},[a._v("20")]),e("br"),e("span",{staticClass:"line-number"},[a._v("21")]),e("br")])]),e("ul",[e("li",[a._v("MyPartitioner")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("//mapper的输出key类型是自定义的key类型OrderBean；输出value类型是单笔订单的总开销double -> DoubleWritable\npublic class MyPartitioner extends Partitioner<OrderBean, DoubleWritable> {\n    @Override\n    public int getPartition{\n        //userid相同的，落入同一分区\n        return (orderBean.getUserid().hashCode() & Integer.MAX_VALUE) % numReduceTasks;\n    }\n}\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br")])]),e("ul",[e("li",[a._v("MyMapper")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("public class MyMapper extends Mapper<LongWritable, Text, OrderBean, DoubleWritable> {\n    protected void map(LongWritable key, Text value, Context context){\n            // 生成OrderBean对象\n            OrderBean orderBean = getOrderBean();\n            context.write(orderBean, valueOut);\n        }\n    }\n}\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br")])]),e("ul",[e("li",[a._v("MyReducer")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v('public class MyReducer extends Reducer<OrderBean, DoubleWritable, Text, DoubleWritable> {\n    /**\n     * ①由于自定义分组逻辑，相同用户、相同年月的订单是一组，调用一次reduce()；\n     * ②由于自定义的key类OrderBean中，比较规则compareTo规定，相同用户、相同年月的订单，按总金额降序排序\n     * 所以取出头两笔，就实现需求\n     */\n    @Override\n    protected void reduce(OrderBean key, Iterable<DoubleWritable> values, Context context) throws IOException, InterruptedException {\n        //求每个用户、每个月、消费金额最多的两笔多少钱\n        int num = 0;\n        for(DoubleWritable value: values) {\n            if(num < 2) {\n                String keyOut = key.getUserid() + "  " + key.getDatetime();\n                context.write(new Text(keyOut), value);\n                num++;\n            } else {\n                break;\n            }\n        }\n\n    }\n}\n')])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br"),e("span",{staticClass:"line-number"},[a._v("17")]),e("br"),e("span",{staticClass:"line-number"},[a._v("18")]),e("br"),e("span",{staticClass:"line-number"},[a._v("19")]),e("br"),e("span",{staticClass:"line-number"},[a._v("20")]),e("br"),e("span",{staticClass:"line-number"},[a._v("21")]),e("br"),e("span",{staticClass:"line-number"},[a._v("22")]),e("br")])]),e("ul",[e("li",[a._v("MyGroup")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("//自定义分组类：reduce端调用reduce()前，对数据做分组；每组数据调用一次reduce()\npublic class MyGroup extends WritableComparator {\n  \t// 注意： 分组实现的方法是这个\n    public int compare(WritableComparable a, WritableComparable b) {\n        //userid、年、月相同的，作为一组\n        int ret1 = aUserId.compareTo(bUserId);\n        if(ret1 == 0) {//同一用户\n            //年月也相同返回0，在同一组；\n            return aOrderBean.getDatetime().compareTo(bOrderBean.getDatetime());\n        } else {\n            return ret1;\n        }\n    }\n}\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br")])]),e("ul",[e("li",[a._v("CustomGroupingMain")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("//设置处理Map阶段的自定义的类\njob.setMapperClass(MyMapper.class);\n//设置map combine类，减少网路传出量\n//job.setCombinerClass(MyReducer.class);\njob.setPartitionerClass(MyPartitioner.class);\n//设置处理Reduce阶段的自定义的类\njob.setReducerClass(MyReducer.class);\njob.setGroupingComparatorClass(MyGroup.class);\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br")])]),e("h2",{attrs:{id:"mapreduce数据倾斜"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce数据倾斜"}},[a._v("#")]),a._v(" MapReduce数据倾斜")]),a._v(" "),e("ul",[e("li",[a._v("什么是数据倾斜？\n"),e("ul",[e("li",[a._v("数据中不可避免地会出现离群值（outlier），并导致数据倾斜。这些离群值会显著地拖慢MapReduce的执行。")])])]),a._v(" "),e("li",[a._v("常见的数据倾斜有以下几类：\n"),e("ul",[e("li",[a._v("数据频率倾斜——某一个区域的数据量要远远大于其他区域。比如某一个key对应的键值对远远大于其他键的键值对。")]),a._v(" "),e("li",[a._v("数据大小倾斜——部分记录的大小远远大于平均值。")])])]),a._v(" "),e("li",[a._v("在map端和reduce端都有可能发生数据倾斜\n"),e("ul",[e("li",[a._v("在map端的数据倾斜可以考虑使用combine")]),a._v(" "),e("li",[a._v("在reduce端的数据倾斜常常来源于MapReduce的默认分区器")])])]),a._v(" "),e("li",[a._v("数据倾斜会导致map和reduce的任务执行时间大为延长，也会让需要缓存数据集的操作消耗更多的内存资源")])]),a._v(" "),e("h3",{attrs:{id:"诊断是否存在数据倾斜"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#诊断是否存在数据倾斜"}},[a._v("#")]),a._v(" 诊断是否存在数据倾斜")]),a._v(" "),e("ul",[e("li",[a._v("发现倾斜数据之后，有必要诊断造成数据倾斜的那些键。有一个简便方法就是在代码里实现追踪每个键的"),e("strong",[a._v("最大值")]),a._v("。")]),a._v(" "),e("li",[a._v("为了减少追踪量，可以设置数据量阀值，只追踪那些数据量大于阀值的键，并输出到日志中。实现代码如下")]),a._v(" "),e("li",[a._v("运行作业后就可以从日志中判断发生倾斜的键以及倾斜程度；跟踪倾斜数据是了解数据的重要一步，也是设计MapReduce作业的重要基础")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v('public class WordCountReduce extends Reducer<Text, IntWritable, Text, IntWritable> {\n   \n  private int maxValueThreshold;\n\n  @Override\n  protected void setup(Context context) throws IOException, InterruptedException {\n\n    //一个键达到多少后，会做数据倾斜记录\n    maxValueThreshold = 10000;\n  }\n\n  public void reduce(Text key, Iterable<IntWritable> values,\n                     Context context) throws IOException, InterruptedException {\n    int sum = 0;\n    //用于记录键出现的次数\n    int i = 0;\n\n    for (IntWritable count : values) {\n      sum += count.get();\n      i++;\n    }\n\n    //如果当前键超过10000个，则打印日志\n    if(i > maxValueThreshold) {\n      LOGGER.info("Received " + i + " values for key " + key);\n    }\n\n    context.write(key, new IntWritable(sum));// 输出最终结果\n  };\n}\n')])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br"),e("span",{staticClass:"line-number"},[a._v("17")]),e("br"),e("span",{staticClass:"line-number"},[a._v("18")]),e("br"),e("span",{staticClass:"line-number"},[a._v("19")]),e("br"),e("span",{staticClass:"line-number"},[a._v("20")]),e("br"),e("span",{staticClass:"line-number"},[a._v("21")]),e("br"),e("span",{staticClass:"line-number"},[a._v("22")]),e("br"),e("span",{staticClass:"line-number"},[a._v("23")]),e("br"),e("span",{staticClass:"line-number"},[a._v("24")]),e("br"),e("span",{staticClass:"line-number"},[a._v("25")]),e("br"),e("span",{staticClass:"line-number"},[a._v("26")]),e("br"),e("span",{staticClass:"line-number"},[a._v("27")]),e("br"),e("span",{staticClass:"line-number"},[a._v("28")]),e("br"),e("span",{staticClass:"line-number"},[a._v("29")]),e("br"),e("span",{staticClass:"line-number"},[a._v("30")]),e("br")])]),e("h3",{attrs:{id:"减缓数据倾斜"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#减缓数据倾斜"}},[a._v("#")]),a._v(" 减缓数据倾斜")]),a._v(" "),e("ul",[e("li",[a._v("Reduce数据倾斜一般是指map的输出数据中存在数据频率倾斜的状况，即部分输出键的数据量远远大于其它的输出键")]),a._v(" "),e("li",[a._v("如何减小reduce端数据倾斜的性能损失？常用方式有：\n"),e("ul",[e("li",[a._v("自定义分区\n"),e("ul",[e("li",[a._v("基于输出键的背景知识进行自定义分区。")]),a._v(" "),e("li",[a._v("例如，如果map输出键的单词来源于一本书。其中大部分必然是省略词（stopword）。那么就可以将自定义分区将这部分省略词发送给固定的一部分reduce实例。而将其他的都发送给剩余的reduce实例。")])])]),a._v(" "),e("li",[a._v("Combine\n"),e("ul",[e("li",[a._v("使用Combine可以大量地减小数据频率倾斜和数据大小倾斜。")]),a._v(" "),e("li",[a._v("combine的目的就是聚合并精简数据。")])])]),a._v(" "),e("li",[a._v("抽样和范围分区\n"),e("ul",[e("li",[a._v("Hadoop默认的分区器是HashPartitioner，基于map输出键的哈希值分区。这仅在数据分布比较均匀时比较好。"),e("strong",[a._v("在有数据倾斜时就很有问题")]),a._v("。")]),a._v(" "),e("li",[a._v("使用分区器需要首先了解数据的特性。"),e("strong",[a._v("TotalOrderPartitioner")]),a._v("中，可以通过对原始数据进行抽样得到的结果集来"),e("strong",[a._v("预设分区边界值")]),a._v("。")]),a._v(" "),e("li",[a._v("TotalOrderPartitioner中的范围分区器可以通过预设的分区边界值进行分区。因此它也可以很好地用在矫正数据中的部分键的数据倾斜问题。")])])]),a._v(" "),e("li",[a._v("数据大小倾斜的自定义策略\n"),e("ul",[e("li",[a._v("在map端或reduce端的数据大小倾斜都会对缓存造成较大的影响，乃至导致OutOfMemoryError异常。处理这种情况并不容易。可以参考以下方法。")]),a._v(" "),e("li",[a._v("设置mapreduce.input.linerecordreader.line.maxlength来限制RecordReader读取的最大长度。")]),a._v(" "),e("li",[a._v("RecordReader在TextInputFormat和KeyValueTextInputFormat类中使用。默认长度没有上限。")])])])])])]),a._v(" "),e("h2",{attrs:{id:"抽样分区案例"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#抽样分区案例"}},[a._v("#")]),a._v(" 抽样分区案例")]),a._v(" "),e("blockquote",[e("p",[a._v("使用全排序分区器TotalOrderPartitioner")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("//分区器：全局排序分区器\njob.setPartitionerClass(TotalOrderPartitioner.class);\n\n/**\n     * 随机采样器从所有的分片中采样\n     * 每一个参数：采样率；\n     * 第二个参数：总的采样数\n     * 第三个参数：采样的最大分区数；\n     * 只要numSamples和maxSplitSampled（第二、第三参数）任一条件满足，则停止采样\n     */\nInputSampler.Sampler<IntWritable, Text> sampler =\n  new InputSampler.RandomSampler<IntWritable, Text>(0.1, 5000, 10);\n//    TotalOrderPartitioner.setPartitionFile();\n/**\n     * 存储定义分区的键；即整个数据集中温度的大致分布情况；\n     * 由TotalOrderPartitioner读取，作为全排序的分区依据，让每个分区中的数据量近似\n     */\nInputSampler.writePartitionFile(job, sampler);\n\n// 根据上边的SequenceFile文件（包含键的近似分布情况），创建分区\nString partitionFile = TotalOrderPartitioner.getPartitionFile(job.getConfiguration());\nURI partitionUri = new URI(partitionFile);\n\n//与所有map任务共享此文件，添加到分布式缓存中\nDistributedCache.addCacheFile(partitionUri, job.getConfiguration());\n// job.addCacheFile(partitionUri);\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br"),e("span",{staticClass:"line-number"},[a._v("17")]),e("br"),e("span",{staticClass:"line-number"},[a._v("18")]),e("br"),e("span",{staticClass:"line-number"},[a._v("19")]),e("br"),e("span",{staticClass:"line-number"},[a._v("20")]),e("br"),e("span",{staticClass:"line-number"},[a._v("21")]),e("br"),e("span",{staticClass:"line-number"},[a._v("22")]),e("br"),e("span",{staticClass:"line-number"},[a._v("23")]),e("br"),e("span",{staticClass:"line-number"},[a._v("24")]),e("br"),e("span",{staticClass:"line-number"},[a._v("25")]),e("br"),e("span",{staticClass:"line-number"},[a._v("26")]),e("br")])]),e("p",[e("a",{attrs:{href:"https://github.com/orchid-ding/myself-learning/tree/master/hadoop/hadoop/src/main/java/bigdata/hadoop/mapreduces",target:"_blank",rel:"noopener noreferrer"}},[a._v("示例代码"),e("OutboundLink")],1)])])}),[],!1,null,null,null);s.default=n.exports}}]);