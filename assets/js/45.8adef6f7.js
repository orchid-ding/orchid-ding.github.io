(window.webpackJsonp=window.webpackJsonp||[]).push([[45],{530:function(s,a,e){"use strict";e.r(a);var n=e(19),t=Object(n.a)({},(function(){var s=this,a=s.$createElement,e=s._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[e("h2",{attrs:{id:"spark参数设置"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#spark参数设置"}},[s._v("#")]),s._v(" spark参数设置")]),s._v(" "),e("p",[s._v("spark官网所有配置参数说明：\n"),e("a",{attrs:{href:"https://spark.apache.org/docs/2.3.0/configuration.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("https://spark.apache.org/docs/2.3.0/configuration.html"),e("OutboundLink")],1)]),s._v(" "),e("h3",{attrs:{id:"_1、sparkconf参数设置"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1、sparkconf参数设置"}},[s._v("#")]),s._v(" 1、sparkConf参数设置")]),s._v(" "),e("p",[s._v("不管是我们的sparkCore的应用，还是sparkStreaming流式应用，还是我们的sparkSQL的批处理应用，我们都会用到一个配置对象叫做SparkConf的对象，为了统一封装我们的SparkConf里面的配置参数，我们可以抽取SparkConf对象配置到一个公共的地方，然后每次都获取公共的sparkConf对象即可")]),s._v(" "),e("p",[s._v("在我们的travel_spark项目下的src/main/scala下创建package com.travel.spark，然后在该package下面定义com.travel.spark.SparkEngine.scala的object文件，定义我们的sparkConf")]),s._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[s._v('def getSparkConf():SparkConf = {\n\n      val sparkConf: SparkConf = new SparkConf()\n        .set("spark.driver.cores","4") //设置driver的CPU核数_\n        .set("spark.driver.maxResultSize","2g")//设置driver端结果存放的最大容量，这里设置成为2G，超过2G的数据,job就直接放弃，不运行了_\n        .set("spark.driver.memory","4g") //driver给的内存大小_\n        .set("spark.executor.memory","8g")_// 每个executor的内存_\n        .set("spark.submit.deployMode","cluster") //spark 任务提交模式，线上使用cluster模式，开发使用client模式_\n        .set("spark.worker.timeout" ,"500")//基于standAlone模式下提交任务，worker的连接超时时间_\n        .set("spark.cores.max" , "10") //基于standAlone和mesos模式下部署，最大的CPU和数量_\n        .set("spark.rpc.askTimeout" , "600s") //spark任务通过rpc拉取数据的超时时间_\n        .set("spark.locality.wait" , "5s")//每个task获取本地数据的等待时间，默认3s钟，如果没获取到，依次获取本进程，本机，本机架数据_\n        .set("spark.task.maxFailures" , "5") //允许最大失败任务数，根据自身容错情况来定_\n        .set("spark.serializer" ,"org.apache.spark.serializer.KryoSerializer") //配置序列化方式_\n        .set("spark.streaming.kafka.maxRatePerPartition" , "5000") //使用directStream方式消费kafka当中的数据，获取每个分区数据最大速率_\n        .set("spark.streaming.backpressure.enabled" , "true") //开启sparkStreaming背压机制，接收数据的速度与消费数据的速度实现平衡_\n     //  .set("spark.streaming.backpressure.pid.minRate","10")_\n        .set("spark.driver.host", "localhost") //配置driver地址_\n       //shuffle相关参数调优开始_\n        .set("spark.reducer.maxSizeInFlight","96m") //reduceTask拉取map端输出的最大数据量，调整太大有OOM的风险_\n        .set("spark.shuffle.compress","true") //开启shuffle数据压缩_\n        .set("spark.default.parallelism","10") //设置任务的并行度_\n        .set("spark.files.fetchTimeout","120s") //设置文件获取的超时时间_\n       //网络相关参数_\n        .set("spark.rpc.message.maxSize","256") //RPC拉取数据的最大数据量，单位M_\n        .set("spark.network.timeout","120s") //网络超时时间设置_\n        .set("spark.scheduler.mode","FAIR") //spark 任务调度模式  使用 fair公平调度_\n       //spark任务资源动态划分  _[_https://spark.apache.org/docs/2.3.0/job-scheduling.html#configuration-and-setup_](https://spark.apache.org/docs/2.3.0/job-scheduling.html#configuration-and-setup)\n        .set("spark.dynamicAllocation.enabled","true")\n        .set("spark.shuffle.service.enabled","true")\n        .set("spark.dynamicAllocation.executorIdleTimeout","120s") //executor空闲时间超过这个值，该executor就会被回收_\n        .set("spark.dynamicAllocation.minExecutors","0") //最少的executor个数_\n        .set("spark.dynamicAllocation.maxExecutors","32") //最大的executor个数  根据自己实际情况调整_\n        .set("spark.dynamicAllocation.initialExecutors","4")_//初始executor个数_\n        .set("spark.dynamicAllocation.schedulerBacklogTimeout","5s") //pending 状态的task时间，过了这个时间继续pending ，申请新的executor_\n        .setMaster("local[1]")\n        .setAppName("Stream")\n      sparkConf.set("spark.speculation", "true")  //开启推测执行_\n      sparkConf.set("spark.speculation.interval", "100s") // 每隔多久检测一次是否需要进行推测执行任务_\n      sparkConf.set("spark.speculation.quantile","0.9") //完成任务的百分比，然后才能启动推测执行_\n      sparkConf.set("spark.streaming.backpressure.initialRate" , "500") // //开启sparkStreaming的背压机制，然后第一批次获取数据的最大速率_\n\n      sparkConf.registerKryoClasses(\n        Array(\n          classOf[OrderInfo],\n          classOf[Opt_alliance_business],\n          classOf[DriverInfo],\n          classOf[RegisterUsers]\n        )\n      )\n      sparkConf\n    }\n')])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br"),e("span",{staticClass:"line-number"},[s._v("10")]),e("br"),e("span",{staticClass:"line-number"},[s._v("11")]),e("br"),e("span",{staticClass:"line-number"},[s._v("12")]),e("br"),e("span",{staticClass:"line-number"},[s._v("13")]),e("br"),e("span",{staticClass:"line-number"},[s._v("14")]),e("br"),e("span",{staticClass:"line-number"},[s._v("15")]),e("br"),e("span",{staticClass:"line-number"},[s._v("16")]),e("br"),e("span",{staticClass:"line-number"},[s._v("17")]),e("br"),e("span",{staticClass:"line-number"},[s._v("18")]),e("br"),e("span",{staticClass:"line-number"},[s._v("19")]),e("br"),e("span",{staticClass:"line-number"},[s._v("20")]),e("br"),e("span",{staticClass:"line-number"},[s._v("21")]),e("br"),e("span",{staticClass:"line-number"},[s._v("22")]),e("br"),e("span",{staticClass:"line-number"},[s._v("23")]),e("br"),e("span",{staticClass:"line-number"},[s._v("24")]),e("br"),e("span",{staticClass:"line-number"},[s._v("25")]),e("br"),e("span",{staticClass:"line-number"},[s._v("26")]),e("br"),e("span",{staticClass:"line-number"},[s._v("27")]),e("br"),e("span",{staticClass:"line-number"},[s._v("28")]),e("br"),e("span",{staticClass:"line-number"},[s._v("29")]),e("br"),e("span",{staticClass:"line-number"},[s._v("30")]),e("br"),e("span",{staticClass:"line-number"},[s._v("31")]),e("br"),e("span",{staticClass:"line-number"},[s._v("32")]),e("br"),e("span",{staticClass:"line-number"},[s._v("33")]),e("br"),e("span",{staticClass:"line-number"},[s._v("34")]),e("br"),e("span",{staticClass:"line-number"},[s._v("35")]),e("br"),e("span",{staticClass:"line-number"},[s._v("36")]),e("br"),e("span",{staticClass:"line-number"},[s._v("37")]),e("br"),e("span",{staticClass:"line-number"},[s._v("38")]),e("br"),e("span",{staticClass:"line-number"},[s._v("39")]),e("br"),e("span",{staticClass:"line-number"},[s._v("40")]),e("br"),e("span",{staticClass:"line-number"},[s._v("41")]),e("br"),e("span",{staticClass:"line-number"},[s._v("42")]),e("br"),e("span",{staticClass:"line-number"},[s._v("43")]),e("br"),e("span",{staticClass:"line-number"},[s._v("44")]),e("br"),e("span",{staticClass:"line-number"},[s._v("45")]),e("br"),e("span",{staticClass:"line-number"},[s._v("46")]),e("br"),e("span",{staticClass:"line-number"},[s._v("47")]),e("br"),e("span",{staticClass:"line-number"},[s._v("48")]),e("br"),e("span",{staticClass:"line-number"},[s._v("49")]),e("br"),e("span",{staticClass:"line-number"},[s._v("50")]),e("br"),e("span",{staticClass:"line-number"},[s._v("51")]),e("br"),e("span",{staticClass:"line-number"},[s._v("52")]),e("br")])]),e("h3",{attrs:{id:"_2、sparksession参数设置"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2、sparksession参数设置"}},[s._v("#")]),s._v(" 2、sparkSession参数设置")]),s._v(" "),e("p",[s._v("上面sparkConf里面设置了大部分的关于spark的参数基本上就够用了，关于sparkSQL的入口SparkSession，我们还需要额外设置一些参数\n继续在SparkEngine当中定义SparkSession的获取")]),s._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[s._v('def getSparkSession(sparkConf:SparkConf):SparkSession = {\n    val sparkSession: SparkSession = SparkSession.builder()\n      .config(sparkConf)\n      _//调度模式_\n      .config("spark.scheduler.mode", "FAIR")\n      .config("spark.executor.memoryOverhead", "512")_//堆外内存_\n      .config("enableSendEmailOnTaskFail", "true")\n   _//   .enableHiveSupport() //开启支持hive_\n      .getOrCreate()\n    sparkSession.sparkContext.setLocalProperty("spark.scheduler.pool", "n1")\n    sparkSession\n  }\n')])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br"),e("span",{staticClass:"line-number"},[s._v("10")]),e("br"),e("span",{staticClass:"line-number"},[s._v("11")]),e("br"),e("span",{staticClass:"line-number"},[s._v("12")]),e("br")])]),e("h2",{attrs:{id:"spark的任务监控"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#spark的任务监控"}},[s._v("#")]),s._v(" spark的任务监控")]),s._v(" "),e("p",[s._v("对于我们的spark的任务，如果我们需要知道每个任务运行时候的一些状态，任务运行成功与否，以及任务出错的提示等，这就涉及到我们spark的任务监控了，spark的任务监控主要分为sparkStreaming流式任务的监控以及sparkSQL批量处理任务监控")]),s._v(" "),e("h3",{attrs:{id:"_1-sparkstreaming的任务监控"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-sparkstreaming的任务监控"}},[s._v("#")]),s._v(" 1. sparkStreaming的任务监控")]),s._v(" "),e("p",[s._v("sparkStreaming的任务，本质上还是微批次处理，对于每批次的任务，我们都可以对其进行监控，通过对每批次的数据任务的监控，可以查看我们的数据是否有积压等，针对项目当中的流式处理程序，我们也可以对其进行监控")]),s._v(" "),e("h4",{attrs:{id:"第一步-定义我们的任务监控类"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第一步-定义我们的任务监控类"}},[s._v("#")]),s._v(" 第一步：定义我们的任务监控类")]),s._v(" "),e("p",[s._v("在travel_spark工程下面创建package com.travel.listener，然后创建scala的class文件  SparkStreamingListener.scala")]),s._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[s._v('import java.util.logging.Logger\n\nimport com.alibaba.fastjson.JSON\n  import com.travel.common.JedisUtil\n  import com.travel.utils.TimeUtils\n  import org.apache.spark.streaming.scheduler._\n  import redis.clients.jedis.Jedis\n\nimport scala.collection.mutable\n\nclass SparkStreamingListener(duration:Int) extends StreamingListener {\n\n    private val log: Logger = Logger.getLogger("sparkStreamingLogger")\n\n    private val mapDatas = new mutable.HashMap[String,String]()\n\n    private var finish_batchNum :Int = 0\n\n    override def onStreamingStarted(streamingStarted: StreamingListenerStreamingStarted): Unit = {\n    log.info("startingStream" +TimeUtils.formatDate(System.currentTimeMillis(),"yyyy-MM-dd HH:mm:ss"))\n  }\n\n    override def onBatchStarted(batchStarted: StreamingListenerBatchStarted): Unit = {\n     val scheduleDelay: String = batchStarted.batchInfo.schedulingDelay.get.toString\n      _//调度延迟时间为_\n\n    mapDatas.put("scheduleDelay",scheduleDelay)\n    }\n\n    override def onBatchSubmitted(batchSubmitted: StreamingListenerBatchSubmitted): Unit = {\n    _//数据提交数量_\n\n    val records: Long = batchSubmitted.batchInfo.numRecords\n      mapDatas.put("submitRecords",records.toString)\n    }\n\n    override def onBatchCompleted(batchCompleted: StreamingListenerBatchCompleted): Unit = {\n    val jedis: Jedis = JedisUtil.getJedis\n\n    _//该批次完成调用_\n\n    _//该批次数据处理总时间_\n\n    val totalDelay: String = batchCompleted.batchInfo.totalDelay.get.toString\n      _//完成数量_\n\n    val records: Long = batchCompleted.batchInfo.numRecords\n      val processingStratTime: Long = batchCompleted.batchInfo.processingStartTime.get\n      val processingEndTime: Long = batchCompleted.batchInfo.processingEndTime.get\n      mapDatas.put("totalDelay",totalDelay)\n      mapDatas.put("records",records+"")\n      mapDatas.put("processingStratTime",processingStratTime+"")\n      mapDatas.put("processingEndTime",processingEndTime+"")\n      _//该批次是否出现阻塞_\n\n    if(duration * 6 < totalDelay.toLong * 1000){\n        log.info("流处理程序出现阻塞")\n          _//发送邮件_\n\n      }\n      _//完成的批次_\n\n    finish_batchNum = finish_batchNum +1\n      mapDatas.put("finish_batchNum",finish_batchNum + "")\n    val jsonStr: String = JSON.toJSONString(mapDatas)\n      jedis.set("batchMessage",jsonStr)\n      jedis.expire("batchMessage",3600)\n      JedisUtil.returnJedis(jedis)\n    }\n  _//接收数据异常_\n\n    override def onReceiverError(receiverError: StreamingListenerReceiverError): Unit = {\n    val active: Boolean = receiverError.receiverInfo.active\n      val id: String = receiverError.receiverInfo.executorId\n      val message: String = receiverError.receiverInfo.lastErrorMessage\n      val streamId: Int = receiverError.receiverInfo.streamId\n      mapDatas.put("receiveError",s"发生错误的executorId为：${id}, 错误消息为：${message},当前流程序是否运行：${active}")\n      val jedis: Jedis = JedisUtil.getJedis\n      val jsonStr: String = JSON.toJSONString(mapDatas)\n      jedis.set("receiveErrorMsg",jsonStr)\n      jedis.expire("receiveErrorMsg",3600)\n      JedisUtil.returnJedis(jedis)\n    }\n    }\n')])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br"),e("span",{staticClass:"line-number"},[s._v("10")]),e("br"),e("span",{staticClass:"line-number"},[s._v("11")]),e("br"),e("span",{staticClass:"line-number"},[s._v("12")]),e("br"),e("span",{staticClass:"line-number"},[s._v("13")]),e("br"),e("span",{staticClass:"line-number"},[s._v("14")]),e("br"),e("span",{staticClass:"line-number"},[s._v("15")]),e("br"),e("span",{staticClass:"line-number"},[s._v("16")]),e("br"),e("span",{staticClass:"line-number"},[s._v("17")]),e("br"),e("span",{staticClass:"line-number"},[s._v("18")]),e("br"),e("span",{staticClass:"line-number"},[s._v("19")]),e("br"),e("span",{staticClass:"line-number"},[s._v("20")]),e("br"),e("span",{staticClass:"line-number"},[s._v("21")]),e("br"),e("span",{staticClass:"line-number"},[s._v("22")]),e("br"),e("span",{staticClass:"line-number"},[s._v("23")]),e("br"),e("span",{staticClass:"line-number"},[s._v("24")]),e("br"),e("span",{staticClass:"line-number"},[s._v("25")]),e("br"),e("span",{staticClass:"line-number"},[s._v("26")]),e("br"),e("span",{staticClass:"line-number"},[s._v("27")]),e("br"),e("span",{staticClass:"line-number"},[s._v("28")]),e("br"),e("span",{staticClass:"line-number"},[s._v("29")]),e("br"),e("span",{staticClass:"line-number"},[s._v("30")]),e("br"),e("span",{staticClass:"line-number"},[s._v("31")]),e("br"),e("span",{staticClass:"line-number"},[s._v("32")]),e("br"),e("span",{staticClass:"line-number"},[s._v("33")]),e("br"),e("span",{staticClass:"line-number"},[s._v("34")]),e("br"),e("span",{staticClass:"line-number"},[s._v("35")]),e("br"),e("span",{staticClass:"line-number"},[s._v("36")]),e("br"),e("span",{staticClass:"line-number"},[s._v("37")]),e("br"),e("span",{staticClass:"line-number"},[s._v("38")]),e("br"),e("span",{staticClass:"line-number"},[s._v("39")]),e("br"),e("span",{staticClass:"line-number"},[s._v("40")]),e("br"),e("span",{staticClass:"line-number"},[s._v("41")]),e("br"),e("span",{staticClass:"line-number"},[s._v("42")]),e("br"),e("span",{staticClass:"line-number"},[s._v("43")]),e("br"),e("span",{staticClass:"line-number"},[s._v("44")]),e("br"),e("span",{staticClass:"line-number"},[s._v("45")]),e("br"),e("span",{staticClass:"line-number"},[s._v("46")]),e("br"),e("span",{staticClass:"line-number"},[s._v("47")]),e("br"),e("span",{staticClass:"line-number"},[s._v("48")]),e("br"),e("span",{staticClass:"line-number"},[s._v("49")]),e("br"),e("span",{staticClass:"line-number"},[s._v("50")]),e("br"),e("span",{staticClass:"line-number"},[s._v("51")]),e("br"),e("span",{staticClass:"line-number"},[s._v("52")]),e("br"),e("span",{staticClass:"line-number"},[s._v("53")]),e("br"),e("span",{staticClass:"line-number"},[s._v("54")]),e("br"),e("span",{staticClass:"line-number"},[s._v("55")]),e("br"),e("span",{staticClass:"line-number"},[s._v("56")]),e("br"),e("span",{staticClass:"line-number"},[s._v("57")]),e("br"),e("span",{staticClass:"line-number"},[s._v("58")]),e("br"),e("span",{staticClass:"line-number"},[s._v("59")]),e("br"),e("span",{staticClass:"line-number"},[s._v("60")]),e("br"),e("span",{staticClass:"line-number"},[s._v("61")]),e("br"),e("span",{staticClass:"line-number"},[s._v("62")]),e("br"),e("span",{staticClass:"line-number"},[s._v("63")]),e("br"),e("span",{staticClass:"line-number"},[s._v("64")]),e("br"),e("span",{staticClass:"line-number"},[s._v("65")]),e("br"),e("span",{staticClass:"line-number"},[s._v("66")]),e("br"),e("span",{staticClass:"line-number"},[s._v("67")]),e("br"),e("span",{staticClass:"line-number"},[s._v("68")]),e("br"),e("span",{staticClass:"line-number"},[s._v("69")]),e("br"),e("span",{staticClass:"line-number"},[s._v("70")]),e("br"),e("span",{staticClass:"line-number"},[s._v("71")]),e("br"),e("span",{staticClass:"line-number"},[s._v("72")]),e("br"),e("span",{staticClass:"line-number"},[s._v("73")]),e("br"),e("span",{staticClass:"line-number"},[s._v("74")]),e("br"),e("span",{staticClass:"line-number"},[s._v("75")]),e("br"),e("span",{staticClass:"line-number"},[s._v("76")]),e("br"),e("span",{staticClass:"line-number"},[s._v("77")]),e("br"),e("span",{staticClass:"line-number"},[s._v("78")]),e("br"),e("span",{staticClass:"line-number"},[s._v("79")]),e("br"),e("span",{staticClass:"line-number"},[s._v("80")]),e("br"),e("span",{staticClass:"line-number"},[s._v("81")]),e("br"),e("span",{staticClass:"line-number"},[s._v("82")]),e("br"),e("span",{staticClass:"line-number"},[s._v("83")]),e("br"),e("span",{staticClass:"line-number"},[s._v("84")]),e("br")])]),e("h4",{attrs:{id:"第二步-代码当中添加流任务监控"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第二步-代码当中添加流任务监控"}},[s._v("#")]),s._v(" 第二步：代码当中添加流任务监控")]),s._v(" "),e("p",[s._v("例如在我们的StreamingMaxwellKafka.scala代码中添加我们的流监控程序")]),s._v(" "),e("p",[s._v("ssc.addStreamingListener(new SparkStreamingListener(1))")]),s._v(" "),e("p",[e("img",{attrs:{src:"https://gitee.com/kflys/uPic/raw/master/uPic/1593619390484-4e446edf-1d03-4203-8cf5-db92346799fb.png",alt:""}})]),s._v(" "),e("h2",{attrs:{id:"_2、sparksql的任务监控"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2、sparksql的任务监控"}},[s._v("#")]),s._v(" 2、sparkSQL的任务监控")]),s._v(" "),e("p",[s._v("除了我们可以对我们的sparkStreaming的任务进行监控之外，我们也可以对我们的sparkSQL的任务进行监控，sparkSQL的任务本质上还是一个批处理程序，每次对我们的一批数据进行处理\n"),e("a",{attrs:{href:"https://spark.apache.org/docs/2.3.0/monitoring.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("https://spark.apache.org/docs/2.3.0/monitoring.html"),e("OutboundLink")],1)]),s._v(" "),e("h3",{attrs:{id:"第一步-创建监听类"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第一步-创建监听类"}},[s._v("#")]),s._v(" 第一步：创建监听类")]),s._v(" "),e("p",[s._v("在我们的travel_spark项目模块下创建package com.travel.listener，然后创建scala的class文件 "),e("strong",[s._v("SparkSessionListener.scala")])]),s._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[s._v('import com.alibaba.fastjson.JSON\nimport com.travel.common.JedisUtil\nimport org.apache.spark.executor.TaskMetrics\nimport org.apache.spark.scheduler.{SparkListener, SparkListenerTaskEnd}\nimport redis.clients.jedis.Jedis\n\nimport scala.collection.mutable\n\nclass SparkSessionListener  extends SparkListener{\n\n    override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = {\n        val jedis: Jedis = JedisUtil.getJedis\n\n        val jedisMap = new mutable.HashMap[String,String]()\n\n        val metrics: TaskMetrics = taskEnd.taskMetrics\n        jedisMap.put("executorCpuTime",metrics.executorCpuTime+"")\n        jedisMap.put("jvmGCTime",metrics.jvmGCTime+"")\n        jedisMap.put("executorDeserializeCpuTime",metrics.executorDeserializeCpuTime+"")\n        jedisMap.put("diskBytesSpilled",metrics.diskBytesSpilled+"")\n        jedisMap.put("executorDeserializeTime",metrics.executorDeserializeTime+"")\n        jedisMap.put("resultSize",metrics.resultSize+"")\n\n        jedisMap.put("executorCpuTime",metrics.memoryBytesSpilled+"")\n        jedisMap.put("executorCpuTime",metrics.resultSerializationTime+"")\n\n        jedis.set("taskMetrics",JSON.toJSONString(jedisMap))\n\n        //####################shuffle#######_\n\n        val shuffleReadMetrics = metrics.shuffleReadMetrics\n        val shuffleWriteMetrics = metrics.shuffleWriteMetrics\n\n        val shuffleMap = scala.collection.mutable.HashMap(\n          "remoteBlocksFetched" -> shuffleReadMetrics.remoteBlocksFetched ,//shuffle远程拉取数据块_\n\n          "localBlocksFetched" -> shuffleReadMetrics.localBlocksFetched ,\n          "remoteBytesRead" -> shuffleReadMetrics.remoteBytesRead , //shuffle远程读取的字节数_\n\n          "localBytesRead" -> shuffleReadMetrics.localBytesRead ,\n          "fetchWaitTime" -> shuffleReadMetrics.fetchWaitTime ,\n          "recordsRead" -> shuffleReadMetrics.recordsRead , //shuffle读取的记录总数_\n\n          "bytesWritten" -> shuffleWriteMetrics.bytesWritten , //shuffle写的总大小_\n\n          "recordsWritte" -> shuffleWriteMetrics.recordsWritten , //shuffle写的总记录数_\n\n          "writeTime" -> shuffleWriteMetrics.writeTime\n        )\n\n        jedis.set("shuffleMetrics",JSON.toJSONString(shuffleMap))\n\n        //####################input   output#######_\n\n        val inputMetrics = metrics.inputMetrics\n        val outputMetrics = metrics.outputMetrics\n        val input_output = scala.collection.mutable.HashMap(\n          "bytesRead" ->  inputMetrics.bytesRead ,//读取的大小_\n\n          "recordsRead" -> inputMetrics.recordsRead , //总记录数_\n\n          "bytesWritten" -> outputMetrics.bytesWritten ,\n          "recordsWritten" -> outputMetrics.recordsWritten\n        )\n\n        jedis.set("inputOutputMetrics",JSON.toJSONString(input_output))\n\n        //####################taskInfo#######_\n\n        val taskInfo = taskEnd.taskInfo\n\n        val taskInfoMap = scala.collection.mutable.HashMap(\n          "taskId" -> taskInfo.taskId ,\n          "host" -> taskInfo.host ,\n          "speculative" -> taskInfo.speculative , //推测执行_\n\n          "failed" -> taskInfo.failed ,\n          "killed" -> taskInfo.killed ,\n          "running" -> taskInfo.running\n        )\n\n        jedis.set("taskInfo",JSON.toJSONString(taskInfoMap))\n\n        JedisUtil.returnJedis(jedis)\n\n      }\n} \n')])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br"),e("span",{staticClass:"line-number"},[s._v("10")]),e("br"),e("span",{staticClass:"line-number"},[s._v("11")]),e("br"),e("span",{staticClass:"line-number"},[s._v("12")]),e("br"),e("span",{staticClass:"line-number"},[s._v("13")]),e("br"),e("span",{staticClass:"line-number"},[s._v("14")]),e("br"),e("span",{staticClass:"line-number"},[s._v("15")]),e("br"),e("span",{staticClass:"line-number"},[s._v("16")]),e("br"),e("span",{staticClass:"line-number"},[s._v("17")]),e("br"),e("span",{staticClass:"line-number"},[s._v("18")]),e("br"),e("span",{staticClass:"line-number"},[s._v("19")]),e("br"),e("span",{staticClass:"line-number"},[s._v("20")]),e("br"),e("span",{staticClass:"line-number"},[s._v("21")]),e("br"),e("span",{staticClass:"line-number"},[s._v("22")]),e("br"),e("span",{staticClass:"line-number"},[s._v("23")]),e("br"),e("span",{staticClass:"line-number"},[s._v("24")]),e("br"),e("span",{staticClass:"line-number"},[s._v("25")]),e("br"),e("span",{staticClass:"line-number"},[s._v("26")]),e("br"),e("span",{staticClass:"line-number"},[s._v("27")]),e("br"),e("span",{staticClass:"line-number"},[s._v("28")]),e("br"),e("span",{staticClass:"line-number"},[s._v("29")]),e("br"),e("span",{staticClass:"line-number"},[s._v("30")]),e("br"),e("span",{staticClass:"line-number"},[s._v("31")]),e("br"),e("span",{staticClass:"line-number"},[s._v("32")]),e("br"),e("span",{staticClass:"line-number"},[s._v("33")]),e("br"),e("span",{staticClass:"line-number"},[s._v("34")]),e("br"),e("span",{staticClass:"line-number"},[s._v("35")]),e("br"),e("span",{staticClass:"line-number"},[s._v("36")]),e("br"),e("span",{staticClass:"line-number"},[s._v("37")]),e("br"),e("span",{staticClass:"line-number"},[s._v("38")]),e("br"),e("span",{staticClass:"line-number"},[s._v("39")]),e("br"),e("span",{staticClass:"line-number"},[s._v("40")]),e("br"),e("span",{staticClass:"line-number"},[s._v("41")]),e("br"),e("span",{staticClass:"line-number"},[s._v("42")]),e("br"),e("span",{staticClass:"line-number"},[s._v("43")]),e("br"),e("span",{staticClass:"line-number"},[s._v("44")]),e("br"),e("span",{staticClass:"line-number"},[s._v("45")]),e("br"),e("span",{staticClass:"line-number"},[s._v("46")]),e("br"),e("span",{staticClass:"line-number"},[s._v("47")]),e("br"),e("span",{staticClass:"line-number"},[s._v("48")]),e("br"),e("span",{staticClass:"line-number"},[s._v("49")]),e("br"),e("span",{staticClass:"line-number"},[s._v("50")]),e("br"),e("span",{staticClass:"line-number"},[s._v("51")]),e("br"),e("span",{staticClass:"line-number"},[s._v("52")]),e("br"),e("span",{staticClass:"line-number"},[s._v("53")]),e("br"),e("span",{staticClass:"line-number"},[s._v("54")]),e("br"),e("span",{staticClass:"line-number"},[s._v("55")]),e("br"),e("span",{staticClass:"line-number"},[s._v("56")]),e("br"),e("span",{staticClass:"line-number"},[s._v("57")]),e("br"),e("span",{staticClass:"line-number"},[s._v("58")]),e("br"),e("span",{staticClass:"line-number"},[s._v("59")]),e("br"),e("span",{staticClass:"line-number"},[s._v("60")]),e("br"),e("span",{staticClass:"line-number"},[s._v("61")]),e("br"),e("span",{staticClass:"line-number"},[s._v("62")]),e("br"),e("span",{staticClass:"line-number"},[s._v("63")]),e("br"),e("span",{staticClass:"line-number"},[s._v("64")]),e("br"),e("span",{staticClass:"line-number"},[s._v("65")]),e("br"),e("span",{staticClass:"line-number"},[s._v("66")]),e("br"),e("span",{staticClass:"line-number"},[s._v("67")]),e("br"),e("span",{staticClass:"line-number"},[s._v("68")]),e("br"),e("span",{staticClass:"line-number"},[s._v("69")]),e("br"),e("span",{staticClass:"line-number"},[s._v("70")]),e("br"),e("span",{staticClass:"line-number"},[s._v("71")]),e("br"),e("span",{staticClass:"line-number"},[s._v("72")]),e("br"),e("span",{staticClass:"line-number"},[s._v("73")]),e("br"),e("span",{staticClass:"line-number"},[s._v("74")]),e("br"),e("span",{staticClass:"line-number"},[s._v("75")]),e("br"),e("span",{staticClass:"line-number"},[s._v("76")]),e("br"),e("span",{staticClass:"line-number"},[s._v("77")]),e("br"),e("span",{staticClass:"line-number"},[s._v("78")]),e("br"),e("span",{staticClass:"line-number"},[s._v("79")]),e("br"),e("span",{staticClass:"line-number"},[s._v("80")]),e("br"),e("span",{staticClass:"line-number"},[s._v("81")]),e("br"),e("span",{staticClass:"line-number"},[s._v("82")]),e("br"),e("span",{staticClass:"line-number"},[s._v("83")]),e("br"),e("span",{staticClass:"line-number"},[s._v("84")]),e("br"),e("span",{staticClass:"line-number"},[s._v("85")]),e("br"),e("span",{staticClass:"line-number"},[s._v("86")]),e("br"),e("span",{staticClass:"line-number"},[s._v("87")]),e("br")])]),e("h3",{attrs:{id:"第二步-在sparksession当中添加监听项"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第二步-在sparksession当中添加监听项"}},[s._v("#")]),s._v(" 第二步：在sparkSession当中添加监听项")]),s._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[s._v('   val sparkSession: SparkSession = SparkSession.builder()\n      .config(conf)\n      .config("spark.extraListeners","com.travel.listener.SparkStreamingListener")\n      .getOrCreate()\n')])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br")])])])}),[],!1,null,null,null);a.default=t.exports}}]);