(window.webpackJsonp=window.webpackJsonp||[]).push([[100],{588:function(a,s,t){"use strict";t.r(s);var r=t(19),e=Object(r.a)({},(function(){var a=this,s=a.$createElement,t=a._self._c||s;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"资源分配方面"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#资源分配方面"}},[a._v("#")]),a._v(" 资源分配方面")]),a._v(" "),t("blockquote",[t("p",[a._v("它是性能优化调优的王道，就是增加和分配更多的资源，这对于性能和速度上的提升是显而易见的，基本上，在一定范围之内，增加资源与性能的提升，是成正比的；写完了一个复杂的spark作业之后，进行性能调优的时候，首先第一步，就是要来调节最优的资源配置；在这个基础之上，如果说你的spark作业，能够分配的资源达到了你的能力范围的顶端之后，无法再分配更多的资源了，公司资源有限；那么才是考虑去做后面的这些性能调优的点。")])]),a._v(" "),t("h2",{attrs:{id:"分配哪些资源"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分配哪些资源"}},[a._v("#")]),a._v(" 分配哪些资源")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("spark-submit --master spark://node1:7077  --class cn.itcast.WordCount --num-executors 3 --driver-memory 1g --executor-memory 1g --executor-cores 3 \t/export/servers/wordcount.jar\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("h3",{attrs:{id:"executor-memory"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#executor-memory"}},[a._v("#")]),a._v(" executor-memory")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("  --num-executors 3      配置executor的数量\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("h3",{attrs:{id:"executor-cores"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#executor-cores"}},[a._v("#")]),a._v(" executor-cores")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v(" --executor-cores 3    配置每一个executor的cpu个数\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("h3",{attrs:{id:"executor-memory-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#executor-memory-2"}},[a._v("#")]),a._v(" executor-memory")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v(" --executor-memory 1g  配置每一个executor的内存大小\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("h3",{attrs:{id:"driver-memory"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#driver-memory"}},[a._v("#")]),a._v(" driver-memory")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v(" --driver-memory 1g     配置driver的内存（影响不大）\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("h2",{attrs:{id:"如何进行分配"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如何进行分配"}},[a._v("#")]),a._v(" 如何进行分配")]),a._v(" "),t("blockquote",[t("p",[a._v("在资源比较充足的情况下，尽可能的使用更多的计算资源，尽量去调节到最大的大小")])]),a._v(" "),t("h3",{attrs:{id:"standalone模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#standalone模式"}},[a._v("#")]),a._v(" Standalone模式")]),a._v(" "),t("p",[a._v("先计算出公司spark集群上的所有资源 每台节点的内存大小和cpu核数，比如：一共有20台worker节点，每台节点8g内存，10个cpu。实际任务在给定资源的时候，可以给20个executor、每个executor的内存8g、每个executor的使用的cpu个数10。")]),a._v(" "),t("h3",{attrs:{id:"yarn模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#yarn模式"}},[a._v("#")]),a._v(" Yarn模式")]),a._v(" "),t("p",[a._v("先计算出yarn集群的所有大小，比如一共500g内存，100个cpu；这个时候可以分配的最大资源，比如给定50个executor、每个executor的内存大小10g,每个executor使用的cpu个数为2。")]),a._v(" "),t("h2",{attrs:{id:"具体分析"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#具体分析"}},[a._v("#")]),a._v(" 具体分析")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/kflys/uPic/raw/master/uPic/1612346460888-a1da381b-2a26-4224-af7a-c2121d7b3f57.png",alt:"img"}})]),a._v(" "),t("h1",{attrs:{id:"提高并行度"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#提高并行度"}},[a._v("#")]),a._v(" 提高并行度")]),a._v(" "),t("p",[a._v("spark作业中，各个stage的task的数量，也就代表了spark作业在各个阶段stage的并行度！")]),a._v(" "),t("p",[a._v("当分配完所能分配的最大资源了，然后对应资源去调节程序的并行度，如果并行度没有与资源相匹配，那么导致你分配下去的资源都浪费掉了。同时并行运行，还可以让每个task要处理的数量变少（很简单的原理。合理设置并行度，可以充分利用集群资源，减少每个task处理数据量，而增加性能加快运行速度。）")]),a._v(" "),t("h2",{attrs:{id:"task的数量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#task的数量"}},[a._v("#")]),a._v(" task的数量")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("\t至少设置成与spark Application 的总cpu core 数量相同。\n\t最理想情况，150个core，分配150task，一起运行，差不多同一时间运行完毕\n\t官方推荐，task数量，设置成spark Application 总cpu core数量的2~3倍 。\n\t\n\t\n\t比如150个cpu core ，基本设置task数量为300~500. 与理想情况不同的，有些task会运行快一点，比如50s就完了，有些task 可能会慢一点，要一分半才运行完，所以如果你的task数量，刚好设置的跟cpu core 数量相同，可能会导致资源的浪费。\n\t因为比如150个task中10个先运行完了，剩余140个还在运行，但是这个时候，就有10个cpu core空闲出来了，导致浪费。如果设置2~3倍，那么一个task运行完以后，另外一个task马上补上来，尽量让cpu core不要空闲。同时尽量提升spark运行效率和速度。提升性能。\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br")])]),t("h2",{attrs:{id:"如何设置task数量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如何设置task数量"}},[a._v("#")]),a._v(" 如何设置task数量")]),a._v(" "),t("h3",{attrs:{id:"spark-defalut-parallelism"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-defalut-parallelism"}},[a._v("#")]),a._v(" spark.defalut.parallelism")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v('   默认是没有值的，如果设置了值为10，它会在shuffle的过程才会起作用。\n   比如 val rdd2 = rdd1.reduceByKey(_+_) \n   此时rdd2的分区数就是10\n   \n可以通过在构建SparkConf对象的时候设置，例如：\n   new SparkConf().set("spark.defalut.parallelism","500")\n')])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br")])]),t("h3",{attrs:{id:"rdd-repartition"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rdd-repartition"}},[a._v("#")]),a._v(" rdd.repartition")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("使用rdd.repartition 来重新分区，该方法会生成一个新的rdd，使其分区数变大。\n此时由于一个partition对应一个task，那么对应的task个数越多，通过这种方式也可以提高并行度。\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br")])]),t("h3",{attrs:{id:"spark-sql-shuffle-partitions"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-sql-shuffle-partitions"}},[a._v("#")]),a._v(" spark.sql.shuffle.partitions")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("提高sparksql运行的task数量，通过设置参数 spark.sql.shuffle.partitions=500  默认为200；\n可以适当增大，来提高并行度。 比如设置为 spark.sql.shuffle.partitions=500\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br")])]),t("h1",{attrs:{id:"rdd的重用和持久化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rdd的重用和持久化"}},[a._v("#")]),a._v(" RDD的重用和持久化")]),a._v(" "),t("h2",{attrs:{id:"实际开发遇到的情况说明"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#实际开发遇到的情况说明"}},[a._v("#")]),a._v(" 实际开发遇到的情况说明")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/kflys/uPic/raw/master/uPic/1612346460896-723fb61a-38e0-4e41-880d-d74c54f7f44e.png",alt:"img"}})]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("如上图所示的计算逻辑：\n（1）当第一次使用rdd2做相应的算子操作得到rdd3的时候，就会从rdd1开始计算，先读取HDFS上的文件，然后对rdd1做对应的算子操作得到rdd2,再由rdd2计算之后得到rdd3。同样为了计算得到rdd4，前面的逻辑会被重新计算。\n\n（3）默认情况下多次对一个rdd执行算子操作，去获取不同的rdd，都会对这个rdd及之前的父rdd全部重新计算一次。\n这种情况在实际开发代码的时候会经常遇到，但是我们一定要避免一个rdd重复计算多次，否则会导致性能急剧降低。\n\n总结：可以把多次使用到的rdd，也就是公共rdd进行持久化，避免后续需要，再次重新计算，提升效率。\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br")])]),t("p",[t("img",{attrs:{src:"https://gitee.com/kflys/uPic/raw/master/uPic/1612346460884-23ea7e59-3a00-49f2-a13b-0de1d6f6b3e3.png",alt:"img"}})]),a._v(" "),t("h2",{attrs:{id:"rdd持久化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rdd持久化"}},[a._v("#")]),a._v(" rdd持久化")]),a._v(" "),t("h3",{attrs:{id:"可以调用rdd的cache或者persist方法。"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#可以调用rdd的cache或者persist方法。"}},[a._v("#")]),a._v(" 可以调用rdd的cache或者persist方法。")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("（1）cache方法默认是把数据持久化到内存中 ，例如：rdd.cache ，其本质还是调用了persist方法\n（2）persist方法中有丰富的缓存级别，这些缓存级别都定义在StorageLevel这个object中，可以结合实际的应用场景合理的设置缓存级别。例如： rdd.persist(StorageLevel.MEMORY_ONLY),这是cache方法的实现。\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br")])]),t("h3",{attrs:{id:"rdd持久化-采用序列化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rdd持久化-采用序列化"}},[a._v("#")]),a._v(" rdd持久化，采用序列化")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("（1）如果正常将数据持久化在内存中，那么可能会导致内存的占用过大，这样的话，也许会导致OOM内存溢出。\n（2）当纯内存无法支撑公共RDD数据完全存放的时候，就优先考虑使用序列化的方式在纯内存中存储。将RDD的每个partition的数据，序列化成一个字节数组；序列化后，大大减少内存的空间占用。\n（3）序列化的方式，唯一的缺点就是，在获取数据的时候，需要反序列化。但是可以减少占用的空间和便于网络传输\n（4）如果序列化纯内存方式，还是导致OOM，内存溢出；就只能考虑磁盘的方式，内存+磁盘的普通方式（无序列化）。\n（5）为了数据的高可靠性，而且内存充足，可以使用双副本机制，进行持久化\n\t持久化的双副本机制，持久化后的一个副本，因为机器宕机了，副本丢了，就还是得重新计算一次；\n\t持久化的每个数据单元，存储一份副本，放在其他节点上面，从而进行容错；\n\t一个副本丢了，不用重新计算，还可以使用另外一份副本。这种方式，仅仅针对你的内存资源极度充足。\n\t 比如: StorageLevel.MEMORY_ONLY_2\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br")])]),t("h3",{attrs:{id:"广播变量的使用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#广播变量的使用"}},[a._v("#")]),a._v(" 广播变量的使用")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("\t在实际工作中可能会遇到这样的情况，由于要处理的数据量非常大，这个时候可能会在一个stage中出现大量的task，比如有1000个task，这些task都需要一份相同的数据来处理业务，这份数据的大小为100M，该数据会拷贝1000份副本，通过网络传输到各个task中去，给task使用。这里会涉及大量的网络传输开销，同时至少需要的内存为1000*100M=100G，这个内存开销是非常大的。不必要的内存的消耗和占用，就导致了你在进行RDD持久化到内存，也许就没法完全在内存中放下；就只能写入磁盘，最后导致后续的操作在磁盘IO上消耗性能；这对于spark任务处理来说就是一场灾难。\n\n    由于内存开销比较大，task在创建对象的时候，可能会出现堆内存放不下所有对象，就会导致频繁的垃圾回收器的回收GC。GC的时候一定是会导致工作线程停止，也就是导致Spark暂停工作那么一点时间。频繁GC的话，对Spark作业的运行的速度会有相当可观的影响。\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br")])]),t("p",[t("img",{attrs:{src:"https://gitee.com/kflys/uPic/raw/master/uPic/1612346460898-e97693d7-ea42-4122-983c-951de2fa20b4.png",alt:"img"}})]),a._v(" "),t("h1",{attrs:{id:"广播变量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#广播变量"}},[a._v("#")]),a._v(" 广播变量")]),a._v(" "),t("blockquote",[t("p",[a._v("Spark中分布式执行的代码需要传递到各个executor的task上运行。对于一些只读、固定的数据,每次都需要Driver广播到各个Task上，这样效率低下。广播变量允许将变量只广播给各个executor。该executor上的各个task再从所在节点的BlockManager(负责管理某个executor对应的内存和磁盘上的数据)获取变量，而不是从Driver获取变量，从而提升了效率。")])]),a._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/kflys/uPic/raw/master/uPic/1612346460901-ecbd91d0-ede3-416e-9008-c1207c6389a9.png",alt:"img"}})]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("广播变量，初始的时候，就在Drvier上有一份副本。通过在Driver把共享数据转换成广播变量。\n\n\ttask在运行的时候，想要使用广播变量中的数据，此时首先会在自己本地的Executor对应的BlockManager中，尝试获取变量副本；如果本地没有，那么就从Driver远程拉取广播变量副本，并保存在本地的BlockManager中；\n\t\n\t此后这个executor上的task，都会直接使用本地的BlockManager中的副本。那么这个时候所有该executor中的task都会使用这个广播变量的副本。也就是说一个executor只需要在第一个task启动时，获得一份广播变量数据，之后的task都从本节点的BlockManager中获取相关数据。\n\n\texecutor的BlockManager除了从driver上拉取，也可能从其他节点的BlockManager上拉取变量副本，网络距离越近越好。\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br")])]),t("h3",{attrs:{id:"使用广播变量前后的性能分析"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#使用广播变量前后的性能分析"}},[a._v("#")]),a._v(" 使用广播变量前后的性能分析")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("比如一个任务需要50个executor，1000个task，共享数据为100M。\n(1)在不使用广播变量的情况下，1000个task，就需要该共享数据的1000个副本，也就是说有1000份数需要大量的网络传输和内存开销存储。耗费的内存大小1000*100=100G.\n\n(2)使用了广播变量后，50个executor就只需要50个副本数据，而且不一定都是从Driver传输到每个节点，还可能是就近从最近的节点的executor的blockmanager上拉取广播变量副本，网络传输速度大大增加；内存开销 50*100M=5G\n\n总结：\n\t不使用广播变量的内存开销为100G，使用后的内存开销5G，这里就相差了20倍左右的网络传输性能损耗和内存开销，使用广播变量后对于性能的提升和影响，还是很可观的。\n\t\n\t广播变量的使用不一定会对性能产生决定性的作用。比如运行30分钟的spark作业，可能做了广播变量以后，速度快了2分钟，或者5分钟。但是一点一滴的调优，积少成多。最后还是会有效果的。\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br")])]),t("h3",{attrs:{id:"广播变量使用注意事项"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#广播变量使用注意事项"}},[a._v("#")]),a._v(" 广播变量使用注意事项")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("（1）不能将一个RDD使用广播变量广播出去，因为RDD是不存储数据的。可以将RDD的结果广播出去。\n\n（2）广播变量只能在Driver端定义，不能在Executor端定义。\n\n（3）在Driver端可以修改广播变量的值，在Executor端无法修改广播变量的值。\n\n（4）如果executor端用到了Driver的变量，如果不使用广播变量在Executor有多少task就有多少Driver端的变量副本。\n\n（5）如果Executor端用到了Driver的变量，如果使用广播变量在每个Executor中只有一份Driver端的变量副本。\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br")])]),t("h3",{attrs:{id:"示例"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#示例"}},[a._v("#")]),a._v(" 示例")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("(1) 通过sparkContext的broadcast方法把数据转换成广播变量，类型为Broadcast，\n\tval broadcastArray: Broadcast[Array[Int]] = sc.broadcast(Array(1,2,3,4,5,6))\n\t\n(2) 然后executor上的BlockManager就可以拉取该广播变量的副本获取具体的数据。\n\t\t获取广播变量中的值可以通过调用其value方法\n\t val array: Array[Int] = broadcastArray.value\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br")])]),t("h1",{attrs:{id:"避免使用shuffle类算子"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#避免使用shuffle类算子"}},[a._v("#")]),a._v(" 避免使用shuffle类算子")]),a._v(" "),t("blockquote",[t("p",[a._v("1、spark中的shuffle涉及到数据要进行大量的网络传输，下游阶段的task任务需要通过网络拉取上阶段task的输出数据，shuffle过程，简单来说，就是将分布在集群中多个节点上的同一个key，拉取到同一个节点上，进行聚合或join等操作。比如reduceByKey、join等算子，都会触发shuffle操作。\n2、如果有可能的话，要尽量避免使用shuffle类算子。\n因为Spark作业运行过程中，最消耗性能的地方就是shuffle过程。")])]),a._v(" "),t("h3",{attrs:{id:"会产生shuffle的算子"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#会产生shuffle的算子"}},[a._v("#")]),a._v(" 会产生shuffle的算子")]),a._v(" "),t("p",[a._v("spark程序在开发的过程中使用reduceByKey、join、distinct、repartition等算子操作，这里都会产生shuffle，由于shuffle这一块是非常耗费性能的，实际开发中尽量使用map类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。")]),a._v(" "),t("h3",{attrs:{id:"避免产生shuffle"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#避免产生shuffle"}},[a._v("#")]),a._v(" 避免产生shuffle")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("//错误的做法：\n// 传统的join操作会导致shuffle操作。\n// 因为两个RDD中，相同的key都需要通过网络拉取到一个节点上，由一个task进行join操作。\nval rdd3 = rdd1.join(rdd2)\n    \n//正确的做法：\n// Broadcast+map的join操作，不会导致shuffle操作。\n// 使用Broadcast将一个数据量较小的RDD作为广播变量。\nval rdd2Data = rdd2.collect()\nval rdd2DataBroadcast = sc.broadcast(rdd2Data)\n\n// 在rdd1.map算子中，可以从rdd2DataBroadcast中，获取rdd2的所有数据。\n// 然后进行遍历，如果发现rdd2中某条数据的key与rdd1的当前数据的key是相同的，那么就判定可以进行join。\n// 此时就可以根据自己需要的方式，将rdd1当前数据与rdd2中可以连接的数据，拼接在一起（String或Tuple）。\nval rdd3 = rdd1.map(rdd2DataBroadcast...)\n\n// 注意，以上操作，建议仅仅在rdd2的数据量比较少（比如几百M，或者一两G）的情况下使用。\n// 因为每个Executor的内存中，都会驻留一份rdd2的全量数据。\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br"),t("span",{staticClass:"line-number"},[a._v("10")]),t("br"),t("span",{staticClass:"line-number"},[a._v("11")]),t("br"),t("span",{staticClass:"line-number"},[a._v("12")]),t("br"),t("span",{staticClass:"line-number"},[a._v("13")]),t("br"),t("span",{staticClass:"line-number"},[a._v("14")]),t("br"),t("span",{staticClass:"line-number"},[a._v("15")]),t("br"),t("span",{staticClass:"line-number"},[a._v("16")]),t("br"),t("span",{staticClass:"line-number"},[a._v("17")]),t("br"),t("span",{staticClass:"line-number"},[a._v("18")]),t("br")])]),t("h2",{attrs:{id:"使用map-side预聚合的shuffle操作"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#使用map-side预聚合的shuffle操作"}},[a._v("#")]),a._v(" 使用map-side预聚合的shuffle操作")]),a._v(" "),t("h3",{attrs:{id:"map-side预聚合"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#map-side预聚合"}},[a._v("#")]),a._v(" map-side预聚合")]),a._v(" "),t("blockquote",[t("p",[a._v("如果因为业务需要，一定要使用shuffle操作，无法用map类的算子来替代，那么尽量使用可以map-side预聚合的算子。")])]),a._v(" "),t("p",[a._v("所谓的map-side预聚合，说的是在每个节点本地对相同的key进行一次聚合操作，类似于MapReduce中的本地combiner。")]),a._v(" "),t("p",[a._v("map-side预聚合之后，每个节点本地就只会有一条相同的key，因为多条相同的key都被聚合起来了。其他节点在拉取所有节点上的相同key时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销。")]),a._v(" "),t("p",[a._v("通常来说，在可能的情况下，建议使用reduceByKey或者aggregateByKey算子来替代掉groupByKey算子。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合。\n而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差。")]),a._v(" "),t("p",[a._v("比如如下两幅图，就是典型的例子，分别基于reduceByKey和groupByKey进行单词计数。")]),a._v(" "),t("h4",{attrs:{id:"groupbykey进行单词计数原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#groupbykey进行单词计数原理"}},[a._v("#")]),a._v(" groupByKey进行单词计数原理")]),a._v(" "),t("blockquote",[t("p",[a._v("没有进行任何本地聚合时，所有数据都会在集群节点之间传输。\ngroupByKey 不会进行预聚合操作，进行数据的全量拉取，性能比较低")])]),a._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/kflys/uPic/raw/master/uPic/1612346460909-afa9cd87-290b-41a8-9c34-a4b016009090.png",alt:"img"}})]),a._v(" "),t("h4",{attrs:{id:"reducebykey单词计数原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#reducebykey单词计数原理"}},[a._v("#")]),a._v(" reduceByKey单词计数原理")]),a._v(" "),t("blockquote",[t("p",[a._v("每个节点本地的相同key数据，都进行了预聚合，然后才传输到其他节点上进行全局聚合。\nreduceByKey/aggregateByKey 可以进行预聚合操作，减少数据的传输量，提升性能")])]),a._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/kflys/uPic/raw/master/uPic/1612346460915-20ba4bee-79ee-441c-a48f-6f2a867fdc4d.png",alt:"img"}})]),a._v(" "),t("h2",{attrs:{id:"高性能的算子"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#高性能的算子"}},[a._v("#")]),a._v(" 高性能的算子")]),a._v(" "),t("h3",{attrs:{id:"mappartitions"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mappartitions"}},[a._v("#")]),a._v(" mapPartitions")]),a._v(" "),t("p",[a._v("mapPartitions类的算子，一次函数调用会处理一个partition所有的数据，而不是一次函数调用处理一条，性能相对来说会高一些。")]),a._v(" "),t("p",[a._v("但是有的时候，使用mapPartitions会出现OOM（内存溢出）的问题。因为单次函数调用就要处理掉一个partition所有的数据，如果内存不够，垃圾回收时是无法回收掉太多对象的，很可能出现OOM异常。所以使用这类操作时要慎重！")]),a._v(" "),t("h3",{attrs:{id:"foreachpartitions类的算子"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#foreachpartitions类的算子"}},[a._v("#")]),a._v(" foreachPartitions类的算子")]),a._v(" "),t("p",[a._v("foreachPartitions类的算子原理类似于“使用mapPartitions替代map”，也是一次函数调用处理一个partition的所有数据，而不是一次函数调用处理一条数据。")]),a._v(" "),t("p",[a._v("在实践中发现，foreachPartitions类的算子，对性能的提升还是很有帮助的。比如在foreach函数中，将RDD中所有数据写MySQL，那么如果是普通的foreach算子，就会一条数据一条数据地写，每次函数调用可能就会创建一个数据库连接，此时就势必会频繁地创建和销毁数据库连接，性能是非常低下；")]),a._v(" "),t("p",[a._v("如果用foreachPartitions算子一次性处理一个partition的数据，那么对于每个partition，只要创建一个数据库连接即可，然后执行批量插入操作，此时性能是比较高的。实践中发现，对于1万条左右的数据量写MySQL，性能可以提升30%以上。")]),a._v(" "),t("h3",{attrs:{id:"filter之后进行coalesce操作"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#filter之后进行coalesce操作"}},[a._v("#")]),a._v(" filter之后进行coalesce操作")]),a._v(" "),t("p",[a._v("通常对一个RDD执行filter算子过滤掉RDD中较多数据后（比如30%以上的数据），建议使用coalesce算子，手动减少RDD的partition数量，将RDD中的数据压缩到更少的partition中去。")]),a._v(" "),t("p",[a._v("filter之后，RDD的每个partition中都会有很多数据被过滤掉，此时如果照常进行后续的计算，其实每个task处理的partition中的数据量并不是很多，有一点资源浪费，而且此时处理的task越多，可能速度反而越慢。")]),a._v(" "),t("p",[a._v("用coalesce减少partition数量，将RDD中的数据压缩到更少的partition之后，只要使用更少的task即可处理完所有的partition。在某些场景下，对于性能的提升会有一定的帮助。")]),a._v(" "),t("h3",{attrs:{id:"使用repartitionandsortwithinpartitions替代repartition与sort类操作"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#使用repartitionandsortwithinpartitions替代repartition与sort类操作"}},[a._v("#")]),a._v(" 使用repartitionAndSortWithinPartitions替代repartition与sort类操作")]),a._v(" "),t("p",[a._v("repartitionAndSortWithinPartitions是Spark官网推荐的一个算子，官方建议，如果需要在repartition重分区之后，还要进行排序，建议直接使用repartitionAndSortWithinPartitions算子。因为该算子可以一边进行重分区的shuffle操作，一边进行排序。shuffle与sort两个操作同时进行，比先shuffle再sort来说，性能可能是要高的。")]),a._v(" "),t("h1",{attrs:{id:"kryo优化序列化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kryo优化序列化"}},[a._v("#")]),a._v(" Kryo优化序列化")]),a._v(" "),t("blockquote",[t("p",[a._v("Spark在进行任务计算的时候，会涉及到数据跨进程的网络传输、数据的持久化，这个时候就需要对数据进行序列化。")])]),a._v(" "),t("h2",{attrs:{id:"默认采用java的序列化器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#默认采用java的序列化器"}},[a._v("#")]),a._v(" 默认采用Java的序列化器")]),a._v(" "),t("h3",{attrs:{id:"优点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#优点"}},[a._v("#")]),a._v(" 优点")]),a._v(" "),t("p",[a._v("处理起来方便，不需要我们手动做其他操作，只是在使用一个对象和变量的时候，需要实现Serializble接口。")]),a._v(" "),t("h3",{attrs:{id:"缺点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#缺点"}},[a._v("#")]),a._v(" 缺点")]),a._v(" "),t("p",[a._v("默认的序列化机制的效率不高，序列化的速度比较慢；序列化以后的数据，占用的内存空间相对还是比较大。")]),a._v(" "),t("h2",{attrs:{id:"kryo序列化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kryo序列化"}},[a._v("#")]),a._v(" Kryo序列化")]),a._v(" "),t("blockquote",[t("p",[a._v("Spark支持使用Kryo序列化机制。Kryo序列化机制，比默认的Java序列化机制，速度要快，序列化后的数据要更小，大概是Java序列化机制的1/10。所以Kryo序列化优化以后，可以让网络传输的数据变少；在集群中耗费的内存资源大大减少。")])]),a._v(" "),t("p",[a._v("Kryo序列化机制，一旦启用以后，会生效的几个地方：")]),a._v(" "),t("h3",{attrs:{id:"_1、算子函数中使用到的外部变量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1、算子函数中使用到的外部变量"}},[a._v("#")]),a._v(" 1、算子函数中使用到的外部变量")]),a._v(" "),t("p",[a._v("算子中的外部变量可能来着与driver需要涉及到网络传输，就需要用到序列化。最终可以优化网络传输的性能，优化集群中内存的占用和消耗。")]),a._v(" "),t("h3",{attrs:{id:"持久化rdd时进行序列化-storagelevel-memory-only-ser"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#持久化rdd时进行序列化-storagelevel-memory-only-ser"}},[a._v("#")]),a._v(" 持久化RDD时进行序列化，StorageLevel.MEMORY_ONLY_SER")]),a._v(" "),t("p",[a._v("将rdd持久化时，对应的存储级别里，需要用到序列化。最终可以优化内存的占用和消耗；持久化RDD占用的内存越少，task执行的时候，创建的对象，就不至于频繁的占满内存，频繁发生GC。")]),a._v(" "),t("h3",{attrs:{id:"产生shuffle的地方-也就是宽依赖"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#产生shuffle的地方-也就是宽依赖"}},[a._v("#")]),a._v(" 产生shuffle的地方，也就是宽依赖")]),a._v(" "),t("p",[a._v("下游的stage中的task，拉取上游stage中的task产生的结果数据，跨网络传输，需要用到序列化。最终可以优化网络传输的性能.")]),a._v(" "),t("h3",{attrs:{id:"示例-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#示例-2"}},[a._v("#")]),a._v(" 示例")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v('// 创建SparkConf对象。\nval conf = new SparkConf().setMaster(...).setAppName(...)\n// 设置序列化器为KryoSerializer。\nconf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")\n\n// 注册要序列化的自定义类型。\nconf.registerKryoClasses(Array(classOf[MyClass1], classOf[MyClass2]))\n')])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br")])]),t("h1",{attrs:{id:"fastutil优化数据格式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#fastutil优化数据格式"}},[a._v("#")]),a._v(" fastutil优化数据格式")]),a._v(" "),t("blockquote",[t("p",[a._v("fastutil是扩展了Java标准集合框架（Map、List、Set；HashMap、ArrayList、HashSet）的类库，提供了特殊类型的map、set、list和queue；\nfastutil能够提供更小的内存占用，更快的存取速度；我们使用fastutil提供的集合类，来替代自己平时使用的JDK的原生的Map、List、Set.")])]),a._v(" "),t("h2",{attrs:{id:"fastutil有点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#fastutil有点"}},[a._v("#")]),a._v(" fastutil有点")]),a._v(" "),t("p",[a._v("fastutil集合类，可以减小内存的占用，并且在进行集合的遍历、根据索引（或者key）获取元素的值和设置元素的值的时候，提供更快的存取速度；")]),a._v(" "),t("h2",{attrs:{id:"spark中应用fastutil的场景和使用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark中应用fastutil的场景和使用"}},[a._v("#")]),a._v(" Spark中应用fastutil的场景和使用")]),a._v(" "),t("h3",{attrs:{id:"算子函数使用了外部变量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#算子函数使用了外部变量"}},[a._v("#")]),a._v(" 算子函数使用了外部变量")]),a._v(" "),t("p",[a._v("（1）你可以使用Broadcast广播变量优化；")]),a._v(" "),t("p",[a._v("（2）可以使用Kryo序列化类库，提升序列化性能和效率；")]),a._v(" "),t("p",[a._v("（3）如果外部变量是某种比较大的集合，那么可以考虑使用fastutil改写外部变量；")]),a._v(" "),t("p",[a._v("首先从源头上就减少内存的占用(fastutil)，通过广播变量进一步减少内存占用，再通过Kryo序列化类库进一步减少内存占用。")]),a._v(" "),t("h3",{attrs:{id:"算子函数里使用了比较大的集合map-list"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#算子函数里使用了比较大的集合map-list"}},[a._v("#")]),a._v(" 算子函数里使用了比较大的集合Map/List")]),a._v(" "),t("p",[a._v("在你的算子函数里，也就是task要执行的计算逻辑里面，如果有逻辑中，出现，要创建比较大的Map、List等集合，可能会占用较大的内存空间，而且可能涉及到消耗性能的遍历、存取等集合操作；")]),a._v(" "),t("p",[a._v("此时，可以考虑将这些集合类型使用fastutil类库重写，")]),a._v(" "),t("p",[a._v("使用了fastutil集合类以后，就可以在一定程度上，减少task创建出来的集合类型的内存占用。 避免executor内存频繁占满，频繁唤起GC，导致性能下降。")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("第一步：在pom.xml中引用fastutil的包\n    <dependency>\n      <groupId>fastutil</groupId>\n      <artifactId>fastutil</artifactId>\n      <version>5.0.9</version>\n    </dependency>\n    \n第二步：平时使用List （Integer）的替换成IntList即可。 \n\tList<Integer>的list对应的到fastutil就是IntList类型\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br")])]),t("h3",{attrs:{id:"使用说明"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#使用说明"}},[a._v("#")]),a._v(" 使用说明")]),a._v(" "),t("p",[a._v("基本都是类似于IntList的格式，前缀就是集合的元素类型； 特殊的就是Map，Int2IntMap，代表了key-value映射的元素类型。")]),a._v(" "),t("h1",{attrs:{id:"调节数据本地化等待时长"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#调节数据本地化等待时长"}},[a._v("#")]),a._v(" 调节数据本地化等待时长")]),a._v(" "),t("p",[a._v("Spark在Driver上对Application的每一个stage的task进行分配之前，都会计算出每个task要计算的是哪个分片数据，RDD的某个partition；Spark的task分配算法，优先会希望每个task正好分配到它要计算的数据所在的节点，这样的话就不用在网络间传输数据；")]),a._v(" "),t("p",[a._v("但是通常来说，有时事与愿违，可能task没有机会分配到它的数据所在的节点，为什么呢，可能那个节点的计算资源和计算能力都满了；所以这种时候，通常来说，Spark会等待一段时间，默认情况下是3秒（不是绝对的，还有很多种情况，对不同的本地化级别，都会去等待），到最后实在是等待不了了，就会选择一个比较差的本地化级别，比如说将task分配到距离要计算的数据所在节点比较近的一个节点，然后进行计算。")]),a._v(" "),t("h2",{attrs:{id:"本地化级别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#本地化级别"}},[a._v("#")]),a._v(" 本地化级别")]),a._v(" "),t("h3",{attrs:{id:"process-local"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#process-local"}},[a._v("#")]),a._v(" PROCESS_LOCAL")]),a._v(" "),t("p",[a._v("PROCESS_LOCAL：进程本地化。代码和数据在同一个进程中，也就是在同一个executor中；计算数据的task由executor执行，数据在executor的BlockManager中；性能最好")]),a._v(" "),t("h3",{attrs:{id:"node-local"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#node-local"}},[a._v("#")]),a._v(" NODE_LOCAL")]),a._v(" "),t("p",[a._v("NODE_LOCAL：节点本地化。代码和数据在同一个节点中；比如说数据作为一个HDFS block块，就在节点上，而task在节点上某个executor中运行；或者是数据和task在一个节点上的不同executor中；数据需要在进程间进行传输；性能其次。")]),a._v(" "),t("h3",{attrs:{id:"rack-local"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rack-local"}},[a._v("#")]),a._v(" RACK_LOCAL")]),a._v(" "),t("p",[a._v("RACK_LOCAL：机架本地化。数据和task在一个机架的两个节点上；数据需要通过网络在节点之间进行传输； 性能比较差。")]),a._v(" "),t("h3",{attrs:{id:"any"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#any"}},[a._v("#")]),a._v(" ANY")]),a._v(" "),t("p",[a._v("ANY：无限制。数据和task可能在集群中的任何地方，而且不在一个机架中；性能最差。")]),a._v(" "),t("h2",{attrs:{id:"本地化级别参数设置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#本地化级别参数设置"}},[a._v("#")]),a._v(" 本地化级别参数设置")]),a._v(" "),t("h3",{attrs:{id:"spark-locality-wait"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-locality-wait"}},[a._v("#")]),a._v(" spark.locality.wait")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("spark.locality.wait，默认是3s\n首先采用最佳的方式，等待3s后降级,还是不行，继续降级...,最后还是不行，只能够采用最差的。\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br")])]),t("h3",{attrs:{id:"不同级别的时间设置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#不同级别的时间设置"}},[a._v("#")]),a._v(" 不同级别的时间设置")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("修改spark.locality.wait参数，默认是3s，可以增加\n\n下面是每个数据本地化级别的等待时间，默认都是跟spark.locality.wait时间相同，\n默认都是3s(可查看spark官网对应参数说明，如下图所示)\nspark.locality.wait.node\nspark.locality.wait.process\nspark.locality.wait.rack\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br")])]),t("p",[t("img",{attrs:{src:"https://kflys.gitee.io/upic/2021/spark/1612346460913-3991630e-d6b1-43cd-bb76-327af15bbdc8.png#align=left&display=inline&height=319&margin=%5Bobject%20Object%5D&originHeight=319&originWidth=1170&size=0&status=done&style=none&width=1170",alt:""}})]),a._v(" "),t("h3",{attrs:{id:"在代码中设置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#在代码中设置"}},[a._v("#")]),a._v(" 在代码中设置")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v('new SparkConf().set("spark.locality.wait","10")\n')])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("p",[a._v("然后把程序提交到spark集群中运行，注意观察日志，spark作业的运行日志，推荐大家在测试的时候，先用client模式，在本地就直接可以看到比较全的日志。\n日志里面会显示，")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("starting task .... PROCESS LOCAL、NODE LOCAL.....\nStarting task 0.0 in stage 1.0 (TID 2, 192.168.200.102, partition 0, NODE_LOCAL, 5254 bytes)\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br")])]),t("p",[a._v("观察大部分task的数据本地化级别,如果大多都是PROCESS_LOCAL，那就不用调节了。如果是发现，多数的级别都是NODE_LOCAL、ANY，那么最好就去调节一下数据本地化的等待时长。应该是要反复调节，每次调节完以后，再来运行，观察日志\n看看大部分的task的本地化级别有没有提升；看看整个spark作业的运行时间有没有缩短。")]),a._v(" "),t("blockquote",[t("p",[a._v("在调节参数、运行任务的时候，别本末倒置，本地化级别倒是提升了， 但是因为大量的等待时长，spark作业的运行时间反而增加了，那就还是不要调节了。")])]),a._v(" "),t("h3",{attrs:{id:"spark内存模型调优"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark内存模型调优"}},[a._v("#")]),a._v(" Spark内存模型调优")]),a._v(" "),t("h4",{attrs:{id:"spark中executor内存划分"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark中executor内存划分"}},[a._v("#")]),a._v(" spark中executor内存划分")]),a._v(" "),t("ul",[t("li",[a._v("Executor的内存主要分为三块\n"),t("ul",[t("li",[a._v("第一块是让task执行我们自己编写的代码时使用；")]),a._v(" "),t("li",[a._v("第二块是让task通过shuffle过程拉取了上一个stage的task的输出后，进行聚合等操作时使用")]),a._v(" "),t("li",[a._v("第三块是让RDD缓存时使用")])])])]),a._v(" "),t("h1",{attrs:{id:"spark的内存模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark的内存模型"}},[a._v("#")]),a._v(" spark的内存模型")]),a._v(" "),t("blockquote",[t("p",[a._v("在spark1.6版本以前 spark的executor使用的静态内存模型，但是在spark1.6开始，多增加了一个统一内存模型。通过spark.memory.useLegacyMode 这个参数去配置默认这个值是false，代表用的是新的动态内存模型；如果想用以前的静态内存模型，那么就要把这个值改为true。")])]),a._v(" "),t("h2",{attrs:{id:"静态内存模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#静态内存模型"}},[a._v("#")]),a._v(" 静态内存模型")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/kflys/uPic/raw/master/uPic/1612346460925-9592565a-6afd-43e2-bb6c-63ae8eccbb85.png",alt:"img"}})]),a._v(" "),t("p",[a._v("实际上就是把我们的一个executor分成了三部分，一部分是Storage内存区域，一部分是execution区域，还有一部分是其他区域。如果使用的静态内存模型，那么用这几个参数去控制：")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("spark.storage.memoryFraction：# 默认0.6\n\nspark.shuffle.memoryFraction： # 默认0.2 \n# 所以第三部分就是0.2\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br")])]),t("p",[a._v("如果我们cache数据量比较大，或者是我们的广播变量比较大，\n那我们就把spark.storage.memoryFraction这个值调大一点。\n但是如果我们代码里面没有广播变量，也没有cache，shuffle又比较多，那我们要把spark.shuffle.memoryFraction 这值调大。")]),a._v(" "),t("h3",{attrs:{id:"静态内存模型的缺点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#静态内存模型的缺点"}},[a._v("#")]),a._v(" 静态内存模型的缺点")]),a._v(" "),t("p",[a._v("我们配置好了Storage内存区域和execution区域后，我们的一个任务假设execution内存不够用了，但是它的Storage内存区域是空闲的，两个之间不能互相借用，不够灵活，所以才出来我们新的统一内存模型。")]),a._v(" "),t("h2",{attrs:{id:"统一内存模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#统一内存模型"}},[a._v("#")]),a._v(" 统一内存模型")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/kflys/uPic/raw/master/uPic/1612346460915-c289c8df-f8a6-4701-8c83-b78ff01d93b6.png",alt:"img"}})]),a._v(" "),t("p",[a._v("动态内存模型先是预留了300m内存，防止内存溢出。动态内存模型把整体内存分成了两部分，\n由这个参数表示spark.memory.fraction 这个指的默认值是0.6 代表另外的一部分是0.4,")]),a._v(" "),t("p",[a._v("spark.memory.fraction 这部分又划分成为两个小部分。这两小部分共占整体内存的0.6 .这两部分其实就是：Storage内存和execution内存。由spark.memory.storageFraction 这个参数去调配，因为两个共占0.6。如果spark.memory.storageFraction这个值配的是0.5,那说明这0.6里面 storage占了0.5，也就是execution占了0.3 。")]),a._v(" "),t("h3",{attrs:{id:"统一内存模型特点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#统一内存模型特点"}},[a._v("#")]),a._v(" 统一内存模型特点")]),a._v(" "),t("p",[a._v("Storage内存和execution内存 可以相互借用。不用像静态内存模型那样死板，但是是有规则的")]),a._v(" "),t("h4",{attrs:{id:"场景一"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#场景一"}},[a._v("#")]),a._v(" 场景一")]),a._v(" "),t("p",[a._v("Execution使用的时候发现内存不够了，然后就会把storage的内存里的数据驱逐到磁盘上。")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/kflys/uPic/raw/master/uPic/1612346460942-a72508f1-84c7-421c-9e0a-22a5b2787ea5.png",alt:"img"}})]),a._v(" "),t("h4",{attrs:{id:"场景二"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#场景二"}},[a._v("#")]),a._v(" 场景二")]),a._v(" "),t("p",[a._v("一开始execution的内存使用得不多，但是storage使用的内存多，所以storage就借用了execution的内存，但是后来execution也要需要内存了，这个时候就会把storage的内存里的数据写到磁盘上，腾出内存空间。")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/kflys/uPic/raw/master/uPic/1612346460927-cac57f5c-b2a2-4262-b747-f0e16a8bf033.png",alt:"img"}})]),a._v(" "),t("h3",{attrs:{id:"为什么受伤的都是storage"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#为什么受伤的都是storage"}},[a._v("#")]),a._v(" 为什么受伤的都是storage")]),a._v(" "),t("p",[a._v("是因为execution里面的数据是马上就要用的，而storage里的数据不一定马上就要用。")]),a._v(" "),t("h1",{attrs:{id:"任务提交脚本参考"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#任务提交脚本参考"}},[a._v("#")]),a._v(" 任务提交脚本参考")]),a._v(" "),t("p",[a._v("以下是一份spark-submit命令的示例，大家可以参考一下，并根据自己的实际情况进行调节")]),a._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[a._v("./bin/spark-submit "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  --master yarn-cluster "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  --num-executors "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("100")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  --executor-memory 6G "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  --executor-cores "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  --driver-memory 1G "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  --conf spark.default.parallelism"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1000")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  --conf spark.storage.memoryFraction"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.5")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  --conf spark.shuffle.memoryFraction"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.3")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br")])]),t("h2",{attrs:{id:"内存问题常见异常"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#内存问题常见异常"}},[a._v("#")]),a._v(" 内存问题常见异常")]),a._v(" "),t("p",[a._v("java.lang.OutOfMemoryError")]),a._v(" "),t("p",[a._v("ExecutorLostFailure")]),a._v(" "),t("p",[a._v("Executor exit code 为143")]),a._v(" "),t("p",[a._v("executor lost")]),a._v(" "),t("p",[a._v("hearbeat time out")]),a._v(" "),t("p",[a._v("shuffle file lost")]),a._v(" "),t("p",[a._v("如果遇到以上问题，很有可能就是内存除了问题，可以先尝试增加内存。如果还是解决不了，那么请听下一次数据倾斜调优的课。")])])}),[],!1,null,null,null);s.default=e.exports}}]);