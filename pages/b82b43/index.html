<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Spark Core常用优化 | clivia‘s blog</title>
    <meta name="generator" content="VuePress 1.8.0">
    <link rel="icon" href="/img/favicon.ico">
    <script data-ad-client="ca-pub-7828333725993554" async="async" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <meta name="description" content="Java后端、大数据等技术博客，专注于各种技术总结。Java、高并发、hadoop、spark、hbase、hive、zookeeper、mysql、mongodb、redis">
    <meta name="keywords" content="前端博客,个人技术博客,前端,前端开发,前端框架,web前端,前端面试题,技术文档,学习,面试,JavaScript,js,ES6,TypeScript,vue,python,css3,html5,Node,git,github,markdown">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    <link rel="preload" href="/assets/css/0.styles.027adcb0.css" as="style"><link rel="preload" href="/assets/js/app.06f86fe0.js" as="script"><link rel="preload" href="/assets/js/2.ed69dcfc.js" as="script"><link rel="preload" href="/assets/js/3.b6cd915d.js" as="script"><link rel="preload" href="/assets/js/100.16d5c2bc.js" as="script"><link rel="prefetch" href="/assets/js/10.2b0a2d8d.js"><link rel="prefetch" href="/assets/js/101.c4ff0a78.js"><link rel="prefetch" href="/assets/js/102.4e574824.js"><link rel="prefetch" href="/assets/js/103.ac1661b8.js"><link rel="prefetch" href="/assets/js/104.dfdf274c.js"><link rel="prefetch" href="/assets/js/105.f792ba33.js"><link rel="prefetch" href="/assets/js/106.4347b2a7.js"><link rel="prefetch" href="/assets/js/107.7248a258.js"><link rel="prefetch" href="/assets/js/108.a3c43671.js"><link rel="prefetch" href="/assets/js/109.e8c087b3.js"><link rel="prefetch" href="/assets/js/11.0c3d61f1.js"><link rel="prefetch" href="/assets/js/110.2b89ad56.js"><link rel="prefetch" href="/assets/js/111.d35e07d0.js"><link rel="prefetch" href="/assets/js/112.2402331a.js"><link rel="prefetch" href="/assets/js/113.82a39665.js"><link rel="prefetch" href="/assets/js/114.4c8d3fcb.js"><link rel="prefetch" href="/assets/js/115.f038010e.js"><link rel="prefetch" href="/assets/js/116.c7865d0c.js"><link rel="prefetch" href="/assets/js/117.2729b824.js"><link rel="prefetch" href="/assets/js/118.b8c9bb1f.js"><link rel="prefetch" href="/assets/js/119.a9eea003.js"><link rel="prefetch" href="/assets/js/12.e4b75a11.js"><link rel="prefetch" href="/assets/js/120.06f1eb1b.js"><link rel="prefetch" href="/assets/js/121.354a7fd4.js"><link rel="prefetch" href="/assets/js/122.af00dd2b.js"><link rel="prefetch" href="/assets/js/123.976e22ad.js"><link rel="prefetch" href="/assets/js/124.de810dba.js"><link rel="prefetch" href="/assets/js/125.2c17fa05.js"><link rel="prefetch" href="/assets/js/126.ffeb8997.js"><link rel="prefetch" href="/assets/js/127.6b2f64dd.js"><link rel="prefetch" href="/assets/js/128.f9b62119.js"><link rel="prefetch" href="/assets/js/129.ce5c5c0e.js"><link rel="prefetch" href="/assets/js/13.2c54c92b.js"><link rel="prefetch" href="/assets/js/130.7db38d34.js"><link rel="prefetch" href="/assets/js/131.5abdd66a.js"><link rel="prefetch" href="/assets/js/132.5dd5eece.js"><link rel="prefetch" href="/assets/js/133.651d4b9b.js"><link rel="prefetch" href="/assets/js/134.68173250.js"><link rel="prefetch" href="/assets/js/135.ca520569.js"><link rel="prefetch" href="/assets/js/136.1515cd12.js"><link rel="prefetch" href="/assets/js/137.d783808b.js"><link rel="prefetch" href="/assets/js/138.05efd534.js"><link rel="prefetch" href="/assets/js/139.a65dce22.js"><link rel="prefetch" href="/assets/js/14.5cb33b3a.js"><link rel="prefetch" href="/assets/js/140.44dc5c4e.js"><link rel="prefetch" href="/assets/js/141.0632e3aa.js"><link rel="prefetch" href="/assets/js/142.66ac9883.js"><link rel="prefetch" href="/assets/js/143.8a75f55a.js"><link rel="prefetch" href="/assets/js/144.349bba43.js"><link rel="prefetch" href="/assets/js/15.06dff62d.js"><link rel="prefetch" href="/assets/js/16.ad74e0a9.js"><link rel="prefetch" href="/assets/js/17.e0d7a93c.js"><link rel="prefetch" href="/assets/js/18.0c217b19.js"><link rel="prefetch" href="/assets/js/19.33d29011.js"><link rel="prefetch" href="/assets/js/20.5c47e53a.js"><link rel="prefetch" href="/assets/js/21.4623dcf3.js"><link rel="prefetch" href="/assets/js/22.1d2819bf.js"><link rel="prefetch" href="/assets/js/23.da3264cc.js"><link rel="prefetch" href="/assets/js/24.a3976766.js"><link rel="prefetch" href="/assets/js/25.52b1b746.js"><link rel="prefetch" href="/assets/js/26.527a58d4.js"><link rel="prefetch" href="/assets/js/27.1a611ca9.js"><link rel="prefetch" href="/assets/js/28.19848920.js"><link rel="prefetch" href="/assets/js/29.0399b7cc.js"><link rel="prefetch" href="/assets/js/30.f4967fc4.js"><link rel="prefetch" href="/assets/js/31.ec15c096.js"><link rel="prefetch" href="/assets/js/32.ea29ed83.js"><link rel="prefetch" href="/assets/js/33.2506e8df.js"><link rel="prefetch" href="/assets/js/34.b317cb6a.js"><link rel="prefetch" href="/assets/js/35.e98b1f8e.js"><link rel="prefetch" href="/assets/js/36.5a3c937d.js"><link rel="prefetch" href="/assets/js/37.d8e66f15.js"><link rel="prefetch" href="/assets/js/38.583bd78a.js"><link rel="prefetch" href="/assets/js/39.02884927.js"><link rel="prefetch" href="/assets/js/4.4f8d037f.js"><link rel="prefetch" href="/assets/js/40.11d31d5e.js"><link rel="prefetch" href="/assets/js/41.e3b7229f.js"><link rel="prefetch" href="/assets/js/42.ed31fd5c.js"><link rel="prefetch" href="/assets/js/43.71601b99.js"><link rel="prefetch" href="/assets/js/44.7235eb98.js"><link rel="prefetch" href="/assets/js/45.8adef6f7.js"><link rel="prefetch" href="/assets/js/46.44d68224.js"><link rel="prefetch" href="/assets/js/47.ec6b4de8.js"><link rel="prefetch" href="/assets/js/48.ee56118d.js"><link rel="prefetch" href="/assets/js/49.0f6101ee.js"><link rel="prefetch" href="/assets/js/5.0e4db68d.js"><link rel="prefetch" href="/assets/js/50.2d01b40c.js"><link rel="prefetch" href="/assets/js/51.ddf132cb.js"><link rel="prefetch" href="/assets/js/52.fbc9619b.js"><link rel="prefetch" href="/assets/js/53.089b304e.js"><link rel="prefetch" href="/assets/js/54.34c0d377.js"><link rel="prefetch" href="/assets/js/55.41e71cff.js"><link rel="prefetch" href="/assets/js/56.ed6b0ac8.js"><link rel="prefetch" href="/assets/js/57.538bf884.js"><link rel="prefetch" href="/assets/js/58.d0051104.js"><link rel="prefetch" href="/assets/js/59.00792d53.js"><link rel="prefetch" href="/assets/js/6.6a15c5c7.js"><link rel="prefetch" href="/assets/js/60.44529245.js"><link rel="prefetch" href="/assets/js/61.6a6e2fe6.js"><link rel="prefetch" href="/assets/js/62.b02509d6.js"><link rel="prefetch" href="/assets/js/63.c865f599.js"><link rel="prefetch" href="/assets/js/64.7aafe0f4.js"><link rel="prefetch" href="/assets/js/65.029254a7.js"><link rel="prefetch" href="/assets/js/66.1d8c00be.js"><link rel="prefetch" href="/assets/js/67.191949ec.js"><link rel="prefetch" href="/assets/js/68.fc11d430.js"><link rel="prefetch" href="/assets/js/69.5e5d346e.js"><link rel="prefetch" href="/assets/js/7.4353a828.js"><link rel="prefetch" href="/assets/js/70.61cd3f71.js"><link rel="prefetch" href="/assets/js/71.1a87ddd4.js"><link rel="prefetch" href="/assets/js/72.f561b5cf.js"><link rel="prefetch" href="/assets/js/73.d1c67ae7.js"><link rel="prefetch" href="/assets/js/74.3725d6d7.js"><link rel="prefetch" href="/assets/js/75.310c7556.js"><link rel="prefetch" href="/assets/js/76.b8a53386.js"><link rel="prefetch" href="/assets/js/77.e04be33a.js"><link rel="prefetch" href="/assets/js/78.17c06f28.js"><link rel="prefetch" href="/assets/js/79.3ff2fb40.js"><link rel="prefetch" href="/assets/js/8.248194f5.js"><link rel="prefetch" href="/assets/js/80.96d575dc.js"><link rel="prefetch" href="/assets/js/81.770ca2a4.js"><link rel="prefetch" href="/assets/js/82.8900493c.js"><link rel="prefetch" href="/assets/js/83.4716d242.js"><link rel="prefetch" href="/assets/js/84.5ae9874f.js"><link rel="prefetch" href="/assets/js/85.924e7d3d.js"><link rel="prefetch" href="/assets/js/86.5073d16d.js"><link rel="prefetch" href="/assets/js/87.1148acd0.js"><link rel="prefetch" href="/assets/js/88.629d8beb.js"><link rel="prefetch" href="/assets/js/89.36b4cdb0.js"><link rel="prefetch" href="/assets/js/9.85151a25.js"><link rel="prefetch" href="/assets/js/90.fac275aa.js"><link rel="prefetch" href="/assets/js/91.93484ec9.js"><link rel="prefetch" href="/assets/js/92.01e42c63.js"><link rel="prefetch" href="/assets/js/93.50a55dd7.js"><link rel="prefetch" href="/assets/js/94.6a3f96c8.js"><link rel="prefetch" href="/assets/js/95.7dd7befb.js"><link rel="prefetch" href="/assets/js/96.38d049b2.js"><link rel="prefetch" href="/assets/js/97.a129eb48.js"><link rel="prefetch" href="/assets/js/98.f848c937.js"><link rel="prefetch" href="/assets/js/99.2dc3271b.js">
    <link rel="stylesheet" href="/assets/css/0.styles.027adcb0.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/img/C-logo.png" alt="clivia‘s blog" class="logo"> <span class="site-name can-hide">clivia‘s blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/bigdata/" class="nav-link">大数据</a></div><div class="nav-item"><a href="/technology/" class="nav-link">技术</a></div><div class="nav-item"><a href="/project/" class="nav-link">项目</a></div><div class="nav-item"><a href="/more/" class="nav-link">更多</a></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://gitee.com/kflys/clivia-blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    Gitee
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="/img/logo.png"> <div class="blogger-info"><h3>clivia’s blog</h3> <span>专注于后端开发，致力于简洁知识。</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/bigdata/" class="nav-link">大数据</a></div><div class="nav-item"><a href="/technology/" class="nav-link">技术</a></div><div class="nav-item"><a href="/project/" class="nav-link">项目</a></div><div class="nav-item"><a href="/more/" class="nav-link">更多</a></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://gitee.com/kflys/clivia-blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    Gitee
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Spark Core</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/64b489/" class="sidebar-link">Spark基础简介</a></li><li><a href="/pages/26b095/" class="sidebar-link">Spark RDD</a></li><li><a href="/pages/4ccb94/" class="sidebar-link">Spark任务调度</a></li><li><a href="/pages/b82b43/" aria-current="page" class="active sidebar-link">Spark Core常用优化</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/pages/b82b43/#分配哪些资源" class="sidebar-link">分配哪些资源</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/pages/b82b43/#executor-memory" class="sidebar-link">executor-memory</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#executor-cores" class="sidebar-link">executor-cores</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#executor-memory-2" class="sidebar-link">executor-memory</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#driver-memory" class="sidebar-link">driver-memory</a></li></ul></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#如何进行分配" class="sidebar-link">如何进行分配</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/pages/b82b43/#standalone模式" class="sidebar-link">Standalone模式</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#yarn模式" class="sidebar-link">Yarn模式</a></li></ul></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#具体分析" class="sidebar-link">具体分析</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#task的数量" class="sidebar-link">task的数量</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#如何设置task数量" class="sidebar-link">如何设置task数量</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/pages/b82b43/#spark-defalut-parallelism" class="sidebar-link">spark.defalut.parallelism</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#rdd-repartition" class="sidebar-link">rdd.repartition</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#spark-sql-shuffle-partitions" class="sidebar-link">spark.sql.shuffle.partitions</a></li></ul></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#实际开发遇到的情况说明" class="sidebar-link">实际开发遇到的情况说明</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#rdd持久化" class="sidebar-link">rdd持久化</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/pages/b82b43/#可以调用rdd的cache或者persist方法。" class="sidebar-link">可以调用rdd的cache或者persist方法。</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#rdd持久化-采用序列化" class="sidebar-link">rdd持久化，采用序列化</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#广播变量的使用" class="sidebar-link">广播变量的使用</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#使用广播变量前后的性能分析" class="sidebar-link">使用广播变量前后的性能分析</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#广播变量使用注意事项" class="sidebar-link">广播变量使用注意事项</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#示例" class="sidebar-link">示例</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#会产生shuffle的算子" class="sidebar-link">会产生shuffle的算子</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#避免产生shuffle" class="sidebar-link">避免产生shuffle</a></li></ul></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#使用map-side预聚合的shuffle操作" class="sidebar-link">使用map-side预聚合的shuffle操作</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/pages/b82b43/#map-side预聚合" class="sidebar-link">map-side预聚合</a></li></ul></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#高性能的算子" class="sidebar-link">高性能的算子</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/pages/b82b43/#mappartitions" class="sidebar-link">mapPartitions</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#foreachpartitions类的算子" class="sidebar-link">foreachPartitions类的算子</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#filter之后进行coalesce操作" class="sidebar-link">filter之后进行coalesce操作</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#使用repartitionandsortwithinpartitions替代repartition与sort类操作" class="sidebar-link">使用repartitionAndSortWithinPartitions替代repartition与sort类操作</a></li></ul></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#默认采用java的序列化器" class="sidebar-link">默认采用Java的序列化器</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/pages/b82b43/#优点" class="sidebar-link">优点</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#缺点" class="sidebar-link">缺点</a></li></ul></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#kryo序列化" class="sidebar-link">Kryo序列化</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/pages/b82b43/#_1、算子函数中使用到的外部变量" class="sidebar-link">1、算子函数中使用到的外部变量</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#持久化rdd时进行序列化-storagelevel-memory-only-ser" class="sidebar-link">持久化RDD时进行序列化，StorageLevel.MEMORYONLYSER</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#产生shuffle的地方-也就是宽依赖" class="sidebar-link">产生shuffle的地方，也就是宽依赖</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#示例-2" class="sidebar-link">示例</a></li></ul></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#fastutil有点" class="sidebar-link">fastutil有点</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#spark中应用fastutil的场景和使用" class="sidebar-link">Spark中应用fastutil的场景和使用</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/pages/b82b43/#算子函数使用了外部变量" class="sidebar-link">算子函数使用了外部变量</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#算子函数里使用了比较大的集合map-list" class="sidebar-link">算子函数里使用了比较大的集合Map/List</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#使用说明" class="sidebar-link">使用说明</a></li></ul></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#本地化级别" class="sidebar-link">本地化级别</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/pages/b82b43/#process-local" class="sidebar-link">PROCESS_LOCAL</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#node-local" class="sidebar-link">NODE_LOCAL</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#rack-local" class="sidebar-link">RACK_LOCAL</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#any" class="sidebar-link">ANY</a></li></ul></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#本地化级别参数设置" class="sidebar-link">本地化级别参数设置</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/pages/b82b43/#spark-locality-wait" class="sidebar-link">spark.locality.wait</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#不同级别的时间设置" class="sidebar-link">不同级别的时间设置</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#在代码中设置" class="sidebar-link">在代码中设置</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#spark内存模型调优" class="sidebar-link">Spark内存模型调优</a></li></ul></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#静态内存模型" class="sidebar-link">静态内存模型</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/pages/b82b43/#静态内存模型的缺点" class="sidebar-link">静态内存模型的缺点</a></li></ul></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#统一内存模型" class="sidebar-link">统一内存模型</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/pages/b82b43/#统一内存模型特点" class="sidebar-link">统一内存模型特点</a></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#为什么受伤的都是storage" class="sidebar-link">为什么受伤的都是storage</a></li></ul></li><li class="sidebar-sub-header"><a href="/pages/b82b43/#内存问题常见异常" class="sidebar-link">内存问题常见异常</a></li></ul></li><li><a href="/pages/f03bcf/" class="sidebar-link">Spark Shuffle原理分析</a></li><li><a href="/pages/1588b9/" class="sidebar-link">Spark or Flink中Broadcast维表更新</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Spark SQL</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Spark Streaming</span> <span class="arrow right"></span></p> <!----></section></li></ul> <div class="sidebar-slot sidebar-slot-bottom"><!-- 正方形 -->
      <ins class="adsbygoogle"
          style="display:block"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="3508773082"
          data-ad-format="auto"
          data-full-width-responsive="true"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script></div></aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-70a2d273><div class="articleInfo" data-v-70a2d273><ul class="breadcrumbs" data-v-70a2d273><li data-v-70a2d273><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-70a2d273></a></li> <li data-v-70a2d273><a href="/categories/?category=%E3%80%8ASpark%E3%80%8B%E7%AC%94%E8%AE%B0" title="分类" data-v-70a2d273>《Spark》笔记</a></li> <li data-v-70a2d273><a href="/categories/?category=Spark%20Core" title="分类" data-v-70a2d273>Spark Core</a></li> <!----></ul> <div class="info" data-v-70a2d273><div title="作者" class="author iconfont icon-touxiang" data-v-70a2d273><a href="https://gitee.com/kflys" target="_blank" title="作者" class="beLink" data-v-70a2d273>kflys</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-70a2d273><a href="javascript:;" data-v-70a2d273>2021-09-30</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABH1JREFUSA3tVl1oHFUUPmdmd2ltklqbpJDiNnXFmgbFktho7YMPNiJSSZM0+CAYSkUELVhM6YuwIPpgoOKDqOBDC0XE2CQoNtQXBUFTTcCi+Wlh1V2TQExsUzcltd3M9Tt3ZjZzZ2fT+OJTL8yeM+eee757fmeJbq//KQL8X3DUSFOcfr7cRsRtxNQMWueeVzOkaITIGqQHNg5y8+jNW9ldM7A6nTpAjuolUikAwq7CE3WcM2RRDz+XGVgN3FptU/aUSlvq9Pa3iZ1+sgAqJyyAFqkipd9dqiwHF3P65YycLWc/6sqGrvoEoIp6DOFaX5h6+dnfjkWprwqsPk0dUGq5vySwDImC10KxFHgGL1SWoc92O3eVht09qdXNH11I2SsTsJYqMWzihqGMi+A+Garf3BAuuLI5oGlULyNfyB/HYNujwktOfRrMr5t77NmevqaUopx0grnKAyvVpmwUDB4x6FPXuGvYLTDwWsejwgtgkYKPqRJg8SV6xaiZ3ZTppGneS4yfH5/66fZSDHv+QZci/+h5c5UHtpy67JUqGppM0sh0Nc1dW6/N1W5Yoqat8/TU/VnadmdeW2PLLSyh0cvxBs3KbqTmwYPpxN4do/mzE8nEpvX/UMu2Wbp74zUAK5q6WkHns7V0eWkdPbPzd3rxkTGybadYySumVzhcaJFbs5UrEkQ/+CK8gF5dnh/6ciIZ73gwQ927L1IitoxKLXYP3SjYdOrHHfTZhRRlFyrorafPk20B3HPD1y2G3qKZME5Jcf3t/HUC13/8tSd++vqFveMUTwAUxSUFI1QekR1+bIze3D9MF2aq6cPvG72CgnldWCFqyRw3lwH8ZMerjTD9ElRO7Gv44wNpC90aASqGfVlz/Rx17srQ57/UU26hkhQqUB7dBR71WmzQhHUnblGmVOEw0jhbV1n9OlXUDCIRGaNV5Jp43N516fN7JmnTHdfp7Hgy0luO4aMhtkLL8Bi3bUWYvzh5Mn1dTxrL6QmGuRhGL/TiTTxRoEdTszSaq9GR0NGA3KdkOz3hqSV3MIDhQ5IVX/Ivx3umBti2es2h4eZby7x8br1rkf7Mo90AqC8aQ3sJeNzqFRu+vSANAQe3PL7l0HGOAdwDCeZYvNKeoZp1Qfs6Aipndh86HmFRi0LAnEO47wsqM6cdfjh3jBPUzhZy7nvlUfFsamED1VQt6aISHVymXZ/B2aCtIG8AI8xfobj2d3en1wWVhOeHELKmLQ1s211s88comkv4UCwWyF787mJdYXtNfhKAXVqnKTq8QZvGAGGOfaTo5pGZ/PwbUCr5+DPr/1J92JNHr9aOl/F3iI5+O1nfybsGxoimvZ3ViWSluDITw3P37mypheDIPY0tw7+O/5ApbkYw+zpfaUVu32Pi98+defdUhEpZkRFq0aqyNh9FuL9hpYbEm6iwi0z2REd09ZmyENEbuhjDWzKvZXTqKYaBIr3tt5kuPtQBZFvEUwHt60vfCNu41XsksH9Ij1BMMz1Y0OOunHNShFIP5868g5zeXmuLwL9T4b6Q2+KejgAAAABJRU5ErkJggg==">
          Spark Core常用优化
        </h1> <div class="page-slot page-slot-top"><!-- 固定100% * 90px可显示，max-height:90px未见显示-->
     <ins class="adsbygoogle"
          style="display:inline-block;width:100%;max-height:90px"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="6625304284"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script></div> <div class="theme-vdoing-content content__default"><h1 id="资源分配方面"><a href="#资源分配方面" class="header-anchor">#</a> 资源分配方面</h1> <blockquote><p>它是性能优化调优的王道，就是增加和分配更多的资源，这对于性能和速度上的提升是显而易见的，基本上，在一定范围之内，增加资源与性能的提升，是成正比的；写完了一个复杂的spark作业之后，进行性能调优的时候，首先第一步，就是要来调节最优的资源配置；在这个基础之上，如果说你的spark作业，能够分配的资源达到了你的能力范围的顶端之后，无法再分配更多的资源了，公司资源有限；那么才是考虑去做后面的这些性能调优的点。</p></blockquote> <h2 id="分配哪些资源"><a href="#分配哪些资源" class="header-anchor">#</a> 分配哪些资源</h2> <div class="language- line-numbers-mode"><pre class="language-text"><code>spark-submit --master spark://node1:7077  --class cn.itcast.WordCount --num-executors 3 --driver-memory 1g --executor-memory 1g --executor-cores 3 	/export/servers/wordcount.jar
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h3 id="executor-memory"><a href="#executor-memory" class="header-anchor">#</a> executor-memory</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>  --num-executors 3      配置executor的数量
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h3 id="executor-cores"><a href="#executor-cores" class="header-anchor">#</a> executor-cores</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code> --executor-cores 3    配置每一个executor的cpu个数
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h3 id="executor-memory-2"><a href="#executor-memory-2" class="header-anchor">#</a> executor-memory</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code> --executor-memory 1g  配置每一个executor的内存大小
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h3 id="driver-memory"><a href="#driver-memory" class="header-anchor">#</a> driver-memory</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code> --driver-memory 1g     配置driver的内存（影响不大）
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h2 id="如何进行分配"><a href="#如何进行分配" class="header-anchor">#</a> 如何进行分配</h2> <blockquote><p>在资源比较充足的情况下，尽可能的使用更多的计算资源，尽量去调节到最大的大小</p></blockquote> <h3 id="standalone模式"><a href="#standalone模式" class="header-anchor">#</a> Standalone模式</h3> <p>先计算出公司spark集群上的所有资源 每台节点的内存大小和cpu核数，比如：一共有20台worker节点，每台节点8g内存，10个cpu。实际任务在给定资源的时候，可以给20个executor、每个executor的内存8g、每个executor的使用的cpu个数10。</p> <h3 id="yarn模式"><a href="#yarn模式" class="header-anchor">#</a> Yarn模式</h3> <p>先计算出yarn集群的所有大小，比如一共500g内存，100个cpu；这个时候可以分配的最大资源，比如给定50个executor、每个executor的内存大小10g,每个executor使用的cpu个数为2。</p> <h2 id="具体分析"><a href="#具体分析" class="header-anchor">#</a> 具体分析</h2> <p><img src="https://gitee.com/kflys/uPic/raw/master/uPic/1612346460888-a1da381b-2a26-4224-af7a-c2121d7b3f57.png" alt="img"></p> <h1 id="提高并行度"><a href="#提高并行度" class="header-anchor">#</a> 提高并行度</h1> <p>spark作业中，各个stage的task的数量，也就代表了spark作业在各个阶段stage的并行度！</p> <p>当分配完所能分配的最大资源了，然后对应资源去调节程序的并行度，如果并行度没有与资源相匹配，那么导致你分配下去的资源都浪费掉了。同时并行运行，还可以让每个task要处理的数量变少（很简单的原理。合理设置并行度，可以充分利用集群资源，减少每个task处理数据量，而增加性能加快运行速度。）</p> <h2 id="task的数量"><a href="#task的数量" class="header-anchor">#</a> task的数量</h2> <div class="language- line-numbers-mode"><pre class="language-text"><code>	至少设置成与spark Application 的总cpu core 数量相同。
	最理想情况，150个core，分配150task，一起运行，差不多同一时间运行完毕
	官方推荐，task数量，设置成spark Application 总cpu core数量的2~3倍 。
	
	
	比如150个cpu core ，基本设置task数量为300~500. 与理想情况不同的，有些task会运行快一点，比如50s就完了，有些task 可能会慢一点，要一分半才运行完，所以如果你的task数量，刚好设置的跟cpu core 数量相同，可能会导致资源的浪费。
	因为比如150个task中10个先运行完了，剩余140个还在运行，但是这个时候，就有10个cpu core空闲出来了，导致浪费。如果设置2~3倍，那么一个task运行完以后，另外一个task马上补上来，尽量让cpu core不要空闲。同时尽量提升spark运行效率和速度。提升性能。
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h2 id="如何设置task数量"><a href="#如何设置task数量" class="header-anchor">#</a> 如何设置task数量</h2> <h3 id="spark-defalut-parallelism"><a href="#spark-defalut-parallelism" class="header-anchor">#</a> spark.defalut.parallelism</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>   默认是没有值的，如果设置了值为10，它会在shuffle的过程才会起作用。
   比如 val rdd2 = rdd1.reduceByKey(_+_) 
   此时rdd2的分区数就是10
   
可以通过在构建SparkConf对象的时候设置，例如：
   new SparkConf().set(&quot;spark.defalut.parallelism&quot;,&quot;500&quot;)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><h3 id="rdd-repartition"><a href="#rdd-repartition" class="header-anchor">#</a> rdd.repartition</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>使用rdd.repartition 来重新分区，该方法会生成一个新的rdd，使其分区数变大。
此时由于一个partition对应一个task，那么对应的task个数越多，通过这种方式也可以提高并行度。
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h3 id="spark-sql-shuffle-partitions"><a href="#spark-sql-shuffle-partitions" class="header-anchor">#</a> spark.sql.shuffle.partitions</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>提高sparksql运行的task数量，通过设置参数 spark.sql.shuffle.partitions=500  默认为200；
可以适当增大，来提高并行度。 比如设置为 spark.sql.shuffle.partitions=500
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h1 id="rdd的重用和持久化"><a href="#rdd的重用和持久化" class="header-anchor">#</a> RDD的重用和持久化</h1> <h2 id="实际开发遇到的情况说明"><a href="#实际开发遇到的情况说明" class="header-anchor">#</a> 实际开发遇到的情况说明</h2> <p><img src="https://gitee.com/kflys/uPic/raw/master/uPic/1612346460896-723fb61a-38e0-4e41-880d-d74c54f7f44e.png" alt="img"></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>如上图所示的计算逻辑：
（1）当第一次使用rdd2做相应的算子操作得到rdd3的时候，就会从rdd1开始计算，先读取HDFS上的文件，然后对rdd1做对应的算子操作得到rdd2,再由rdd2计算之后得到rdd3。同样为了计算得到rdd4，前面的逻辑会被重新计算。

（3）默认情况下多次对一个rdd执行算子操作，去获取不同的rdd，都会对这个rdd及之前的父rdd全部重新计算一次。
这种情况在实际开发代码的时候会经常遇到，但是我们一定要避免一个rdd重复计算多次，否则会导致性能急剧降低。

总结：可以把多次使用到的rdd，也就是公共rdd进行持久化，避免后续需要，再次重新计算，提升效率。
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p><img src="https://gitee.com/kflys/uPic/raw/master/uPic/1612346460884-23ea7e59-3a00-49f2-a13b-0de1d6f6b3e3.png" alt="img"></p> <h2 id="rdd持久化"><a href="#rdd持久化" class="header-anchor">#</a> rdd持久化</h2> <h3 id="可以调用rdd的cache或者persist方法。"><a href="#可以调用rdd的cache或者persist方法。" class="header-anchor">#</a> 可以调用rdd的cache或者persist方法。</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>（1）cache方法默认是把数据持久化到内存中 ，例如：rdd.cache ，其本质还是调用了persist方法
（2）persist方法中有丰富的缓存级别，这些缓存级别都定义在StorageLevel这个object中，可以结合实际的应用场景合理的设置缓存级别。例如： rdd.persist(StorageLevel.MEMORY_ONLY),这是cache方法的实现。
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h3 id="rdd持久化-采用序列化"><a href="#rdd持久化-采用序列化" class="header-anchor">#</a> rdd持久化，采用序列化</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>（1）如果正常将数据持久化在内存中，那么可能会导致内存的占用过大，这样的话，也许会导致OOM内存溢出。
（2）当纯内存无法支撑公共RDD数据完全存放的时候，就优先考虑使用序列化的方式在纯内存中存储。将RDD的每个partition的数据，序列化成一个字节数组；序列化后，大大减少内存的空间占用。
（3）序列化的方式，唯一的缺点就是，在获取数据的时候，需要反序列化。但是可以减少占用的空间和便于网络传输
（4）如果序列化纯内存方式，还是导致OOM，内存溢出；就只能考虑磁盘的方式，内存+磁盘的普通方式（无序列化）。
（5）为了数据的高可靠性，而且内存充足，可以使用双副本机制，进行持久化
	持久化的双副本机制，持久化后的一个副本，因为机器宕机了，副本丢了，就还是得重新计算一次；
	持久化的每个数据单元，存储一份副本，放在其他节点上面，从而进行容错；
	一个副本丢了，不用重新计算，还可以使用另外一份副本。这种方式，仅仅针对你的内存资源极度充足。
	 比如: StorageLevel.MEMORY_ONLY_2
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><h3 id="广播变量的使用"><a href="#广播变量的使用" class="header-anchor">#</a> 广播变量的使用</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>	在实际工作中可能会遇到这样的情况，由于要处理的数据量非常大，这个时候可能会在一个stage中出现大量的task，比如有1000个task，这些task都需要一份相同的数据来处理业务，这份数据的大小为100M，该数据会拷贝1000份副本，通过网络传输到各个task中去，给task使用。这里会涉及大量的网络传输开销，同时至少需要的内存为1000*100M=100G，这个内存开销是非常大的。不必要的内存的消耗和占用，就导致了你在进行RDD持久化到内存，也许就没法完全在内存中放下；就只能写入磁盘，最后导致后续的操作在磁盘IO上消耗性能；这对于spark任务处理来说就是一场灾难。

    由于内存开销比较大，task在创建对象的时候，可能会出现堆内存放不下所有对象，就会导致频繁的垃圾回收器的回收GC。GC的时候一定是会导致工作线程停止，也就是导致Spark暂停工作那么一点时间。频繁GC的话，对Spark作业的运行的速度会有相当可观的影响。
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p><img src="https://gitee.com/kflys/uPic/raw/master/uPic/1612346460898-e97693d7-ea42-4122-983c-951de2fa20b4.png" alt="img"></p> <h1 id="广播变量"><a href="#广播变量" class="header-anchor">#</a> 广播变量</h1> <blockquote><p>Spark中分布式执行的代码需要传递到各个executor的task上运行。对于一些只读、固定的数据,每次都需要Driver广播到各个Task上，这样效率低下。广播变量允许将变量只广播给各个executor。该executor上的各个task再从所在节点的BlockManager(负责管理某个executor对应的内存和磁盘上的数据)获取变量，而不是从Driver获取变量，从而提升了效率。</p></blockquote> <p><img src="https://gitee.com/kflys/uPic/raw/master/uPic/1612346460901-ecbd91d0-ede3-416e-9008-c1207c6389a9.png" alt="img"></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>广播变量，初始的时候，就在Drvier上有一份副本。通过在Driver把共享数据转换成广播变量。

	task在运行的时候，想要使用广播变量中的数据，此时首先会在自己本地的Executor对应的BlockManager中，尝试获取变量副本；如果本地没有，那么就从Driver远程拉取广播变量副本，并保存在本地的BlockManager中；
	
	此后这个executor上的task，都会直接使用本地的BlockManager中的副本。那么这个时候所有该executor中的task都会使用这个广播变量的副本。也就是说一个executor只需要在第一个task启动时，获得一份广播变量数据，之后的task都从本节点的BlockManager中获取相关数据。

	executor的BlockManager除了从driver上拉取，也可能从其他节点的BlockManager上拉取变量副本，网络距离越近越好。
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h3 id="使用广播变量前后的性能分析"><a href="#使用广播变量前后的性能分析" class="header-anchor">#</a> 使用广播变量前后的性能分析</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>比如一个任务需要50个executor，1000个task，共享数据为100M。
(1)在不使用广播变量的情况下，1000个task，就需要该共享数据的1000个副本，也就是说有1000份数需要大量的网络传输和内存开销存储。耗费的内存大小1000*100=100G.

(2)使用了广播变量后，50个executor就只需要50个副本数据，而且不一定都是从Driver传输到每个节点，还可能是就近从最近的节点的executor的blockmanager上拉取广播变量副本，网络传输速度大大增加；内存开销 50*100M=5G

总结：
	不使用广播变量的内存开销为100G，使用后的内存开销5G，这里就相差了20倍左右的网络传输性能损耗和内存开销，使用广播变量后对于性能的提升和影响，还是很可观的。
	
	广播变量的使用不一定会对性能产生决定性的作用。比如运行30分钟的spark作业，可能做了广播变量以后，速度快了2分钟，或者5分钟。但是一点一滴的调优，积少成多。最后还是会有效果的。
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><h3 id="广播变量使用注意事项"><a href="#广播变量使用注意事项" class="header-anchor">#</a> 广播变量使用注意事项</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>（1）不能将一个RDD使用广播变量广播出去，因为RDD是不存储数据的。可以将RDD的结果广播出去。

（2）广播变量只能在Driver端定义，不能在Executor端定义。

（3）在Driver端可以修改广播变量的值，在Executor端无法修改广播变量的值。

（4）如果executor端用到了Driver的变量，如果不使用广播变量在Executor有多少task就有多少Driver端的变量副本。

（5）如果Executor端用到了Driver的变量，如果使用广播变量在每个Executor中只有一份Driver端的变量副本。
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><h3 id="示例"><a href="#示例" class="header-anchor">#</a> 示例</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>(1) 通过sparkContext的broadcast方法把数据转换成广播变量，类型为Broadcast，
	val broadcastArray: Broadcast[Array[Int]] = sc.broadcast(Array(1,2,3,4,5,6))
	
(2) 然后executor上的BlockManager就可以拉取该广播变量的副本获取具体的数据。
		获取广播变量中的值可以通过调用其value方法
	 val array: Array[Int] = broadcastArray.value
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><h1 id="避免使用shuffle类算子"><a href="#避免使用shuffle类算子" class="header-anchor">#</a> 避免使用shuffle类算子</h1> <blockquote><p>1、spark中的shuffle涉及到数据要进行大量的网络传输，下游阶段的task任务需要通过网络拉取上阶段task的输出数据，shuffle过程，简单来说，就是将分布在集群中多个节点上的同一个key，拉取到同一个节点上，进行聚合或join等操作。比如reduceByKey、join等算子，都会触发shuffle操作。
2、如果有可能的话，要尽量避免使用shuffle类算子。
因为Spark作业运行过程中，最消耗性能的地方就是shuffle过程。</p></blockquote> <h3 id="会产生shuffle的算子"><a href="#会产生shuffle的算子" class="header-anchor">#</a> 会产生shuffle的算子</h3> <p>spark程序在开发的过程中使用reduceByKey、join、distinct、repartition等算子操作，这里都会产生shuffle，由于shuffle这一块是非常耗费性能的，实际开发中尽量使用map类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。</p> <h3 id="避免产生shuffle"><a href="#避免产生shuffle" class="header-anchor">#</a> 避免产生shuffle</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>//错误的做法：
// 传统的join操作会导致shuffle操作。
// 因为两个RDD中，相同的key都需要通过网络拉取到一个节点上，由一个task进行join操作。
val rdd3 = rdd1.join(rdd2)
    
//正确的做法：
// Broadcast+map的join操作，不会导致shuffle操作。
// 使用Broadcast将一个数据量较小的RDD作为广播变量。
val rdd2Data = rdd2.collect()
val rdd2DataBroadcast = sc.broadcast(rdd2Data)

// 在rdd1.map算子中，可以从rdd2DataBroadcast中，获取rdd2的所有数据。
// 然后进行遍历，如果发现rdd2中某条数据的key与rdd1的当前数据的key是相同的，那么就判定可以进行join。
// 此时就可以根据自己需要的方式，将rdd1当前数据与rdd2中可以连接的数据，拼接在一起（String或Tuple）。
val rdd3 = rdd1.map(rdd2DataBroadcast...)

// 注意，以上操作，建议仅仅在rdd2的数据量比较少（比如几百M，或者一两G）的情况下使用。
// 因为每个Executor的内存中，都会驻留一份rdd2的全量数据。
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><h2 id="使用map-side预聚合的shuffle操作"><a href="#使用map-side预聚合的shuffle操作" class="header-anchor">#</a> 使用map-side预聚合的shuffle操作</h2> <h3 id="map-side预聚合"><a href="#map-side预聚合" class="header-anchor">#</a> map-side预聚合</h3> <blockquote><p>如果因为业务需要，一定要使用shuffle操作，无法用map类的算子来替代，那么尽量使用可以map-side预聚合的算子。</p></blockquote> <p>所谓的map-side预聚合，说的是在每个节点本地对相同的key进行一次聚合操作，类似于MapReduce中的本地combiner。</p> <p>map-side预聚合之后，每个节点本地就只会有一条相同的key，因为多条相同的key都被聚合起来了。其他节点在拉取所有节点上的相同key时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销。</p> <p>通常来说，在可能的情况下，建议使用reduceByKey或者aggregateByKey算子来替代掉groupByKey算子。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合。
而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差。</p> <p>比如如下两幅图，就是典型的例子，分别基于reduceByKey和groupByKey进行单词计数。</p> <h4 id="groupbykey进行单词计数原理"><a href="#groupbykey进行单词计数原理" class="header-anchor">#</a> groupByKey进行单词计数原理</h4> <blockquote><p>没有进行任何本地聚合时，所有数据都会在集群节点之间传输。
groupByKey 不会进行预聚合操作，进行数据的全量拉取，性能比较低</p></blockquote> <p><img src="https://gitee.com/kflys/uPic/raw/master/uPic/1612346460909-afa9cd87-290b-41a8-9c34-a4b016009090.png" alt="img"></p> <h4 id="reducebykey单词计数原理"><a href="#reducebykey单词计数原理" class="header-anchor">#</a> reduceByKey单词计数原理</h4> <blockquote><p>每个节点本地的相同key数据，都进行了预聚合，然后才传输到其他节点上进行全局聚合。
reduceByKey/aggregateByKey 可以进行预聚合操作，减少数据的传输量，提升性能</p></blockquote> <p><img src="https://gitee.com/kflys/uPic/raw/master/uPic/1612346460915-20ba4bee-79ee-441c-a48f-6f2a867fdc4d.png" alt="img"></p> <h2 id="高性能的算子"><a href="#高性能的算子" class="header-anchor">#</a> 高性能的算子</h2> <h3 id="mappartitions"><a href="#mappartitions" class="header-anchor">#</a> mapPartitions</h3> <p>mapPartitions类的算子，一次函数调用会处理一个partition所有的数据，而不是一次函数调用处理一条，性能相对来说会高一些。</p> <p>但是有的时候，使用mapPartitions会出现OOM（内存溢出）的问题。因为单次函数调用就要处理掉一个partition所有的数据，如果内存不够，垃圾回收时是无法回收掉太多对象的，很可能出现OOM异常。所以使用这类操作时要慎重！</p> <h3 id="foreachpartitions类的算子"><a href="#foreachpartitions类的算子" class="header-anchor">#</a> foreachPartitions类的算子</h3> <p>foreachPartitions类的算子原理类似于“使用mapPartitions替代map”，也是一次函数调用处理一个partition的所有数据，而不是一次函数调用处理一条数据。</p> <p>在实践中发现，foreachPartitions类的算子，对性能的提升还是很有帮助的。比如在foreach函数中，将RDD中所有数据写MySQL，那么如果是普通的foreach算子，就会一条数据一条数据地写，每次函数调用可能就会创建一个数据库连接，此时就势必会频繁地创建和销毁数据库连接，性能是非常低下；</p> <p>如果用foreachPartitions算子一次性处理一个partition的数据，那么对于每个partition，只要创建一个数据库连接即可，然后执行批量插入操作，此时性能是比较高的。实践中发现，对于1万条左右的数据量写MySQL，性能可以提升30%以上。</p> <h3 id="filter之后进行coalesce操作"><a href="#filter之后进行coalesce操作" class="header-anchor">#</a> filter之后进行coalesce操作</h3> <p>通常对一个RDD执行filter算子过滤掉RDD中较多数据后（比如30%以上的数据），建议使用coalesce算子，手动减少RDD的partition数量，将RDD中的数据压缩到更少的partition中去。</p> <p>filter之后，RDD的每个partition中都会有很多数据被过滤掉，此时如果照常进行后续的计算，其实每个task处理的partition中的数据量并不是很多，有一点资源浪费，而且此时处理的task越多，可能速度反而越慢。</p> <p>用coalesce减少partition数量，将RDD中的数据压缩到更少的partition之后，只要使用更少的task即可处理完所有的partition。在某些场景下，对于性能的提升会有一定的帮助。</p> <h3 id="使用repartitionandsortwithinpartitions替代repartition与sort类操作"><a href="#使用repartitionandsortwithinpartitions替代repartition与sort类操作" class="header-anchor">#</a> 使用repartitionAndSortWithinPartitions替代repartition与sort类操作</h3> <p>repartitionAndSortWithinPartitions是Spark官网推荐的一个算子，官方建议，如果需要在repartition重分区之后，还要进行排序，建议直接使用repartitionAndSortWithinPartitions算子。因为该算子可以一边进行重分区的shuffle操作，一边进行排序。shuffle与sort两个操作同时进行，比先shuffle再sort来说，性能可能是要高的。</p> <h1 id="kryo优化序列化"><a href="#kryo优化序列化" class="header-anchor">#</a> Kryo优化序列化</h1> <blockquote><p>Spark在进行任务计算的时候，会涉及到数据跨进程的网络传输、数据的持久化，这个时候就需要对数据进行序列化。</p></blockquote> <h2 id="默认采用java的序列化器"><a href="#默认采用java的序列化器" class="header-anchor">#</a> 默认采用Java的序列化器</h2> <h3 id="优点"><a href="#优点" class="header-anchor">#</a> 优点</h3> <p>处理起来方便，不需要我们手动做其他操作，只是在使用一个对象和变量的时候，需要实现Serializble接口。</p> <h3 id="缺点"><a href="#缺点" class="header-anchor">#</a> 缺点</h3> <p>默认的序列化机制的效率不高，序列化的速度比较慢；序列化以后的数据，占用的内存空间相对还是比较大。</p> <h2 id="kryo序列化"><a href="#kryo序列化" class="header-anchor">#</a> Kryo序列化</h2> <blockquote><p>Spark支持使用Kryo序列化机制。Kryo序列化机制，比默认的Java序列化机制，速度要快，序列化后的数据要更小，大概是Java序列化机制的1/10。所以Kryo序列化优化以后，可以让网络传输的数据变少；在集群中耗费的内存资源大大减少。</p></blockquote> <p>Kryo序列化机制，一旦启用以后，会生效的几个地方：</p> <h3 id="_1、算子函数中使用到的外部变量"><a href="#_1、算子函数中使用到的外部变量" class="header-anchor">#</a> 1、算子函数中使用到的外部变量</h3> <p>算子中的外部变量可能来着与driver需要涉及到网络传输，就需要用到序列化。最终可以优化网络传输的性能，优化集群中内存的占用和消耗。</p> <h3 id="持久化rdd时进行序列化-storagelevel-memory-only-ser"><a href="#持久化rdd时进行序列化-storagelevel-memory-only-ser" class="header-anchor">#</a> 持久化RDD时进行序列化，StorageLevel.MEMORY_ONLY_SER</h3> <p>将rdd持久化时，对应的存储级别里，需要用到序列化。最终可以优化内存的占用和消耗；持久化RDD占用的内存越少，task执行的时候，创建的对象，就不至于频繁的占满内存，频繁发生GC。</p> <h3 id="产生shuffle的地方-也就是宽依赖"><a href="#产生shuffle的地方-也就是宽依赖" class="header-anchor">#</a> 产生shuffle的地方，也就是宽依赖</h3> <p>下游的stage中的task，拉取上游stage中的task产生的结果数据，跨网络传输，需要用到序列化。最终可以优化网络传输的性能.</p> <h3 id="示例-2"><a href="#示例-2" class="header-anchor">#</a> 示例</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>// 创建SparkConf对象。
val conf = new SparkConf().setMaster(...).setAppName(...)
// 设置序列化器为KryoSerializer。
conf.set(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;)

// 注册要序列化的自定义类型。
conf.registerKryoClasses(Array(classOf[MyClass1], classOf[MyClass2]))
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h1 id="fastutil优化数据格式"><a href="#fastutil优化数据格式" class="header-anchor">#</a> fastutil优化数据格式</h1> <blockquote><p>fastutil是扩展了Java标准集合框架（Map、List、Set；HashMap、ArrayList、HashSet）的类库，提供了特殊类型的map、set、list和queue；
fastutil能够提供更小的内存占用，更快的存取速度；我们使用fastutil提供的集合类，来替代自己平时使用的JDK的原生的Map、List、Set.</p></blockquote> <h2 id="fastutil有点"><a href="#fastutil有点" class="header-anchor">#</a> fastutil有点</h2> <p>fastutil集合类，可以减小内存的占用，并且在进行集合的遍历、根据索引（或者key）获取元素的值和设置元素的值的时候，提供更快的存取速度；</p> <h2 id="spark中应用fastutil的场景和使用"><a href="#spark中应用fastutil的场景和使用" class="header-anchor">#</a> Spark中应用fastutil的场景和使用</h2> <h3 id="算子函数使用了外部变量"><a href="#算子函数使用了外部变量" class="header-anchor">#</a> 算子函数使用了外部变量</h3> <p>（1）你可以使用Broadcast广播变量优化；</p> <p>（2）可以使用Kryo序列化类库，提升序列化性能和效率；</p> <p>（3）如果外部变量是某种比较大的集合，那么可以考虑使用fastutil改写外部变量；</p> <p>首先从源头上就减少内存的占用(fastutil)，通过广播变量进一步减少内存占用，再通过Kryo序列化类库进一步减少内存占用。</p> <h3 id="算子函数里使用了比较大的集合map-list"><a href="#算子函数里使用了比较大的集合map-list" class="header-anchor">#</a> 算子函数里使用了比较大的集合Map/List</h3> <p>在你的算子函数里，也就是task要执行的计算逻辑里面，如果有逻辑中，出现，要创建比较大的Map、List等集合，可能会占用较大的内存空间，而且可能涉及到消耗性能的遍历、存取等集合操作；</p> <p>此时，可以考虑将这些集合类型使用fastutil类库重写，</p> <p>使用了fastutil集合类以后，就可以在一定程度上，减少task创建出来的集合类型的内存占用。 避免executor内存频繁占满，频繁唤起GC，导致性能下降。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>第一步：在pom.xml中引用fastutil的包
    &lt;dependency&gt;
      &lt;groupId&gt;fastutil&lt;/groupId&gt;
      &lt;artifactId&gt;fastutil&lt;/artifactId&gt;
      &lt;version&gt;5.0.9&lt;/version&gt;
    &lt;/dependency&gt;
    
第二步：平时使用List （Integer）的替换成IntList即可。 
	List&lt;Integer&gt;的list对应的到fastutil就是IntList类型
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><h3 id="使用说明"><a href="#使用说明" class="header-anchor">#</a> 使用说明</h3> <p>基本都是类似于IntList的格式，前缀就是集合的元素类型； 特殊的就是Map，Int2IntMap，代表了key-value映射的元素类型。</p> <h1 id="调节数据本地化等待时长"><a href="#调节数据本地化等待时长" class="header-anchor">#</a> 调节数据本地化等待时长</h1> <p>Spark在Driver上对Application的每一个stage的task进行分配之前，都会计算出每个task要计算的是哪个分片数据，RDD的某个partition；Spark的task分配算法，优先会希望每个task正好分配到它要计算的数据所在的节点，这样的话就不用在网络间传输数据；</p> <p>但是通常来说，有时事与愿违，可能task没有机会分配到它的数据所在的节点，为什么呢，可能那个节点的计算资源和计算能力都满了；所以这种时候，通常来说，Spark会等待一段时间，默认情况下是3秒（不是绝对的，还有很多种情况，对不同的本地化级别，都会去等待），到最后实在是等待不了了，就会选择一个比较差的本地化级别，比如说将task分配到距离要计算的数据所在节点比较近的一个节点，然后进行计算。</p> <h2 id="本地化级别"><a href="#本地化级别" class="header-anchor">#</a> 本地化级别</h2> <h3 id="process-local"><a href="#process-local" class="header-anchor">#</a> PROCESS_LOCAL</h3> <p>PROCESS_LOCAL：进程本地化。代码和数据在同一个进程中，也就是在同一个executor中；计算数据的task由executor执行，数据在executor的BlockManager中；性能最好</p> <h3 id="node-local"><a href="#node-local" class="header-anchor">#</a> NODE_LOCAL</h3> <p>NODE_LOCAL：节点本地化。代码和数据在同一个节点中；比如说数据作为一个HDFS block块，就在节点上，而task在节点上某个executor中运行；或者是数据和task在一个节点上的不同executor中；数据需要在进程间进行传输；性能其次。</p> <h3 id="rack-local"><a href="#rack-local" class="header-anchor">#</a> RACK_LOCAL</h3> <p>RACK_LOCAL：机架本地化。数据和task在一个机架的两个节点上；数据需要通过网络在节点之间进行传输； 性能比较差。</p> <h3 id="any"><a href="#any" class="header-anchor">#</a> ANY</h3> <p>ANY：无限制。数据和task可能在集群中的任何地方，而且不在一个机架中；性能最差。</p> <h2 id="本地化级别参数设置"><a href="#本地化级别参数设置" class="header-anchor">#</a> 本地化级别参数设置</h2> <h3 id="spark-locality-wait"><a href="#spark-locality-wait" class="header-anchor">#</a> spark.locality.wait</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>spark.locality.wait，默认是3s
首先采用最佳的方式，等待3s后降级,还是不行，继续降级...,最后还是不行，只能够采用最差的。
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h3 id="不同级别的时间设置"><a href="#不同级别的时间设置" class="header-anchor">#</a> 不同级别的时间设置</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>修改spark.locality.wait参数，默认是3s，可以增加

下面是每个数据本地化级别的等待时间，默认都是跟spark.locality.wait时间相同，
默认都是3s(可查看spark官网对应参数说明，如下图所示)
spark.locality.wait.node
spark.locality.wait.process
spark.locality.wait.rack
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p><img src="https://kflys.gitee.io/upic/2021/spark/1612346460913-3991630e-d6b1-43cd-bb76-327af15bbdc8.png#align=left&amp;display=inline&amp;height=319&amp;margin=%5Bobject%20Object%5D&amp;originHeight=319&amp;originWidth=1170&amp;size=0&amp;status=done&amp;style=none&amp;width=1170" alt=""></p> <h3 id="在代码中设置"><a href="#在代码中设置" class="header-anchor">#</a> 在代码中设置</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>new SparkConf().set(&quot;spark.locality.wait&quot;,&quot;10&quot;)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>然后把程序提交到spark集群中运行，注意观察日志，spark作业的运行日志，推荐大家在测试的时候，先用client模式，在本地就直接可以看到比较全的日志。
日志里面会显示，</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>starting task .... PROCESS LOCAL、NODE LOCAL.....
Starting task 0.0 in stage 1.0 (TID 2, 192.168.200.102, partition 0, NODE_LOCAL, 5254 bytes)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>观察大部分task的数据本地化级别,如果大多都是PROCESS_LOCAL，那就不用调节了。如果是发现，多数的级别都是NODE_LOCAL、ANY，那么最好就去调节一下数据本地化的等待时长。应该是要反复调节，每次调节完以后，再来运行，观察日志
看看大部分的task的本地化级别有没有提升；看看整个spark作业的运行时间有没有缩短。</p> <blockquote><p>在调节参数、运行任务的时候，别本末倒置，本地化级别倒是提升了， 但是因为大量的等待时长，spark作业的运行时间反而增加了，那就还是不要调节了。</p></blockquote> <h3 id="spark内存模型调优"><a href="#spark内存模型调优" class="header-anchor">#</a> Spark内存模型调优</h3> <h4 id="spark中executor内存划分"><a href="#spark中executor内存划分" class="header-anchor">#</a> spark中executor内存划分</h4> <ul><li>Executor的内存主要分为三块
<ul><li>第一块是让task执行我们自己编写的代码时使用；</li> <li>第二块是让task通过shuffle过程拉取了上一个stage的task的输出后，进行聚合等操作时使用</li> <li>第三块是让RDD缓存时使用</li></ul></li></ul> <h1 id="spark的内存模型"><a href="#spark的内存模型" class="header-anchor">#</a> spark的内存模型</h1> <blockquote><p>在spark1.6版本以前 spark的executor使用的静态内存模型，但是在spark1.6开始，多增加了一个统一内存模型。通过spark.memory.useLegacyMode 这个参数去配置默认这个值是false，代表用的是新的动态内存模型；如果想用以前的静态内存模型，那么就要把这个值改为true。</p></blockquote> <h2 id="静态内存模型"><a href="#静态内存模型" class="header-anchor">#</a> 静态内存模型</h2> <p><img src="https://gitee.com/kflys/uPic/raw/master/uPic/1612346460925-9592565a-6afd-43e2-bb6c-63ae8eccbb85.png" alt="img"></p> <p>实际上就是把我们的一个executor分成了三部分，一部分是Storage内存区域，一部分是execution区域，还有一部分是其他区域。如果使用的静态内存模型，那么用这几个参数去控制：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>spark.storage.memoryFraction：# 默认0.6

spark.shuffle.memoryFraction： # 默认0.2 
# 所以第三部分就是0.2
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>如果我们cache数据量比较大，或者是我们的广播变量比较大，
那我们就把spark.storage.memoryFraction这个值调大一点。
但是如果我们代码里面没有广播变量，也没有cache，shuffle又比较多，那我们要把spark.shuffle.memoryFraction 这值调大。</p> <h3 id="静态内存模型的缺点"><a href="#静态内存模型的缺点" class="header-anchor">#</a> 静态内存模型的缺点</h3> <p>我们配置好了Storage内存区域和execution区域后，我们的一个任务假设execution内存不够用了，但是它的Storage内存区域是空闲的，两个之间不能互相借用，不够灵活，所以才出来我们新的统一内存模型。</p> <h2 id="统一内存模型"><a href="#统一内存模型" class="header-anchor">#</a> 统一内存模型</h2> <p><img src="https://gitee.com/kflys/uPic/raw/master/uPic/1612346460915-c289c8df-f8a6-4701-8c83-b78ff01d93b6.png" alt="img"></p> <p>动态内存模型先是预留了300m内存，防止内存溢出。动态内存模型把整体内存分成了两部分，
由这个参数表示spark.memory.fraction 这个指的默认值是0.6 代表另外的一部分是0.4,</p> <p>spark.memory.fraction 这部分又划分成为两个小部分。这两小部分共占整体内存的0.6 .这两部分其实就是：Storage内存和execution内存。由spark.memory.storageFraction 这个参数去调配，因为两个共占0.6。如果spark.memory.storageFraction这个值配的是0.5,那说明这0.6里面 storage占了0.5，也就是execution占了0.3 。</p> <h3 id="统一内存模型特点"><a href="#统一内存模型特点" class="header-anchor">#</a> 统一内存模型特点</h3> <p>Storage内存和execution内存 可以相互借用。不用像静态内存模型那样死板，但是是有规则的</p> <h4 id="场景一"><a href="#场景一" class="header-anchor">#</a> 场景一</h4> <p>Execution使用的时候发现内存不够了，然后就会把storage的内存里的数据驱逐到磁盘上。</p> <p><img src="https://gitee.com/kflys/uPic/raw/master/uPic/1612346460942-a72508f1-84c7-421c-9e0a-22a5b2787ea5.png" alt="img"></p> <h4 id="场景二"><a href="#场景二" class="header-anchor">#</a> 场景二</h4> <p>一开始execution的内存使用得不多，但是storage使用的内存多，所以storage就借用了execution的内存，但是后来execution也要需要内存了，这个时候就会把storage的内存里的数据写到磁盘上，腾出内存空间。</p> <p><img src="https://gitee.com/kflys/uPic/raw/master/uPic/1612346460927-cac57f5c-b2a2-4262-b747-f0e16a8bf033.png" alt="img"></p> <h3 id="为什么受伤的都是storage"><a href="#为什么受伤的都是storage" class="header-anchor">#</a> 为什么受伤的都是storage</h3> <p>是因为execution里面的数据是马上就要用的，而storage里的数据不一定马上就要用。</p> <h1 id="任务提交脚本参考"><a href="#任务提交脚本参考" class="header-anchor">#</a> 任务提交脚本参考</h1> <p>以下是一份spark-submit命令的示例，大家可以参考一下，并根据自己的实际情况进行调节</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>./bin/spark-submit <span class="token punctuation">\</span>
  --master yarn-cluster <span class="token punctuation">\</span>
  --num-executors <span class="token number">100</span> <span class="token punctuation">\</span>
  --executor-memory 6G <span class="token punctuation">\</span>
  --executor-cores <span class="token number">4</span> <span class="token punctuation">\</span>
  --driver-memory 1G <span class="token punctuation">\</span>
  --conf spark.default.parallelism<span class="token operator">=</span><span class="token number">1000</span> <span class="token punctuation">\</span>
  --conf spark.storage.memoryFraction<span class="token operator">=</span><span class="token number">0.5</span> <span class="token punctuation">\</span>
  --conf spark.shuffle.memoryFraction<span class="token operator">=</span><span class="token number">0.3</span> <span class="token punctuation">\</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><h2 id="内存问题常见异常"><a href="#内存问题常见异常" class="header-anchor">#</a> 内存问题常见异常</h2> <p>java.lang.OutOfMemoryError</p> <p>ExecutorLostFailure</p> <p>Executor exit code 为143</p> <p>executor lost</p> <p>hearbeat time out</p> <p>shuffle file lost</p> <p>如果遇到以上问题，很有可能就是内存除了问题，可以先尝试增加内存。如果还是解决不了，那么请听下一次数据倾斜调优的课。</p></div></div> <div class="page-slot page-slot-bottom"><!-- 横向自适应 -->
      <ins class="adsbygoogle"
          style="display:block"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="6620245489"
          data-ad-format="auto"
          data-full-width-responsive="true"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script></div> <div class="page-edit"><div class="edit-link"><a href="https://gitee.com/kflys/clivia-blog/edit/master/docs/《Spark》笔记/10.Spark Core/04.Spark Core常用优化.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <div class="tags"><a href="/tags/?tag=spark%20core" title="标签">#spark core</a></div> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">10/11/2021, 5:53:41 PM</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/4ccb94/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">Spark任务调度</div></a> <a href="/pages/f03bcf/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">Spark Shuffle原理分析</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/4ccb94/" class="prev">Spark任务调度</a></span> <span class="next"><a href="/pages/f03bcf/">Spark Shuffle原理分析</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/8e0b33/"><div>阿里官方Redis开发规范</div></a> <span>10-08</span></dt></dl><dl><dd>02</dd> <dt><a href="/pages/20a714/"><div>无监督学习</div></a> <span>01-26</span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/e78220/"><div>模拟保存预加载</div></a> <span>01-26</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:clivia.pro@gmail.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://gitee.com/kflys" title="Gitee" target="_blank" class="iconfont icon-gitee"></a><a href="https://y.qq.com/n/ryqq/songDetail/003lgoEG1SWHmF" title="music" target="_blank" class="iconfont icon-erji"></a></div> <div><span> Theme by <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> | Powered by <a href="https://webify.cloudbase.net/" target="_blank">CloudBase Webify</a></span></div> <span>Clivia‘s <a href="https://gitee.com/kflys/clivia-blog" target="_blank">blog</a> </span>
    | Copyright © 2019-2022
    <span><a href="http://beian.miit.gov.cn/" target="_blank">皖ICP备2021014093号</a> </span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <div class="custom-html-window custom-html-window-rb" style="display:;"><div class="custom-wrapper"><i class="close-but">×</i> <div><!-- 固定160*160px -->
      <ins class="adsbygoogle"
          style="display:inline-block;max-width:160px;max-height:160px"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="8377369658"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script>
      </div></div></div></div><div class="global-ui"><div id="live2d-widget" class="live2d-widget-container" style="position:fixed;left:65px;bottom:0px;width:135px;height:300px;z-index:99999;opacity:0.8;pointer-events:none;"><!----></div></div></div>
    <script src="/assets/js/app.06f86fe0.js" defer></script><script src="/assets/js/2.ed69dcfc.js" defer></script><script src="/assets/js/3.b6cd915d.js" defer></script><script src="/assets/js/100.16d5c2bc.js" defer></script>
  </body>
</html>