<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="天行健、君子以自强不息；地势坤，君子以厚德载物。">
    <meta name="keyword"  content="兰草">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        大数据开发之HBase（二） - kfly的博客 | kfly&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_1598291_q3el2wqimj.css" type="text/css">
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>kfly</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont iconhome"></i>
                    <span>主页</span>
                </a>
            </li>
 	   <li >
                <a href="/spec/">
                    <i class="iconfont iconzhuanti"></i>
                    <span>专题</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>简历</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#大数据数据库之hbase"><span class="toc-text">大数据数据库之hbase</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-HBase的数据存储原理"><span class="toc-text">1. HBase的数据存储原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-HBase读数据流程"><span class="toc-text">2. HBase读数据流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-HBase写数据流程"><span class="toc-text">3. HBase写数据流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-HBase的flush、compact机制"><span class="toc-text">4. HBase的flush、compact机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Flush触发条件"><span class="toc-text">4.1 Flush触发条件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-1-memstore级别限制"><span class="toc-text">4.1.1 memstore级别限制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-2-region级别限制"><span class="toc-text">4.1.2 region级别限制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-3-Region-Server级别限制"><span class="toc-text">4.1.3 Region Server级别限制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-4-HLog数量上限"><span class="toc-text">4.1.4 HLog数量上限</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-5-定期刷新Memstore"><span class="toc-text">4.1.5 定期刷新Memstore</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-6-手动flush"><span class="toc-text">4.1.6 手动flush</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-flush的流程"><span class="toc-text">4.2 flush的流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-Compact合并机制"><span class="toc-text">4.3  Compact合并机制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-1-minor-compaction-小合并"><span class="toc-text">4.3.1 minor compaction 小合并</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-2-major-compaction-大合并"><span class="toc-text">4.3.2 major compaction 大合并</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-region-拆分机制"><span class="toc-text">5. region 拆分机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-HBase表的预分区"><span class="toc-text">6. HBase表的预分区</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-为何要预分区？"><span class="toc-text">6.1 为何要预分区？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-预分区原理"><span class="toc-text">6.2 预分区原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3-手动指定预分区"><span class="toc-text">6.3 手动指定预分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-2-HexStringSplit-算法"><span class="toc-text">6.2.2 HexStringSplit 算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-region-合并"><span class="toc-text">7. region 合并</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-region合并说明"><span class="toc-text">7.1 region合并说明</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-如何进行region合并"><span class="toc-text">7.2 如何进行region合并</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#7-2-1-通过Merge类冷合并Region"><span class="toc-text">7.2.1 通过Merge类冷合并Region</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-2-2-通过online-merge热合并Region"><span class="toc-text">7.2.2  通过online_merge热合并Region</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-HBase集成MapReduce"><span class="toc-text">8. HBase集成MapReduce</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-实战一"><span class="toc-text">8.1 实战一</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-实战二"><span class="toc-text">8.2 实战二</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-3-实战三"><span class="toc-text">8.3 实战三</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-HBase集成Hive"><span class="toc-text">8. HBase集成Hive</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-HBase与Hive的对比（"><span class="toc-text">8.1 HBase与Hive的对比（</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-1-Hive"><span class="toc-text">8.1.1 Hive</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-2-HBase"><span class="toc-text">8.1.2 HBase</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#8-1-3-总结：Hive与HBase"><span class="toc-text">8.1.3 总结：Hive与HBase</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-整合配置"><span class="toc-text">9.2 整合配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#9-2-1-拷贝jar包"><span class="toc-text">9.2.1 拷贝jar包</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-2-2-修改hive的配置文件"><span class="toc-text">9.2.2 修改hive的配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-2-3-修改hive-env-sh配置文件"><span class="toc-text">9.2.3 修改hive-env.sh配置文件</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-需求一：将hive表当中分析的结果保存到hbase表当中去"><span class="toc-text">9.3 需求一：将hive表当中分析的结果保存到hbase表当中去</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#9-3-1-hive当中建表"><span class="toc-text">9.3.1 hive当中建表</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-3-2-准备数据内容如下并加载到hive表"><span class="toc-text">9.3.2 准备数据内容如下并加载到hive表</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-3-3-创建hive管理表与HBase进行映射"><span class="toc-text">9.3.3 创建hive管理表与HBase进行映射</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-3-4-hbase当中查看表hbase-score"><span class="toc-text">9.3.4 hbase当中查看表hbase_score</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-需求二：创建hive外部表，映射HBase当中已有的表模型（5分钟）"><span class="toc-text">9.4 需求二：创建hive外部表，映射HBase当中已有的表模型（5分钟）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#9-4-1-HBase当中创建表并手动插入加载一些数据"><span class="toc-text">9.4.1 HBase当中创建表并手动插入加载一些数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-4-2-建立hive的外部表，映射HBase当中的表以及字段"><span class="toc-text">9.4.2 建立hive的外部表，映射HBase当中的表以及字段</span></a></li></ol></li></ol></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        大数据开发之HBase（二）
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2019-11-13 14:46:15</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#hbase" title="hbase">hbase</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#hadoop" title="hadoop">hadoop</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#hbase与hive整合" title="hbase与hive整合">hbase与hive整合</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <h1 id="大数据数据库之hbase"><a href="#大数据数据库之hbase" class="headerlink" title="大数据数据库之hbase"></a>大数据数据库之hbase</h1><h2 id="1-HBase的数据存储原理"><a href="#1-HBase的数据存储原理" class="headerlink" title="1. HBase的数据存储原理"></a>1. HBase的数据存储原理</h2><p><img src="assets/hbase%E5%AD%98%E5%82%A8%E6%9E%B6%E6%9E%84.png?lastModify=1573631775" alt="hbase存储架构"></p>
<p><img src="assets/hbase_data_storage-1565601156263.png?lastModify=1573631775" alt="img"></p>
<ul>
<li>一个HRegionServer会负责管理很多个region</li>
<li>一个<strong>==region==</strong>包含很多个==store==<ul>
<li>一个<strong>==列族==</strong>就划分成一个<strong>==store==</strong></li>
<li>如果一个表中只有1个列族，那么每一个region中只有一个store</li>
<li>如果一个表中有N个列族，那么每一个region中有N个store</li>
</ul>
</li>
<li>==一个store==里面只有==一个memstore==<ul>
<li>memstore是一块<strong>内存区域</strong>，写入的数据会先写入memstore进行缓冲，然后再把数据刷到磁盘</li>
</ul>
</li>
<li>一个store里面有很多个<strong>==StoreFile==</strong>, 最后数据是以很多个<strong>==HFile==</strong>这种数据结构的文件保存在HDFS上<ul>
<li>StoreFile是HFile的抽象对象，如果说到StoreFile就等于HFile</li>
<li>==每次memstore刷写数据到磁盘，就生成对应的一个新的HFile文件出来==</li>
</ul>
</li>
</ul>
<p><img src="assets/region.png?lastModify=1573631775" alt="region"></p>
<h2 id="2-HBase读数据流程"><a href="#2-HBase读数据流程" class="headerlink" title="2. HBase读数据流程"></a>2. HBase读数据流程</h2><p><img src="assets/hbase%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B.png?lastModify=1573631775" alt="img"></p>
<blockquote>
<p>说明：HBase集群，只有一张meta表，此表只有一个region，该region数据保存在一个HRegionServer上</p>
</blockquote>
<ul>
<li>1、客户端首先与zk进行连接；从zk找到meta表的region位置，即meta表的数据存储在某一HRegionServer上；客户端与此HRegionServer建立连接，然后读取meta表中的数据；meta表中存储了所有用户表的region信息，我们可以通过<code>scan  &#39;hbase:meta&#39;</code>来查看meta表信息</li>
<li>2、根据要查询的namespace、表名和rowkey信息。找到写入数据对应的region信息</li>
<li>3、找到这个region对应的regionServer，然后发送请求</li>
<li>4、查找并定位到对应的region</li>
<li>5、先从memstore查找数据，如果没有，再从BlockCache上读取<ul>
<li>HBase上Regionserver的内存分为两个部分<ul>
<li>一部分作为Memstore，主要用来写；</li>
<li>另外一部分作为BlockCache，主要用于读数据；</li>
</ul>
</li>
</ul>
</li>
<li>6、如果BlockCache中也没有找到，再到StoreFile上进行读取<ul>
<li>从storeFile中读取到数据之后，不是直接把结果数据返回给客户端，而是把数据先写入到BlockCache中，目的是为了加快后续的查询；然后在返回结果给客户端。</li>
</ul>
</li>
</ul>
<h2 id="3-HBase写数据流程"><a href="#3-HBase写数据流程" class="headerlink" title="3. HBase写数据流程"></a>3. HBase写数据流程</h2><p><img src="assets/hbase%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B.png?lastModify=1573631775" alt="img"></p>
<ul>
<li>1、客户端首先从zk找到meta表的region位置，然后读取meta表中的数据，meta表中存储了用户表的region信息</li>
<li>2、根据namespace、表名和rowkey信息。找到写入数据对应的region信息</li>
<li>3、找到这个region对应的regionServer，然后发送请求</li>
<li>4、把数据分别写到HLog（write ahead log）和memstore各一份</li>
<li>5、memstore达到阈值后把数据刷到磁盘，生成storeFile文件</li>
<li>6、删除HLog中的历史数据</li>
</ul>
<pre><code>补充：
HLog（write ahead log）：
  也称为WAL意为Write ahead log，类似mysql中的binlog,用来做灾难恢复时用，HLog记录数据的所有变更,一旦数据修改，就可以从log中进行恢复。
</code></pre><h2 id="4-HBase的flush、compact机制"><a href="#4-HBase的flush、compact机制" class="headerlink" title="4. HBase的flush、compact机制"></a>4. HBase的flush、compact机制</h2><p><img src="assets/hbase-split-compaction.png" alt=""></p>
<h3 id="4-1-Flush触发条件"><a href="#4-1-Flush触发条件" class="headerlink" title="4.1 Flush触发条件"></a>4.1 Flush触发条件</h3><h4 id="4-1-1-memstore级别限制"><a href="#4-1-1-memstore级别限制" class="headerlink" title="4.1.1 memstore级别限制"></a>4.1.1 memstore级别限制</h4><ul>
<li>当Region中任意一个MemStore的大小达到了上限（hbase.hregion.memstore.flush.size，默认128MB），会触发Memstore刷新。</li>
</ul>
<pre><code class="xml">&lt;property&gt;
    &lt;name&gt;hbase.hregion.memstore.flush.size&lt;/name&gt;
    &lt;value&gt;134217728&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<h4 id="4-1-2-region级别限制"><a href="#4-1-2-region级别限制" class="headerlink" title="4.1.2 region级别限制"></a>4.1.2 region级别限制</h4><ul>
<li>当Region中所有Memstore的大小总和达到了上限（hbase.hregion.memstore.block.multiplier <em> hbase.hregion.memstore.flush.size，默认 2</em> 128M = 256M），会触发memstore刷新。</li>
</ul>
<pre><code class="xml">&lt;property&gt;
    &lt;name&gt;hbase.hregion.memstore.flush.size&lt;/name&gt;
    &lt;value&gt;134217728&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hbase.hregion.memstore.block.multiplier&lt;/name&gt;
    &lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;   
</code></pre>
<h4 id="4-1-3-Region-Server级别限制"><a href="#4-1-3-Region-Server级别限制" class="headerlink" title="4.1.3 Region Server级别限制"></a>4.1.3 Region Server级别限制</h4><ul>
<li>当一个Region Server中所有Memstore的大小总和超过低水位阈值hbase.regionserver.global.memstore.size.lower.limit*hbase.regionserver.global.memstore.size（前者默认值0.95），RegionServer开始强制flush；</li>
<li>先Flush Memstore最大的Region，再执行次大的，依次执行；</li>
<li>如写入速度大于flush写出的速度，导致总MemStore大小超过高水位阈值hbase.regionserver.global.memstore.size（默认为JVM内存的40%），此时RegionServer会阻塞更新并强制执行flush，直到总MemStore大小低于低水位阈值</li>
</ul>
<pre><code class="xml">&lt;property&gt;
    &lt;name&gt;hbase.regionserver.global.memstore.size.lower.limit&lt;/name&gt;
    &lt;value&gt;0.95&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hbase.regionserver.global.memstore.size&lt;/name&gt;
    &lt;value&gt;0.4&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<h4 id="4-1-4-HLog数量上限"><a href="#4-1-4-HLog数量上限" class="headerlink" title="4.1.4 HLog数量上限"></a>4.1.4 HLog数量上限</h4><ul>
<li>当一个Region Server中HLog数量达到上限（可通过参数hbase.regionserver.maxlogs配置）时，系统会选取最早的一个 HLog对应的一个或多个Region进行flush</li>
</ul>
<h4 id="4-1-5-定期刷新Memstore"><a href="#4-1-5-定期刷新Memstore" class="headerlink" title="4.1.5 定期刷新Memstore"></a>4.1.5 定期刷新Memstore</h4><ul>
<li>默认周期为1小时，确保Memstore不会长时间没有持久化。为避免所有的MemStore在同一时间都进行flush导致的问题，定期的flush操作有20000左右的随机延时。</li>
</ul>
<h4 id="4-1-6-手动flush"><a href="#4-1-6-手动flush" class="headerlink" title="4.1.6 手动flush"></a>4.1.6 手动flush</h4><ul>
<li>用户可以通过shell命令<code>flush ‘tablename’</code>或者<code>flush ‘region name’</code>分别对一个表或者一个Region进行flush。</li>
</ul>
<h3 id="4-2-flush的流程"><a href="#4-2-flush的流程" class="headerlink" title="4.2 flush的流程"></a>4.2 flush的流程</h3><ul>
<li><p>为了减少flush过程对读写的影响，将整个flush过程分为三个阶段：</p>
<ul>
<li><p>prepare阶段：遍历当前Region中所有的Memstore，将Memstore中当前数据集CellSkipListSet做一个<strong>快照snapshot</strong>；然后再新建一个CellSkipListSet。后期写入的数据都会写入新的CellSkipListSet中。prepare阶段需要加一把updateLock对<strong>写请求阻塞</strong>，结束之后会释放该锁。因为此阶段没有任何费时操作，因此持锁时间很短。</p>
</li>
<li><p>flush阶段：遍历所有Memstore，将prepare阶段生成的snapshot持久化为<strong>临时文件</strong>，临时文件会统一放到目录.tmp下。这个过程因为涉及到磁盘IO操作，因此相对比较耗时。</p>
</li>
<li>commit阶段：遍历所有Memstore，将flush阶段生成的临时文件移到指定的ColumnFamily目录下，针对HFile生成对应的storefile和Reader，把storefile添加到HStore的storefiles列表中，最后再<strong>清空</strong>prepare阶段生成的snapshot。</li>
</ul>
</li>
</ul>
<h3 id="4-3-Compact合并机制"><a href="#4-3-Compact合并机制" class="headerlink" title="4.3  Compact合并机制"></a>4.3  Compact合并机制</h3><ul>
<li><p>hbase为了==防止小文件过多==，以保证查询效率，hbase需要在必要的时候将这些小的store file合并成相对较大的store file，这个过程就称之为compaction。</p>
</li>
<li><p>在hbase中主要存在两种类型的compaction合并</p>
<ul>
<li><strong>==minor compaction 小合并==</strong></li>
<li><strong>==major compaction 大合并==</strong></li>
</ul>
</li>
</ul>
<h4 id="4-3-1-minor-compaction-小合并"><a href="#4-3-1-minor-compaction-小合并" class="headerlink" title="4.3.1 minor compaction 小合并"></a>4.3.1 minor compaction 小合并</h4><ul>
<li><p>在将Store中多个HFile合并为一个HFile</p>
<p>在这个过程中会选取一些小的、相邻的StoreFile将他们合并成一个更大的StoreFile，对于超过了TTL的数据、更新的数据、删除的数据仅仅只是做了标记。并没有进行物理删除，一次Minor Compaction的结果是更少并且更大的StoreFile。这种合并的触发频率很高。</p>
</li>
<li><p>minor compaction触发条件由以下几个参数共同决定：</p>
</li>
</ul>
<pre><code class="xml">&lt;!--表示至少需要三个满足条件的store file时，minor compaction才会启动--&gt;
&lt;property&gt;
    &lt;name&gt;hbase.hstore.compactionThreshold&lt;/name&gt;
    &lt;value&gt;3&lt;/value&gt;
&lt;/property&gt;

&lt;!--表示一次minor compaction中最多选取10个store file--&gt;
&lt;property&gt;
    &lt;name&gt;hbase.hstore.compaction.max&lt;/name&gt;
    &lt;value&gt;10&lt;/value&gt;
&lt;/property&gt;

&lt;!--默认值为128m,
表示文件大小小于该值的store file 一定会加入到minor compaction的store file中
--&gt;
&lt;property&gt;
    &lt;name&gt;hbase.hstore.compaction.min.size&lt;/name&gt;
    &lt;value&gt;134217728&lt;/value&gt;
&lt;/property&gt;

&lt;!--默认值为LONG.MAX_VALUE，
表示文件大小大于该值的store file 一定会被minor compaction排除--&gt;
&lt;property&gt;
    &lt;name&gt;hbase.hstore.compaction.max.size&lt;/name&gt;
    &lt;value&gt;9223372036854775807&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<h4 id="4-3-2-major-compaction-大合并"><a href="#4-3-2-major-compaction-大合并" class="headerlink" title="4.3.2 major compaction 大合并"></a>4.3.2 major compaction 大合并</h4><ul>
<li><p>合并Store中所有的HFile为一个HFile</p>
<p>将所有的StoreFile合并成一个StoreFile，这个过程还会清理三类无意义数据：被删除的数据、TTL过期数据、版本号超过设定版本号的数据。合并频率比较低，默认7天执行一次，并且性能消耗非常大，建议生产关闭(设置为0)，在应用空闲时间手动触发。一般可以是手动控制进行合并，防止出现在业务高峰期。</p>
</li>
<li><p>major compaction触发时间条件</p>
<pre><code class="xml">&lt;!--默认值为7天进行一次大合并，--&gt;
&lt;property&gt;
    &lt;name&gt;hbase.hregion.majorcompaction&lt;/name&gt;
    &lt;value&gt;604800000&lt;/value&gt;
&lt;/property&gt;
</code></pre>
</li>
<li><p>手动触发</p>
<pre><code class="ruby">##使用major_compact命令
major_compact tableName
</code></pre>
</li>
</ul>
<h2 id="5-region-拆分机制"><a href="#5-region-拆分机制" class="headerlink" title="5. region 拆分机制"></a>5. region 拆分机制</h2><ul>
<li><p>region中存储的是大量的rowkey数据 ,当region中的数据条数过多的时候,直接影响查询效率.当region过大的时候.hbase会拆分region , 这也是Hbase的一个优点 .</p>
</li>
<li><p>HBase的region split策略一共有以下几种：</p>
</li>
</ul>
<ul>
<li><p>1、<strong>ConstantSizeRegionSplitPolicy</strong></p>
<ul>
<li>0.94版本前默认切分策略</li>
</ul>
</li>
<li><p>当region大小大于某个阈值(hbase.hregion.max.filesize=10G)之后就会触发切分，一个region等分为2个region。</p>
<ul>
<li>但是在生产线上这种切分策略却有相当大的弊端：切分策略对于大表和小表没有明显的区分。阈值(hbase.hregion.max.filesize)设置较大对大表比较友好，但是小表就有可能不会触发分裂，极端情况下可能就1个，这对业务来说并不是什么好事。如果设置较小则对小表友好，但一个大表就会在整个集群产生大量的region，这对于集群的管理、资源使用、failover来说都不是一件好事。</li>
</ul>
</li>
</ul>
<ul>
<li><p>2、<strong>IncreasingToUpperBoundRegionSplitPolicy</strong></p>
<ul>
<li>0.94版本~2.0版本默认切分策略</li>
</ul>
<ul>
<li><p>切分策略稍微有点复杂，总体看和ConstantSizeRegionSplitPolicy思路相同，一个region大小大于设置阈值就会触发切分。但是这个阈值并不像ConstantSizeRegionSplitPolicy是一个固定的值，而是会在一定条件下不断调整，调整规则和region所属表在当前regionserver上的region个数有关系.</p>
</li>
<li><p>region split的计算公式是：<br>regioncount^3 <em> 128M </em> 2，当region达到该size的时候进行split<br>例如：<br>第一次split：1^3 <em> 256 = 256MB<br>第二次split：2^3 </em> 256 = 2048MB<br>第三次split：3^3 <em> 256 = 6912MB<br>第四次split：4^3 </em> 256 = 16384MB &gt; 10GB，因此取较小的值10GB<br>后面每次split的size都是10GB了</p>
</li>
</ul>
</li>
<li><p>3、<strong>SteppingSplitPolicy</strong></p>
<ul>
<li>2.0版本默认切分策略</li>
</ul>
<ul>
<li>这种切分策略的切分阈值又发生了变化，相比 IncreasingToUpperBoundRegionSplitPolicy 简单了一些，依然和待分裂region所属表在当前regionserver上的region个数有关系，如果region个数等于1，<br>切分阈值为flush size * 2，否则为MaxRegionFileSize。这种切分策略对于大集群中的大表、小表会比 IncreasingToUpperBoundRegionSplitPolicy 更加友好，小表不会再产生大量的小region，而是适可而止。</li>
</ul>
</li>
<li><p>4、<strong>KeyPrefixRegionSplitPolicy</strong></p>
<ul>
<li>根据rowKey的前缀对数据进行分组，这里是指定rowKey的前多少位作为前缀，比如rowKey都是16位的，指定前5位是前缀，那么前5位相同的rowKey在进行region split的时候会分到相同的region中。</li>
</ul>
</li>
<li><p>5、<strong>DelimitedKeyPrefixRegionSplitPolicy</strong></p>
<ul>
<li>保证相同前缀的数据在同一个region中，例如rowKey的格式为：userid_eventtype_eventid，指定的delimiter为 _ ，则split的的时候会确保userid相同的数据在同一个region中。</li>
</ul>
</li>
</ul>
<ul>
<li>6、<strong>DisabledRegionSplitPolicy</strong><ul>
<li>不启用自动拆分, 需要指定手动拆分</li>
</ul>
</li>
</ul>
<h2 id="6-HBase表的预分区"><a href="#6-HBase表的预分区" class="headerlink" title="6. HBase表的预分区"></a>6. HBase表的预分区</h2><ul>
<li>当一个table刚被创建的时候，Hbase默认的分配一个region给table。也就是说这个时候，所有的读写请求都会访问到同一个regionServer的同一个region中，这个时候就达不到负载均衡的效果了，集群中的其他regionServer就可能会处于比较空闲的状态。</li>
<li>解决这个问题可以用<strong>pre-splitting</strong>,在创建table的时候就配置好，生成多个region。</li>
</ul>
<h3 id="6-1-为何要预分区？"><a href="#6-1-为何要预分区？" class="headerlink" title="6.1 为何要预分区？"></a>6.1 为何要预分区？</h3><ul>
<li>增加数据读写效率</li>
<li>负载均衡，防止数据倾斜</li>
<li>方便集群容灾调度region</li>
<li>优化Map数量</li>
</ul>
<h3 id="6-2-预分区原理"><a href="#6-2-预分区原理" class="headerlink" title="6.2 预分区原理"></a>6.2 预分区原理</h3><ul>
<li>每一个region维护着startRow与endRowKey，如果加入的数据符合某个region维护的rowKey范围，则该数据交给这个region维护。</li>
</ul>
<h3 id="6-3-手动指定预分区"><a href="#6-3-手动指定预分区" class="headerlink" title="6.3 手动指定预分区"></a>6.3 手动指定预分区</h3><ul>
<li><p>两种方式</p>
</li>
<li><p>方式一</p>
</li>
</ul>
<pre><code class="ruby">create &#39;person&#39;,&#39;info1&#39;,&#39;info2&#39;,SPLITS =&gt; [&#39;1000&#39;,&#39;2000&#39;,&#39;3000&#39;,&#39;4000&#39;]
</code></pre>
<p><img src="assets/personSplit.png" alt="personSplit"></p>
<ul>
<li><p>方式二：也可以把分区规则创建于文件中</p>
<pre><code class="shell">cd /kfly/doc

vim split.txt
</code></pre>
<ul>
<li>文件内容</li>
</ul>
<pre><code>aaa
bbb
ccc
ddd
</code></pre><ul>
<li>hbase shell中，执行命令</li>
</ul>
<pre><code class="ruby">create &#39;student&#39;,&#39;info&#39;,SPLITS_FILE =&gt; &#39;/kfly/install/split.txt&#39;
</code></pre>
<ul>
<li>成功后查看web界面</li>
</ul>
<p><img src="assets/splitFile.png" alt="splitFile"></p>
</li>
</ul>
<h3 id="6-2-2-HexStringSplit-算法"><a href="#6-2-2-HexStringSplit-算法" class="headerlink" title="6.2.2 HexStringSplit 算法"></a>6.2.2 HexStringSplit 算法</h3><ul>
<li><p>HexStringSplit会将数据从“00000000”到“FFFFFFFF”之间的数据长度按照<strong>n等分</strong>之后算出每一段的其实rowkey和结束rowkey，以此作为拆分点。</p>
</li>
<li><p>例如：</p>
<pre><code class="ruby">create &#39;mytable&#39;, &#39;base_info&#39;,&#39; extra_info&#39;, {NUMREGIONS =&gt; 15, SPLITALGO =&gt; &#39;HexStringSplit&#39;}
</code></pre>
</li>
</ul>
<p><img src="assets/hbasePreSplit.png" alt="hbasePreSplit"></p>
<h2 id="7-region-合并"><a href="#7-region-合并" class="headerlink" title="7. region 合并"></a>7. region 合并</h2><h3 id="7-1-region合并说明"><a href="#7-1-region合并说明" class="headerlink" title="7.1 region合并说明"></a>7.1 region合并说明</h3><ul>
<li>Region的合并不是为了性能,  而是出于维护的目的 .</li>
<li>比如删除了大量的数据 ,这个时候每个Region都变得很小 ,存储多个Region就浪费了 ,这个时候可以把Region合并起来，进而可以减少一些Region服务器节点 </li>
</ul>
<h3 id="7-2-如何进行region合并"><a href="#7-2-如何进行region合并" class="headerlink" title="7.2 如何进行region合并"></a>7.2 如何进行region合并</h3><h4 id="7-2-1-通过Merge类冷合并Region"><a href="#7-2-1-通过Merge类冷合并Region" class="headerlink" title="7.2.1 通过Merge类冷合并Region"></a>7.2.1 通过Merge类冷合并Region</h4><ul>
<li><p>执行合并前，==需要先关闭hbase集群==</p>
</li>
<li><p>创建一张hbase表：</p>
</li>
</ul>
<pre><code class="ruby">create &#39;test&#39;,&#39;info1&#39;,SPLITS =&gt; [&#39;1000&#39;,&#39;2000&#39;,&#39;3000&#39;]
</code></pre>
<ul>
<li>查看表region</li>
</ul>
<p><img src="assets/testRegion.png" alt="testRegion"></p>
<ul>
<li><p>需求：</p>
<p>需要把test表中的2个region数据进行合并：<br>test,,1565940912661.62d28d7d20f18debd2e7dac093bc09d8.<br>test,1000,1565940912661.5b6f9e8dad3880bcc825826d12e81436.</p>
</li>
<li><p>这里通过org.apache.hadoop.hbase.util.Merge类来实现，不需要进入hbase shell，直接执行（==需要先关闭hbase集群==）：<br>hbase org.apache.hadoop.hbase.util.Merge test test,,1565940912661.62d28d7d20f18debd2e7dac093bc09d8. test,1000,1565940912661.5b6f9e8dad3880bcc825826d12e81436.</p>
</li>
<li><p>成功后界面观察</p>
</li>
</ul>
<p><img src="assets/testMerge.png" alt="testMerge"></p>
<h4 id="7-2-2-通过online-merge热合并Region"><a href="#7-2-2-通过online-merge热合并Region" class="headerlink" title="7.2.2  通过online_merge热合并Region"></a>7.2.2  通过online_merge热合并Region</h4><ul>
<li><p>==不需要关闭hbase集群==，在线进行合并</p>
</li>
<li><p>与冷合并不同的是，online_merge的传参是Region的hash值，而Region的hash值就是Region名称的最后那段在两个.之间的字符串部分。</p>
</li>
<li><p>需求：需要把test表中的2个region数据进行合并：<br>test,2000,1565940912661.c2212a3956b814a6f0d57a90983a8515.<br>test,3000,1565940912661.553dd4db667814cf2f050561167ca030.</p>
</li>
<li><p>需要进入hbase shell：</p>
<pre><code class="ruby">merge_region &#39;c2212a3956b814a6f0d57a90983a8515&#39;,&#39;553dd4db667814cf2f050561167ca030&#39;
</code></pre>
</li>
<li><p>成功后观察界面</p>
</li>
</ul>
<p><img src="assets/online_merge.png" alt="online_merge"></p>
<h2 id="8-HBase集成MapReduce"><a href="#8-HBase集成MapReduce" class="headerlink" title="8. HBase集成MapReduce"></a>8. HBase集成MapReduce</h2><ul>
<li>HBase表中的数据最终都是存储在HDFS上，HBase天生的支持MR的操作，我们可以通过MR直接处理HBase表中的数据，并且MR可以将处理后的结果直接存储到HBase表中。<ul>
<li>参考地址：<a href="http://hbase.apache.org/book.html#mapreduce" target="_blank" rel="noopener">http://hbase.apache.org/book.html#mapreduce</a></li>
</ul>
</li>
</ul>
<h3 id="8-1-实战一"><a href="#8-1-实战一" class="headerlink" title="8.1 实战一"></a>8.1 实战一</h3><ul>
<li>需求：==读取HBase当中myuser这张表的数据，将数据写入到另外一张myuser2表里面去==</li>
</ul>
<ul>
<li><p>第一步：创建myuser2这张hbase表</p>
<p><strong>注意：</strong>列族的名字要与myuser表的列族名字相同</p>
</li>
</ul>
<pre><code class="ruby">hbase(main):010:0&gt; create &#39;myuser2&#39;,&#39;f1&#39;
</code></pre>
<ul>
<li>第二步：创建maven工程并导入jar包</li>
</ul>
<pre><code class="xml">    &lt;repositories&gt;
        &lt;repository&gt;
            &lt;id&gt;cloudera&lt;/id&gt;
            &lt;url&gt;https://repository.cloudera.com/artifactory/cloudera-repos/&lt;/url&gt;
        &lt;/repository&gt;
    &lt;/repositories&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
            &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;
            &lt;version&gt;2.6.0-mr1-cdh5.14.2&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;
            &lt;artifactId&gt;hbase-client&lt;/artifactId&gt;
            &lt;version&gt;1.2.0-cdh5.14.2&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;
            &lt;artifactId&gt;hbase-server&lt;/artifactId&gt;
            &lt;version&gt;1.2.0-cdh5.14.2&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;junit&lt;/groupId&gt;
            &lt;artifactId&gt;junit&lt;/artifactId&gt;
            &lt;version&gt;4.12&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.testng&lt;/groupId&gt;
            &lt;artifactId&gt;testng&lt;/artifactId&gt;
            &lt;version&gt;6.14.3&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.0&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;1.8&lt;/source&gt;
                    &lt;target&gt;1.8&lt;/target&gt;
                    &lt;encoding&gt;UTF-8&lt;/encoding&gt;
                    &lt;!--    &lt;verbal&gt;true&lt;/verbal&gt;--&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
                &lt;version&gt;2.2&lt;/version&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;shade&lt;/goal&gt;
                        &lt;/goals&gt;
                        &lt;configuration&gt;
                            &lt;filters&gt;
                                &lt;filter&gt;
                                    &lt;artifact&gt;*:*&lt;/artifact&gt;
                                    &lt;excludes&gt;
                                        &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*/RSA&lt;/exclude&gt;
                                    &lt;/excludes&gt;
                                &lt;/filter&gt;
                            &lt;/filters&gt;
                        &lt;/configuration&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
</code></pre>
<ul>
<li>第三步：开发MR程序实现功能</li>
</ul>
<pre><code class="java">package com.kaikeba;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.Cell;
import org.apache.hadoop.hbase.CellUtil;
import org.apache.hadoop.hbase.TableName;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.client.Result;
import org.apache.hadoop.hbase.client.Scan;
import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
import org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;
import org.apache.hadoop.hbase.mapreduce.TableMapper;
import org.apache.hadoop.hbase.mapreduce.TableReducer;
import org.apache.hadoop.hbase.util.Bytes;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;

import java.io.IOException;

public class HBaseMR {

    public static class HBaseMapper extends TableMapper&lt;Text,Put&gt;{
        @Override
        protected void map(ImmutableBytesWritable key, Result value, Context context) throws IOException, InterruptedException {
             //获取rowkey的字节数组
            byte[] bytes = key.get();
            String rowkey = Bytes.toString(bytes);
            //构建一个put对象
            Put put = new Put(bytes);
            //获取一行中所有的cell对象
            Cell[] cells = value.rawCells();
            for (Cell cell : cells) {
                  // f1列族
                if(&quot;f1&quot;.equals(Bytes.toString(CellUtil.cloneFamily(cell)))){
                    // name列名
                     if(&quot;name&quot;.equals(Bytes.toString(CellUtil.cloneQualifier(cell)))){
                          put.add(cell);
                     }
                     // age列名
                    if(&quot;age&quot;.equals(Bytes.toString(CellUtil.cloneQualifier(cell)))){
                        put.add(cell);
                    }
                }
            }
            if(!put.isEmpty()){
              context.write(new Text(rowkey),put);
            }
        }
    }

     public  static  class HbaseReducer extends TableReducer&lt;Text,Put,ImmutableBytesWritable&gt;{
         @Override
         protected void reduce(Text key, Iterable&lt;Put&gt; values, Context context) throws IOException, InterruptedException {
             for (Put put : values) {
                 context.write(null,put);
             }
         }
     }

    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {
        Configuration conf = new Configuration();

        Scan scan = new Scan();

        Job job = Job.getInstance(conf);
        job.setJarByClass(HBaseMR.class);
        //使用TableMapReduceUtil 工具类来初始化我们的mapper
        TableMapReduceUtil.initTableMapperJob(TableName.valueOf(args[0]),scan,HBaseMapper.class,Text.class,Put.class,job);
        //使用TableMapReduceUtil 工具类来初始化我们的reducer
        TableMapReduceUtil.initTableReducerJob(args[1],HbaseReducer.class,job);
        //设置reduce task个数
         job.setNumReduceTasks(1);
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}
</code></pre>
<ul>
<li><p>打成jar包提交到集群中运行</p>
<pre><code class="shell">hadoop jar hbase_java_api-1.0-SNAPSHOT.jar com.kaikeba.HBaseMR t1 t2
</code></pre>
</li>
</ul>
<h3 id="8-2-实战二"><a href="#8-2-实战二" class="headerlink" title="8.2 实战二"></a>8.2 实战二</h3><ul>
<li><p>需求 读取hdfs上面的数据，写入到hbase表里面去</p>
<p>node03执行以下命令准备数据文件，并将数据文件上传到HDFS上面去</p>
<pre><code>hdfs dfs -mkdir -p /hbase/input
cd /kfly/install
vim 
user.txt

0007    zhangsan    18
0008    lisi    25
0009    wangwu    20

将文件上传到hdfs的路径下面去
hdfs dfs -put kflyb/install/user.txt   /hbase/input/
</code></pre></li>
<li><p>代码开发</p>
<p>~~~java<br>package com.kaikeba;</p>
</li>
</ul>
<p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.hbase.client.Put;<br>import org.apache.hadoop.hbase.io.ImmutableBytesWritable;<br>import org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;<br>import org.apache.hadoop.hbase.mapreduce.TableReducer;<br>import org.apache.hadoop.hbase.util.Bytes;<br>import org.apache.hadoop.io.LongWritable;<br>import org.apache.hadoop.io.NullWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.Mapper;<br>import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;<br>import java.io.IOException;</p>
<p>public class Hdfs2Hbase {</p>
<pre><code>public static class HdfsMapper extends Mapper&lt;LongWritable,Text,Text,NullWritable&gt; {

    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        context.write(value,NullWritable.get());
    }
}

public static class HBASEReducer extends TableReducer&lt;Text,NullWritable,ImmutableBytesWritable&gt; {

    protected void reduce(Text key, Iterable&lt;NullWritable&gt; values, Context context) throws IOException, InterruptedException {
        String[] split = key.toString().split(&quot; &quot;);
        Put put = new Put(Bytes.toBytes(split[0]));
        put.addColumn(&quot;f1&quot;.getBytes(),&quot;name&quot;.getBytes(),split[1].getBytes());
        put.addColumn(&quot;f1&quot;.getBytes(),&quot;age&quot;.getBytes(), split[2].getBytes());
        context.write(new ImmutableBytesWritable(Bytes.toBytes(split[0])),put);
    }
}

public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf);

    job.setJarByClass(Hdfs2Hbase.class);

    job.setInputFormatClass(TextInputFormat.class);
    //输入文件路径
    TextInputFormat.addInputPath(job,new Path(args[0]));
    job.setMapperClass(HdfsMapper.class);
    //map端的输出的key value 类型
    job.setMapOutputKeyClass(Text.class);
    job.setMapOutputValueClass(NullWritable.class);

    //指定输出到hbase的表名
    TableMapReduceUtil.initTableReducerJob(args[1],HBASEReducer.class,job);

    //设置reduce个数
    job.setNumReduceTasks(1);

    System.exit(job.waitForCompletion(true)?0:1);
}
</code></pre><p>}</p>
<pre><code>
* 创建hbase表 t3

~~~ruby
create &#39;t3&#39;,&#39;f1&#39;
</code></pre><ul>
<li>打成jar包提交到集群中运行</li>
</ul>
<pre><code class="shell">hadoop jar hbase_java_api-1.0-SNAPSHOT.jar com.kaikeba.Hdfs2Hbase /data/user.txt t3

</code></pre>
<h3 id="8-3-实战三"><a href="#8-3-实战三" class="headerlink" title="8.3 实战三"></a>8.3 实战三</h3><ul>
<li><p>需求</p>
<ul>
<li>==通过bulkload的方式批量加载数据到HBase表中==</li>
<li>==将我们hdfs上面的这个路径/hbase/input/user.txt的数据文件，转换成HFile格式，然后load到myuser2这张表里面去==</li>
</ul>
</li>
<li><p>知识点描述</p>
<ul>
<li>加载数据到HBase当中去的方式多种多样，我们可以使用HBase的javaAPI或者使用sqoop将我们的数据写入或者导入到HBase当中去，但是这些方式不是慢就是在导入的过程的占用Region资源导致效率低下</li>
<li>我们也可以通过MR的程序，将我们的数据直接转换成HBase的最终存储格式HFile，然后直接load数据到HBase当中去即可</li>
</ul>
</li>
<li><p>HBase数据正常写流程回顾</p>
<p><img src="assets/hbase-write.png" alt="hbase-write"></p>
</li>
<li><p>bulkload方式的处理示意图</p>
</li>
</ul>
<p><img src="assets/bulkload.png" alt=""></p>
<ul>
<li><p>好处</p>
<ul>
<li>导入过程不占用Region资源</li>
<li>能快速导入海量的数据</li>
<li>节省内存</li>
</ul>
</li>
<li><p>==1、开发生成HFile文件的代码==</p>
</li>
</ul>
<pre><code class="java">package com.kaikeba;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.TableName;
import org.apache.hadoop.hbase.client.Connection;
import org.apache.hadoop.hbase.client.ConnectionFactory;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.client.Table;
import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
import org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2;
import org.apache.hadoop.hbase.util.Bytes;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;

public class HBaseLoad {

    public static class LoadMapper  extends Mapper&lt;LongWritable,Text,ImmutableBytesWritable,Put&gt; {
        @Override
        protected void map(LongWritable key, Text value, Mapper.Context context) throws IOException, InterruptedException {
            String[] split = value.toString().split(&quot; &quot;);
            Put put = new Put(Bytes.toBytes(split[0]));
            put.addColumn(&quot;f1&quot;.getBytes(),&quot;name&quot;.getBytes(),split[1].getBytes());
            put.addColumn(&quot;f1&quot;.getBytes(),&quot;age&quot;.getBytes(), split[2].getBytes());
            context.write(new ImmutableBytesWritable(Bytes.toBytes(split[0])),put);
        }
    }

    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {
            final String INPUT_PATH=  &quot;hdfs://node01:8020/hbase/input&quot;;
            final String OUTPUT_PATH= &quot;hdfs://node01:8020/hbase/output_file&quot;;
            Configuration conf = HBaseConfiguration.create();

            Connection connection = ConnectionFactory.createConnection(conf);
            Table table = connection.getTable(TableName.valueOf(&quot;t4&quot;));
            Job job= Job.getInstance(conf);

            job.setJarByClass(HBaseLoad.class);
            job.setMapperClass(LoadMapper.class);
            job.setMapOutputKeyClass(ImmutableBytesWritable.class);
            job.setMapOutputValueClass(Put.class);

            //指定输出的类型HFileOutputFormat2
            job.setOutputFormatClass(HFileOutputFormat2.class);

         HFileOutputFormat2.configureIncrementalLoad(job,table,connection.getRegionLocator(TableName.valueOf(&quot;t4&quot;)));
            FileInputFormat.addInputPath(job,new Path(INPUT_PATH));
            FileOutputFormat.setOutputPath(job,new Path(OUTPUT_PATH));
            System.exit(job.waitForCompletion(true)?0:1);


    }
}

</code></pre>
<ul>
<li>==2、打成jar包提交到集群中运行==</li>
</ul>
<pre><code class="shell">hadoop jar hbase_java_api-1.0-SNAPSHOT.jar com.kaikeba.HBaseLoad
</code></pre>
<ul>
<li>==3、观察HDFS上输出的结果==</li>
</ul>
<p><img src="assets/f1.png" alt="f1"></p>
<p><img src="assets/HFile文件.png" alt="HFile文件"></p>
<ul>
<li><p>==4、加载HFile文件到hbase表中==</p>
<ul>
<li>方式一：代码加载</li>
</ul>
<pre><code class="java">package com.kaikeba;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.TableName;
import org.apache.hadoop.hbase.client.Admin;
import org.apache.hadoop.hbase.client.Connection;
import org.apache.hadoop.hbase.client.ConnectionFactory;
import org.apache.hadoop.hbase.client.Table;
import org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles;

public class LoadData {
    public static void main(String[] args) throws Exception {
        Configuration configuration = HBaseConfiguration.create();
        configuration.set(&quot;hbase.zookeeper.quorum&quot;, &quot;node01,node02,node03&quot;);
    //获取数据库连接
    Connection connection =  ConnectionFactory.createConnection(configuration);
    //获取表的管理器对象
    Admin admin = connection.getAdmin();
    //获取table对象
    TableName tableName = TableName.valueOf(&quot;t4&quot;);
    Table table = connection.getTable(tableName);
    //构建LoadIncrementalHFiles加载HFile文件
    LoadIncrementalHFiles load = new LoadIncrementalHFiles(configuration);
    load.doBulkLoad(new Path(&quot;hdfs://node01:8020/hbase/output_file&quot;), admin,table,connection.getRegionLocator(tableName));
 }
}
</code></pre>
<ul>
<li>方式二：命令加载</li>
</ul>
<p>先将hbase的jar包添加到hadoop的classpath路径下</p>
<pre><code class="shell">先将hbase的jar包添加到hadoop的classpath路径下
export HBASE_HOME=/kfly/install/hbase-1.2.0-cdh5.14.2/
export HADOOP_HOME=/kfly/install/hadoop-2.6.0/
export HADOOP_CLASSPATH=`${HBASE_HOME}/bin/hbase mapredcp`
</code></pre>
</li>
</ul>
<ul>
<li><p>运行命令</p>
<pre><code class="shell">yarn jar /kfly/install/hbase-1.2.0-cdh5.14.2/lib/hbase-server-1.2.0-cdh5.14.2.jar   completebulkload /hbase/output_hfile myuser2
</code></pre>
</li>
</ul>
<p>​    </p>
<h2 id="8-HBase集成Hive"><a href="#8-HBase集成Hive" class="headerlink" title="8. HBase集成Hive"></a>8. HBase集成Hive</h2><ul>
<li>Hive提供了与HBase的集成，使得能够在HBase表上使用hive sql 语句进行查询、插入操作以及进行Join和Union等复杂查询，同时也可以将hive表中的数据映射到Hbase中</li>
</ul>
<h3 id="8-1-HBase与Hive的对比（"><a href="#8-1-HBase与Hive的对比（" class="headerlink" title="8.1 HBase与Hive的对比（"></a>8.1 HBase与Hive的对比（</h3><h4 id="8-1-1-Hive"><a href="#8-1-1-Hive" class="headerlink" title="8.1.1 Hive"></a>8.1.1 Hive</h4><ul>
<li><p>数据仓库</p>
<p>Hive的本质其实就相当于将HDFS中已经存储的文件在Mysql中做了一个双射关系，以方便使用HQL去管理查询。</p>
</li>
<li><p>用于数据分析、清洗                </p>
<p>Hive适用于离线的数据分析和清洗，延迟较高</p>
</li>
<li><p>基于HDFS、MapReduce</p>
<p>Hive存储的数据依旧在DataNode上，编写的HQL语句终将是转换为MapReduce代码执行。（不要钻不需要执行MapReduce代码的情况的牛角尖）</p>
</li>
</ul>
<h4 id="8-1-2-HBase"><a href="#8-1-2-HBase" class="headerlink" title="8.1.2 HBase"></a>8.1.2 HBase</h4><ul>
<li><p>数据库</p>
<p>是一种面向列存储的非关系型数据库。</p>
</li>
<li><p>用于存储结构化和非结构话的数据</p>
<p>适用于单表非关系型数据的存储，不适合做关联查询，类似JOIN等操作。</p>
</li>
<li><p>基于HDFS</p>
<p>数据持久化存储的体现形式是Hfile，存放于DataNode中，被ResionServer以region的形式进行管理。</p>
</li>
<li><p>延迟较低，接入在线业务使用</p>
<p>面对大量的企业数据，HBase可以直线单表大量数据的存储，同时提供了高效的数据访问速度。</p>
</li>
</ul>
<h5 id="8-1-3-总结：Hive与HBase"><a href="#8-1-3-总结：Hive与HBase" class="headerlink" title="8.1.3 总结：Hive与HBase"></a>8.1.3 总结：Hive与HBase</h5><ul>
<li>Hive和Hbase是两种基于Hadoop的不同技术，Hive是一种类SQL的引擎，并且运行MapReduce任务，Hbase是一种在Hadoop之上的NoSQL 的Key/vale数据库。这两种工具是可以同时使用的。就像用Google来搜索，用FaceBook进行社交一样，Hive可以用来进行统计查询，HBase可以用来进行实时查询，数据也可以从Hive写到HBase，或者从HBase写回Hive。</li>
</ul>
<h3 id="9-2-整合配置"><a href="#9-2-整合配置" class="headerlink" title="9.2 整合配置"></a>9.2 整合配置</h3><h4 id="9-2-1-拷贝jar包"><a href="#9-2-1-拷贝jar包" class="headerlink" title="9.2.1 拷贝jar包"></a>9.2.1 拷贝jar包</h4><ul>
<li><p>将我们HBase的五个jar包拷贝到hive的lib目录下</p>
</li>
<li><p>hbase的jar包都在/kfly/install/hbase-1.2.0-cdh5.14.2/lib</p>
</li>
<li><p>我们需要拷贝五个jar包名字如下</p>
</li>
</ul>
<pre><code>hbase-client-1.2.0-cdh5.14.2.jar                  
hbase-hadoop2-compat-1.2.0-cdh5.14.2.jar 
hbase-hadoop-compat-1.2.0-cdh5.14.2.jar  
hbase-it-1.2.0-cdh5.14.2.jar    
hbase-server-1.2.0-cdh5.14.2.jar
</code></pre><ul>
<li>我们直接在node03执行以下命令，通过创建软连接的方式来进行jar包的依赖</li>
</ul>
<pre><code class="shell">ln -s /kfly/install/hbase-1.2.0-cdh5.14.2/lib/hbase-client-1.2.0-cdh5.14.2.jar              /kfly/install/hive-1.1.0-cdh5.14.2/lib/hbase-client-1.2.0-cdh5.14.2.jar   

ln -s /kfly/install/hbase-1.2.0-cdh5.14.2/lib/hbase-hadoop2-compat-1.2.0-cdh5.14.2.jar      /kfly/install/hive-1.1.0-cdh5.14.2/lib/hbase-hadoop2-compat-1.2.0-cdh5.14.2.jar             
ln -s /kfly/install/hbase-1.2.0-cdh5.14.2/lib/hbase-hadoop-compat-1.2.0-cdh5.14.2.jar       /kfly/install/hive-1.1.0-cdh5.14.2/lib/hbase-hadoop-compat-1.2.0-cdh5.14.2.jar            
ln -s /kfly/install/hbase-1.2.0-cdh5.14.2/lib/hbase-it-1.2.0-cdh5.14.2.jar     /kfly/install/hive-1.1.0-cdh5.14.2/lib/hbase-it-1.2.0-cdh5.14.2.jar    

ln -s /kfly/install/hbase-1.2.0-cdh5.14.2/lib/hbase-server-1.2.0-cdh5.14.2.jar          /kfly/install/hive-1.1.0-cdh5.14.2/lib/hbase-server-1.2.0-cdh5.14.2.jar  
</code></pre>
<h4 id="9-2-2-修改hive的配置文件"><a href="#9-2-2-修改hive的配置文件" class="headerlink" title="9.2.2 修改hive的配置文件"></a>9.2.2 修改hive的配置文件</h4><ul>
<li>编辑<strong>node03</strong>服务器上面的hive的配置文件hive-site.xml</li>
</ul>
<pre><code class="shell">cd /kfly/install/hive-1.1.0-cdh5.14.2/conf
vim hive-site.xml
</code></pre>
<ul>
<li>添加以下两个属性的配置</li>
</ul>
<pre><code class="xml">&lt;property&gt;
        &lt;name&gt;hive.zookeeper.quorum&lt;/name&gt;
        &lt;value&gt;node01,node02,node03&lt;/value&gt;
&lt;/property&gt;
 &lt;property&gt;
        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
        &lt;value&gt;node01,node02,node03&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<h4 id="9-2-3-修改hive-env-sh配置文件"><a href="#9-2-3-修改hive-env-sh配置文件" class="headerlink" title="9.2.3 修改hive-env.sh配置文件"></a>9.2.3 修改hive-env.sh配置文件</h4><pre><code class="shell">cd /kfly/install/hive-1.1.0-cdh5.14.2/conf
vim hive-env.sh
</code></pre>
<ul>
<li>添加以下配置</li>
</ul>
<pre><code>export HADOOP_HOME=/export/servers/hadoop-2.6.0
export HBASE_HOME=/export/servers/hbase-1.2.0-cdh5.14.2
export HIVE_CONF_DIR=/export/servers/hive-1.1.0-cdh5.14.2/conf
</code></pre><h3 id="9-3-需求一：将hive表当中分析的结果保存到hbase表当中去"><a href="#9-3-需求一：将hive表当中分析的结果保存到hbase表当中去" class="headerlink" title="9.3 需求一：将hive表当中分析的结果保存到hbase表当中去"></a>9.3 需求一：将hive表当中分析的结果保存到hbase表当中去</h3><h4 id="9-3-1-hive当中建表"><a href="#9-3-1-hive当中建表" class="headerlink" title="9.3.1 hive当中建表"></a>9.3.1 hive当中建表</h4><ul>
<li>node03执行以下命令，进入hive客户端，并创建hive表</li>
</ul>
<pre><code class="shell">cd /kfly/install/hive-1.1.0-cdh5.14.2/
bin/hive
</code></pre>
<ul>
<li>创建hive数据库与hive对应的数据库表</li>
</ul>
<pre><code class="mysql">create database course;
use course;

create external table if not exists course.score(id int,cname string,score int) row format delimited fields terminated by &#39;\t&#39; stored as textfile ;
</code></pre>
<h4 id="9-3-2-准备数据内容如下并加载到hive表"><a href="#9-3-2-准备数据内容如下并加载到hive表" class="headerlink" title="9.3.2 准备数据内容如下并加载到hive表"></a>9.3.2 准备数据内容如下并加载到hive表</h4><ul>
<li>node03执行以下命令，创建数据文件</li>
</ul>
<pre><code class="shell">cd /kfly/install/hivedatas
vi hive-hbase.txt
</code></pre>
<ul>
<li>文件内容如下</li>
</ul>
<pre><code>1    zhangsan    80
2    lisi    60
3    wangwu    30
4    zhaoliu    70
</code></pre><ul>
<li>进入hive客户端进行加载数据</li>
</ul>
<pre><code class="mysql">hive (course)&gt; load data local inpath &#39;/kfly/doc/hive-hbase.txt&#39; into table score;
hive (course)&gt; select * from score;
</code></pre>
<h4 id="9-3-3-创建hive管理表与HBase进行映射"><a href="#9-3-3-创建hive管理表与HBase进行映射" class="headerlink" title="9.3.3 创建hive管理表与HBase进行映射"></a>9.3.3 创建hive管理表与HBase进行映射</h4><ul>
<li><p>我们可以创建一个hive的管理表与hbase当中的表进行映射，hive管理表当中的数据，都会存储到hbase上面去</p>
</li>
<li><p>hive当中创建内部表</p>
</li>
</ul>
<pre><code class="sql">create table course.hbase_score(id int,cname string,score int) stored by &#39;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#39;  with serdeproperties(&quot;hbase.columns.mapping&quot; = &quot;cf:name,cf:score&quot;) tblproperties(&quot;hbase.table.name&quot; = &quot;hbase_score&quot;);
</code></pre>
<ul>
<li>通过insert  overwrite select  插入数据</li>
</ul>
<pre><code class="mysql">insert overwrite table course.hbase_score select id,cname,score from course.score;
</code></pre>
<h4 id="9-3-4-hbase当中查看表hbase-score"><a href="#9-3-4-hbase当中查看表hbase-score" class="headerlink" title="9.3.4 hbase当中查看表hbase_score"></a>9.3.4 hbase当中查看表hbase_score</h4><ul>
<li>进入hbase的客户端查看表hbase_score，并查看当中的数据</li>
</ul>
<pre><code class="ruby">hbase(main):023:0&gt; list

TABLE                                                                                 hbase_score                                                                           myuser                                                                                 myuser2                                                                               student                                                                               user                                                                                   5 row(s) in 0.0210 seconds
=&gt; [&quot;hbase_score&quot;, &quot;myuser&quot;, &quot;myuser2&quot;, &quot;student&quot;, &quot;user&quot;]

hbase(main):024:0&gt; scan &#39;hbase_score&#39;

ROW                      COLUMN+CELL                                                   
 1                       column=cf:name, timestamp=1550628395266, value=zhangsan       
 1                       column=cf:score, timestamp=1550628395266, value=80           
 2                       column=cf:name, timestamp=1550628395266, value=lisi           
 2                       column=cf:score, timestamp=1550628395266, value=60           
 3                       column=cf:name, timestamp=1550628395266, value=wangwu         
 3                       column=cf:score, timestamp=1550628395266, value=30           
 4                       column=cf:name, timestamp=1550628395266, value=zhaoliu       
 4                       column=cf:score, timestamp=1550628395266, value=70           
4 row(s) in 0.0360 seconds
</code></pre>
<h3 id="9-4-需求二：创建hive外部表，映射HBase当中已有的表模型（5分钟）"><a href="#9-4-需求二：创建hive外部表，映射HBase当中已有的表模型（5分钟）" class="headerlink" title="9.4 需求二：创建hive外部表，映射HBase当中已有的表模型（5分钟）"></a>9.4 需求二：创建hive外部表，映射HBase当中已有的表模型（5分钟）</h3><h4 id="9-4-1-HBase当中创建表并手动插入加载一些数据"><a href="#9-4-1-HBase当中创建表并手动插入加载一些数据" class="headerlink" title="9.4.1 HBase当中创建表并手动插入加载一些数据"></a>9.4.1 HBase当中创建表并手动插入加载一些数据</h4><ul>
<li>进入HBase的shell客户端，</li>
</ul>
<pre><code class="shell">bin/hbase shell
</code></pre>
<ul>
<li>手动创建一张表，并插入加载一些数据进去</li>
</ul>
<pre><code class="ruby"># 创建一张表
create &#39;hbase_hive_score&#39;,{ NAME =&gt;&#39;cf&#39;}
# 通过put插入数据到hbase表
put &#39;hbase_hive_score&#39;,&#39;1&#39;,&#39;cf:name&#39;,&#39;zhangsan&#39;
put &#39;hbase_hive_score&#39;,&#39;1&#39;,&#39;cf:score&#39;, &#39;95&#39;
put &#39;hbase_hive_score&#39;,&#39;2&#39;,&#39;cf:name&#39;,&#39;lisi&#39;
put &#39;hbase_hive_score&#39;,&#39;2&#39;,&#39;cf:score&#39;, &#39;96&#39;
put &#39;hbase_hive_score&#39;,&#39;3&#39;,&#39;cf:name&#39;,&#39;wangwu&#39;
put &#39;hbase_hive_score&#39;,&#39;3&#39;,&#39;cf:score&#39;, &#39;97&#39;
</code></pre>
<h4 id="9-4-2-建立hive的外部表，映射HBase当中的表以及字段"><a href="#9-4-2-建立hive的外部表，映射HBase当中的表以及字段" class="headerlink" title="9.4.2 建立hive的外部表，映射HBase当中的表以及字段"></a>9.4.2 建立hive的外部表，映射HBase当中的表以及字段</h4><ul>
<li><p>在hive当中建立外部表</p>
</li>
<li><p>进入hive客户端，然后执行以下命令进行创建hive外部表，就可以实现映射HBase当中的表数据</p>
</li>
</ul>
<pre><code class="mysql">CREATE external TABLE course.hbase2hive(id int, name string, score int) STORED BY &#39;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#39; WITH SERDEPROPERTIES (&quot;hbase.columns.mapping&quot; = &quot;:key,cf:name,cf:score&quot;) TBLPROPERTIES(&quot;hbase.table.name&quot; =&quot;hbase_hive_score&quot;);
</code></pre>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a href="https://blog.sev7e0.site/">大数据施工现场</a></span>
        <span>/</span>
        
        <span><a href="https://wangchujiang.com/linux-command/">linux命令行工具</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script src="/js/gitment.js"></script>
<script>
    var gitment = new Gitment({
        id: '大数据开发之HBase（二）',
        owner: 'orchid-ding',
        repo: 'kfly-blog-comment',
        oauth: {
            client_id: '0770cdab79393197b6f5',
            client_secret: '376fb6c7bcd5047718b356712f596b89e490360c',
        },
    })
    gitment.render('comment-container')
</script>




</html>
