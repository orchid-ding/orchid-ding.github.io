<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="天行健、君子以自强不息；地势坤，君子以厚德载物。">
    <meta name="keyword"  content="兰草">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        大数据之批流处理的未来之路Flink - kfly的博客 | kfly&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_1598291_q3el2wqimj.css" type="text/css">
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>kfly</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont iconhome"></i>
                    <span>主页</span>
                </a>
            </li>
 	   <li >
                <a href="/spec/">
                    <i class="iconfont iconzhuanti"></i>
                    <span>专题</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>简历</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#大数据批流处理的未来之路"><span class="toc-text">大数据批流处理的未来之路</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Flink介绍"><span class="toc-text">1 Flink介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-核心功能"><span class="toc-text">1.1 核心功能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-应用场景"><span class="toc-text">1.2 应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Flink的基础架构"><span class="toc-text">2 Flink的基础架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-基础组建栈"><span class="toc-text">2.1 基础组建栈</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-基础架构图"><span class="toc-text">2.2 基础架构图</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Flient-API开发"><span class="toc-text">3 Flient API开发</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-批处理开发"><span class="toc-text">3.1 批处理开发</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-流式处理开发"><span class="toc-text">3.2 流式处理开发</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Flink的Table-amp-SQL-API"><span class="toc-text">4 Flink的Table &amp; SQL API</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-批处理开发"><span class="toc-text">4.1 批处理开发</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-流处理开发"><span class="toc-text">4.2 流处理开发</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-批流一体处理逻辑"><span class="toc-text">4.3 批流一体处理逻辑</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-1-初始化环境"><span class="toc-text">4.3.1 初始化环境</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-2-获取一个table"><span class="toc-text">4.3.2 获取一个table</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-3-输出一个table"><span class="toc-text">4.2.3 输出一个table</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-4-Table-API"><span class="toc-text">4.2.4 Table API</span></a></li></ol></li></ol></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        大数据之批流处理的未来之路Flink
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2019-11-22 15:03:08</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#hadoop" title="hadoop">hadoop</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#flink" title="flink">flink</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <h1 id="大数据批流处理的未来之路"><a href="#大数据批流处理的未来之路" class="headerlink" title="大数据批流处理的未来之路"></a>大数据批流处理的未来之路</h1><h2 id="1-Flink介绍"><a href="#1-Flink介绍" class="headerlink" title="1 Flink介绍"></a>1 Flink介绍</h2><pre><code>早起柏林工业大学联合发起的一个关于数据库的研究项目，叫做：stratorsphere。直到2014年4月份捐献给apache基金会，称为apache基金会的孵化项目， 在孵化期间项目stratosphere改名为Flink 随后到2014年12月，该项目成为了apache基金会的顶级项目。
目前新的flink版本已经到了1.9
</code></pre><ul>
<li>Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态的计算。 </li>
<li>官网地址:<a href="http://flink.apache.org" target="_blank" rel="noopener">http://flink.apache.org</a> </li>
</ul>
<p><img src="https://flink.apache.org/img/flink-home-graphic.png" alt="img"></p>
<ul>
<li><p>上图分为三部分</p>
<ol>
<li><p>首先要有数据，负责接收数据</p>
</li>
<li><p>中间就是进行计算的部分，具体对数据处理的地方</p>
</li>
<li><p>最终数据输出的地方，把结果存储在某地方</p>
</li>
</ol>
</li>
</ul>
<h3 id="1-1-核心功能"><a href="#1-1-核心功能" class="headerlink" title="1.1 核心功能"></a>1.1 核心功能</h3><ul>
<li>同时支持高吞吐、低延迟、高性能<ul>
<li>Sparck Core： 支持高吞吐、高性能： 相对延迟较高</li>
<li>Stream ：低延迟、高性能框架</li>
</ul>
</li>
<li>支持事件时间（Event Time）概念</li>
<li>支持有状态的计算</li>
<li>支持高度灵活的窗口操作（流式计算）</li>
<li>基于轻量级的分布式快照（Snapshot）容错</li>
<li>基于JVM实现独立的内存管理</li>
<li>SavePoints保存点</li>
</ul>
<h3 id="1-2-应用场景"><a href="#1-2-应用场景" class="headerlink" title="1.2 应用场景"></a>1.2 应用场景</h3><ul>
<li>实时智能推荐系统<ul>
<li>今日头条广告： 与淘宝共享检索数据，实时推送广告</li>
</ul>
</li>
<li>复杂事件处理</li>
<li>实时欺诈监测</li>
<li>实时数仓ETL</li>
<li>流数据分析</li>
<li>实时报表分析</li>
</ul>
<h2 id="2-Flink的基础架构"><a href="#2-Flink的基础架构" class="headerlink" title="2 Flink的基础架构"></a>2 Flink的基础架构</h2><h3 id="2-1-基础组建栈"><a href="#2-1-基础组建栈" class="headerlink" title="2.1 基础组建栈"></a>2.1 基础组建栈</h3><p><img src="assets/image-20191122163707117.png" alt="image-20191122163707117"></p>
<h3 id="2-2-基础架构图"><a href="#2-2-基础架构图" class="headerlink" title="2.2 基础架构图"></a>2.2 基础架构图</h3><p><img src="assets/image-20191122163747496.png" alt="image-20191122163747496"></p>
<h2 id="3-Flient-API开发"><a href="#3-Flient-API开发" class="headerlink" title="3 Flient API开发"></a>3 Flient API开发</h2><h3 id="3-1-批处理开发"><a href="#3-1-批处理开发" class="headerlink" title="3.1 批处理开发"></a>3.1 批处理开发</h3><p>==使用DataSet Api开发批处理程序==</p>
<ul>
<li>创建maven工程依赖</li>
</ul>
<pre><code class="xml">  &lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-scala_2.12&lt;/artifactId&gt;
    &lt;version&gt;1.8.1&lt;/version&gt;
  &lt;/dependency&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-clients_2.12&lt;/artifactId&gt;
    &lt;version&gt;1.8.1&lt;/version&gt;
  &lt;/dependency&gt;
</code></pre>
<ul>
<li>Scala代码</li>
</ul>
<pre><code class="scala">    package flink

    import org.apache.flink.api.scala._

    /**
     * 通过Scala语言开发Flink 批处理程序
     */
    object ScalaWorkCount {

      def main(args: Array[String]): Unit = {

        // 获取Flink批处理执行环境
        var env:ExecutionEnvironment = ExecutionEnvironment.getExecutionEnvironment;

        // 初始化原数据
        var data:DataSet[String] = env.fromCollection(List(&quot;hadoop mapreduce&quot;,&quot;hadoop spark&quot;,&quot;spark core&quot;))

        // 数据处理，切分每一行数据获取所有单词
        var words : DataSet[String] = data.flatMap(_.split(&quot; &quot;))

        // 把每个单词记为1，封装成元组
        var wordAndOne:DataSet[(String,Int)] = words.map((_,1))

        // 按照单词进行分组
        var groupByWord:GroupedDataSet[(String,Int)] = wordAndOne.groupBy(0)

        // 对相同的单词进行分组
        var aggregateDataSet: AggregateDataSet[(String,Int)] = groupByWord.sum(1)

        // 打印
        aggregateDataSet.print()
      }
    }

</code></pre>
<ul>
<li>Java代码</li>
</ul>
<pre><code class="java">    package flink;

    import org.apache.flink.api.common.functions.FlatMapFunction;
    import org.apache.flink.api.java.DataSet;
    import org.apache.flink.api.java.ExecutionEnvironment;
    import org.apache.flink.api.java.operators.DataSource;
    import org.apache.flink.api.java.tuple.Tuple2;

    /**
     * @author dingchuangshi
     */
    public class ScalaWorkCountJava {
        public static void main(String[] args) throws Exception {

            // 获取Flink批处理执行环境
            ExecutionEnvironment env = ExecutionEnvironment.createCollectionsEnvironment();

            // 初始化原数据
            DataSource&lt;String&gt; data = env.fromElements(&quot;hadoop mapreduce&quot;, &quot;hadoop spark&quot;, &quot;spark core&quot;);

            // 数据处理
            DataSet&lt;Tuple2&lt;String, Integer&gt;&gt; words = data
                    .flatMap((FlatMapFunction&lt;String, Tuple2&lt;String,Integer&gt;&gt;)(s,out)-&gt;{
                        for (String word: s.split(&quot; &quot;)) {
                            out.collect(new Tuple2&lt;String,Integer&gt;(word,1));
                        }
                    })
                    .groupBy(0)
                    .sum(1);

            // sink
            words.print();
        }
    }

</code></pre>
<h3 id="3-2-流式处理开发"><a href="#3-2-流式处理开发" class="headerlink" title="3.2 流式处理开发"></a>3.2 流式处理开发</h3><pre><code class="xml">&lt;dependency&gt;
  &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
  &lt;artifactId&gt;flink-streaming-scala_2.12&lt;/artifactId&gt;
  &lt;version&gt;1.8.1&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<ul>
<li>Scala代码</li>
</ul>
<pre><code class="scala">  package flink


import org.apache.flink.streaming.api.scala._
import org.apache.flink.streaming.api.windowing.time.Time
import org.apache.flink.streaming.api.windowing.windows.TimeWindow

/**
  * 基于scala语言开发Flink的流式处理程序
 */
object ScalaStreamWordCount {

  def main(args: Array[String]): Unit = {

       //1. 获取flink的流式处理环境
      val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

      //2. 构建source数据源
      val socketTextStream: DataStream[String] = env.socketTextStream(&quot;192.168.18.238&quot;,9999)

      //3. 数据处理
      //3.1 切分每一行，获取所有的单词
      val words: DataStream[String] = socketTextStream.flatMap(_.split(&quot; &quot;))

      //3.2 把每个单词计为1 封装成元组(单词，1)
      val wordAndOne: DataStream[(String, Int)] = words.map((_,1))

      //3.3 按照单词进行分组
      val groupByWord: KeyedStream[(String, Int), String] = wordAndOne.keyBy(_._1)

      //3.4 设置时间窗口
      val timeWindow: WindowedStream[(String, Int), String, TimeWindow] = groupByWord.timeWindow(Time.seconds(5))

      //3.5 相同单词出现的1累加
      val result: DataStream[(String, Int)] = timeWindow.reduce((v1,v2)=&gt; (v1._1,v1._2+v2._2))

      //4. 构建Sink
      result.print()

      //5. 启动流式应用程序
      env.execute(&quot;ScalaStreamWordCount&quot;)
  }
}
</code></pre>
<ul>
<li>模拟一个socket服务器</li>
</ul>
<pre><code class="shell">nc -lk 9999
</code></pre>
<h2 id="4-Flink的Table-amp-SQL-API"><a href="#4-Flink的Table-amp-SQL-API" class="headerlink" title="4 Flink的Table &amp; SQL API"></a>4 Flink的Table &amp; SQL API</h2><p><img src="assets/image-20191122170247587.png" alt="image-20191122170247587"></p>
<ul>
<li><p>Table Api是一种关系型Api，类SQL的API。 用户可以像操作表一样的操作数据，非常直观和方便。</p>
</li>
<li><p>Table &amp; SQL API的出现可以解决流处理和批处理统一的API层</p>
<ul>
<li>批处理上的查询会随着输入数据的结束而结束并生成有限的结果集。</li>
<li>流处理上的查询会一直运行并生成结果流</li>
<li>Table &amp; SQL API 做到了批与流上的查询具有相同的语法，因此不用修改代码就能同时实现批和流。</li>
</ul>
<pre><code class="xml">&lt;dependency&gt;
  &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
  &lt;artifactId&gt;flink-table-planner_2.11&lt;/artifactId&gt; 
  &lt;version&gt;1.8.1&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
</li>
</ul>
<h3 id="4-1-批处理开发"><a href="#4-1-批处理开发" class="headerlink" title="4.1 批处理开发"></a>4.1 批处理开发</h3><pre><code class="scala">  package flink

  import org.apache.flink.api.scala._
  import org.apache.flink.core.fs.FileSystem.WriteMode
  import org.apache.flink.table.api.{Table, Types}
  import org.apache.flink.table.api.scala.BatchTableEnvironment
  import org.apache.flink.table.sinks.CsvTableSink
  import org.apache.flink.table.sources.CsvTableSource

  /**
   * 基于table &amp; sql api开发 Flink的批处理程序
   */
  object ScalaTableSQLBatchWordCount {

    def main(args: Array[String]): Unit = {

        //1. 获取flink的table批处理环境
        val env: ExecutionEnvironment = ExecutionEnvironment.getExecutionEnvironment

        val tEnv: BatchTableEnvironment = BatchTableEnvironment.create(env)

        //2.构建Source数据源
        val tableSource: CsvTableSource = CsvTableSource.builder()
          .path(&quot;./data/person.txt&quot;)
          .fieldDelimiter(&quot; &quot;)
          .field(&quot;id&quot;, Types.INT)
          .field(&quot;name&quot;, Types.STRING)
          .field(&quot;age&quot;, Types.INT)
          .ignoreParseErrors().lineDelimiter(&quot;\r\n&quot;)
          .build()

        //将tableSource注册成表 tEnv.registerTableSource(&quot;person&quot;,tableSource)
        //3. 查询
        //3.1 查询年龄大于30岁的人
        val result1: Table = tEnv.scan(&quot;person&quot;).filter(&quot;age &gt; 30&quot;)

        //3.2 统计不同的年龄用户数
        val result2: Table = tEnv.sqlQuery(&quot;select age,count(*) from person group by age &quot;)

        //4. 构建sink //打印表的元数据schema信息
        result1.printSchema()

        //保存结果数据到文件中 val tableSink1 = new
        var tableSink1 = new CsvTableSink(&quot;./out/result1.txt&quot;, &quot;\t&quot;, 1, WriteMode.OVERWRITE)
        result1.writeToSink(tableSink1)

        val tableSink2 = new CsvTableSink(&quot;./out/result2.txt&quot;, &quot;\t&quot;, 1, WriteMode.OVERWRITE)
        result2.writeToSink(tableSink2)

        //开启计算
        env.execute()
    }
  }
</code></pre>
<h3 id="4-2-流处理开发"><a href="#4-2-流处理开发" class="headerlink" title="4.2 流处理开发"></a>4.2 流处理开发</h3><pre><code class="scala">package flink

import org.apache.flink.core.fs.FileSystem.WriteMode
import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment}
import org.apache.flink.table.api.Table
import org.apache.flink.table.api.scala.StreamTableEnvironment
import org.apache.flink.table.sinks.CsvTableSink
import org.apache.flink.api.scala._

/**
 * 基于table &amp; sql api开发 Flink的流式处理程序
 */
object ScalaTableSQLStreamWordCount {

  case class User(id:Int,name:String,age:Int)

  def main(args: Array[String]): Unit = {

    //1. 获取flink的table流式处理的环境
    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

    val streamSQLEnv: StreamTableEnvironment = StreamTableEnvironment.create(env)
    //2. 构建Source数据源
    /**
      * 101,zhangsan,18
      * 102,lisi,20
      * 103,wangwu,25
      * 104,zhaoliu,15
      */
    val socketDataStream: DataStream[String] = env.socketTextStream(&quot;node01&quot;,9999)

    val userDataStream: DataStream[User] = socketDataStream.map(x=&gt;x.split(&quot;,&quot;)).map(y=&gt;User(y(0).toInt,y(1),y(2).toInt ))

    //3. 将流注册成一张表
    streamSQLEnv.registerDataStream(&quot;userTable&quot;,userDataStream)

    //4. 使用table &amp;&amp; sql api来查询数据

     // 使用table 的api查询年龄大于20岁的人
    val result1: Table = streamSQLEnv.scan(&quot;userTable&quot;).filter(&quot;age &gt;20&quot;)

    //使用sql 的api查询
    val result2: Table = streamSQLEnv.sqlQuery(&quot; select * from userTable &quot;)

    //5. 构建Sink
    val tableSink1 = new CsvTableSink(&quot;./out/tableSink1.txt&quot;,&quot;\t&quot;,1,WriteMode.OVERWRITE)
    result1.writeToSink(tableSink1)

    val tableSink2 = new CsvTableSink(&quot;./out/tableSink2.txt&quot;,&quot;\t&quot;,1,WriteMode.OVERWRITE)
    result2.writeToSink(tableSink2) //开启执行流式计算

    env.execute() }
}
</code></pre>
<h3 id="4-3-批流一体处理逻辑"><a href="#4-3-批流一体处理逻辑" class="headerlink" title="4.3 批流一体处理逻辑"></a>4.3 批流一体处理逻辑</h3><h4 id="4-3-1-初始化环境"><a href="#4-3-1-初始化环境" class="headerlink" title="4.3.1 初始化环境"></a>4.3.1 初始化环境</h4><p><img src="assets/image-20191122192954640.png" alt="image-20191122192954640"></p>
<h4 id="4-3-2-获取一个table"><a href="#4-3-2-获取一个table" class="headerlink" title="4.3.2 获取一个table"></a>4.3.2 获取一个table</h4><p><img src="assets/image-20191122193054844.png" alt="image-20191122193054844"></p>
<h4 id="4-2-3-输出一个table"><a href="#4-2-3-输出一个table" class="headerlink" title="4.2.3 输出一个table"></a>4.2.3 输出一个table</h4><p><img src="assets/image-20191122193124451.png" alt="image-20191122193124451"></p>
<h4 id="4-2-4-Table-API"><a href="#4-2-4-Table-API" class="headerlink" title="4.2.4 Table API"></a>4.2.4 Table API</h4><p><img src="assets/image-20191122193206331.png" alt="image-20191122193206331"></p>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a href="https://blog.sev7e0.site/">大数据施工现场</a></span>
        <span>/</span>
        
        <span><a href="https://wangchujiang.com/linux-command/">linux命令行工具</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script src="/js/gitment.js"></script>
<script>
    var gitment = new Gitment({
        id: '大数据之批流处理的未来之路Flink',
        owner: 'orchid-ding',
        repo: 'kfly-blog-comment',
        oauth: {
            client_id: '0770cdab79393197b6f5',
            client_secret: '376fb6c7bcd5047718b356712f596b89e490360c',
        },
    })
    gitment.render('comment-container')
</script>




</html>
