<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="天行健、君子以自强不息；地势坤，君子以厚德载物。">
    <meta name="keyword"  content="兰草">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        大数据之批流处理的未来之路Flink - Kaffir Lily的博客 | Kaffir Lily&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_1598291_q3el2wqimj.css" type="text/css">
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>kfly</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont iconhome"></i>
                    <span>主页</span>
                </a>
            </li>
 	   <li >
                <a href="/spec/">
                    <i class="iconfont iconzhuanti"></i>
                    <span>专题</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>简历</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#大数据批流处理的未来之路"><span class="toc-text">大数据批流处理的未来之路</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Flink介绍"><span class="toc-text">1 Flink介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-核心功能"><span class="toc-text">1.1 核心功能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-应用场景"><span class="toc-text">1.2 应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Flink的基础架构"><span class="toc-text">2 Flink的基础架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-基础组建栈"><span class="toc-text">2.1 基础组建栈</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-基础架构图"><span class="toc-text">2.2 基础架构图</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Flient-API开发"><span class="toc-text">3 Flient API开发</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-批处理开发"><span class="toc-text">3.1 批处理开发</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-流式处理开发"><span class="toc-text">3.2 流式处理开发</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Flink的Table-amp-SQL-API"><span class="toc-text">4 Flink的Table &amp; SQL API</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-批处理开发"><span class="toc-text">4.1 批处理开发</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-流处理开发"><span class="toc-text">4.2 流处理开发</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-批流一体处理逻辑"><span class="toc-text">4.3 批流一体处理逻辑</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-1-初始化环境"><span class="toc-text">4.3.1 初始化环境</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-2-获取一个table"><span class="toc-text">4.3.2 获取一个table</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-3-输出一个table"><span class="toc-text">4.2.3 输出一个table</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-4-Table-API"><span class="toc-text">4.2.4 Table API</span></a></li></ol></li></ol></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        大数据之批流处理的未来之路Flink
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2019-11-22 15:03:08</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#hadoop" title="hadoop">hadoop</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#flink" title="flink">flink</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <h1 id="大数据批流处理的未来之路"><a href="#大数据批流处理的未来之路" class="headerlink" title="大数据批流处理的未来之路"></a>大数据批流处理的未来之路</h1><h2 id="1-Flink介绍"><a href="#1-Flink介绍" class="headerlink" title="1 Flink介绍"></a>1 Flink介绍</h2><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">早起柏林工业大学联合发起的一个关于数据库的研究项目，叫做：stratorsphere。直到<span class="number">2014</span>年<span class="number">4</span>月份捐献给apache基金会，称为apache基金会的孵化项目， 在孵化期间项目stratosphere改名为Flink 随后到<span class="number">2014</span>年<span class="number">12</span>月，该项目成为了apache基金会的顶级项目。</span><br><span class="line">目前新的flink版本已经到了<span class="number">1.9</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态的计算。 </li>
<li>官网地址:<a href="http://flink.apache.org" target="_blank" rel="noopener">http://flink.apache.org</a> </li>
</ul>
<p><img src="https://flink.apache.org/img/flink-home-graphic.png" alt="img"></p>
<ul>
<li><p>上图分为三部分</p>
<ol>
<li><p>首先要有数据，负责接收数据</p>
</li>
<li><p>中间就是进行计算的部分，具体对数据处理的地方</p>
</li>
<li><p>最终数据输出的地方，把结果存储在某地方</p>
</li>
</ol>
</li>
</ul>
<h3 id="1-1-核心功能"><a href="#1-1-核心功能" class="headerlink" title="1.1 核心功能"></a>1.1 核心功能</h3><ul>
<li>同时支持高吞吐、低延迟、高性能<ul>
<li>Sparck Core： 支持高吞吐、高性能： 相对延迟较高</li>
<li>Stream ：低延迟、高性能框架</li>
</ul>
</li>
<li>支持事件时间（Event Time）概念</li>
<li>支持有状态的计算</li>
<li>支持高度灵活的窗口操作（流式计算）</li>
<li>基于轻量级的分布式快照（Snapshot）容错</li>
<li>基于JVM实现独立的内存管理</li>
<li>SavePoints保存点</li>
</ul>
<h3 id="1-2-应用场景"><a href="#1-2-应用场景" class="headerlink" title="1.2 应用场景"></a>1.2 应用场景</h3><ul>
<li>实时智能推荐系统<ul>
<li>今日头条广告： 与淘宝共享检索数据，实时推送广告</li>
</ul>
</li>
<li>复杂事件处理</li>
<li>实时欺诈监测</li>
<li>实时数仓ETL</li>
<li>流数据分析</li>
<li>实时报表分析</li>
</ul>
<h2 id="2-Flink的基础架构"><a href="#2-Flink的基础架构" class="headerlink" title="2 Flink的基础架构"></a>2 Flink的基础架构</h2><h3 id="2-1-基础组建栈"><a href="#2-1-基础组建栈" class="headerlink" title="2.1 基础组建栈"></a>2.1 基础组建栈</h3><p><img src="assets/image-20191122163707117.png" alt="image-20191122163707117"></p>
<h3 id="2-2-基础架构图"><a href="#2-2-基础架构图" class="headerlink" title="2.2 基础架构图"></a>2.2 基础架构图</h3><p><img src="assets/image-20191122163747496.png" alt="image-20191122163747496"></p>
<h2 id="3-Flient-API开发"><a href="#3-Flient-API开发" class="headerlink" title="3 Flient API开发"></a>3 Flient API开发</h2><h3 id="3-1-批处理开发"><a href="#3-1-批处理开发" class="headerlink" title="3.1 批处理开发"></a>3.1 批处理开发</h3><p>==使用DataSet Api开发批处理程序==</p>
<ul>
<li>创建maven工程依赖</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-scala_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-clients_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Scala代码</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> flink</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 通过Scala语言开发Flink 批处理程序</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaWorkCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取Flink批处理执行环境</span></span><br><span class="line">    <span class="keyword">var</span> env:<span class="type">ExecutionEnvironment</span> = <span class="type">ExecutionEnvironment</span>.getExecutionEnvironment;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化原数据</span></span><br><span class="line">    <span class="keyword">var</span> data:<span class="type">DataSet</span>[<span class="type">String</span>] = env.fromCollection(<span class="type">List</span>(<span class="string">"hadoop mapreduce"</span>,<span class="string">"hadoop spark"</span>,<span class="string">"spark core"</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 数据处理，切分每一行数据获取所有单词</span></span><br><span class="line">    <span class="keyword">var</span> words : <span class="type">DataSet</span>[<span class="type">String</span>] = data.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 把每个单词记为1，封装成元组</span></span><br><span class="line">    <span class="keyword">var</span> wordAndOne:<span class="type">DataSet</span>[(<span class="type">String</span>,<span class="type">Int</span>)] = words.map((_,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 按照单词进行分组</span></span><br><span class="line">    <span class="keyword">var</span> groupByWord:<span class="type">GroupedDataSet</span>[(<span class="type">String</span>,<span class="type">Int</span>)] = wordAndOne.groupBy(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 对相同的单词进行分组</span></span><br><span class="line">    <span class="keyword">var</span> aggregateDataSet: <span class="type">AggregateDataSet</span>[(<span class="type">String</span>,<span class="type">Int</span>)] = groupByWord.sum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印</span></span><br><span class="line">    aggregateDataSet.print()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Java代码</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> flink;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.DataSet;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.ExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.operators.DataSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> dingchuangshi</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ScalaWorkCountJava</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取Flink批处理执行环境</span></span><br><span class="line">        ExecutionEnvironment env = ExecutionEnvironment.createCollectionsEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 初始化原数据</span></span><br><span class="line">        DataSource&lt;String&gt; data = env.fromElements(<span class="string">"hadoop mapreduce"</span>, <span class="string">"hadoop spark"</span>, <span class="string">"spark core"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 数据处理</span></span><br><span class="line">        DataSet&lt;Tuple2&lt;String, Integer&gt;&gt; words = data</span><br><span class="line">                .flatMap((FlatMapFunction&lt;String, Tuple2&lt;String,Integer&gt;&gt;)(s,out)-&gt;&#123;</span><br><span class="line">                    <span class="keyword">for</span> (String word: s.split(<span class="string">" "</span>)) &#123;</span><br><span class="line">                        out.collect(<span class="keyword">new</span> Tuple2&lt;String,Integer&gt;(word,<span class="number">1</span>));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;)</span><br><span class="line">                .groupBy(<span class="number">0</span>)</span><br><span class="line">                .sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// sink</span></span><br><span class="line">        words.print();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-2-流式处理开发"><a href="#3-2-流式处理开发" class="headerlink" title="3.2 流式处理开发"></a>3.2 流式处理开发</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-scala_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Scala代码</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">package</span> flink</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.<span class="type">TimeWindow</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 基于scala语言开发Flink的流式处理程序</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaStreamWordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">       <span class="comment">//1. 获取flink的流式处理环境</span></span><br><span class="line">      <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">      <span class="comment">//2. 构建source数据源</span></span><br><span class="line">      <span class="keyword">val</span> socketTextStream: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">"192.168.18.238"</span>,<span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment">//3. 数据处理</span></span><br><span class="line">      <span class="comment">//3.1 切分每一行，获取所有的单词</span></span><br><span class="line">      <span class="keyword">val</span> words: <span class="type">DataStream</span>[<span class="type">String</span>] = socketTextStream.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line"></span><br><span class="line">      <span class="comment">//3.2 把每个单词计为1 封装成元组(单词，1)</span></span><br><span class="line">      <span class="keyword">val</span> wordAndOne: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = words.map((_,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">      <span class="comment">//3.3 按照单词进行分组</span></span><br><span class="line">      <span class="keyword">val</span> groupByWord: <span class="type">KeyedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] = wordAndOne.keyBy(_._1)</span><br><span class="line"></span><br><span class="line">      <span class="comment">//3.4 设置时间窗口</span></span><br><span class="line">      <span class="keyword">val</span> timeWindow: <span class="type">WindowedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>, <span class="type">TimeWindow</span>] = groupByWord.timeWindow(<span class="type">Time</span>.seconds(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">      <span class="comment">//3.5 相同单词出现的1累加</span></span><br><span class="line">      <span class="keyword">val</span> result: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = timeWindow.reduce((v1,v2)=&gt; (v1._1,v1._2+v2._2))</span><br><span class="line"></span><br><span class="line">      <span class="comment">//4. 构建Sink</span></span><br><span class="line">      result.print()</span><br><span class="line"></span><br><span class="line">      <span class="comment">//5. 启动流式应用程序</span></span><br><span class="line">      env.execute(<span class="string">"ScalaStreamWordCount"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>模拟一个socket服务器</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nc -lk 9999</span><br></pre></td></tr></table></figure>
<h2 id="4-Flink的Table-amp-SQL-API"><a href="#4-Flink的Table-amp-SQL-API" class="headerlink" title="4 Flink的Table &amp; SQL API"></a>4 Flink的Table &amp; SQL API</h2><p><img src="assets/image-20191122170247587.png" alt="image-20191122170247587"></p>
<ul>
<li><p>Table Api是一种关系型Api，类SQL的API。 用户可以像操作表一样的操作数据，非常直观和方便。</p>
</li>
<li><p>Table &amp; SQL API的出现可以解决流处理和批处理统一的API层</p>
<ul>
<li>批处理上的查询会随着输入数据的结束而结束并生成有限的结果集。</li>
<li>流处理上的查询会一直运行并生成结果流</li>
<li>Table &amp; SQL API 做到了批与流上的查询具有相同的语法，因此不用修改代码就能同时实现批和流。</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-planner_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="4-1-批处理开发"><a href="#4-1-批处理开发" class="headerlink" title="4.1 批处理开发"></a>4.1 批处理开发</h3>  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> flink</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.core.fs.<span class="type">FileSystem</span>.<span class="type">WriteMode</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.&#123;<span class="type">Table</span>, <span class="type">Types</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.scala.<span class="type">BatchTableEnvironment</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.sinks.<span class="type">CsvTableSink</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.sources.<span class="type">CsvTableSource</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 基于table &amp; sql api开发 Flink的批处理程序</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaTableSQLBatchWordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//1. 获取flink的table批处理环境</span></span><br><span class="line">      <span class="keyword">val</span> env: <span class="type">ExecutionEnvironment</span> = <span class="type">ExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> tEnv: <span class="type">BatchTableEnvironment</span> = <span class="type">BatchTableEnvironment</span>.create(env)</span><br><span class="line"></span><br><span class="line">      <span class="comment">//2.构建Source数据源</span></span><br><span class="line">      <span class="keyword">val</span> tableSource: <span class="type">CsvTableSource</span> = <span class="type">CsvTableSource</span>.builder()</span><br><span class="line">        .path(<span class="string">"./data/person.txt"</span>)</span><br><span class="line">        .fieldDelimiter(<span class="string">" "</span>)</span><br><span class="line">        .field(<span class="string">"id"</span>, <span class="type">Types</span>.<span class="type">INT</span>)</span><br><span class="line">        .field(<span class="string">"name"</span>, <span class="type">Types</span>.<span class="type">STRING</span>)</span><br><span class="line">        .field(<span class="string">"age"</span>, <span class="type">Types</span>.<span class="type">INT</span>)</span><br><span class="line">        .ignoreParseErrors().lineDelimiter(<span class="string">"\r\n"</span>)</span><br><span class="line">        .build()</span><br><span class="line"></span><br><span class="line">      <span class="comment">//将tableSource注册成表 tEnv.registerTableSource("person",tableSource)</span></span><br><span class="line">      <span class="comment">//3. 查询</span></span><br><span class="line">      <span class="comment">//3.1 查询年龄大于30岁的人</span></span><br><span class="line">      <span class="keyword">val</span> result1: <span class="type">Table</span> = tEnv.scan(<span class="string">"person"</span>).filter(<span class="string">"age &gt; 30"</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment">//3.2 统计不同的年龄用户数</span></span><br><span class="line">      <span class="keyword">val</span> result2: <span class="type">Table</span> = tEnv.sqlQuery(<span class="string">"select age,count(*) from person group by age "</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment">//4. 构建sink //打印表的元数据schema信息</span></span><br><span class="line">      result1.printSchema()</span><br><span class="line"></span><br><span class="line">      <span class="comment">//保存结果数据到文件中 val tableSink1 = new</span></span><br><span class="line">      <span class="keyword">var</span> tableSink1 = <span class="keyword">new</span> <span class="type">CsvTableSink</span>(<span class="string">"./out/result1.txt"</span>, <span class="string">"\t"</span>, <span class="number">1</span>, <span class="type">WriteMode</span>.<span class="type">OVERWRITE</span>)</span><br><span class="line">      result1.writeToSink(tableSink1)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> tableSink2 = <span class="keyword">new</span> <span class="type">CsvTableSink</span>(<span class="string">"./out/result2.txt"</span>, <span class="string">"\t"</span>, <span class="number">1</span>, <span class="type">WriteMode</span>.<span class="type">OVERWRITE</span>)</span><br><span class="line">      result2.writeToSink(tableSink2)</span><br><span class="line"></span><br><span class="line">      <span class="comment">//开启计算</span></span><br><span class="line">      env.execute()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-2-流处理开发"><a href="#4-2-流处理开发" class="headerlink" title="4.2 流处理开发"></a>4.2 流处理开发</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> flink</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.core.fs.<span class="type">FileSystem</span>.<span class="type">WriteMode</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.&#123;<span class="type">DataStream</span>, <span class="type">StreamExecutionEnvironment</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.<span class="type">Table</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.scala.<span class="type">StreamTableEnvironment</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.sinks.<span class="type">CsvTableSink</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 基于table &amp; sql api开发 Flink的流式处理程序</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaTableSQLStreamWordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">id:<span class="type">Int</span>,name:<span class="type">String</span>,age:<span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">  <span class="title">def</span> <span class="title">main</span>(<span class="params">args: <span class="type">Array</span>[<span class="type">String</span>]</span>)</span>: <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//1. 获取flink的table流式处理的环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> streamSQLEnv: <span class="type">StreamTableEnvironment</span> = <span class="type">StreamTableEnvironment</span>.create(env)</span><br><span class="line">    <span class="comment">//2. 构建Source数据源</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">      * 101,zhangsan,18</span></span><br><span class="line"><span class="comment">      * 102,lisi,20</span></span><br><span class="line"><span class="comment">      * 103,wangwu,25</span></span><br><span class="line"><span class="comment">      * 104,zhaoliu,15</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">    <span class="keyword">val</span> socketDataStream: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">"node01"</span>,<span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> userDataStream: <span class="type">DataStream</span>[<span class="type">User</span>] = socketDataStream.map(x=&gt;x.split(<span class="string">","</span>)).map(y=&gt;<span class="type">User</span>(y(<span class="number">0</span>).toInt,y(<span class="number">1</span>),y(<span class="number">2</span>).toInt ))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3. 将流注册成一张表</span></span><br><span class="line">    streamSQLEnv.registerDataStream(<span class="string">"userTable"</span>,userDataStream)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4. 使用table &amp;&amp; sql api来查询数据</span></span><br><span class="line"></span><br><span class="line">     <span class="comment">// 使用table 的api查询年龄大于20岁的人</span></span><br><span class="line">    <span class="keyword">val</span> result1: <span class="type">Table</span> = streamSQLEnv.scan(<span class="string">"userTable"</span>).filter(<span class="string">"age &gt;20"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用sql 的api查询</span></span><br><span class="line">    <span class="keyword">val</span> result2: <span class="type">Table</span> = streamSQLEnv.sqlQuery(<span class="string">" select * from userTable "</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//5. 构建Sink</span></span><br><span class="line">    <span class="keyword">val</span> tableSink1 = <span class="keyword">new</span> <span class="type">CsvTableSink</span>(<span class="string">"./out/tableSink1.txt"</span>,<span class="string">"\t"</span>,<span class="number">1</span>,<span class="type">WriteMode</span>.<span class="type">OVERWRITE</span>)</span><br><span class="line">    result1.writeToSink(tableSink1)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> tableSink2 = <span class="keyword">new</span> <span class="type">CsvTableSink</span>(<span class="string">"./out/tableSink2.txt"</span>,<span class="string">"\t"</span>,<span class="number">1</span>,<span class="type">WriteMode</span>.<span class="type">OVERWRITE</span>)</span><br><span class="line">    result2.writeToSink(tableSink2) <span class="comment">//开启执行流式计算</span></span><br><span class="line"></span><br><span class="line">    env.execute() &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-3-批流一体处理逻辑"><a href="#4-3-批流一体处理逻辑" class="headerlink" title="4.3 批流一体处理逻辑"></a>4.3 批流一体处理逻辑</h3><h4 id="4-3-1-初始化环境"><a href="#4-3-1-初始化环境" class="headerlink" title="4.3.1 初始化环境"></a>4.3.1 初始化环境</h4><p><img src="assets/image-20191122192954640.png" alt="image-20191122192954640"></p>
<h4 id="4-3-2-获取一个table"><a href="#4-3-2-获取一个table" class="headerlink" title="4.3.2 获取一个table"></a>4.3.2 获取一个table</h4><p><img src="assets/image-20191122193054844.png" alt="image-20191122193054844"></p>
<h4 id="4-2-3-输出一个table"><a href="#4-2-3-输出一个table" class="headerlink" title="4.2.3 输出一个table"></a>4.2.3 输出一个table</h4><p><img src="assets/image-20191122193124451.png" alt="image-20191122193124451"></p>
<h4 id="4-2-4-Table-API"><a href="#4-2-4-Table-API" class="headerlink" title="4.2.4 Table API"></a>4.2.4 Table API</h4><p><img src="assets/image-20191122193206331.png" alt="image-20191122193206331"></p>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a href="https://blog.sev7e0.site/">大数据施工现场</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




</html>
