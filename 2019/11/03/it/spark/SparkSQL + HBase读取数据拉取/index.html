<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="天行健、君子以自强不息；地势坤，君子以厚德载物。">
    <meta name="keyword"  content="兰草">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        SparkSQL + HBase数据拉取 - kfly的博客 | kfly&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_1598291_q3el2wqimj.css" type="text/css">
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>kfly</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont iconhome"></i>
                    <span>主页</span>
                </a>
            </li>
 	   <li >
                <a href="/spec/">
                    <i class="iconfont iconzhuanti"></i>
                    <span>专题</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>简历</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#SparkSQL-HBase数据拉取"><span class="toc-text">SparkSQL + HBase数据拉取</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#NewApiHadoop"><span class="toc-text">NewApiHadoop</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#DataSource-V2"><span class="toc-text">DataSource V2</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#DataSource"><span class="toc-text">DataSource</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#DataSourceReader"><span class="toc-text">DataSourceReader</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#DataReaderFactory"><span class="toc-text">DataReaderFactory</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#DataReader"><span class="toc-text">DataReader</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#fullScanByColumns"><span class="toc-text">fullScanByColumns</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#fullScanByFilters"><span class="toc-text">fullScanByFilters</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#DataWriter"><span class="toc-text">DataWriter</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#使用"><span class="toc-text">使用</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#注意"><span class="toc-text">注意</span></a></li></ol></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        SparkSQL + HBase数据拉取
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2019-11-03 12:00:30</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#spark sql" title="spark sql">spark sql</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#DataSource2" title="DataSource2">DataSource2</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <h2 id="SparkSQL-HBase数据拉取"><a href="#SparkSQL-HBase数据拉取" class="headerlink" title="SparkSQL + HBase数据拉取"></a>SparkSQL + HBase数据拉取</h2><h4 id="NewApiHadoop"><a href="#NewApiHadoop" class="headerlink" title="NewApiHadoop"></a>NewApiHadoop</h4><pre><code class="scala">val context: SparkContext = sparkSession.sparkContext
// set inputformat
conf.set(TableInputFormat.INPUT_TABLE, Constants.HTAB_ORDER)
val scan = new Scan
// todo scan 过滤条件
conf.set(TableInputFormat.SCAN, convertScanToString(scan))
val rddResult: RDD[(ImmutableBytesWritable, Result)] = 
                                        context.newAPIHadoopRDD(
                      conf, // hbase配置文件
                      classOf[TableInputFormat],
                      classOf[ImmutableBytesWritable],
                      classOf[Result])
import sparkSession.implicits._
// result to rdd
val orderRDD: RDD[Order] = rddResult.mapPartitions(eachPartition =&gt; {
  val orders: Iterator[Order] = eachPartition.map(eachResult =&gt; {
    val value: Result = eachResult._2
    Order(order_id, city_id, start_time, end_time)
  })
  orders
})
orderRDD.toDF

def convertScanToString(scan: Scan):String = {
    val proto = ProtobufUtil.toScan(scan)
    Base64.encodeBytes(proto.toByteArray)
}
</code></pre>
<h4 id="DataSource-V2"><a href="#DataSource-V2" class="headerlink" title="DataSource V2"></a>DataSource V2</h4><ul>
<li>DataSource V1和V2的区别可以参考 <a href="https://blog.csdn.net/zjerryj/article/details/84922369" target="_blank" rel="noopener">文章</a></li>
</ul>
<h5 id="DataSource"><a href="#DataSource" class="headerlink" title="DataSource"></a>DataSource</h5><pre><code class="scala">/**
     * 自定义spark sql数据源
  * 1.继承DataSourceV2向Spark注册数据源
  * 2.继承ReadSupport支持读数据
 *  {@link ReadSupport }支持读取操作
 */
class HBaseCustomSource extends DataSourceV2 with ReadSupport{
  // 自定义的DataSourceReader
  override def createReader(options: DataSourceOptions): DataSourceReader = {
      new HBaseCustomDataSourceReader(hbaseTableName,sparkSqlTableSchema,hbaseTableSchema)
  }
}
</code></pre>
<h5 id="DataSourceReader"><a href="#DataSourceReader" class="headerlink" title="DataSourceReader"></a>DataSourceReader</h5><pre><code class="scala">/**
 * 自定义的DataSourceReader
 * 继承DataSourceReader
 * 重写readSchema方法用来生成schema
 * 重写createDataReaderFactories,多分区支持。用来根据条件，创建多个工厂实例
 *
 * 注意：
 *  {@link SupportsPushDownFilters } 过滤条件
 *  {@link SupportsPushDownRequiredColumns }裁剪字段
 * 1. 下推条件必须满足数据类型 比如：string 不能判断大小
 * 2. short and bytes 比较大小必须使用显示转换 where id case (见spark ParquetFilter源码)
 */
class HBaseCustomDataSourceReader extends DataSourceReader 
                with SupportsPushDownFilters 
                with SupportsPushDownRequiredColumns{

  var supportsFilters = Array.empty[Filter]
  var requiredSchema:StructType = null

  // 过滤条件
  override def pushFilters(filters: Array[Filter]): Array[Filter] = {
    val supported = ListBuffer.empty[Filter]
    val unsupported = ListBuffer.empty[Filter]

    /**
     * 仅仅把等于大于大于等于，小于小于等于下推
     */
    filters.foreach{
      case filter: EqualTo =&gt; supported +=filter
      case filter: GreaterThan=&gt; supported +=filter
      case filter: GreaterThanOrEqual=&gt; supported +=filter
      case filter: LessThan =&gt; supported +=filter
      case filter: LessThanOrEqual =&gt; supported +=filter
      case filter =&gt; unsupported +=filter
    }
    this.supportsFilters = supported.toArray[Filter]
    unsupported.toArray
  }

  // 下推支持的过滤条件
  override def pushedFilters(): Array[Filter] = supportsFilters.toArray

   // 获取select的列
  override def pruneColumns(requiredSchema: StructType): Unit = {
    this.requiredSchema = requiredSchema
  }

  // 生成schema
  override def readSchema(): StructType = {
    if(requiredSchema != null){
      return requiredSchema
    }
    StructType.fromDDL(sparkSqlTableSchema)
  }

  // 多分区支持
  override def createDataReaderFactories(): util.List[DataReaderFactory[Row]] = {
    import scala.collection.JavaConverters._
    Seq(
      new HBaseDataReaderFactory(...).asInstanceOf[DataReaderFactory[Row]]
    ).asJava
  }
}
</code></pre>
<h5 id="DataReaderFactory"><a href="#DataReaderFactory" class="headerlink" title="DataReaderFactory"></a>DataReaderFactory</h5><pre><code class="scala">/**
 * 创建DataReader工厂类
 */
class HBaseDataReaderFactory extends DataReaderFactory[Row]{
  override def createDataReader(): DataReader[Row] = {
    new HBaseCustomDataReader()
  }
}
</code></pre>
<h5 id="DataReader"><a href="#DataReader" class="headerlink" title="DataReader"></a>DataReader</h5><pre><code class="scala">class HBaseCustomDataReaderextends DataReader[Row]{
    // hbase连接
  var hbaseConnection : Connection = null
  // 读取到的数据
  val datas:Iterator[Result] = getIterator

  // load hbase data
  def getIterator: Iterator[Result] = {
    table = hbaseConnection.getTable(TableName.valueOf(hbaseTableName.trim))
    val scan: Scan = new Scan
    // 填充DataSourceReader下推的过滤条件,和列裁剪
    fullScanByColumns(scan,requiredSchemaList)
    fullScanByFilter(scan)
    // 查询数据并解析
    scanner = table.getScanner(scan)
    import scala.collection.JavaConverters._
    scanner.iterator.asScala
  }
}
</code></pre>
<h6 id="fullScanByColumns"><a href="#fullScanByColumns" class="headerlink" title="fullScanByColumns"></a>fullScanByColumns</h6><pre><code class="scala"> // 例如：拼接查询所需要的列
def fullScanByColumns(scan:Scan)={
    hbaseTableSelectedFamilyAndColumn.map(tuple=&gt;{
        scan.addColumn(tuple._1getBytes,tuple._2.getBytes)
        })
}
</code></pre>
<h6 id="fullScanByFilters"><a href="#fullScanByFilters" class="headerlink" title="fullScanByFilters"></a>fullScanByFilters</h6><pre><code class="scala">//例如：拼接所需要的filter supportFilters
def fullScanByFilter(scan: Scan) = {
  val filterList = new FilterList()
  supportsFilters.foreach{
    case filter: EqualTo =&gt; {
      filterList.addFilter()
    }
    // todo 
  }
  if(filterList.getFilters.size() &gt; 0){
    scan.setFilter(filterList)
  }
}

</code></pre>
<h5 id="DataWriter"><a href="#DataWriter" class="headerlink" title="DataWriter"></a>DataWriter</h5><pre><code class="java">// data writer支持事物的读写
public interface DataSourceWriter {
  void commit(WriterCommitMessage[] messages);
  void abort(WriterCommitMessage[] messages);
}

public interface DataWriter&lt;T&gt; {
  void write(T record) throws IOException;
  WriterCommitMessage commit() throws IOException;
  void abort() throws IOException;
}
</code></pre>
<h5 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h5><pre><code class="java"> // 数据源1
 Dataset&lt;Row&gt; load = spark.read()
   .format(&quot;top.kfly.hbase.source.HBaseCustomSource&quot;)
   .option(Constants.HBASE_TABlE_NAME, &quot;flink:kfly_orders&quot;)
   .option(Constants.HBASE_TABLE_SCHEMA, &quot; f1:userId,f1:goodsMoney,f1:orderNo,f1:goodId&quot;)
   .option(Constants.SPARK_SQL_TABlE_SCHEMA, &quot;userId String,goodsMoney String,orderNo String,goodId int&quot;)
   .load()
   .select(&quot;goodsMoney&quot;,&quot;orderNo&quot;,&quot;goodId&quot;)
   .filter(&quot;goodId &lt;= 16&quot;);
</code></pre>
<h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><p><em>当字段类型出现short / byte时，将不会被下推。需要显性的转换为smallint,如下</em></p>
<pre><code class="sql">select * from t where id = cast(2 as smallint) 
</code></pre>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a href="https://blog.sev7e0.site/">大数据施工现场</a></span>
        <span>/</span>
        
        <span><a href="https://wangchujiang.com/linux-command/">linux命令</a></span>
        <span>/</span>
        
        <span><a href="http://redisdoc.com/">Redis命令</a></span>
        <span>/</span>
        
        <span><a href="https://github.com/orchid-ding">github</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




</html>
