<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="天行健、君子以自强不息；地势坤，君子以厚德载物。">
    <meta name="keyword"  content="兰草">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        Hadoop之数据分析Hive（一） - kfly的博客 | kfly&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_1598291_q3el2wqimj.css" type="text/css">
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>kfly</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont iconhome"></i>
                    <span>主页</span>
                </a>
            </li>
 	   <li >
                <a href="/spec/">
                    <i class="iconfont iconzhuanti"></i>
                    <span>专题</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>简历</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-数据仓库的基本概念"><span class="toc-text">1.数据仓库的基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-数据仓库的基本概念-1"><span class="toc-text">1.数据仓库的基本概念</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-数据仓库的主要特征"><span class="toc-text">2.数据仓库的主要特征</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-数据仓库与数据库区别"><span class="toc-text">3. 数据仓库与数据库区别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-数据仓库分层架构"><span class="toc-text">4.数据仓库分层架构</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Hive是什么"><span class="toc-text">2. Hive是什么</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-hive的概念"><span class="toc-text">1 hive的概念</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-Hive与数据库的区别"><span class="toc-text">2 Hive与数据库的区别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-Hive的优缺点"><span class="toc-text">3 Hive的优缺点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-Hive架构原理"><span class="toc-text">4 Hive架构原理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Hive的安装部署"><span class="toc-text">3. Hive的安装部署</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-hive的交互方式"><span class="toc-text">4. hive的交互方式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-Hive交互shell"><span class="toc-text">1 Hive交互shell</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-Hive-JDBC服务"><span class="toc-text">2 Hive JDBC服务</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-Hive的命令"><span class="toc-text">3  Hive的命令</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5、Hive的数据类型"><span class="toc-text">5、Hive的数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-基本数据类型"><span class="toc-text">1 基本数据类型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-复合数据类型"><span class="toc-text">2 复合数据类型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6、Hive的DDL操作"><span class="toc-text">6、Hive的DDL操作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-hive的数据库DDL操作"><span class="toc-text">1 hive的数据库DDL操作</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1、创建数据库"><span class="toc-text">1、创建数据库</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2、显示所有数据库"><span class="toc-text">2、显示所有数据库</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3、查询数据库"><span class="toc-text">3、查询数据库</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4、查看数据库详情"><span class="toc-text">4、查看数据库详情</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5、显示数据库详细信息"><span class="toc-text">5、显示数据库详细信息</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6、切换当前数据库"><span class="toc-text">6、切换当前数据库</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7、删除数据库"><span class="toc-text">7、删除数据库</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-2-hive的表DDL操作"><span class="toc-text">6.2 hive的表DDL操作</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-、建表语法介绍"><span class="toc-text">1 、建表语法介绍</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-、字段解释说明"><span class="toc-text">2 、字段解释说明</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3、-创建内部表"><span class="toc-text">3、 创建内部表</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4、-创建外部表"><span class="toc-text">4、 创建外部表</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5、-内部表与外部表的互相转换"><span class="toc-text">5、 内部表与外部表的互相转换</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6、-内部表与外部表的区别"><span class="toc-text">6、 内部表与外部表的区别</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7、内部表与外部表的使用时机"><span class="toc-text">7、内部表与外部表的使用时机</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#8、hive的分区表"><span class="toc-text">8、hive的分区表</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#9、hive的分桶表"><span class="toc-text">9、hive的分桶表</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7、Hive修改表结构"><span class="toc-text">7、Hive修改表结构</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#7-1-修改表的名称"><span class="toc-text">7.1 修改表的名称</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-2-表的结构信息"><span class="toc-text">7.2 表的结构信息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-3-增加-修改-替换列信息"><span class="toc-text">7.3 增加/修改/替换列信息</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-Hive数据导入"><span class="toc-text">8. Hive数据导入</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1、直接向表中插入数据（强烈不推荐使用）"><span class="toc-text">8.1、直接向表中插入数据（强烈不推荐使用）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-2、通过load方式加载数据（必须掌握）"><span class="toc-text">8.2、通过load方式加载数据（必须掌握）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-3、通过查询方式加载数据（必须掌握）"><span class="toc-text">8.3、通过查询方式加载数据（必须掌握）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-4、查询语句中创建表并加载数据（as-select）"><span class="toc-text">8.4、查询语句中创建表并加载数据（as select）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-5、创建表时通过location指定加载数据路径"><span class="toc-text">8.5、创建表时通过location指定加载数据路径</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-6、export导出与import-导入-hive表数据（内部表操作）"><span class="toc-text">8.6、export导出与import 导入 hive表数据（内部表操作）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9、Hive数据导出"><span class="toc-text">9、Hive数据导出</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#9-1-insert-导出"><span class="toc-text">9.1 insert 导出</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-2、-Hive-Shell-命令导出"><span class="toc-text">9.2、 Hive Shell 命令导出</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-3、export导出到HDFS上"><span class="toc-text">9.3、export导出到HDFS上</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10、hive的静态分区和动态分区"><span class="toc-text">10、hive的静态分区和动态分区</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#10-1-静态分区"><span class="toc-text">10.1 静态分区</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11、hive的基本查询语法"><span class="toc-text">11、hive的基本查询语法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-基本查询"><span class="toc-text">1. 基本查询</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-1-全表和特定列查询"><span class="toc-text">1.1 全表和特定列查询</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-2-列起别名"><span class="toc-text">1.2 列起别名</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-4-limit-语句"><span class="toc-text">1.4 limit 语句</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-5-where-语句"><span class="toc-text">1.5 where 语句</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-6-算术运算符"><span class="toc-text">1.6 算术运算符</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-7-比较运算符"><span class="toc-text">1.7 比较运算符</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-8-逻辑运算符"><span class="toc-text">1.8 逻辑运算符</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-分组"><span class="toc-text">2. 分组</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-Group-By-语句"><span class="toc-text">2.1 Group By 语句</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-Having语句"><span class="toc-text">2.2 Having语句</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-join语句"><span class="toc-text">3. join语句</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#11-3-1-等值-join"><span class="toc-text">11.3.1 等值 join</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-3-2-表的别名"><span class="toc-text">11.3.2 表的别名</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-3-3-内连接-inner-join"><span class="toc-text">11.3.3 内连接 inner join</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-3-4-左外连接-left-outer-join"><span class="toc-text">11.3.4 左外连接 left outer join</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-5-右外连接-right-outer-join"><span class="toc-text">3.5 右外连接 right outer join</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-3-6-满外连接-full-outer-join"><span class="toc-text">11.3.6 满外连接 full outer join</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-3-7-多表连接"><span class="toc-text">11.3.7 多表连接</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-4-排序"><span class="toc-text">11.4. 排序</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#11-4-1-order-by-全局排序"><span class="toc-text">11.4.1 order by 全局排序</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-4-2-按照别名排序"><span class="toc-text">11.4.2 按照别名排序</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-4-3-每个MapReduce内部排序（Sort-By）局部排序"><span class="toc-text">11.4.3 每个MapReduce内部排序（Sort By）局部排序</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-4-4-distribute-by-分区排序"><span class="toc-text">11.4.4 distribute by 分区排序</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-4-5-cluster-by"><span class="toc-text">11.4.5 cluster by</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#第三步：代码开发"><span class="toc-text">第三步：代码开发</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#、hive的可视化工具dbeaver介绍以及使用"><span class="toc-text">、hive的可视化工具dbeaver介绍以及使用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1、dbeaver的基本介绍"><span class="toc-text">1、dbeaver的基本介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2、dbeaver的下载安装"><span class="toc-text">2、dbeaver的下载安装</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3、dbeaver的安装与使用"><span class="toc-text">3、dbeaver的安装与使用</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#第一步：双击dbeaver-exe然后启动dbeaver图形化界面"><span class="toc-text">第一步：双击dbeaver.exe然后启动dbeaver图形化界面</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#第二步：配置我们的主机名与端口号"><span class="toc-text">第二步：配置我们的主机名与端口号</span></a></li></ol></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        Hadoop之数据分析Hive（一）
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2019-11-01 16:01:32</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#hive" title="hive">hive</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <h3 id="1-数据仓库的基本概念"><a href="#1-数据仓库的基本概念" class="headerlink" title="1.数据仓库的基本概念"></a>1.数据仓库的基本概念</h3><h4 id="1-数据仓库的基本概念-1"><a href="#1-数据仓库的基本概念-1" class="headerlink" title="1.数据仓库的基本概念"></a>1.数据仓库的基本概念</h4><p>英文名称为Data Warehouse，可简写为DW或DWH。数据仓库的目的是构建面向分析的集成化数据环境，为企业提供决策支持（Decision Support）。它出于分析性报告和决策支持目的而创建。</p>
<p>数据仓库本身并不“生产”任何数据，同时自身也不需要“消费”任何的数据，数据来源于外部，并且开放给外部应用，这也是为什么叫“仓库”，而不叫“工厂”的原因。</p>
<h4 id="2-数据仓库的主要特征"><a href="#2-数据仓库的主要特征" class="headerlink" title="2.数据仓库的主要特征"></a>2.数据仓库的主要特征</h4><p>数据仓库是面向主题的（Subject-Oriented）、集成的（Integrated）、非易失的（Non-Volatile）和时变的（Time-Variant ）数据集合，用以支持管理决策。</p>
<h4 id="3-数据仓库与数据库区别"><a href="#3-数据仓库与数据库区别" class="headerlink" title="3. 数据仓库与数据库区别"></a>3. 数据仓库与数据库区别</h4><p>数据库与数据仓库的区别实际讲的是 OLTP 与 OLAP 的区别。 </p>
<p>操作型处理，叫联机事务处理 OLTP（On-Line Transaction Processing，），也可以称面向交易的处理系统，它是针对具体业务在数据库联机的日常操作，通常对少数记录进行查询、修改。用户较为关心操作的响应时间、数据的安全性、完整性和并发支持的用户数等问题。传统的数据库系统作为数据管理的主要手段，主要用于操作型处理。 </p>
<p>分析型处理，叫联机分析处理 OLAP（On-Line Analytical Processing）一般针对某些主题的历史数据进行分析，支持管理决策。</p>
<p>首先要明白，数据仓库的出现，并不是要取代数据库。</p>
<p>数据库是面向事务的设计，数据仓库是面向主题设计的。</p>
<p>数据库一般存储业务数据，数据仓库存储的一般是历史数据。</p>
<p>数据库设计是尽量避免冗余，一般针对某一业务应用进行设计，比如一张简单的User表，记录用户名、密码等简单数据即可，符合业务应用，但是不符合分析。数据仓库在设计是有意引入冗余，依照分析需求，分析维度、分析指标进行设计。</p>
<p>数据库是为捕获数据而设计，数据仓库是为分析数据而设计。</p>
<p>以银行业务为例。数据库是事务系统的数据平台，客户在银行做的每笔交易都会写入数据库，被记录下来，这里，可以简单地理解为用数据库记账。数据仓库是分析系统的数据平台，它从事务系统获取数据，并做汇总、加工，为决策者提供决策的依据。比如，某银行某分行一个月发生多少交易，该分行当前存款余额是多少。如果存款又多，消费交易又多，那么该地区就有必要设立ATM了。 </p>
<p>显然，银行的交易量是巨大的，通常以百万甚至千万次来计算。事务系统是实时的，这就要求时效性，客户存一笔钱需要几十秒是无法忍受的，这就要求数据库只能存储很短一段时间的数据。而分析系统是事后的，它要提供关注时间段内所有的有效数据。这些数据是海量的，汇总计算起来也要慢一些，但是，只要能够提供有效的分析数据就达到目的了。 </p>
<p>数据仓库，是在数据库已经大量存在的情况下，为了进一步挖掘数据资源、为了决策需要而产生的，它决不是所谓的“大型数据库”。</p>
<h4 id="4-数据仓库分层架构"><a href="#4-数据仓库分层架构" class="headerlink" title="4.数据仓库分层架构"></a>4.数据仓库分层架构</h4><p>按照数据流入流出的过程，数据仓库架构可分为三层——<strong>源数据</strong>、<strong>数据仓库</strong>、<strong>数据应用。</strong>                            </p>
<p>数据仓库的数据来源于不同的源数据，并提供多样的数据应用，数据自下而上流入数据仓库后向上层开放应用，而数据仓库只是中间集成化数据管理的一个平台。</p>
<p>源数据层（ODS）：此层数据无任何更改，直接沿用外围系统数据结构和数据，不对外开放；为临时存储层，是接口数据的临时存储区域，为后一步的数据处理做准备。</p>
<p>数据仓库层（DW）：也称为细节层，DW层的数据应该是一致的、准确的、干净的数据，即对源系统数据进行了清洗（去除了杂质）后的数据。</p>
<p>数据应用层（DA或APP）：前端应用直接读取的数据源；根据报表、专题分析需求而计算生成的数据。</p>
<p>数据仓库从各数据源获取数据及在数据仓库内的数据转换和流动都可以认为是ETL（抽取Extra, 转化Transfer, 装载Load）的过程，ETL是数据仓库的流水线，也可以认为是数据仓库的血液，它维系着数据仓库中数据的新陈代谢，而数据仓库日常的管理和维护工作的大部分精力就是保持ETL的正常和稳定。</p>
<p>为什么要对数据仓库分层？</p>
<p>用空间换时间，通过大量的预处理来提升应用系统的用户体验（效率），因此数据仓库会存在大量冗余的数据；不分层的话，如果源业务系统的业务规则发生变化将会影响整个数据清洗过程，工作量巨大。</p>
<p>通过数据分层管理可以简化数据清洗的过程，因为把原来一步的工作分到了多个步骤去完成，相当于把一个复杂的工作拆成了多个简单的工作，把一个大的黑盒变成了一个白盒，每一层的处理逻辑都相对简单和容易理解，这样我们比较容易保证每一个步骤的正确性，当数据发生错误的时候，往往我们只需要局部调整某个步骤即可。</p>
<h3 id="2-Hive是什么"><a href="#2-Hive是什么" class="headerlink" title="2. Hive是什么"></a>2. Hive是什么</h3><h4 id="1-hive的概念"><a href="#1-hive的概念" class="headerlink" title="1 hive的概念"></a>1 hive的概念</h4><p>Hive是基于Hadoop的一个数据仓库工具，==可以将结构化的数据文件映射为一张数据库表==，并提供类SQL查询功能。其本质是将SQL转换为MapReduce的任务进行运算，底层由HDFS来提供数据的存储，说白了hive可以理解为一个将SQL转换为MapReduce的任务的工具，甚至更进一步可以说hive就是一个MapReduce的客户端</p>
<p><img src="/Users/dingchuangshi/Downloads/hive_day01_课前资料/hive_day01课程设计.assets/Snipaste_2019-07-10_23-23-31.png" alt=""></p>
<h4 id="2-Hive与数据库的区别"><a href="#2-Hive与数据库的区别" class="headerlink" title="2 Hive与数据库的区别"></a>2 Hive与数据库的区别</h4><p><img src="/Users/dingchuangshi/Downloads/hive_day01_课前资料/hive_day01课程设计.assets/2018040319335283.png" alt=""></p>
<ul>
<li>Hive 具有 SQL 数据库的外表，但应用场景完全不同。</li>
<li>==Hive 只适合用来做海量离线数据统计分析，也就是数据仓库==。</li>
</ul>
<h4 id="3-Hive的优缺点"><a href="#3-Hive的优缺点" class="headerlink" title="3 Hive的优缺点"></a>3 Hive的优缺点</h4><ul>
<li><p>==优点==</p>
<ul>
<li><p><strong>操作接口采用类SQL语法</strong>，提供快速开发的能力（简单、容易上手）。</p>
</li>
<li><p><strong>避免了去写MapReduce</strong>，减少开发人员的学习成本。</p>
</li>
<li><p><strong>Hive支持用户自定义函数</strong>，用户可以根据自己的需求来实现自己的函数。</p>
</li>
</ul>
</li>
<li><p>==缺点==</p>
<ul>
<li><strong>Hive 不支持记录级别的增删改操作</strong></li>
<li><strong>Hive 的查询延迟很严重</strong><ul>
<li>hadoop jar  xxxx.jar  xxx.class /input /output<ul>
<li>进行任务的划分，然后进行计算资源的申请</li>
<li>map 0%  reduce 0%</li>
<li>map 10%  reduce 0%</li>
</ul>
</li>
</ul>
</li>
<li><strong>Hive 不支持事务</strong></li>
</ul>
</li>
</ul>
<h4 id="4-Hive架构原理"><a href="#4-Hive架构原理" class="headerlink" title="4 Hive架构原理"></a>4 Hive架构原理</h4><p><img src="assets/2019-07-11_11-08-35.png" alt=""></p>
<ul>
<li>1、用户接口：Client</li>
</ul>
<ul>
<li>CLI（hive shell）、JDBC/ODBC(java访问hive)、WEBUI（浏览器访问hive）</li>
</ul>
<ul>
<li><p>2、元数据：Metastore</p>
<ul>
<li><p>元数据包括：表名、表所属的数据库（默认是default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等；</p>
<ul>
<li>默认存储在自带的derby数据库中，==推荐使用MySQL存储Metastore==</li>
</ul>
</li>
</ul>
</li>
<li><p>3、Hadoop集群</p>
<ul>
<li>使用HDFS进行存储，使用MapReduce进行计算。</li>
</ul>
</li>
<li><p>4、Driver：驱动器</p>
<ul>
<li>解析器（SQL Parser） <ul>
<li>将SQL字符串转换成抽象语法树AST</li>
<li>对AST进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误</li>
</ul>
</li>
<li>编译器（Physical Plan）：将AST编译生成逻辑执行计划</li>
<li>优化器（Query Optimizer）：对逻辑执行计划进行优化</li>
<li>执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于Hive来说默认就是mapreduce任务</li>
</ul>
</li>
</ul>
<p><img src="assets/hive1.png" alt="hive1"></p>
<h3 id="3-Hive的安装部署"><a href="#3-Hive的安装部署" class="headerlink" title="3. Hive的安装部署"></a>3. Hive的安装部署</h3><p>​    <a href="https://kfly.top/2019/11/26/hadoop/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/">hive安装部署</a>    </p>
<h3 id="4-hive的交互方式"><a href="#4-hive的交互方式" class="headerlink" title="4. hive的交互方式"></a>4. hive的交互方式</h3><ul>
<li>==先启动hadoop集群和mysql服务==</li>
</ul>
<h4 id="1-Hive交互shell"><a href="#1-Hive交互shell" class="headerlink" title="1 Hive交互shell"></a>1 Hive交互shell</h4><pre><code class="shell">cd /kkb/install/hive-1.1.0-cdh5.14.2
bin/hive
</code></pre>
<h4 id="2-Hive-JDBC服务"><a href="#2-Hive-JDBC服务" class="headerlink" title="2 Hive JDBC服务"></a>2 Hive JDBC服务</h4><ul>
<li><p>启动hiveserver2服务</p>
<ul>
<li><p>前台启动</p>
<pre><code class="shell">cd /kkb/install/hive-1.1.0-cdh5.14.2
bin/hive --service hiveserver2
</code></pre>
</li>
<li><p>后台启动</p>
</li>
</ul>
<pre><code class="shell">cd /kkb/install/hive-1.1.0-cdh5.14.2
nohup  bin/hive --service hiveserver2  &amp;
</code></pre>
</li>
<li><p>beeline连接hiveserver2</p>
<p>重新开启一个会话窗口，然后使用beeline连接hive</p>
<pre><code class="shell">cd /kkb/install/hive-1.1.0-cdh5.14.2
bin/beeline
beeline&gt; !connect jdbc:hive2://node03:10000
</code></pre>
</li>
</ul>
<h4 id="3-Hive的命令"><a href="#3-Hive的命令" class="headerlink" title="3  Hive的命令"></a>3  Hive的命令</h4><ul>
<li>hive  ==-e== sql语句<ul>
<li>使用 –e  参数来直接执行hql的语句</li>
</ul>
</li>
</ul>
<pre><code>cd /kkb/install/hive-1.1.0-cdh5.14.2/
bin/hive -e &quot;show databases&quot;
</code></pre><ul>
<li><p>hive  ==-f==  sql文件</p>
<ul>
<li><p>使用 –f  参数执行包含hql语句的文件</p>
</li>
<li><p>node03执行以下命令准备hive执行脚本</p>
</li>
<li><pre><code>cd /kkb/install/
vim hive.sql

文件内容如下
create database if not exists myhive;

通过以下命令来执行我们的hive脚本
cd /kkb/install/hive-1.1.0-cdh5.14.2/
bin/hive -f /kkb/install/hive.sql 
</code></pre></li>
</ul>
</li>
</ul>
<h3 id="5、Hive的数据类型"><a href="#5、Hive的数据类型" class="headerlink" title="5、Hive的数据类型"></a>5、Hive的数据类型</h3><h4 id="1-基本数据类型"><a href="#1-基本数据类型" class="headerlink" title="1 基本数据类型"></a>1 基本数据类型</h4><table>
<thead>
<tr>
<th style="text-align:center">类型名称</th>
<th style="text-align:center">描述</th>
<th style="text-align:center">举例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">boolean</td>
<td style="text-align:center">true/false</td>
<td style="text-align:center">true</td>
</tr>
<tr>
<td style="text-align:center">tinyint</td>
<td style="text-align:center">1字节的有符号整数</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">smallint</td>
<td style="text-align:center">2字节的有符号整数</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">==<strong>int</strong>==</td>
<td style="text-align:center">4字节的有符号整数</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center"><strong>==bigint==</strong></td>
<td style="text-align:center">8字节的有符号整数</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">float</td>
<td style="text-align:center">4字节单精度浮点数</td>
<td style="text-align:center">1.0</td>
</tr>
<tr>
<td style="text-align:center"><strong>==double==</strong></td>
<td style="text-align:center">8字节单精度浮点数</td>
<td style="text-align:center">1.0</td>
</tr>
<tr>
<td style="text-align:center"><strong>==string==</strong></td>
<td style="text-align:center">字符串(不设长度)</td>
<td style="text-align:center">“abc”</td>
</tr>
<tr>
<td style="text-align:center">varchar</td>
<td style="text-align:center">字符串（1-65355长度，超长截断）</td>
<td style="text-align:center">“abc”</td>
</tr>
<tr>
<td style="text-align:center">timestamp</td>
<td style="text-align:center">时间戳</td>
<td style="text-align:center">1563157873</td>
</tr>
<tr>
<td style="text-align:center">date</td>
<td style="text-align:center">日期</td>
<td style="text-align:center">20190715</td>
</tr>
</tbody>
</table>
<h4 id="2-复合数据类型"><a href="#2-复合数据类型" class="headerlink" title="2 复合数据类型"></a>2 复合数据类型</h4><table>
<thead>
<tr>
<th style="text-align:center">类型名称</th>
<th style="text-align:center">描述</th>
<th style="text-align:center">举例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">array</td>
<td style="text-align:center">一组有序的字段，字段类型必须相同 array(元素1，元素2)</td>
<td style="text-align:center">Array（1,2,3）</td>
</tr>
<tr>
<td style="text-align:center">map</td>
<td style="text-align:center">一组无序的键值对 map(k1,v1,k2,v2)</td>
<td style="text-align:center">Map(‘a’,1,’b’,2)</td>
</tr>
<tr>
<td style="text-align:center">struct</td>
<td style="text-align:center">一组命名的字段，字段类型可以不同 struct(元素1，元素2)</td>
<td style="text-align:center">Struct(‘a’,1,2,0)</td>
</tr>
</tbody>
</table>
<ul>
<li><p>array字段的元素访问方式：</p>
<ul>
<li><p>下标获取元素，下标从0开始</p>
<ul>
<li><p>获取第一个元素</p>
<ul>
<li>array[0]</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>map字段的元素访问方式</p>
<ul>
<li><p>通过键获取值</p>
<ul>
<li><p>获取a这个key对应的value</p>
<ul>
<li>map[‘a’]</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>struct字段的元素获取方式<ul>
<li>定义一个字段c的类型为struct{a int;b string}<ul>
<li>获取a和b的值<ul>
<li>使用c.a 和c.b 获取其中的元素值<ul>
<li>这里可以把这种类型看成是一个对象</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<pre><code class="sql">create table complex(
         col1 array&lt;int&gt;,
         col2 map&lt;string,int&gt;,
         col3 struct&lt;a:string,b:int,c:double&gt;
)

</code></pre>
<h3 id="6、Hive的DDL操作"><a href="#6、Hive的DDL操作" class="headerlink" title="6、Hive的DDL操作"></a>6、Hive的DDL操作</h3><h4 id="1-hive的数据库DDL操作"><a href="#1-hive的数据库DDL操作" class="headerlink" title="1 hive的数据库DDL操作"></a>1 hive的数据库DDL操作</h4><h5 id="1、创建数据库"><a href="#1、创建数据库" class="headerlink" title="1、创建数据库"></a>1、创建数据库</h5><pre><code class="sql">hive &gt; create database db_hive;
# 或者
hive &gt; create database if not exists db_hive;
</code></pre>
<ul>
<li>数据库在HDFS上的默认存储路径是==/user/hive/warehouse/*.db==</li>
</ul>
<h5 id="2、显示所有数据库"><a href="#2、显示所有数据库" class="headerlink" title="2、显示所有数据库"></a>2、显示所有数据库</h5><pre><code class="sql">  hive&gt; show databases;
</code></pre>
<h5 id="3、查询数据库"><a href="#3、查询数据库" class="headerlink" title="3、查询数据库"></a>3、查询数据库</h5><pre><code class="sql">hive&gt; show databases like &#39;db_hive*&#39;;
</code></pre>
<h5 id="4、查看数据库详情"><a href="#4、查看数据库详情" class="headerlink" title="4、查看数据库详情"></a>4、查看数据库详情</h5><pre><code class="sql">hive&gt; desc database db_hive;
</code></pre>
<h5 id="5、显示数据库详细信息"><a href="#5、显示数据库详细信息" class="headerlink" title="5、显示数据库详细信息"></a>5、显示数据库详细信息</h5><pre><code class="sql">hive&gt; desc database extended db_hive;
</code></pre>
<h5 id="6、切换当前数据库"><a href="#6、切换当前数据库" class="headerlink" title="6、切换当前数据库"></a>6、切换当前数据库</h5><pre><code class="sql">hive &gt; use db_hive;
</code></pre>
<h5 id="7、删除数据库"><a href="#7、删除数据库" class="headerlink" title="7、删除数据库"></a>7、删除数据库</h5><pre><code class="sql">#删除为空的数据库
hive&gt; drop database db_hive;

#如果删除的数据库不存在，最好采用if exists 判断数据库是否存在
hive&gt; drop database if exists db_hive;

#如果数据库中有表存在，这里需要使用cascade强制删除数据库
hive&gt; drop database if exists db_hive cascade;
</code></pre>
<h4 id="6-2-hive的表DDL操作"><a href="#6-2-hive的表DDL操作" class="headerlink" title="6.2 hive的表DDL操作"></a>6.2 hive的表DDL操作</h4><h5 id="1-、建表语法介绍"><a href="#1-、建表语法介绍" class="headerlink" title="1 、建表语法介绍"></a>1 、建表语法介绍</h5><pre><code class="sql">CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name 
[(col_name data_type [COMMENT col_comment], ...)] 
[COMMENT table_comment] 
[PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] 分区
[CLUSTERED BY (col_name, col_name, ...) 分桶
[SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS] 
[ROW FORMAT row_format]  row format delimited fields terminated by “分隔符”
[STORED AS file_format] 
[LOCATION hdfs_path]
</code></pre>
<p>官网地址：<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL</a></p>
<h5 id="2-、字段解释说明"><a href="#2-、字段解释说明" class="headerlink" title="2 、字段解释说明"></a>2 、字段解释说明</h5><ul>
<li><p>create table </p>
<ul>
<li>创建一个指定名字的表</li>
</ul>
</li>
<li><p>EXTERNAL  </p>
<ul>
<li>创建一个外部表，在建表的同时指定一个指向实际数据的路径（LOCATION），指定表的数据保存在哪里</li>
</ul>
</li>
<li><p>COMMENT</p>
<ul>
<li>为表和列添加注释</li>
</ul>
</li>
<li><p>PARTITIONED BY</p>
<ul>
<li>创建分区表</li>
</ul>
</li>
<li><p>CLUSTERED BY</p>
<ul>
<li>创建分桶表</li>
</ul>
</li>
<li><p>SORTED BY</p>
<ul>
<li>按照字段排序（一般不常用）</li>
</ul>
</li>
<li><p>ROW FORMAT</p>
<ul>
<li><p>指定每一行中字段的分隔符</p>
<ul>
<li>row format delimited fields terminated by ‘\t’</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>STORED AS<ul>
<li>指定存储文件类型<ul>
<li>常用的存储文件类型：SEQUENCEFILE（二进制序列文件）、TEXTFILE（文本）、RCFILE（列式存储格式文件）</li>
<li>如果文件数据是纯文本，可以使用STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>LOCATION </p>
<ul>
<li>指定表在HDFS上的存储位置。</li>
</ul>
</li>
</ul>
<h5 id="3、-创建内部表"><a href="#3、-创建内部表" class="headerlink" title="3、 创建内部表"></a>3、 创建内部表</h5><ul>
<li>1、==直接建表==<ul>
<li>使用标准的建表语句</li>
</ul>
</li>
</ul>
<pre><code class="sql">use myhive;
create table stu(id int,name string);

可以通过insert  into  向hive表当中插入数据，但是不建议工作当中这么做
insert  into stu(id,name) values(1,&quot;zhangsan&quot;);
select * from  stu;
</code></pre>
<ul>
<li>2、==查询建表法==<ul>
<li>通过AS 查询语句完成建表：将子查询的结果存在新表里，有数据 </li>
</ul>
</li>
</ul>
<pre><code class="sql">create table if not exists myhive.stu1 as select id, name from stu;
</code></pre>
<ul>
<li>3、==like建表法==<ul>
<li>根据已经存在的表结构创建表</li>
</ul>
</li>
</ul>
<pre><code class="sql">create table if not exists myhive.stu2 like stu;
</code></pre>
<ul>
<li>4、查询表的类型</li>
</ul>
<pre><code class="sql">hive &gt; desc formatted myhive.stu;
</code></pre>
<p><img src="/Users/dingchuangshi/Downloads/hive_day01_课前资料/hive_day01课程设计.assets/2019-07-12_14-33-00-1563156555810.png" alt="2019-07-12_14-33-00"></p>
<p>创建内部表并指定字段之间的分隔符，指定文件的存储格式，以及数据存放的位置</p>
<pre><code>create  table if not exists myhive.stu3(id int ,name string)
row format delimited fields terminated by &#39;\t&#39; stored as textfile location       &#39;/user/stu2&#39;;
</code></pre><h5 id="4、-创建外部表"><a href="#4、-创建外部表" class="headerlink" title="4、 创建外部表"></a>4、 创建外部表</h5><p>外部表因为是指定其他的hdfs路径的数据加载到表当中来，所以hive表会认为自己不完全独占这份数据，所以删除hive表的时候，数据仍然存放在hdfs当中，不会删掉</p>
<pre><code>create external table myhive.teacher (t_id string,t_name string) row format delimited fields terminated by &#39;\t&#39;;
</code></pre><ul>
<li>创建外部表的时候需要加上<strong>==external==</strong> 关键字</li>
<li>location字段可以指定，也可以不指定<ul>
<li>指定就是数据存放的具体目录</li>
<li>不指定就是使用默认目录 ==/user/hive/warehouse==</li>
</ul>
</li>
</ul>
<p><img src="assets/2019-07-12_14-51-53.png" alt="2019-07-12_14-51-53"></p>
<p>向外部表当中加载数据：</p>
<p>我们前面已经看到过通过insert的方式向内部表当中插入数据，外部表也可以通过insert的方式进行插入数据，只不过insert的方式，我们一般都不推荐，实际工作当中我们都是使用load的方式来加载数据到内部表或者外部表</p>
<p>load数据可以从本地文件系统加载或者也可以从hdfs上面的数据进行加载</p>
<ul>
<li><p>从本地文件系统加载数据到teacher表当中去，==将我们附件当汇总的数据资料都上传到node03服务器的/kkb/install/hivedatas路径下面去==</p>
<pre><code>mkdir -p /kkb/install/hivedatas
#将数据都上传到/kkb/install/hivedatas路径下，然后在hive客户端下执行以下操作
load data local inpath &#39;/kkb/install/hivedatas/teacher.csv&#39; into table myhive.teacher;
</code></pre></li>
<li><p>从hdfs上面加载文件到teacher表里面去(将teacher.csv文件上传到==hdfs的/kkb/hdfsload/hivedatas==路径下)</p>
<pre><code class="shell">cd /kkb/install/hivedatas
hdfs dfs -mkdir -p /kkb/hdfsload/hivedatas
hdfs dfs -put teacher.csv /kkb/hdfsload/hivedatas
# 在hive的客户端当中执行
load  data  inpath  &#39;/kkb/hdfsload/hivedatas&#39;  overwrite into table myhive.teacher;
</code></pre>
</li>
</ul>
<h5 id="5、-内部表与外部表的互相转换"><a href="#5、-内部表与外部表的互相转换" class="headerlink" title="5、 内部表与外部表的互相转换"></a>5、 内部表与外部表的互相转换</h5><ul>
<li>1、内部表转换为外部表</li>
</ul>
<pre><code class="sql">#将stu内部表改为外部表
alter table stu set tblproperties(&#39;EXTERNAL&#39;=&#39;TRUE&#39;);
</code></pre>
<ul>
<li>2、外部表转换为内部表</li>
</ul>
<pre><code class="sql">#把emp外部表改为内部表
alter table teacher set tblproperties(&#39;EXTERNAL&#39;=&#39;FALSE&#39;);
</code></pre>
<h5 id="6、-内部表与外部表的区别"><a href="#6、-内部表与外部表的区别" class="headerlink" title="6、 内部表与外部表的区别"></a>6、 内部表与外部表的区别</h5><ul>
<li><p>1、建表语法的区别</p>
<ul>
<li>外部表在创建的时候需要加上==external==关键字</li>
</ul>
</li>
<li><p>2、删除表之后的区别</p>
<ul>
<li>内部表删除后，表的元数据和真实数据都被删除了</li>
</ul>
</li>
<li>外部表删除后，仅仅只是把该表的元数据删除了，真实数据还在，后期还是可以恢复出来</li>
</ul>
<h5 id="7、内部表与外部表的使用时机"><a href="#7、内部表与外部表的使用时机" class="headerlink" title="7、内部表与外部表的使用时机"></a>7、内部表与外部表的使用时机</h5><p>​    内部表由于删除表的时候会同步删除HDFS的数据文件，所以确定如果一个表仅仅是你独占使用，其他人不适用的时候就可以创建内部表，如果一个表的文件数据，其他人也要使用，那么就创建外部表</p>
<p>一般外部表都是用在数据仓库的ODS层</p>
<p>内部表都是用在数据仓库的DW层</p>
<h5 id="8、hive的分区表"><a href="#8、hive的分区表" class="headerlink" title="8、hive的分区表"></a>8、hive的分区表</h5><p>如果hive当中所有的数据都存入到一个文件夹下面，那么在使用MR计算程序的时候，读取一整个目录下面的所有文件来进行计算，就会变得特别慢，因为数据量太大了，实际工作当中一般都是计算前一天的数据，所以我们只需要将前一天的数据挑出来放到一个文件夹下面即可，专门去计算前一天的数据。这样就可以使用hive当中的分区表，通过分文件夹的形式，将每一天的数据都分成为一个文件夹，然后我们计算数据的时候，通过指定前一天的文件夹即可只计算前一天的数据。</p>
<p>在大数据中，最常用的一种思想就是分治，我们可以把大的文件切割划分成一个个的小的文件，这样每次操作一个小的文件就会很容易了，同样的道理，在hive当中也是支持这种思想的，就是我们可以把大的数据，按照每天，或者每小时进行切分成一个个的小的文件，这样去操作小的文件就会容易得多了</p>
<p><img src="assets/2019-07-15_11-35-37.png" alt="2019-07-15_11-35-37"></p>
<pre><code>在文件系统上建立文件夹，把表的数据放在不同文件夹下面，加快查询速度。
</code></pre><p>创建分区表语法</p>
<pre><code>hive (myhive)&gt; create table score(s_id string,c_id string, s_score int) partitioned by (month string) row format delimited fields terminated by &#39;\t&#39;;
</code></pre><p>创建一个表带多个分区</p>
<pre><code>hive (myhive)&gt; create table score2 (s_id string,c_id string, s_score int) partitioned by (year string,month string,day string) row format delimited fields terminated by &#39;\t&#39;;
</code></pre><p> 加载数据到分区表当中去</p>
<pre><code> hive (myhive)&gt;load data  local inpath &#39;/kkb/install/hivedatas/score.csv&#39; into table score partition  (month=&#39;201806&#39;);
</code></pre><p>加载数据到多分区表当中去</p>
<pre><code>hive (myhive)&gt; load data local inpath &#39;/kkb/install/hivedatas/score.csv&#39; into table score2 partition(year=&#39;2018&#39;,month=&#39;06&#39;,day=&#39;01&#39;);
</code></pre><p>查看分区</p>
<pre><code>hive (myhive)&gt; show  partitions  score;
</code></pre><p>添加一个分区</p>
<pre><code>hive (myhive)&gt; alter table score add partition(month=&#39;201805&#39;);
</code></pre><p>同时添加多个分区</p>
<pre><code>hive (myhive)&gt; alter table score add partition(month=&#39;201804&#39;) partition(month = &#39;201803&#39;);
</code></pre><p>注意：添加分区之后就可以在hdfs文件系统当中看到表下面多了一个文件夹</p>
<p>删除分区</p>
<pre><code>hive (myhive)&gt; alter table score drop partition(month = &#39;201806&#39;);
</code></pre><p>外部分区表综合练习：</p>
<p>需求描述：现在有一个文件score.csv文件，里面有三个字段，分别是s_id string, c_id string,s_score int，字段都是使用 \t进行分割，存放在集群的这个目录下/scoredatas/day=20180607，这个文件每天都会生成，存放到对应的日期文件夹下面去，文件别人也需要公用，不能移动。需求，创建hive对应的表，并将数据加载到表中，进行数据统计分析，且删除表之后，数据不能删除</p>
<p>需求实现:</p>
<p>数据准备:</p>
<p>node03执行以下命令，将数据上传到hdfs上面去</p>
<p>将我们的score.csv上传到node03服务器的/kkb/install/hivedatas目录下，然后将score.csv文件上传到/kkb/install/hivedatas目录下去</p>
<pre><code>cd /kkb/install/hivedatas/
hdfs dfs -mkdir -p /scoredatas/day=20180607
hdfs dfs -put score.csv /scoredatas/day=20180607/
</code></pre><p>创建外部分区表，并指定文件数据存放目录</p>
<pre><code>hive (myhive)&gt; create external table score4(s_id string, c_id string,s_score int) partitioned by (day string) row format delimited fields terminated by &#39;\t&#39; location &#39;/scoredatas&#39;;
</code></pre><p>进行表的修复,说白了就是建立我们表与我们数据文件之间的一个关系映射</p>
<pre><code>hive (myhive)&gt; msck  repair   table  score4;
</code></pre><p>修复成功之后即可看到数据已经全部加载到表当中去了</p>
<h5 id="9、hive的分桶表"><a href="#9、hive的分桶表" class="headerlink" title="9、hive的分桶表"></a>9、hive的分桶表</h5><p><img src="assets/2019-07-16_17-01-51.png" alt=""></p>
<ul>
<li><p>分桶是相对分区进行更细粒度的划分。</p>
</li>
<li><p>==分桶将整个数据内容安装某列属性值取hash值进行区分，具有相同hash值的数据进入到同一个文件中==</p>
<ul>
<li>比如按照name属性分为3个桶，就是对name属性值的hash值对3取摸，按照取模结果对数据分桶。<ul>
<li>取模结果为==0==的数据记录存放到一个文件</li>
<li>取模结果为==1==的数据记录存放到一个文件</li>
<li>取模结果为==2==的数据记录存放到一个文件</li>
<li>取模结果为==3==的数据记录存放到一个文件</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>==作用==</strong></p>
<ul>
<li>1、取样sampling更高效。没有分区的话需要扫描整个数据集。</li>
<li>2、提升某些查询操作效率，例如map side join</li>
</ul>
</li>
<li><p>案例演示</p>
<ul>
<li><p>1、创建分桶表</p>
<ul>
<li>在创建分桶表之前要执行的命令<ul>
<li>==set hive.enforce.bucketing=true;==  开启对分桶表的支持</li>
<li>==set mapreduce.job.reduces=4;==      设置与桶相同的reduce个数（默认只有一个reduce）</li>
</ul>
</li>
</ul>
<pre><code class="sql"># 进入hive客户端然后执行以下命令
use myhive;
set mapreduce.job.reduces=4;  
set hive.enforce.bucketing=true; 
--分桶表
create table myhive.user_buckets_demo(id int, name string)
clustered by(id) 
into 4 buckets 
row format delimited fields terminated by &#39;\t&#39;;

--普通表
create table user_demo(id int, name string)
row format delimited fields terminated by &#39;\t&#39;;

</code></pre>
</li>
<li><p>2、准备数据文件 buckets.txt</p>
<pre><code>#在linux当中执行以下命令
cd /kkb/install/hivedatas/
vim user_bucket.txt

1    laowang1
2    laowang2
3    laowang3
4    laowang4
5    laowang5
6    laowang6
7    laowang7
8    laowang8
9    laowang9
10    laowang10
</code></pre></li>
</ul>
<p><code>`</code></p>
<ul>
<li>3、加载数据到普通表 user_demo 中</li>
</ul>
<p>load data local inpath ‘/kkb/install/hivedatas/user_bucket.txt’  overwrite into table user_demo; </p>
</li>
</ul>
<pre><code>
```sql
  #在hive客户端当中加载数据
load data local inpath &#39;/kkb/install/hivedatas/user_bucket.txt&#39; into table user_demo;
</code></pre><ul>
<li><p>4、加载数据到桶表user_buckets_demo中</p>
<pre><code class="sql">insert into table user_buckets_demo select * from user_demo;
</code></pre>
</li>
</ul>
<ul>
<li><p>5、hdfs上查看表的数据目录</p>
<p><img src="assets/2019-07-16_16-30-09.png" alt=""></p>
</li>
</ul>
<ul>
<li>6、抽样查询桶表的数据<ul>
<li>tablesample抽样语句，语法：tablesample(bucket  x  out  of  y)<ul>
<li>x表示从第几个桶开始取数据</li>
<li>y表示桶数的倍数，一共需要从 ==桶数/y==  个桶中取数据</li>
</ul>
</li>
</ul>
</li>
</ul>
<pre><code class="sql">select * from user_buckets_demo tablesample(bucket 1 out of 2)

-- 需要的总桶数=4/2=2个
-- 先从第1个桶中取出数据
-- 再从第1+2=3个桶中取出数据
</code></pre>
<h3 id="7、Hive修改表结构"><a href="#7、Hive修改表结构" class="headerlink" title="7、Hive修改表结构"></a>7、Hive修改表结构</h3><p>修改表名称语法</p>
<pre><code>alter table  old_table_name  rename to  new_table_name;
</code></pre><h4 id="7-1-修改表的名称"><a href="#7-1-修改表的名称" class="headerlink" title="7.1 修改表的名称"></a>7.1 修改表的名称</h4><pre><code class="sql">hive&gt; alter table stu3 rename to stu4;
</code></pre>
<h4 id="7-2-表的结构信息"><a href="#7-2-表的结构信息" class="headerlink" title="7.2 表的结构信息"></a>7.2 表的结构信息</h4><pre><code class="sql">hive&gt; desc stu4;

hive&gt; desc formatted stu4;

</code></pre>
<h4 id="7-3-增加-修改-替换列信息"><a href="#7-3-增加-修改-替换列信息" class="headerlink" title="7.3 增加/修改/替换列信息"></a>7.3 增加/修改/替换列信息</h4><ul>
<li>增加列</li>
</ul>
<pre><code class="sql">hive&gt; alter table stu4 add columns(address string);

</code></pre>
<ul>
<li>修改列</li>
</ul>
<pre><code class="sql">hive&gt; alter table stu4 change column address address_id int;

</code></pre>
<h3 id="8-Hive数据导入"><a href="#8-Hive数据导入" class="headerlink" title="8. Hive数据导入"></a>8. Hive数据导入</h3><h4 id="8-1、直接向表中插入数据（强烈不推荐使用）"><a href="#8-1、直接向表中插入数据（强烈不推荐使用）" class="headerlink" title="8.1、直接向表中插入数据（强烈不推荐使用）"></a>8.1、直接向表中插入数据（强烈不推荐使用）</h4><pre><code class="sql">hive (myhive)&gt; create table score3 like score;
hive (myhive)&gt; insert into table score3 partition(month =&#39;201807&#39;) values (&#39;001&#39;,&#39;002&#39;,&#39;100&#39;);

</code></pre>
<h4 id="8-2、通过load方式加载数据（必须掌握）"><a href="#8-2、通过load方式加载数据（必须掌握）" class="headerlink" title="8.2、通过load方式加载数据（必须掌握）"></a>8.2、通过load方式加载数据（必须掌握）</h4><p>语法：</p>
<pre><code class="sql"> hive&gt; load data [local] inpath &#39;dataPath&#39; overwrite | into table student [partition (partcol1=val1,…)]; 

</code></pre>
<p>通过load方式加载数据</p>
<pre><code class="sql">hive (myhive)&gt; load data local inpath &#39;/kkb/install/hivedatas/score.csv&#39; overwrite into table score3 partition(month=&#39;201806&#39;);

</code></pre>
<h4 id="8-3、通过查询方式加载数据（必须掌握）"><a href="#8-3、通过查询方式加载数据（必须掌握）" class="headerlink" title="8.3、通过查询方式加载数据（必须掌握）"></a>8.3、通过查询方式加载数据（必须掌握）</h4><p>通过查询方式加载数据</p>
<pre><code class="sql">hive (myhive)&gt; create table score5 like score;
hive (myhive)&gt; insert overwrite table score5 partition(month = &#39;201806&#39;) select s_id,c_id,s_score from score;

</code></pre>
<h4 id="8-4、查询语句中创建表并加载数据（as-select）"><a href="#8-4、查询语句中创建表并加载数据（as-select）" class="headerlink" title="8.4、查询语句中创建表并加载数据（as select）"></a>8.4、查询语句中创建表并加载数据（as select）</h4><p>将查询的结果保存到一张表当中去</p>
<pre><code>hive (myhive)&gt; create table score6 as select * from score;

</code></pre><h4 id="8-5、创建表时通过location指定加载数据路径"><a href="#8-5、创建表时通过location指定加载数据路径" class="headerlink" title="8.5、创建表时通过location指定加载数据路径"></a>8.5、创建表时通过location指定加载数据路径</h4><p>1）创建表，并指定在hdfs上的位置</p>
<pre><code class="sql">hive (myhive)&gt; create external table score7 (s_id string,c_id string,s_score int) row format delimited fields terminated by &#39;\t&#39; location &#39;/myscore7&#39;;

</code></pre>
<p>2）上传数据到hdfs上，我们也可以直接在hive客户端下面通过dfs命令来进行操作hdfs的数据</p>
<pre><code>hive (myhive)&gt;  dfs -mkdir -p /myscore7;
hive (myhive)&gt; dfs -put /kkb/install/hivedatas/score.csv /myscore7;

</code></pre><p>3）查询数据</p>
<pre><code>hive (myhive)&gt; select * from score7;

</code></pre><h4 id="8-6、export导出与import-导入-hive表数据（内部表操作）"><a href="#8-6、export导出与import-导入-hive表数据（内部表操作）" class="headerlink" title="8.6、export导出与import 导入 hive表数据（内部表操作）"></a>8.6、export导出与import 导入 hive表数据（内部表操作）</h4><pre><code>hive (myhive)&gt; create table teacher2 like teacher;
hive (myhive)&gt; export table teacher to  &#39;/kkb/teacher&#39;;
hive (myhive)&gt; import table teacher2 from &#39;/kkb/teacher&#39;;

</code></pre><h3 id="9、Hive数据导出"><a href="#9、Hive数据导出" class="headerlink" title="9、Hive数据导出"></a>9、Hive数据导出</h3><h4 id="9-1-insert-导出"><a href="#9-1-insert-导出" class="headerlink" title="9.1 insert 导出"></a>9.1 insert 导出</h4><ul>
<li>1、将查询的结果导出到本地</li>
</ul>
<pre><code class="sql">insert overwrite local directory &#39;/kkb/install/hivedatas/stu&#39; select * from stu;

</code></pre>
<ul>
<li>2、将查询的结果格式化导出到本地</li>
</ul>
<pre><code class="sql">insert overwrite local directory &#39;/kkb/install/hivedatas/stu2&#39; row format delimited fields terminated by  &#39;,&#39; select * from stu;

</code></pre>
<ul>
<li>3、将查询的结果导出到HDFS上==(没有local)==</li>
</ul>
<pre><code class="sql">insert overwrite  directory &#39;/kkb/hivedatas/stu&#39;  row format delimited fields terminated by  &#39;,&#39;  select * from stu;

</code></pre>
<h4 id="9-2、-Hive-Shell-命令导出"><a href="#9-2、-Hive-Shell-命令导出" class="headerlink" title="9.2、 Hive Shell 命令导出"></a>9.2、 Hive Shell 命令导出</h4><ul>
<li><p>基本语法：</p>
<ul>
<li>hive -e “sql语句” &gt;   file</li>
<li>hive -f  sql文件   &gt;    file</li>
</ul>
<pre><code class="shell">bin/hive -e &#39;select * from myhive.stu;&#39; &gt; /kkb/install/hivedatas/student1.txt

</code></pre>
</li>
</ul>
<h4 id="9-3、export导出到HDFS上"><a href="#9-3、export导出到HDFS上" class="headerlink" title="9.3、export导出到HDFS上"></a>9.3、export导出到HDFS上</h4><pre><code class="sql">export table  myhive.stu to &#39;/kkb/install/hivedatas/stuexport&#39;;

</code></pre>
<h3 id="10、hive的静态分区和动态分区"><a href="#10、hive的静态分区和动态分区" class="headerlink" title="10、hive的静态分区和动态分区"></a>10、hive的静态分区和动态分区</h3><h4 id="10-1-静态分区"><a href="#10-1-静态分区" class="headerlink" title="10.1 静态分区"></a>10.1 静态分区</h4><ul>
<li><p>表的分区字段的值需要开发人员手动给定</p>
<ul>
<li>1、创建分区表</li>
</ul>
<pre><code class="sql">use myhive;
create table order_partition(
order_number string,
order_price  double,
order_time string
)
partitioned BY(month string)
row format delimited fields terminated by &#39;\t&#39;;

</code></pre>
</li>
</ul>
<pre><code>
- 10.2、准备数据    order.txt内容如下

cd /kkb/install/hivedatas
vim order.txt 
10001    100    2019-03-02
10002    200    2019-03-02
10003    300    2019-03-02
10004    400    2019-03-03
10005    500    2019-03-03
10006    600    2019-03-03
10007    700    2019-03-04
10008    800    2019-03-04
10009    900    2019-03-04

</code></pre><ul>
<li><p>3、加载数据到分区表</p>
<pre><code class="sql">load data local inpath &#39;/kkb/install/hivedatas/order.txt&#39; overwrite into table order_partition partition(month=&#39;2019-03&#39;);

</code></pre>
</li>
<li><p>4、查询结果数据    </p>
<p>~~~sql<br>select * from order_partition where month=’2019-03’;<br>结果为：</p>
</li>
</ul>
<p>10001   100.0   2019-03-02      2019-03<br>10002   200.0   2019-03-02      2019-03<br>10003   300.0   2019-03-02      2019-03<br>10004   400.0   2019-03-03      2019-03<br>10005   500.0   2019-03-03      2019-03<br>10006   600.0   2019-03-03      2019-03<br>10007   700.0   2019-03-04      2019-03<br>10008   800.0   2019-03-04      2019-03<br>10009   900.0   2019-03-04      2019-03</p>
<pre><code>



#### .2 动态分区

- 按照需求实现把数据自动导入到表的不同分区中，==不需要手动指定==

  - **需求：按照不同部门作为分区导数据到目标表** 

    1、创建表

    ~~~sql
    --创建普通表
    create table t_order(
        order_number string,
        order_price  double, 
        order_time   string
    )row format delimited fields terminated by &#39;\t&#39;;

    --创建目标分区表
    create table order_dynamic_partition(
        order_number string,
        order_price  double    
    )partitioned BY(order_time string)
    row format delimited fields terminated by &#39;\t&#39;;


</code></pre><pre><code>2、准备数据     order_created.txt内容如下

~~~sql
cd /kkb/install/hivedatas
vim order_partition.txt

10001    100    2019-03-02 
10002    200    2019-03-02
10003    300    2019-03-02
10004    400    2019-03-03
10005    500    2019-03-03
10006    600    2019-03-03
10007    700    2019-03-04
10008    800    2019-03-04
10009    900    2019-03-04

~~~

3、向普通表t_order加载数据

```
load data local inpath &#39;/kkb/install/hivedatas/order_partition.txt&#39; overwrite into table t_order;

```

4、动态加载数据到分区表中

```
要想进行动态分区，需要设置参数
//开启动态分区功能
hive&gt; set hive.exec.dynamic.partition=true; 
//设置hive为非严格模式
hive&gt; set hive.exec.dynamic.partition.mode=nonstrict; 
hive&gt; insert into table order_dynamic_partition partition(order_time) select order_number,order_price,order_time from t_order;

```

5、查看分区

```
bin/hive&gt;  show partitions order_dynamic_partition;

```

![1569313506031](assets/1569313506031.png)
</code></pre><h3 id="11、hive的基本查询语法"><a href="#11、hive的基本查询语法" class="headerlink" title="11、hive的基本查询语法"></a>11、hive的基本查询语法</h3><h4 id="1-基本查询"><a href="#1-基本查询" class="headerlink" title="1. 基本查询"></a>1. 基本查询</h4><ul>
<li>注意<ul>
<li>SQL 语言==大小写不敏感==</li>
<li>SQL 可以写在一行或者多行</li>
<li>==关键字不能被缩写也不能分行==</li>
<li>各子句一般要分行写</li>
<li>使用缩进提高语句的可读性</li>
</ul>
</li>
</ul>
<h5 id="1-1-全表和特定列查询"><a href="#1-1-全表和特定列查询" class="headerlink" title="1.1 全表和特定列查询"></a>1.1 全表和特定列查询</h5><ul>
<li>全表查询</li>
</ul>
<pre><code class="sql">select * from stu;

</code></pre>
<ul>
<li>选择特定列查询</li>
</ul>
<pre><code class="sql">select id,name from stu;

</code></pre>
<h5 id="1-2-列起别名"><a href="#1-2-列起别名" class="headerlink" title="1.2 列起别名"></a>1.2 列起别名</h5><ul>
<li><p>重命名一个列</p>
<ul>
<li>紧跟列名，也可以在列名和别名之间加入关键字 ‘as’ </li>
</ul>
</li>
<li><p>案例实操</p>
<pre><code class="sql">select id,name as stuName from stu;

</code></pre>
</li>
</ul>
<p>1.3 常用函数</p>
<ul>
<li>1．求总行数（count）</li>
</ul>
<pre><code class="sql"> select count(*) cnt from score;

</code></pre>
<ul>
<li>2、求分数的最大值（max）</li>
</ul>
<pre><code class="sql">select max(s_score) from score;

</code></pre>
<ul>
<li>3、求分数的最小值（min）</li>
</ul>
<pre><code class="sql">select min(s_score) from score;

</code></pre>
<ul>
<li>4、求分数的总和（sum）</li>
</ul>
<pre><code class="sql">select sum(s_score) from score;

</code></pre>
<ul>
<li>5、求分数的平均值（avg）</li>
</ul>
<pre><code class="sql">select avg(s_score) from score;

</code></pre>
<h5 id="1-4-limit-语句"><a href="#1-4-limit-语句" class="headerlink" title="1.4 limit 语句"></a>1.4 limit 语句</h5><ul>
<li>典型的查询会返回多行数据。limit子句用于限制返回的行数。</li>
</ul>
<pre><code class="sql"> select  * from score limit 5;

</code></pre>
<h5 id="1-5-where-语句"><a href="#1-5-where-语句" class="headerlink" title="1.5 where 语句"></a>1.5 where 语句</h5><ul>
<li>1、使用 where 子句，将不满足条件的行过滤掉</li>
<li>2、==where 子句紧随from子句==</li>
<li>3、案例实操</li>
</ul>
<pre><code class="sql">select  * from score where s_score &gt; 60;

</code></pre>
<h5 id="1-6-算术运算符"><a href="#1-6-算术运算符" class="headerlink" title="1.6 算术运算符"></a>1.6 算术运算符</h5><table>
<thead>
<tr>
<th>运算符</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>A+B</td>
<td>A和B 相加</td>
</tr>
<tr>
<td>A-B</td>
<td>A减去B</td>
</tr>
<tr>
<td>A*B</td>
<td>A和B 相乘</td>
</tr>
<tr>
<td>A/B</td>
<td>A除以B</td>
</tr>
<tr>
<td>A%B</td>
<td>A对B取余</td>
</tr>
<tr>
<td>A&amp;B</td>
<td>A和B按位取与</td>
</tr>
<tr>
<td>A\</td>
<td>B</td>
<td>A和B按位取或</td>
</tr>
<tr>
<td>A^B</td>
<td>A和B按位取异或</td>
</tr>
<tr>
<td>~A</td>
<td>A按位取反</td>
</tr>
</tbody>
</table>
<h5 id="1-7-比较运算符"><a href="#1-7-比较运算符" class="headerlink" title="1.7 比较运算符"></a>1.7 比较运算符</h5><table>
<thead>
<tr>
<th style="text-align:center">操作符</th>
<th style="text-align:center">支持的数据类型</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">A=B</td>
<td style="text-align:center">基本数据类型</td>
<td style="text-align:center">如果A等于B则返回true，反之返回false</td>
</tr>
<tr>
<td style="text-align:center">A&lt;=&gt;B</td>
<td style="text-align:center">基本数据类型</td>
<td style="text-align:center">如果A和B都为NULL，则返回true，其他的和等号（=）操作符的结果一致，如果任一为NULL则结果为NULL</td>
</tr>
<tr>
<td style="text-align:center">A&lt;&gt;B, A!=B</td>
<td style="text-align:center">基本数据类型</td>
<td style="text-align:center">A或者B为NULL则返回NULL；如果A不等于B，则返回true，反之返回false</td>
</tr>
<tr>
<td style="text-align:center">A&lt;B</td>
<td style="text-align:center">基本数据类型</td>
<td style="text-align:center">A或者B为NULL，则返回NULL；如果A小于B，则返回true，反之返回false</td>
</tr>
<tr>
<td style="text-align:center">A&lt;=B</td>
<td style="text-align:center">基本数据类型</td>
<td style="text-align:center">A或者B为NULL，则返回NULL；如果A小于等于B，则返回true，反之返回false</td>
</tr>
<tr>
<td style="text-align:center">A&gt;B</td>
<td style="text-align:center">基本数据类型</td>
<td style="text-align:center">A或者B为NULL，则返回NULL；如果A大于B，则返回true，反之返回false</td>
</tr>
<tr>
<td style="text-align:center">A&gt;=B</td>
<td style="text-align:center">基本数据类型</td>
<td style="text-align:center">A或者B为NULL，则返回NULL；如果A大于等于B，则返回true，反之返回false</td>
</tr>
<tr>
<td style="text-align:center">A [NOT] BETWEEN B AND C</td>
<td style="text-align:center">基本数据类型</td>
<td style="text-align:center">如果A，B或者C任一为NULL，则结果为NULL。如果A的值大于等于B而且小于或等于C，则结果为true，反之为false。如果使用NOT关键字则可达到相反的效果。</td>
</tr>
<tr>
<td style="text-align:center">A IS NULL</td>
<td style="text-align:center">所有数据类型</td>
<td style="text-align:center">如果A等于NULL，则返回true，反之返回false</td>
</tr>
<tr>
<td style="text-align:center">A IS NOT NULL</td>
<td style="text-align:center">所有数据类型</td>
<td style="text-align:center">如果A不等于NULL，则返回true，反之返回false</td>
</tr>
<tr>
<td style="text-align:center">IN(数值1, 数值2)</td>
<td style="text-align:center">所有数据类型</td>
<td style="text-align:center">使用 IN运算显示列表中的值</td>
</tr>
<tr>
<td style="text-align:center">A [NOT] LIKE B</td>
<td style="text-align:center">STRING 类型</td>
<td style="text-align:center">B是一个SQL下的简单正则表达式，如果A与其匹配的话，则返回true；反之返回false。B的表达式说明如下：‘x%’表示A必须以字母‘x’开头，‘%x’表示A必须以字母’x’结尾，而‘%x%’表示A包含有字母’x’,可以位于开头，结尾或者字符串中间。如果使用NOT关键字则可达到相反的效果。like不是正则，而是通配符</td>
</tr>
<tr>
<td style="text-align:center">A RLIKE B, A REGEXP B</td>
<td style="text-align:center">STRING 类型</td>
<td style="text-align:center">B是一个正则表达式，如果A与其匹配，则返回true；反之返回false。匹配使用的是JDK中的正则表达式接口实现的，因为正则也依据其中的规则。例如，正则表达式必须和整个字符串A相匹配，而不是只需与其字符串匹配。</td>
</tr>
</tbody>
</table>
<h5 id="1-8-逻辑运算符"><a href="#1-8-逻辑运算符" class="headerlink" title="1.8 逻辑运算符"></a>1.8 逻辑运算符</h5><table>
<thead>
<tr>
<th style="text-align:center">操作符</th>
<th style="text-align:center">操作</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">A AND  B</td>
<td style="text-align:center">逻辑并</td>
<td style="text-align:center">如果A和B都是true则为true，否则false</td>
</tr>
<tr>
<td style="text-align:center">A  OR  B</td>
<td style="text-align:center">逻辑或</td>
<td style="text-align:center">如果A或B或两者都是true则为true，否则false</td>
</tr>
<tr>
<td style="text-align:center">NOT  A</td>
<td style="text-align:center">逻辑否</td>
<td style="text-align:center">如果A为false则为true,否则false</td>
</tr>
</tbody>
</table>
<h4 id="2-分组"><a href="#2-分组" class="headerlink" title="2. 分组"></a>2. 分组</h4><h5 id="2-1-Group-By-语句"><a href="#2-1-Group-By-语句" class="headerlink" title="2.1 Group By 语句"></a>2.1 Group By 语句</h5><p>​    Group By 语句通常会和==聚合函数==一起使用，按照一个或者多个列队结果进行分组，然后对每个组执行聚合操作。</p>
<ul>
<li><p>案例实操：</p>
<ul>
<li>（1）计算每个学生的平均分数</li>
</ul>
<pre><code class="sql">select s_id,avg(s_score) from score group by s_id;

</code></pre>
<ul>
<li>（2）计算每个学生最高的分数</li>
</ul>
<pre><code class="sql">select s_id,max(s_score) from score group by s_id;

</code></pre>
</li>
</ul>
<h5 id="2-2-Having语句"><a href="#2-2-Having语句" class="headerlink" title="2.2 Having语句"></a>2.2 Having语句</h5><ul>
<li><p>having 与 where 不同点</p>
<ul>
<li>where针对==表中的列发挥作用==，查询数据；==having针对查询结果中的列==发挥作用，筛选数据</li>
<li>where后面==不能写分组函数==，而having后面可以==使用分组函数==</li>
<li>having只用于group by分组统计语句</li>
</ul>
</li>
<li><p>案例实操</p>
<ul>
<li>求每个学生的平均分数</li>
</ul>
<pre><code class="sql">select s_id,avg(s_score) from score group by s_id;

</code></pre>
<ul>
<li>求每个学生平均分数大于60的人</li>
</ul>
<pre><code class="sql">select s_id,avg(s_score) as avgScore from score group by s_id having avgScore &gt; 60;

</code></pre>
</li>
</ul>
<h4 id="3-join语句"><a href="#3-join语句" class="headerlink" title="3. join语句"></a>3. join语句</h4><h5 id="11-3-1-等值-join"><a href="#11-3-1-等值-join" class="headerlink" title="11.3.1 等值 join"></a>11.3.1 等值 join</h5><ul>
<li><p>Hive支持通常的SQL JOIN语句，但是只支持等值连接，不支持非等值连接。</p>
</li>
<li><p>案例实操</p>
<ul>
<li>根据学生和成绩表，查询学生姓名对应的成绩</li>
</ul>
<pre><code class="sql">select * from stu left join score on stu.id = score.s_id;

</code></pre>
</li>
</ul>
<h5 id="11-3-2-表的别名"><a href="#11-3-2-表的别名" class="headerlink" title="11.3.2 表的别名"></a>11.3.2 表的别名</h5><ul>
<li><p>好处</p>
<ul>
<li>使用别名可以简化查询。</li>
<li>使用表名前缀可以提高执行效率。</li>
</ul>
</li>
<li><p>案例实操</p>
<ul>
<li>合并老师与课程表</li>
</ul>
<pre><code class="sql">#hive当中创建course表并加载数据
create table course (c_id string,c_name string,t_id string) row format delimited fields terminated by &#39;\t&#39;;
load data local inpath &#39;/kkb/install/hivedatas/course.csv&#39; overwrite into table course;

select * from teacher t join course c on t.t_id = c.t_id;

</code></pre>
</li>
</ul>
<h5 id="11-3-3-内连接-inner-join"><a href="#11-3-3-内连接-inner-join" class="headerlink" title="11.3.3 内连接 inner join"></a>11.3.3 内连接 inner join</h5><ul>
<li>内连接：只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来。<ul>
<li>join默认是inner  join</li>
</ul>
</li>
<li>案例实操</li>
</ul>
<pre><code class="sql">select * from teacher t inner join course c  on t.t_id = c.t_id;

</code></pre>
<h5 id="11-3-4-左外连接-left-outer-join"><a href="#11-3-4-左外连接-left-outer-join" class="headerlink" title="11.3.4 左外连接 left outer join"></a>11.3.4 左外连接 left outer join</h5><ul>
<li><p>左外连接：join操作符==左边表中==符合where子句的所有记录将会被返回。</p>
</li>
<li><p>案例实操</p>
<ul>
<li>查询老师对应的课程</li>
</ul>
<pre><code class="sql"> select * from teacher t left outer join course c  on t.t_id = c.t_id;

</code></pre>
</li>
</ul>
<h5 id="3-5-右外连接-right-outer-join"><a href="#3-5-右外连接-right-outer-join" class="headerlink" title="3.5 右外连接 right outer join"></a>3.5 右外连接 right outer join</h5><ul>
<li><p>右外连接：join操作符==右边表中==符合where子句的所有记录将会被返回。</p>
</li>
<li><p>案例实操</p>
<pre><code class="sql"> select * from teacher t right outer join course c  on t.t_id = c.t_id;

</code></pre>
</li>
</ul>
<h5 id="11-3-6-满外连接-full-outer-join"><a href="#11-3-6-满外连接-full-outer-join" class="headerlink" title="11.3.6 满外连接 full outer join"></a>11.3.6 满外连接 full outer join</h5><ul>
<li><p>满外连接：将会返回==所有表中==符合where语句条件的所有记录。如果任一表的指定字段没有符合条件的值的话，那么就使用null值替代。</p>
</li>
<li><p>案例实操</p>
<pre><code class="sql">select * from teacher t full outer join course c  on t.t_id = c.t_id;

</code></pre>
</li>
</ul>
<h5 id="11-3-7-多表连接"><a href="#11-3-7-多表连接" class="headerlink" title="11.3.7 多表连接"></a>11.3.7 多表连接</h5><ul>
<li><p><strong>多个表使用join进行连接</strong></p>
</li>
<li><p>注意：连接 n个表，至少需要n-1个连接条件。例如：连接三个表，至少需要两个连接条件。</p>
</li>
<li><p>案例实操</p>
<ul>
<li>多表连接查询，查询老师对应的课程，以及对应的分数，对应的学生</li>
</ul>
<pre><code class="sql">select * from teacher t left join course c on t.t_id = c.t_id 
left join score s on c.c_id = s.c_id 
left join stu on s.s_id = stu.id;

</code></pre>
</li>
</ul>
<h4 id="11-4-排序"><a href="#11-4-排序" class="headerlink" title="11.4. 排序"></a>11.4. 排序</h4><h5 id="11-4-1-order-by-全局排序"><a href="#11-4-1-order-by-全局排序" class="headerlink" title="11.4.1 order by 全局排序"></a>11.4.1 order by 全局排序</h5><ul>
<li><p>order by 说明</p>
<ul>
<li>全局排序，只有一个reduce</li>
<li>使用 ORDER BY 子句排序<ul>
<li>asc ( ascend)<ul>
<li>升序 (默认)</li>
</ul>
</li>
<li>desc (descend)<ul>
<li>降序</li>
</ul>
</li>
</ul>
</li>
<li>order by 子句在select语句的结尾</li>
</ul>
</li>
<li><p>案例实操</p>
<ul>
<li>查询学生的成绩，并按照分数降序排列</li>
</ul>
<pre><code class="sql">select * from score  s order by s_score desc ;

</code></pre>
</li>
</ul>
<h5 id="11-4-2-按照别名排序"><a href="#11-4-2-按照别名排序" class="headerlink" title="11.4.2 按照别名排序"></a>11.4.2 按照别名排序</h5><ul>
<li>按照学生分数的平均值排序</li>
</ul>
<pre><code class="sql">select s_id,avg(s_score) avgscore  from score group by s_id order by avgscore desc; 

</code></pre>
<h5 id="11-4-3-每个MapReduce内部排序（Sort-By）局部排序"><a href="#11-4-3-每个MapReduce内部排序（Sort-By）局部排序" class="headerlink" title="11.4.3 每个MapReduce内部排序（Sort By）局部排序"></a>11.4.3 每个MapReduce内部排序（Sort By）局部排序</h5><ul>
<li><p>sort by：每个reducer内部进行排序，对全局结果集来说不是排序。</p>
<p>1、设置reduce个数</p>
<pre><code>set mapreduce.job.reduces=3;

</code></pre><p>2、查看reduce的个数</p>
<pre><code class="sql">set mapreduce.job.reduces;

</code></pre>
<p>3、查询成绩按照成绩降序排列</p>
<pre><code class="sql"> select * from score s sort by s.s_score;

</code></pre>
<p>4、将查询结果导入到文件中（按照成绩降序排列）</p>
<pre><code class="sql">insert overwrite local directory &#39;/kkb/install/hivedatas/sort&#39; select * from score s sort by s.s_score;

</code></pre>
</li>
</ul>
<h5 id="11-4-4-distribute-by-分区排序"><a href="#11-4-4-distribute-by-分区排序" class="headerlink" title="11.4.4 distribute by 分区排序"></a>11.4.4 distribute by 分区排序</h5><ul>
<li><p>distribute by：类似MR中partition，==采集hash算法，在map端将查询的结果中hash值相同的结果分发到对应的reduce文件中==。结合sort by使用。</p>
</li>
<li><p>注意</p>
<ul>
<li>Hive要求 <strong>distribute by</strong> 语句要写在 <strong>sort by</strong> 语句之前。</li>
</ul>
</li>
<li><p>案例实操</p>
<ul>
<li><p>先按照学生 sid 进行分区，再按照学生成绩进行排序</p>
<ul>
<li>设置reduce的个数</li>
</ul>
<pre><code class="sql">set mapreduce.job.reduces=3;

</code></pre>
<ul>
<li>通过distribute by  进行数据的分区,，将不同的sid 划分到对应的reduce当中去</li>
</ul>
<pre><code class="sql">insert overwrite local directory &#39;/kkb/install/hivedatas/distribute&#39; select * from score distribute by s_id sort by s_score;

</code></pre>
</li>
</ul>
</li>
</ul>
<h5 id="11-4-5-cluster-by"><a href="#11-4-5-cluster-by" class="headerlink" title="11.4.5 cluster by"></a>11.4.5 cluster by</h5><ul>
<li><p>当distribute by和sort by字段相同时，可以使用cluster by方式</p>
</li>
<li><p>除了distribute by 的功能外，还会对该字段进行排序，所以cluster by = distribute by + sort by</p>
<p><code>`</code>sql<br>–以下两种写法等价</p>
<p>insert overwrite local directory ‘/kkb/install/hivedatas/distribute_sort’ select * from score distribute  by s_score sort  by s_score;</p>
</li>
</ul>
<p>  insert overwrite local directory ‘/kkb/install/hivedatas/cluster’ select * from score  cluster by s_score;</p>
<pre><code>


### 12、hive客户端jdbc操作

#### 第一步：启动hiveserver2的服务端

node03执行以下命令启动hiveserver2的服务端

</code></pre><p>cd /kkb/install/hive-1.1.0-cdh5.14.2/<br>nohup bin/hive –service hiveserver2 2&gt;&amp;1 &amp;</p>
<pre><code>
#### 第二步：引入依赖

```xml
   &lt;repositories&gt;
        &lt;repository&gt;
            &lt;id&gt;cloudera&lt;/id&gt;
            &lt;url&gt;https://repository.cloudera.com/artifactory/cloudera-repos/&lt;/url&gt;
        &lt;/repository&gt;
    &lt;/repositories&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;
            &lt;artifactId&gt;hive-exec&lt;/artifactId&gt;
            &lt;version&gt;1.1.0-cdh5.14.2&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;
            &lt;artifactId&gt;hive-jdbc&lt;/artifactId&gt;
            &lt;version&gt;1.1.0-cdh5.14.2&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;
            &lt;artifactId&gt;hive-cli&lt;/artifactId&gt;
            &lt;version&gt;1.1.0-cdh5.14.2&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
            &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;
            &lt;version&gt;2.6.0-cdh5.14.2&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.0&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;1.8&lt;/source&gt;
                    &lt;target&gt;1.8&lt;/target&gt;
                    &lt;encoding&gt;UTF-8&lt;/encoding&gt;
                    &lt;!--    &lt;verbal&gt;true&lt;/verbal&gt;--&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

</code></pre><h4 id="第三步：代码开发"><a href="#第三步：代码开发" class="headerlink" title="第三步：代码开发"></a>第三步：代码开发</h4><pre><code class="java">import java.sql.*;

public class HiveJDBC {
    private static String url=&quot;jdbc:hive2://192.168.52.120:10000/myhive&quot;;
    public static void main(String[] args) throws Exception {
        Class.forName(&quot;org.apache.hive.jdbc.HiveDriver&quot;);
        //获取数据库连接
        Connection connection = DriverManager.getConnection(url, &quot;hadoop&quot;,&quot;&quot;);
        //定义查询的sql语句
        String sql=&quot;select * from stu&quot;;
        try {
            PreparedStatement ps = connection.prepareStatement(sql);
            ResultSet rs = ps.executeQuery();
            while (rs.next()){
                //获取id字段值
                int id = rs.getInt(1);
                //获取deptid字段
                String name = rs.getString(2);
                System.out.println(id+&quot;\t&quot;+name);
            }
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }
}

</code></pre>
<h3 id="、hive的可视化工具dbeaver介绍以及使用"><a href="#、hive的可视化工具dbeaver介绍以及使用" class="headerlink" title="、hive的可视化工具dbeaver介绍以及使用"></a>、hive的可视化工具dbeaver介绍以及使用</h3><h4 id="1、dbeaver的基本介绍"><a href="#1、dbeaver的基本介绍" class="headerlink" title="1、dbeaver的基本介绍"></a>1、dbeaver的基本介绍</h4><p>dbeaver是一个图形化的界面工具，专门用于与各种数据库的集成，通过dbeaver我们可以与各种数据库进行集成通过图形化界面的方式来操作我们的数据库与数据库表，类似于我们的sqlyog或者navicate</p>
<h4 id="2、dbeaver的下载安装"><a href="#2、dbeaver的下载安装" class="headerlink" title="2、dbeaver的下载安装"></a>2、dbeaver的下载安装</h4><p><a href="https://github.com/dbeaver/dbeaver/releases" target="_blank" rel="noopener">https://github.com/dbeaver/dbeaver/releases</a></p>
<p>我们可以直接从github上面下载我们需要的对应的安装包即可</p>
<h4 id="3、dbeaver的安装与使用"><a href="#3、dbeaver的安装与使用" class="headerlink" title="3、dbeaver的安装与使用"></a>3、dbeaver的安装与使用</h4><p>这里我们使用的版本是6.15这个版本，下载zip的压缩包，直接解压就可以使用，然后双击dbeaver.exe即可启动</p>
<h5 id="第一步：双击dbeaver-exe然后启动dbeaver图形化界面"><a href="#第一步：双击dbeaver-exe然后启动dbeaver图形化界面" class="headerlink" title="第一步：双击dbeaver.exe然后启动dbeaver图形化界面"></a>第一步：双击dbeaver.exe然后启动dbeaver图形化界面</h5><p><img src="assets/1569407489837.png" alt="1569407489837"></p>
<h5 id="第二步：配置我们的主机名与端口号"><a href="#第二步：配置我们的主机名与端口号" class="headerlink" title="第二步：配置我们的主机名与端口号"></a>第二步：配置我们的主机名与端口号</h5><p><img src="assets/20181113110722636.png" alt="20181113110722636"></p>
<p><img src="assets/1569407697691.png" alt="1569407697691"></p>
<p><strong>注意：⚠️</strong></p>
<p>企业hive可视化工具：Hub</p>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a href="https://blog.sev7e0.site/">大数据施工现场</a></span>
        <span>/</span>
        
        <span><a href="https://wangchujiang.com/linux-command/">linux命令行工具</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script src="/js/gitment.js"></script>
<script>
    var gitment = new Gitment({
        id: 'Hadoop之数据分析Hive（一）',
        owner: 'orchid-ding',
        repo: 'kfly-blog-comment',
        oauth: {
            client_id: '0770cdab79393197b6f5',
            client_secret: '376fb6c7bcd5047718b356712f596b89e490360c',
        },
    })
    gitment.render('comment-container')
</script>




</html>
