<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="天行健、君子以自强不息；地势坤，君子以厚德载物。">
    <meta name="keyword"  content="兰草">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        大数据环境搭建 - kfly的博客 | kfly&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_1598291_q3el2wqimj.css" type="text/css">
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>kfly</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont iconhome"></i>
                    <span>主页</span>
                </a>
            </li>
 	   <li >
                <a href="/spec/">
                    <i class="iconfont iconzhuanti"></i>
                    <span>专题</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>简历</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#大数据环境搭建-MAC"><span class="toc-text">大数据环境搭建(MAC)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Linux-环境配置"><span class="toc-text">1. Linux 环境配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-Vmware-Funsion-Linux网络配置"><span class="toc-text">1.1 Vmware Funsion Linux网络配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-1-查看本机网络"><span class="toc-text">1.1.1 查看本机网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-2-配置linux网络"><span class="toc-text">1.1.2 配置linux网络</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-Linux-设置免密登陆"><span class="toc-text">1.2. Linux 设置免密登陆</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-1-设置用户-amp-权限"><span class="toc-text">1.2.1 设置用户 &amp; 权限</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-2-免密登陆"><span class="toc-text">1.2.2 免密登陆</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-时间同步"><span class="toc-text">1.3 时间同步</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-1-同步阿里云"><span class="toc-text">1.3.1 同步阿里云</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-2-同步node01时间"><span class="toc-text">1.3.2 同步node01时间</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Hadoop环境搭建"><span class="toc-text">2.Hadoop环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-配置hadoop-env-sh"><span class="toc-text">2.1 配置hadoop-env.sh</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-配置core-site-xml"><span class="toc-text">2.2 配置core-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-配置hdfs-site-xml"><span class="toc-text">2.3 配置hdfs-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-配置mapred-site-xml"><span class="toc-text">2.4 配置mapred-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-配置yarn-site-xml"><span class="toc-text">2.5 配置yarn-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-6-编辑slaves"><span class="toc-text">2.6 编辑slaves</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-7-创建文件存放目录"><span class="toc-text">2.7 创建文件存放目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-8-拷贝到其他节点"><span class="toc-text">2.8 拷贝到其他节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-9-格式化节点"><span class="toc-text">2.9 格式化节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-10-访问"><span class="toc-text">2.10 访问</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-11-Hadoop-Ha高可用"><span class="toc-text">2.11. Hadoop Ha高可用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-hive环境搭建"><span class="toc-text">3. hive环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-mysql安装"><span class="toc-text">3.1 mysql安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-hive安装"><span class="toc-text">3.2 hive安装</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-下载hive的安装包"><span class="toc-text">3.2.1 下载hive的安装包</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-2-hive-env-sh"><span class="toc-text">3.2.2 hive-env.sh</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-3-hive-site-xml"><span class="toc-text">3.2.3 hive-site.xml</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-4-日志路径"><span class="toc-text">3.2.4 日志路径</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-5-lib包"><span class="toc-text">3.4.5  lib包</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-hive使用Spark-on-Yarn作为计算引擎"><span class="toc-text">3.3 hive使用Spark on Yarn作为计算引擎</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-zookeeper环境搭建"><span class="toc-text">4. zookeeper环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-下载软件"><span class="toc-text">4.1 下载软件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-修改配置文件"><span class="toc-text">4.2 修改配置文件</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-HBase环境搭建"><span class="toc-text">5. HBase环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-下载软件"><span class="toc-text">5.1 下载软件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-hbase-env-sh"><span class="toc-text">5.2  hbase-env.sh</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-hbase-site-xml"><span class="toc-text">5.3 hbase-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-regionservers"><span class="toc-text">5.4  regionservers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-5-back-masters"><span class="toc-text">5.5  back-masters</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-6-创建软连接"><span class="toc-text">5.6  创建软连接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-7-添加HBase环境变量"><span class="toc-text">5.7 添加HBase环境变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-8-HBase的启动与停止"><span class="toc-text">5.8  HBase的启动与停止</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Flume环境搭建"><span class="toc-text">6. Flume环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-下载软件"><span class="toc-text">1. 下载软件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-flume-env-sh"><span class="toc-text">2. flume-env.sh</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-Sqoop环境搭建"><span class="toc-text">7. Sqoop环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-下载软件"><span class="toc-text">7.1. 下载软件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-sqoop-env-sh"><span class="toc-text">7.2. sqoop-env.sh</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-zakaban环境搭建"><span class="toc-text">8. zakaban环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-下载软件"><span class="toc-text">8.1 下载软件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-azkaban-web服务器安装"><span class="toc-text">8.2 azkaban web服务器安装</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#8-2-1-配置SSL安全访问协议"><span class="toc-text">8.2.1 配置SSL安全访问协议</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-2-2-修改配置文件"><span class="toc-text">8.2.2 修改配置文件</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-3-azkaban-执行服器安装"><span class="toc-text">8.3 azkaban 执行服器安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-4-azkaban脚本导入"><span class="toc-text">8.4 azkaban脚本导入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-5-Azkaban启动"><span class="toc-text">8.5 Azkaban启动</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-Spark环境安装"><span class="toc-text">9. Spark环境安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1-下载软件"><span class="toc-text">9.1 下载软件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-修改配置文件"><span class="toc-text">9.2 修改配置文件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#9-2-1-spark-env-sh"><span class="toc-text">9.2.1 spark-env.sh</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-2-2-slaves"><span class="toc-text">9.2.2  slaves</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-2-3-分发到各个节点"><span class="toc-text">9.2.3 分发到各个节点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-SparkSql整合Hive"><span class="toc-text">9.3 SparkSql整合Hive</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-Spark-on-Yarn"><span class="toc-text">9.4 Spark on Yarn</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-kafka环境搭建"><span class="toc-text">10 kafka环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-1-下载软件"><span class="toc-text">10.1 下载软件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-修改配置文件"><span class="toc-text">10.2 修改配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-3-kafka监控工具的安装"><span class="toc-text">10.3 kafka监控工具的安装</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#10-3-1-Kafka-Manager"><span class="toc-text">10.3.1. Kafka Manager</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-3-2-Kafka-Eagle"><span class="toc-text">10.3.2 Kafka Eagle</span></a></li></ol></li></ol></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        大数据环境搭建
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2019-11-26 19:27:29</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#环境搭建" title="环境搭建">环境搭建</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <h1 id="大数据环境搭建-MAC"><a href="#大数据环境搭建-MAC" class="headerlink" title="大数据环境搭建(MAC)"></a>大数据环境搭建(MAC)</h1><h2 id="1-Linux-环境配置"><a href="#1-Linux-环境配置" class="headerlink" title="1. Linux 环境配置"></a>1. Linux 环境配置</h2><h3 id="1-1-Vmware-Funsion-Linux网络配置"><a href="#1-1-Vmware-Funsion-Linux网络配置" class="headerlink" title="1.1 Vmware Funsion Linux网络配置"></a>1.1 Vmware Funsion Linux网络配置</h3><h4 id="1-1-1-查看本机网络"><a href="#1-1-1-查看本机网络" class="headerlink" title="1.1.1 查看本机网络"></a>1.1.1 查看本机网络</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1. 查看vmnet网络配置，本机mac上</span></span><br><span class="line">cat /Library/Preferences/VMware\ Fusion/vmnet8/nat.conf </span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. 可以看到如下部分信息，记住下面信息，用来配置linux</span></span><br><span class="line">[host]</span><br><span class="line"><span class="meta">#</span><span class="bash"> NAT gateway address</span></span><br><span class="line">ip = 192.168.83.2</span><br><span class="line">netmask = 255.255.255.0</span><br></pre></td></tr></table></figure>
<h4 id="1-1-2-配置linux网络"><a href="#1-1-2-配置linux网络" class="headerlink" title="1.1.2 配置linux网络"></a>1.1.2 配置linux网络</h4><ol>
<li>setting -&gt; Network Adapter -&gt; Share with my msc  如下图</li>
</ol>
<p><img src="assets/image-20191127172534764.png" alt="image-20191127172534764" style="zoom:50%;"></p>
<ol start="2">
<li><p>点击上图左下角 Advanced options，点击Generate（生成MAC Address）</p>
<p><img src="assets/image-20191127172700292.png" alt="image-20191127172700292" style="zoom:50%;"></p>
</li>
<li><p>启动虚拟机</p>
</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1. 修改配置文件</span></span><br><span class="line">sudo vi /etc/sysconf/network-scripts/ifcg-ens192</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. 修改下面内容</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 改为静态</span></span><br><span class="line">BOOTPROTO=static</span><br><span class="line">ONBOOT=yes</span><br><span class="line"><span class="meta">#</span><span class="bash"> 与上面网段保持一致</span></span><br><span class="line">IPPADDR=192.168.83.100</span><br><span class="line"><span class="meta">#</span><span class="bash"> 与上面一致</span></span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line"><span class="meta">#</span><span class="bash"> 与上面ip一致</span></span><br><span class="line">GATEWAY=192.168.83.2</span><br><span class="line">DNS1=8.8.8.8</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">3. 修改之后，重启network</span></span><br><span class="line">service network restart</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>关闭防火墙，selinux</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 关闭</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line"><span class="meta">#</span><span class="bash"> 永久关闭</span></span><br><span class="line">systemctl disable firewalld</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 关闭selinux，修改下面文件内容</span></span><br><span class="line">vi /etc/selinux/config #进入selinux设置文件</span><br><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure>
<h3 id="1-2-Linux-设置免密登陆"><a href="#1-2-Linux-设置免密登陆" class="headerlink" title="1.2. Linux 设置免密登陆"></a>1.2. Linux 设置免密登陆</h3><h4 id="1-2-1-设置用户-amp-权限"><a href="#1-2-1-设置用户-amp-权限" class="headerlink" title="1.2.1 设置用户 &amp; 权限"></a>1.2.1 设置用户 &amp; 权限</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1. 创建hadoop用户</span></span><br><span class="line">useradd hadoop #添加hadoop用户</span><br><span class="line">passwd hadoop #给hadoop用户添加密码</span><br><span class="line">hadoop #密码设为hadoop</span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. 设置用户权限 </span></span><br><span class="line">visudo #进入用户权限配置文件</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Allow root to run any commands anywhere</span></span></span><br><span class="line">root    ALL=(ALL)       ALL</span><br><span class="line">hadoop  ALL=(ALL)	    ALL # 给hadoop用户添加所有权限</span><br><span class="line"><span class="meta">#</span><span class="bash"> 3. 切换到hadoop用户</span></span><br><span class="line">su - hadoop # 加上- 表示切换同时拥有权限</span><br></pre></td></tr></table></figure>
<h4 id="1-2-2-免密登陆"><a href="#1-2-2-免密登陆" class="headerlink" title="1.2.2 免密登陆"></a>1.2.2 免密登陆</h4><ol>
<li>修改/etc/hosts 文件</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/hosts</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加如下内容</span></span><br><span class="line">192.168.83.100 node01</span><br><span class="line">192.168.83.110 node02</span><br><span class="line">192.168.83.120 node03</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>配置免密登陆</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1. hadoop用户下执行下列命令，必须！</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 下面操作node01，node02，node03 都执行，回车next。</span></span><br><span class="line">ssh-keygen -t rsa #生成公钥</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. 三台机器的公钥全部拷贝到node01</span></span><br><span class="line">ssh-copy-id node01 </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3. 第一台机器执行，“:PWD”的意思是：拷贝目标文件位置和node01的位置一致。</span></span><br><span class="line">cd /home/hadoop/.ssh/</span><br><span class="line">scp authorized_keys node02:$PWD #将node01的授权文件拷贝到node02</span><br><span class="line">scp authorized_keys node03:$PWD #将node01的授权文件拷贝到node03</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">4. 验证免密登录</span></span><br><span class="line"><span class="meta">#</span><span class="bash">在node01执行</span></span><br><span class="line">ssh node02 #在node01登录node02，不需要密码就ok</span><br><span class="line">ssh node03 #在node01登录node02，不需要密码就ok</span><br><span class="line"><span class="meta">#</span><span class="bash">回到node01</span></span><br><span class="line">logout</span><br></pre></td></tr></table></figure>
<h3 id="1-3-时间同步"><a href="#1-3-时间同步" class="headerlink" title="1.3 时间同步"></a>1.3 时间同步</h3><h4 id="1-3-1-同步阿里云"><a href="#1-3-1-同步阿里云" class="headerlink" title="1.3.1 同步阿里云"></a>1.3.1 同步阿里云</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装ntpdate</span></span><br><span class="line">sudo yum -y install ntpdate</span><br><span class="line">crontab -e </span><br><span class="line">*/1 * * * * /usr/sbin/ntpdate time1.aliyun.com</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果时间不通可以执行</span></span><br><span class="line">sudo ntpdate -u asia.pool.ntp.org</span><br></pre></td></tr></table></figure>
<h4 id="1-3-2-同步node01时间"><a href="#1-3-2-同步node01时间" class="headerlink" title="1.3.2 同步node01时间"></a>1.3.2 同步node01时间</h4><ul>
<li>以下命令在root用户操作</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1. 安装ntp软件（所有）</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> (注意：ntpd作为node01服务端，node02、node03 ntpdate作为客户端软件不同)</span></span><br><span class="line">sudo yum  -y  install ntpd</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. 设置时区为中国上海（所有）</span></span><br><span class="line">timedatectl set-timezone Asia/Shanghai</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3. node01启动ntp服务，作为服务端供其他节点同步时间</span></span><br><span class="line">systemctl start ntpd</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 4. node01设置开机启动</span></span><br><span class="line">systemctl enable ntpd</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 5.修改配置 node01上</span></span><br><span class="line">sudo vi /etc/ntp.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> 注释掉以下四行，添加最后两行。对应自己的vmnt8内容</span></span><br><span class="line"><span class="meta">#</span><span class="bash">server 0.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="meta">#</span><span class="bash">server 1.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="meta">#</span><span class="bash">server 2.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="meta">#</span><span class="bash">server 3.centos.pool.ntp.org iburst</span></span><br><span class="line"></span><br><span class="line">restrict 192.168.83.2 mask 255.255.255.0 nomodify notrap</span><br><span class="line">server 127.127.1.0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 5.1 node02 node03修改配置</span></span><br><span class="line">sudo vi /etc/sysconfig/ntpdate</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改为 yes</span></span><br><span class="line">SYNC_HWCLOCK=yes</span><br><span class="line"></span><br><span class="line">crontab -e</span><br><span class="line">*/1 * * * * /usr/sbin/ntpdate 192.168.83.100</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 6. node02、node03重启服务</span></span><br><span class="line">systemctl restart ntpdate</span><br></pre></td></tr></table></figure>
<h2 id="2-Hadoop环境搭建"><a href="#2-Hadoop环境搭建" class="headerlink" title="2.Hadoop环境搭建"></a>2.Hadoop环境搭建</h2><h3 id="2-1-配置hadoop-env-sh"><a href="#2-1-配置hadoop-env-sh" class="headerlink" title="2.1 配置hadoop-env.sh"></a>2.1 配置hadoop-env.sh</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> hadoop 用户下</span></span><br><span class="line">su - hadoop</span><br><span class="line"></span><br><span class="line">vi /kfly/install/hadoop-2.6.0-cdh5.14.2/etc/hadoop/hadoop-env.sh </span><br><span class="line">export JAVA_HOME=/kfly/install/jdk1.8.0_141 #修改为此变量</span><br></pre></td></tr></table></figure>
<h3 id="2-2-配置core-site-xml"><a href="#2-2-配置core-site-xml" class="headerlink" title="2.2 配置core-site.xml"></a>2.2 配置core-site.xml</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在hadoop用户下打开配置文件：</span></span><br><span class="line">vi /kfly/install/hadoop-2.6.0-cdh5.14.2/etc/hadoop/core-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node01:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/kfly/install/hadoop-2.6.0/hadoopDatas/tempDatas<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!--  缓冲区大小，实际工作中根据服务器性能动态调整 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>io.file.buffer.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>10080<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>检查点被删除后的分钟数。 如果为零，垃圾桶功能将被禁用。 </span><br><span class="line">      该选项可以在服务器和客户端上配置。 如果垃圾箱被禁用服务器端，则检查客户端配置。 </span><br><span class="line">      如果在服务器端启用垃圾箱，则会使用服务器上配置的值，并忽略客户端配置值。</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.checkpoint.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">description</span>&gt;</span>垃圾检查点之间的分钟数。 应该小于或等于fs.trash.interval。 </span><br><span class="line">       如果为零，则将该值设置为fs.trash.interval的值。 每次检查指针运行时，</span><br><span class="line">       它都会从当前创建一个新的检查点，并删除比fs.trash.interval更早创建的检查点。</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="2-3-配置hdfs-site-xml"><a href="#2-3-配置hdfs-site-xml" class="headerlink" title="2.3 配置hdfs-site.xml"></a>2.3 配置hdfs-site.xml</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在hadoop用户下打开配置文件：</span></span><br><span class="line">vi /kkb/install/hadoop-2.6.0/etc/hadoop/hdfs-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- NameNode存储元数据信息的路径，实际工作中，一般先确定磁盘的挂载目录，然后多个目录用，进行分割   --&gt;</span> </span><br><span class="line">	<span class="comment">&lt;!--   集群动态上下线 </span></span><br><span class="line"><span class="comment">	&lt;property&gt;</span></span><br><span class="line"><span class="comment">		&lt;name&gt;dfs.hosts&lt;/name&gt;</span></span><br><span class="line"><span class="comment">		&lt;value&gt;/kfly/install/hadoop-2.6.0/etc/hadoop/accept_host&lt;/value&gt;</span></span><br><span class="line"><span class="comment">	&lt;/property&gt;</span></span><br><span class="line"><span class="comment">	&lt;property&gt;</span></span><br><span class="line"><span class="comment">		&lt;name&gt;dfs.hosts.exclude&lt;/name&gt;</span></span><br><span class="line"><span class="comment">		&lt;value&gt;/kfly/install/hadoop-2.6.0/etc/hadoop/deny_host&lt;/value&gt;</span></span><br><span class="line"><span class="comment">	&lt;/property&gt;</span></span><br><span class="line"><span class="comment">	 --&gt;</span></span><br><span class="line">	 <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///kfly/install/hadoop-2.6.0/hadoopDatas/namenodeDatas<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!--  定义dataNode数据存储的节点位置，实际工作中，一般先确定磁盘的挂载目录，然后多个目录用，进行分割  --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///kfly/install/hadoop-2.6.0/hadoopDatas/datanodeDatas<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///kfly/install/hadoop-2.6.0/hadoopDatas/dfs/nn/edits<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///kfly/install/hadoop-2.6.0/hadoopDatas/dfs/snn/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///kfly/install/hadoop-2.6.0/hadoopDatas/dfs/nn/snn/edits<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.blocksize<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="2-4-配置mapred-site-xml"><a href="#2-4-配置mapred-site-xml" class="headerlink" title="2.4 配置mapred-site.xml"></a>2.4 配置mapred-site.xml</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在hadoop用户下操作,进入指定文件夹：</span></span><br><span class="line">cd /kfly/install/hadoop-2.6.0-cdh5.14.2/etc/hadoop/</span><br><span class="line"><span class="meta">#</span><span class="bash">由于原来没有mapred-site.xml配置文件，需要根据模板复制一份：</span></span><br><span class="line">cp  mapred-site.xml.template mapred-site.xml</span><br><span class="line">vi /kfly/install/hadoop-2.6.0-cdh5.14.2/etc/hadoop/mapred-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--指定运行mapreduce的环境是yarn --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="2-5-配置yarn-site-xml"><a href="#2-5-配置yarn-site-xml" class="headerlink" title="2.5 配置yarn-site.xml"></a>2.5 配置yarn-site.xml</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在hadoop用户下操作</span></span><br><span class="line">vi /kfly/install/hadoop-2.6.0/etc/hadoop/yarn-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node01<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		 <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		 <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://node01:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!--多长时间聚合删除一次日志 此处--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2592000<span class="tag">&lt;/<span class="name">value</span>&gt;</span><span class="comment">&lt;!--30 day--&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!--时间在几秒钟内保留用户日志。只适用于如果日志聚合是禁用的--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.log.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span><span class="comment">&lt;!--7 day--&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!--指定文件压缩类型用于压缩汇总日志--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.log-aggregation.compression-type<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>gz<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- nodemanager本地文件存储目录--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.local-dirs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/kkb/install/hadoop-2.6.0-cdh5.14.2/hadoopDatas/yarn/local<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- resourceManager  保存最大的任务完成个数 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.max-completed-applications<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="2-6-编辑slaves"><a href="#2-6-编辑slaves" class="headerlink" title="2.6 编辑slaves"></a>2.6 编辑slaves</h3><p>此文件用于配置集群有多少个数据节点,我们把node2，node3作为数据节点,node1作为集群管理节点</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在hadoop用户下操作</span></span><br><span class="line">vim /kfly/install/hadoop-2.6.0/etc/hadoop/slaves</span><br><span class="line"></span><br><span class="line">node01 #添加</span><br><span class="line">node02 #添加</span><br><span class="line">node03 #添加</span><br></pre></td></tr></table></figure>
<h3 id="2-7-创建文件存放目录"><a href="#2-7-创建文件存放目录" class="headerlink" title="2.7 创建文件存放目录"></a>2.7 创建文件存放目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在hadoop用户下操作</span></span><br><span class="line">mkdir -p /kfly/install/hadoop-2.6.0-cdh5.14.2/hadoopDatas/tempDatas</span><br><span class="line">mkdir -p /kfly/install/hadoop-2.6.0-cdh5.14.2/hadoopDatas/namenodeDatas</span><br><span class="line">mkdir -p /kfly/install/hadoop-2.6.0-cdh5.14.2/hadoopDatas/datanodeDatas</span><br><span class="line">mkdir -p /kfly/install/hadoop-2.6.0-cdh5.14.2/hadoopDatas/dfs/nn/edits</span><br><span class="line">mkdir -p /kfly/install/hadoop-2.6.0-cdh5.14.2/hadoopDatas/dfs/snn/name</span><br><span class="line">mkdir -p /kfly/install/hadoop-2.6.0-cdh5.14.2/hadoopDatas/dfs/nn/snn/edits</span><br></pre></td></tr></table></figure>
<h3 id="2-8-拷贝到其他节点"><a href="#2-8-拷贝到其他节点" class="headerlink" title="2.8 拷贝到其他节点"></a>2.8 拷贝到其他节点</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 分发到各个节点下,<span class="variable">$PWD</span> 相同目录</span></span><br><span class="line">scp -r hadoop-2.6.0 node02:$PWD</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">分发配置文件</span></span><br><span class="line">scp /etc/profile node02:$PWD</span><br></pre></td></tr></table></figure>
<h3 id="2-9-格式化节点"><a href="#2-9-格式化节点" class="headerlink" title="2.9 格式化节点"></a>2.9 格式化节点</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">下面命令只在node01上执行</span></span><br><span class="line">hdfs namenode -format #格式化</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动</span></span><br><span class="line">start-all.sh</span><br></pre></td></tr></table></figure>
<h3 id="2-10-访问"><a href="#2-10-访问" class="headerlink" title="2.10 访问"></a>2.10 访问</h3><ul>
<li><p>hadoop webui <a href="http://node01:50070/" target="_blank" rel="noopener">http://node01:50070/</a></p>
</li>
<li><p>hadoop application <a href="http://node01:8088" target="_blank" rel="noopener">http://node01:8088</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动 jobhistory</span></span><br><span class="line">mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>
</li>
<li><p>hadoop job <a href="http://node01:19888" target="_blank" rel="noopener">http://node01:19888</a></p>
</li>
</ul>
<h3 id="2-11-Hadoop-Ha高可用"><a href="#2-11-Hadoop-Ha高可用" class="headerlink" title="2.11. Hadoop Ha高可用"></a>2.11. Hadoop Ha高可用</h3><p>​        <a href="https://kfly.top/2019/10/28/zookeeper/zookeeper%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E6%A1%86%E6%9E%B6%EF%BC%88%E4%BA%8C%EF%BC%89hadoop%20ha%E9%AB%98%E5%8F%AF%E7%94%A8%E5%AE%89%E8%A3%85/">hadoop ha 高可用</a></p>
<h2 id="3-hive环境搭建"><a href="#3-hive环境搭建" class="headerlink" title="3. hive环境搭建"></a>3. hive环境搭建</h2><h3 id="3-1-mysql安装"><a href="#3-1-mysql安装" class="headerlink" title="3.1 mysql安装"></a>3.1 mysql安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装wget</span></span><br><span class="line">sudo yum install wget</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 1. 换源</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 1.1 备份系统源</span></span><br><span class="line">sudo mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</span><br><span class="line"><span class="meta">#</span><span class="bash"> 1.2 下载阿里云CENTOS7镜像文件</span></span><br><span class="line">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line"><span class="meta">#</span><span class="bash"> 1.3 清理缓存、生成新的缓存</span></span><br><span class="line">sudo yum clean all</span><br><span class="line">sudo yum makecache</span><br><span class="line"><span class="meta">#</span><span class="bash"> 1.4 更新源</span></span><br><span class="line">sudo yum update -y</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. 使用yum安装MySQL,下载并安装MySQL官方的 Yum Repository</span></span><br><span class="line">sudo wget -i -c http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm</span><br><span class="line">sudo yum -y install mysql57-community-release-el7-10.noarch.rpm</span><br><span class="line">sudo yum -y install mysql-community-server</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3. 启动mysql，查看运行状态</span></span><br><span class="line">systemctl start  mysqld.service</span><br><span class="line">systemctl status mysqld.service</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 4. 找出默认密码如下图所示</span></span><br><span class="line">sudo grep "password" /var/log/mysqld.log</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 5. 登陆、修改密码</span></span><br><span class="line">mysql -uroot -p     # 回车后会提示输入密码</span><br><span class="line">ALTER USER 'root'@'localhost' IDENTIFIED BY 'new password';</span><br><span class="line"><span class="meta"> #</span><span class="bash"> 注意： 如果失败，修改密码策略,先修改一个复杂的密码，在修改策略，修改密码</span></span><br><span class="line">ALTER USER 'root'@'localhost' IDENTIFIED BY 'z?guwrBhH7p&gt;';</span><br><span class="line">set global validate_password_policy=0;</span><br><span class="line">set global validate_password_policy=1;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 6. 设置mysql可以外部连接</span></span><br><span class="line">grant all on *.* to root@'%' identified by '数据库密码';</span><br></pre></td></tr></table></figure>
<h3 id="3-2-hive安装"><a href="#3-2-hive安装" class="headerlink" title="3.2 hive安装"></a>3.2 hive安装</h3><h4 id="3-2-1-下载hive的安装包"><a href="#3-2-1-下载hive的安装包" class="headerlink" title="3.2.1 下载hive的安装包"></a>3.2.1 下载hive的安装包</h4><ul>
<li><a href="http://archive.cloudera.com/cdh5/cdh/5/hive-1.1.0-cdh5.14.2.tar.gz" target="_blank" rel="noopener">http://archive.cloudera.com/cdh5/cdh/5/hive-1.1.0-cdh5.14.2.tar.gz</a></li>
</ul>
<h4 id="3-2-2-hive-env-sh"><a href="#3-2-2-hive-env-sh" class="headerlink" title="3.2.2 hive-env.sh"></a>3.2.2 hive-env.sh</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim hive-env.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">配置HADOOP_HOME路径</span></span><br><span class="line">export HADOOP_HOME=/kfly/install/hadoop-2.6.0</span><br><span class="line"><span class="meta">#</span><span class="bash">配置HIVE_CONF_DIR路径</span></span><br><span class="line">export HIVE_CONF_DIR=/kfly/install/hive-1.1.0-cdh5.14.2/conf</span><br></pre></td></tr></table></figure>
<h4 id="3-2-3-hive-site-xml"><a href="#3-2-3-hive-site-xml" class="headerlink" title="3.2.3 hive-site.xml"></a>3.2.3 hive-site.xml</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="php"><span class="meta">&lt;?</span>xml-stylesheet type=<span class="string">"text/xsl"</span> href=<span class="string">"configuration.xsl"</span><span class="meta">?&gt;</span></span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://node02:3306/hive?createDatabaseIfNotExist=true&amp;amp;characterEncoding=latin1&amp;amp;useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>node02<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="3-2-4-日志路径"><a href="#3-2-4-日志路径" class="headerlink" title="3.2.4 日志路径"></a>3.2.4 日志路径</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim hive-log4j.properties</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">更改以下内容，设置我们的日志文件存放的路径</span></span><br><span class="line">hive.log.dir=/kkb/install/hive-1.1.0-cdh5.14.2/logs/</span><br></pre></td></tr></table></figure>
<h4 id="3-4-5-lib包"><a href="#3-4-5-lib包" class="headerlink" title="3.4.5  lib包"></a>3.4.5  lib包</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ps: ==需要将mysql的驱动包上传到hive的lib目录下==</span><br><span class="line"> * 例如 mysql-connector-java-5.1.38.jar</span><br></pre></td></tr></table></figure>
<h3 id="3-3-hive使用Spark-on-Yarn作为计算引擎"><a href="#3-3-hive使用Spark-on-Yarn作为计算引擎" class="headerlink" title="3.3 hive使用Spark on Yarn作为计算引擎"></a>3.3 hive使用Spark on Yarn作为计算引擎</h3><p>​        <a href="http://lxw1234.com/archives/2016/05/673.htm" target="_blank" rel="noopener">查看</a></p>
<h2 id="4-zookeeper环境搭建"><a href="#4-zookeeper环境搭建" class="headerlink" title="4. zookeeper环境搭建"></a>4. zookeeper环境搭建</h2><h3 id="4-1-下载软件"><a href="#4-1-下载软件" class="headerlink" title="4.1 下载软件"></a>4.1 下载软件</h3><p>​            <a href="http://archive.cloudera.com/cdh5/cdh/5/zookeeper-3.4.5-cdh5.14.2.tar.gz" target="_blank" rel="noopener">点击下载 zookeeper-3.4.5-cdh5.14.2.tar.gz</a></p>
<h3 id="4-2-修改配置文件"><a href="#4-2-修改配置文件" class="headerlink" title="4.2 修改配置文件"></a>4.2 修改配置文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1. copy配置文件</span></span><br><span class="line">cd /kfly/install/zookeeper-3.4.5-cdh5.14.2/conf</span><br><span class="line">cp zoo_sample.cfg zoo.cfg</span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. 创建存放数据目录</span></span><br><span class="line">mkdir -p /kfly/install/zookeeper-3.4.5-cdh5.14.2/zkdatas</span><br><span class="line"><span class="meta">#</span><span class="bash"> 编辑</span></span><br><span class="line">vim  zoo.cfg</span><br><span class="line"><span class="meta">#</span><span class="bash"> 3. 文件内容如下</span></span><br><span class="line">dataDir=/kfly/install/zookeeper-3.4.5-cdh5.14.2/zkdatas</span><br><span class="line">autopurge.snapRetainCount=3</span><br><span class="line">autopurge.purgeInterval=1</span><br><span class="line">server.1=node01:2888:3888</span><br><span class="line">server.2=node02:2888:3888</span><br><span class="line">server.3=node03:2888:3888</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 4 分发到各个节点</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 5. 写入myid文件，myid分别对应，node01:1，node02:2,node03.3、一次累加</span></span><br><span class="line">echo 1 &gt;  /kfly/install/zookeeper-3.4.5-cdh5.14.2/zkdatas/myid</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 6. 启动服务、查看状态</span></span><br><span class="line">bin/zkServer.sh start</span><br><span class="line">bin/zkServer.sh status</span><br></pre></td></tr></table></figure>
<h2 id="5-HBase环境搭建"><a href="#5-HBase环境搭建" class="headerlink" title="5. HBase环境搭建"></a>5. HBase环境搭建</h2><h3 id="5-1-下载软件"><a href="#5-1-下载软件" class="headerlink" title="5.1 下载软件"></a>5.1 下载软件</h3><p>​        <a href="http://archive.cloudera.com/cdh5/cdh/5/hbase-1.2.0-cdh5.14.2.tar.gz" target="_blank" rel="noopener">点击下载hbase-1.2.0-cdh5.14.2.tar.gz</a></p>
<h3 id="5-2-hbase-env-sh"><a href="#5-2-hbase-env-sh" class="headerlink" title="5.2  hbase-env.sh"></a>5.2  hbase-env.sh</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/kfly/install/jdk1.8.0_141</span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用外部的zookeeper集群</span></span><br><span class="line">export HBASE_MANAGES_ZK=false</span><br></pre></td></tr></table></figure>
<h3 id="5-3-hbase-site-xml"><a href="#5-3-hbase-site-xml" class="headerlink" title="5.3 hbase-site.xml"></a>5.3 hbase-site.xml</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node01:8020/HBase<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 0.98后的新变动，之前版本没有.port,默认端口为60000 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.master.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>16000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>node01,node02,node03<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.clientPort<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/kfly/install/zookeeper-3.4.5-cdh5.14.2/zkdatas<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>zookeeper.znode.parent<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/HBase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="5-4-regionservers"><a href="#5-4-regionservers" class="headerlink" title="5.4  regionservers"></a>5.4  regionservers</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 配置文件 目录 conf下</span></span><br><span class="line"> vim regionservers</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 内容如下</span></span><br><span class="line">node01</span><br><span class="line">node02</span><br><span class="line">node03</span><br></pre></td></tr></table></figure>
<h3 id="5-5-back-masters"><a href="#5-5-back-masters" class="headerlink" title="5.5  back-masters"></a>5.5  back-masters</h3><ul>
<li>创建back-masters配置文件，里边包含备份HMaster节点的主机名，每个机器独占一行，实现HMaster的高可用</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node01 conf]$ vim backup-masters</span><br></pre></td></tr></table></figure>
<ul>
<li>将node02作为备份的HMaster节点，问价内容如下</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node02</span><br></pre></td></tr></table></figure>
<h3 id="5-6-创建软连接"><a href="#5-6-创建软连接" class="headerlink" title="5.6  创建软连接"></a>5.6  创建软连接</h3><ul>
<li><p><strong><font color="red">注意：三台机器</font></strong>均做如下操作</p>
</li>
<li><p>因为HBase集群需要读取hadoop的core-site.xml、hdfs-site.xml的配置文件信息，所以我们==三台机器==都要执行以下命令，在相应的目录创建这两个配置文件的软连接</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ln -s /kfly/install/hadoop-2.6.0-cdh5.14.2/etc/hadoop/core-site.xml  /kfly/install/hbase-1.2.0-cdh5.14.2/conf/core-site.xml</span><br><span class="line"></span><br><span class="line">ln -s /kfly/install/hadoop-2.6.0-cdh5.14.2/etc/hadoop/hdfs-site.xml  /kfly/install/hbase-1.2.0-cdh5.14.2/conf/hdfs-site.xml</span><br></pre></td></tr></table></figure>
<h3 id="5-7-添加HBase环境变量"><a href="#5-7-添加HBase环境变量" class="headerlink" title="5.7 添加HBase环境变量"></a>5.7 添加HBase环境变量</h3><ul>
<li><strong><font color="red">注意：三台机器</font></strong>均执行以下命令，添加环境变量</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加如下</span></span><br><span class="line">export HBASE_HOME=/kkb/install/hbase-1.2.0-cdh5.14.2</span><br><span class="line">export PATH=$PATH:$HBASE_HOME/bin</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 立即生效</span></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<h3 id="5-8-HBase的启动与停止"><a href="#5-8-HBase的启动与停止" class="headerlink" title="5.8  HBase的启动与停止"></a>5.8  HBase的启动与停止</h3><ul>
<li><font color="red">需要提前启动HDFS及ZooKeeper集群</font>
</li>
<li><p>第一台机器node01（HBase主节点）执行以下命令，启动HBase集群</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node01 ~]$ start-hbase.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">HMaster节点上启动HMaster命令</span></span><br><span class="line">hbase-daemon.sh start master</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">启动HRegionServer命令</span></span><br><span class="line">hbase-daemon.sh start regionserver</span><br></pre></td></tr></table></figure>
<ul>
<li><p>浏览器页面访问</p>
<p><a href="http://node01:60010" target="_blank" rel="noopener">http://node01:60010</a></p>
</li>
</ul>
<h2 id="6-Flume环境搭建"><a href="#6-Flume环境搭建" class="headerlink" title="6. Flume环境搭建"></a>6. Flume环境搭建</h2><h3 id="1-下载软件"><a href="#1-下载软件" class="headerlink" title="1. 下载软件"></a>1. 下载软件</h3><p>​            <a href="http://archive.cloudera.com/cdh5/cdh/5/flume-ng-1.6.0-cdh5.14.2.tar.gz" target="_blank" rel="noopener">点击下载 flume-ng-1.6.0-cdh5.14.2.tar.gz</a></p>
<h3 id="2-flume-env-sh"><a href="#2-flume-env-sh" class="headerlink" title="2. flume-env.sh"></a>2. flume-env.sh</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/kfly/install/jdk1.8.0_141</span><br></pre></td></tr></table></figure>
<h2 id="7-Sqoop环境搭建"><a href="#7-Sqoop环境搭建" class="headerlink" title="7. Sqoop环境搭建"></a>7. Sqoop环境搭建</h2><h3 id="7-1-下载软件"><a href="#7-1-下载软件" class="headerlink" title="7.1. 下载软件"></a>7.1. 下载软件</h3><p>​    <a href="http://archive.cloudera.com/cdh5/cdh/5/sqoop-1.4.6-cdh5.14.2.tar.gz" target="_blank" rel="noopener">点击下载 sqoop-1.4.6-cdh5.14.2.tar.gz </a></p>
<h3 id="7-2-sqoop-env-sh"><a href="#7-2-sqoop-env-sh" class="headerlink" title="7.2. sqoop-env.sh"></a>7.2. sqoop-env.sh</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">Set path to <span class="built_in">where</span> bin/hadoop is available</span></span><br><span class="line">export HADOOP_COMMON_HOME=/kfly/install/hadoop-2.6.0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">Set path to <span class="built_in">where</span> hadoop-*-core.jar is available</span></span><br><span class="line">export HADOOP_MAPRED_HOME=/kfly/install/hadoop-2.6.0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">set</span> the path to <span class="built_in">where</span> bin/hbase is available</span></span><br><span class="line">export HBASE_HOME=/kfly/install/hbase-1.2.0-cdh5.14.2</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">Set the path to <span class="built_in">where</span> bin/hive is available</span></span><br><span class="line">export HIVE_HOME=/kfly/install/hive-1.1.0-cdh5.14.2</span><br></pre></td></tr></table></figure>
<h2 id="8-zakaban环境搭建"><a href="#8-zakaban环境搭建" class="headerlink" title="8. zakaban环境搭建"></a>8. zakaban环境搭建</h2><h3 id="8-1-下载软件"><a href="#8-1-下载软件" class="headerlink" title="8.1 下载软件"></a>8.1 下载软件</h3><p>​    <a href="https://azkaban.github.io/downloads.html" target="_blank" rel="noopener">点击下载 </a></p>
<ul>
<li>azkaban-web-server-2.5.0.tar.gz</li>
<li>azkaban-executor-server-2.5.0.tar.gz</li>
<li>azkaban-sql-script-2.5.0.tar.gz</li>
</ul>
<h3 id="8-2-azkaban-web服务器安装"><a href="#8-2-azkaban-web服务器安装" class="headerlink" title="8.2 azkaban web服务器安装"></a>8.2 azkaban web服务器安装</h3><h4 id="8-2-1-配置SSL安全访问协议"><a href="#8-2-1-配置SSL安全访问协议" class="headerlink" title="8.2.1 配置SSL安全访问协议"></a>8.2.1 配置SSL安全访问协议</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1. 创建安装目录，解压、解压文件重命名</span></span><br><span class="line">mkdir /kfly/install/azkaban</span><br><span class="line">tar –zxvf azkaban-web-server-2.5.0.tar.gz -C /kfly/install/azkaban</span><br><span class="line">mv /kkb/install/azkaban/azkaban-web-2.5.0 /kkb/install/azkaban/server</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. 在server目下执行下边的命令</span></span><br><span class="line">keytool -keystore keystore -alias jetty -genkey -keyalg RSA</span><br><span class="line">          # Keytool:   是java数据证书的管理工具，使用户能够管理自己的公/私钥对及相关证书。</span><br><span class="line">          # -keystore：指定密钥库的名称及位置(产生的各类信息将不在.keystore文件中)</span><br><span class="line">          # -alias：   对我们生成的.keystore 进行指认别名；如果没有默认是mykey</span><br><span class="line">          # -genkey：  在用户主目录中创建一个默认文件".keystore" </span><br><span class="line">          # -keyalg：  指定密钥的算法 RSA/DSA 默认是DSA</span><br><span class="line"></span><br><span class="line">          # 运行此命令后,会提示输入当前生成 keystore的密码及相应信息,输入的密码请劳记</span><br><span class="line">         -------------------------------------------------------------------</span><br><span class="line">            输入keystore密码： </span><br><span class="line">            再次输入新密码:</span><br><span class="line">            您的名字与姓氏是什么？</span><br><span class="line">              [Unknown]： </span><br><span class="line">            您的组织单位名称是什么？</span><br><span class="line">              [Unknown]： </span><br><span class="line">            您的组织名称是什么？</span><br><span class="line">              [Unknown]： </span><br><span class="line">            您所在的城市或区域名称是什么？</span><br><span class="line">              [Unknown]： </span><br><span class="line">            您所在的州或省份名称是什么？</span><br><span class="line">              [Unknown]： </span><br><span class="line">            该单位的两字母国家代码是什么</span><br><span class="line">              [Unknown]：  CN</span><br><span class="line">            CN=Unknown, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=CN 正确吗？</span><br><span class="line">              [否]：  y</span><br><span class="line"></span><br><span class="line">              输入&lt;jetty&gt;的主密码</span><br><span class="line">                      （如果和 keystore 密码相同，按回车）： </span><br><span class="line">              再次输入新密码:</span><br><span class="line">          #完成上述工作后,将在当前目录生成 keystore 证书文件,</span><br><span class="line"><span class="meta">#</span><span class="bash"> 3. 将keystore 考贝到 azkaban webserver 服务器根目录中.</span></span><br><span class="line">cp keystore /kfly/install/azkaban/server</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 4. 配置时区、先生成时区配置文件Asia/Shanghai，用交互式命令 tzselect 即可.</span></span><br><span class="line">tzselect </span><br><span class="line"><span class="meta">  	#</span><span class="bash"> 选5 ---&gt;选9----&gt;选1-----&gt;选1</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 4.1、拷贝该时区文件，覆盖系统本地时区配置</span></span><br><span class="line">cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime  </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 5.修改配置文件</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 5.2</span></span><br></pre></td></tr></table></figure>
<h4 id="8-2-2-修改配置文件"><a href="#8-2-2-修改配置文件" class="headerlink" title="8.2.2 修改配置文件"></a>8.2.2 修改配置文件</h4><ul>
<li><ol>
<li>azkaban.properties</li>
</ol>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">vim /kfly/install/azkaban/server/conf/azkaban.properties</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">内容说明如下:</span></span><br><span class="line"><span class="meta">#</span><span class="bash">Azkaban Personalization Settings</span></span><br><span class="line">azkaban.name=Test                   #服务器UI名称,用于服务器上方显示的名字</span><br><span class="line">azkaban.label=My Local Azkaban      #描述</span><br><span class="line">azkaban.color=#FF3601               #UI颜色</span><br><span class="line">azkaban.default.servlet.path=/index    </span><br><span class="line">web.resource.dir=web/                 #默认根web目录</span><br><span class="line">default.timezone.id=Asia/Shanghai     #默认时区,已改为亚洲/上海 默认为美国</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">Azkaban UserManager class</span></span><br><span class="line">user.manager.class=azkaban.user.XmlUserManager   #用户权限管理默认类</span><br><span class="line">user.manager.xml.file=conf/azkaban-users.xml     #用户配置,具体配置参加下文</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">Loader <span class="keyword">for</span> projects</span></span><br><span class="line">executor.global.properties=conf/global.properties    #global配置文件所在位置</span><br><span class="line">azkaban.project.dir=projects                                             </span><br><span class="line"> </span><br><span class="line">database.type=mysql               #数据库类型</span><br><span class="line">mysql.port=3306                   #端口号</span><br><span class="line">mysql.host=node03                 #数据库连接IP</span><br><span class="line">mysql.database=azkaban            #数据库实例名</span><br><span class="line">mysql.user=root                   #数据库用户名</span><br><span class="line">mysql.password=123456             #数据库密码</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> Velocity dev mode</span></span><br><span class="line">velocity.dev.mode=false          #Jetty服务器属性.</span><br><span class="line">jetty.maxThreads=25              #最大线程数</span><br><span class="line">jetty.ssl.port=8443              #Jetty SSL端口</span><br><span class="line">jetty.port=8081                  #Jetty端口</span><br><span class="line">jetty.keystore=keystore          #SSL文件名</span><br><span class="line">jetty.password=123456            #SSL文件密码</span><br><span class="line">jetty.keypassword=123456         #Jetty主密码 与 keystore文件相同</span><br><span class="line">jetty.truststore=keystore        #SSL文件名</span><br><span class="line">jetty.trustpassword=123456       #SSL文件密码</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 执行服务器属性</span></span><br><span class="line">executor.port=12321               #执行服务器端口</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 邮件设置</span></span><br><span class="line">mail.sender=xxxxxxxx@163.com        #发送邮箱</span><br><span class="line">mail.host=smtp.163.com              #发送邮箱smtp地址</span><br><span class="line">mail.user=xxxxxxxx                  #发送邮件时显示的名称</span><br><span class="line">mail.password=**********            #邮箱密码</span><br><span class="line">job.failure.email=xxxxxxxx@163.com  #任务失败时发送邮件的地址</span><br><span class="line">job.success.email=xxxxxxxx@163.com  #任务成功时发送邮件的地址</span><br><span class="line">lockdown.create.projects=false       </span><br><span class="line">cache.directory=cache                #缓存目录</span><br></pre></td></tr></table></figure>
<ul>
<li><ol start="2">
<li>azkaban-users.xml</li>
</ol>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /kfly/install/azkaban/server/conf/azkaban-users.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">azkaban-users</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">user</span> <span class="attr">username</span>=<span class="string">"azkaban"</span> <span class="attr">password</span>=<span class="string">"azkaban"</span> <span class="attr">roles</span>=<span class="string">"admin"</span><span class="attr">groups</span>=<span class="string">"azkaban"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">user</span> <span class="attr">username</span>=<span class="string">"metrics"</span> <span class="attr">password</span>=<span class="string">"metrics"</span> <span class="attr">roles</span>=<span class="string">"metrics"</span>/&gt;</span></span><br><span class="line"> <span class="comment">&lt;!--新增admin用户--&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">user</span> <span class="attr">username</span>=<span class="string">"admin"</span> <span class="attr">password</span>=<span class="string">"admin"</span> <span class="attr">roles</span>=<span class="string">"admin,metrics"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">role</span> <span class="attr">name</span>=<span class="string">"admin"</span> <span class="attr">permissions</span>=<span class="string">"ADMIN"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">role</span> <span class="attr">name</span>=<span class="string">"metrics"</span> <span class="attr">permissions</span>=<span class="string">"METRICS"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">azkaban-users</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="8-3-azkaban-执行服器安装"><a href="#8-3-azkaban-执行服器安装" class="headerlink" title="8.3 azkaban 执行服器安装"></a>8.3 azkaban 执行服器安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1. 解压azkaban-executor-server-2.5.0.tar.gz,重命名文件</span></span><br><span class="line">tar -zxvf azkaban-executor-server-2.5.0.tar.gz -C /kfly/install/azkaban</span><br><span class="line">mv /kfly/install/azkaban/azkaban-executor-2.5.0 /kfly/install/azkaban/executor</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. 修改配置文件</span></span><br><span class="line">vim /kfly/install/azkaban/executor/conf/azkaban.properties</span><br><span class="line">      # 内容如下----------</span><br><span class="line">      #Azkaban   #时区</span><br><span class="line">      default.timezone.id=Asia/Shanghai          </span><br><span class="line"></span><br><span class="line">      #数据库设置-----&gt;需要修改的信息</span><br><span class="line">      mysql.host=node3          #数据库IP地址</span><br><span class="line">      mysql.database=azkaban    #数据库实例名</span><br><span class="line">      mysql.user=root           #数据库用户名</span><br><span class="line">      mysql.password=123456     #数据库密码</span><br></pre></td></tr></table></figure>
<h3 id="8-4-azkaban脚本导入"><a href="#8-4-azkaban脚本导入" class="headerlink" title="8.4 azkaban脚本导入"></a>8.4 azkaban脚本导入</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1. 解压azkaban-sql-script-2.5.0.tar.gz</span></span><br><span class="line">tar -zxvf azkaban-sql-script-2.5.0.tar.gz -C /kfly/install/azkaban</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. 把解压后的脚本导入到mysql中、进入到mysql</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> create database azkaban;</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> use azkaban;</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> <span class="built_in">source</span> /kfly/install/azkaban/azkaban-2.5.0/create-all-sql-2.5.0.sql;</span></span><br></pre></td></tr></table></figure>
<h3 id="8-5-Azkaban启动"><a href="#8-5-Azkaban启动" class="headerlink" title="8.5 Azkaban启动"></a>8.5 Azkaban启动</h3><ul>
<li>在azkaban web server服务器目录下执行启动命令</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1. 启动web server服务、在azkaban web server服务器目录下执行启动命令</span></span><br><span class="line">bin/azkaban-web-start.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. 启动executor执行服务、在azkaban executor服务器目录下执行启动命令</span></span><br><span class="line">bin/azkaban-executor-start.sh</span><br></pre></td></tr></table></figure>
<ul>
<li>启动完成后,在浏览器(建议使用谷歌浏览器)中输入==https://服务器IP地址:8443== ,即可访问azkaban服务了.在登录中输入刚才新的户用名及密码,点击 login.</li>
<li>输入“IP地址:8443”无法访问 web 页面, 且后台报错，原因是浏览器安全证书限制</li>
<li>解决办法：使用“<a href="https://ip:8443”访问" target="_blank" rel="noopener">https://ip:8443”访问</a>, 发现已经可以访问了, 后台会报证数问题的错误, 忽略即可, 不影响使用, 选择高级 ——&gt; 继续访问该网站</li>
</ul>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">（<span class="number">1</span>）、projects：azkaban最重要的一部分，创建一个工程，将所有的工作流放在工程中执行</span><br><span class="line">（<span class="number">2</span>）、scheduling：定时调度任务用的</span><br><span class="line">（<span class="number">3</span>）、<span class="string">executing:</span>  显示当前运行的任务</span><br><span class="line">（<span class="number">4</span>）、<span class="string">History :</span> 显示历史运行任务</span><br><span class="line"></span><br><span class="line">一个project由<span class="number">3</span>个按钮：</span><br><span class="line">（<span class="number">1</span>）、Flows：一个工作流，由多个job组成</span><br><span class="line">（<span class="number">2</span>）、<span class="string">Permissions:</span>权限管理</span><br><span class="line">（<span class="number">3</span>）、Project Logs：工程日志信息</span><br></pre></td></tr></table></figure>
<h2 id="9-Spark环境安装"><a href="#9-Spark环境安装" class="headerlink" title="9. Spark环境安装"></a>9. Spark环境安装</h2><h3 id="9-1-下载软件"><a href="#9-1-下载软件" class="headerlink" title="9.1 下载软件"></a>9.1 下载软件</h3><p>​    <a href="https://archive.apache.org/dist/spark/spark-2.3.3/spark-2.3.3-bin-hadoop2.7.tgz" target="_blank" rel="noopener">点击下载</a></p>
<h3 id="9-2-修改配置文件"><a href="#9-2-修改配置文件" class="headerlink" title="9.2 修改配置文件"></a>9.2 修改配置文件</h3><h4 id="9-2-1-spark-env-sh"><a href="#9-2-1-spark-env-sh" class="headerlink" title="9.2.1 spark-env.sh"></a>9.2.1 spark-env.sh</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#配置java的环境变量</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/kkb/install/jdk1.8.0_141</span><br><span class="line"><span class="comment">#配置zk相关信息</span></span><br><span class="line"><span class="built_in">export</span> SPARK_DAEMON_JAVA_OPTS=<span class="string">"-Dspark.deploy.recoveryMode=ZOOKEEPER  -Dspark.deploy.zookeeper.url=node01:2181,node02:2181,node03:2181  -Dspark.deploy.zookeeper.dir=/spark"</span></span><br></pre></td></tr></table></figure>
<ul>
<li>注意</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">## 如果想运行spark-shell --master local[N] 读取HDFS上文件，则加上如下配置文件</span><br><span class="line">export HADOOP_CONF_DIR=/kkb/install/hadoop-2.6.0-cdh5.14.2/etc/hadoop</span><br><span class="line"># 这就是读取hdfs下，hdfs://node01:8020/words.txt 文件</span><br><span class="line">sc.textFile(&quot;/words.txt&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="9-2-2-slaves"><a href="#9-2-2-slaves" class="headerlink" title="9.2.2  slaves"></a>9.2.2  slaves</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">指定spark集群的worker节点</span></span><br><span class="line">node02</span><br><span class="line">node03</span><br></pre></td></tr></table></figure>
<h4 id="9-2-3-分发到各个节点"><a href="#9-2-3-分发到各个节点" class="headerlink" title="9.2.3 分发到各个节点"></a>9.2.3 分发到各个节点</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 分发到各个节点</span></span><br><span class="line">scp -r /kfly/install/spark node02:/kkb/install</span><br><span class="line"><span class="comment"># 2. 修改source /etc/profile环境</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/kfly/install/spark</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin:<span class="variable">$SPARK_HOME</span>/sbin</span><br></pre></td></tr></table></figure>
<h3 id="9-3-SparkSql整合Hive"><a href="#9-3-SparkSql整合Hive" class="headerlink" title="9.3 SparkSql整合Hive"></a>9.3 SparkSql整合Hive</h3><ul>
<li>步骤<ul>
<li>1、需要把hive安装目录下的配置文件hive-site.xml拷贝到每一个spark安装目录下对应的conf文件夹中</li>
<li>2、需要一个连接mysql驱动的jar包拷贝到spark安装目录下对应的jars文件夹中</li>
<li>3、可以使用spark-sql脚本 后期执行sql相关的任务</li>
</ul>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">spark-sql \</span><br><span class="line">--master spark://node01:7077 \</span><br><span class="line">--executor-memory 1g \</span><br><span class="line">--total-executor-cores 4 \</span><br><span class="line">--conf spasrk.sql.warehouse.dir=hdfs://node01:8020/user/hive/warehouse</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"><span class="comment">#定义sparksql提交脚本的头信息</span></span><br><span class="line">SUBMITINFO=<span class="string">"spark-sql --master spark://node01:7077 --executor-memory 1g --total-executor-cores 4 --conf spark.sql.warehouse.dir=hdfs://node01:8020/user/hive/warehouse"</span> </span><br><span class="line"><span class="comment">#定义一个sql语句</span></span><br><span class="line">SQL=<span class="string">"select * from kfly.psrson;"</span> </span><br><span class="line"><span class="comment">#执行sql语句   类似于 hive -e sql语句</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$SUBMITINFO</span>"</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$SQL</span>"</span></span><br><span class="line"><span class="variable">$SUBMITINFO</span> -e <span class="string">"<span class="variable">$SQL</span>"</span></span><br></pre></td></tr></table></figure>
<h3 id="9-4-Spark-on-Yarn"><a href="#9-4-Spark-on-Yarn" class="headerlink" title="9.4 Spark on Yarn"></a>9.4 Spark on Yarn</h3><ul>
<li><a href="http://spark.apache.org/docs/2.3.3/running-on-yarn.html" target="_blank" rel="noopener">官网资料</a></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 注意这里不需要安装spark集群、只需要解压spark安装包到任意一台服务器</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">修改文件 spark-env.sh</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">指定java的环境变量</span></span><br><span class="line">export JAVA_HOME=/kkb/install/jdk1.8.0_141</span><br><span class="line"><span class="meta">#</span><span class="bash">指定hadoop的配置文件目录</span></span><br><span class="line">export HADOOP_CONF_DIR=/kkb/install/hadoop-2.6.0-cdh5.14.2/etc/hadoop</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--driver-memory 1g \</span><br><span class="line">--executor-memory 1g \</span><br><span class="line">--executor-cores 1 \</span><br><span class="line">/kfly/install/spark-2.3.3-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.3.3.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></figure>
<ul>
<li><p>如果运行出现错误，可能是虚拟内存不足，可以添加参数</p>
<ul>
<li>vim yarn-site.xml</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--容器是否会执行物理内存限制默认为True--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--容器是否会执行虚拟内存限制    默认为True--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="10-kafka环境搭建"><a href="#10-kafka环境搭建" class="headerlink" title="10 kafka环境搭建"></a>10 kafka环境搭建</h2><h3 id="10-1-下载软件"><a href="#10-1-下载软件" class="headerlink" title="10.1 下载软件"></a>10.1 下载软件</h3><p><em><a href="https://archive.apache.org/dist/kafka/1.0.1/kafka_2.11-1.0.1.tgz" target="_blank" rel="noopener">点击下载 https://archive.apache.org/dist/kafka/1.0.1/kafka_2.11-1.0.1.tgz</a></em></p>
<h3 id="10-2-修改配置文件"><a href="#10-2-修改配置文件" class="headerlink" title="10.2 修改配置文件"></a>10.2 修改配置文件</h3><ul>
<li>vi server.properties</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#指定kafka对应的broker id ，唯一(eg：node01 0,node02 1,node03 2)</span><br><span class="line">broker.id=0</span><br><span class="line">#指定数据存放的目录</span><br><span class="line">log.dirs=/kfly/install/kafka/kafka-logs</span><br><span class="line">#指定zk地址</span><br><span class="line">zookeeper.connect=node01:2181,node02:2181,node03:2181</span><br><span class="line">#指定是否可以删除topic ,默认是false 表示不可以删除</span><br><span class="line">delete.topic.enable=true</span><br><span class="line">#指定broker主机名,node01 node02 node03</span><br><span class="line">host.name=node01</span><br></pre></td></tr></table></figure>
<ul>
<li>修改kafka环境变量</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export KAFKA_HOME=/kfly/install/kafka</span><br><span class="line">export PATH=$PATH:$KAFKA_HOME/bin</span><br></pre></td></tr></table></figure>
<ul>
<li>分发到其他节点，然后运行</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span> </span><br><span class="line"><span class="string">"start"</span>)&#123;</span><br><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> node01 node02 node03 </span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  ssh <span class="variable">$host</span> <span class="string">"source /etc/profile; nohup /kfly/install/kafka/bin/kafka-server-start.sh /kfly/install/kafka/config/server.properties &gt; /dev/null 2&gt;&amp;1 &amp;"</span>   </span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"<span class="variable">$host</span> kafka is running..."</span>  </span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"></span><br><span class="line"><span class="string">"stop"</span>)&#123;</span><br><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> node01 node02 node03 </span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  ssh <span class="variable">$host</span> <span class="string">"source /etc/profile; nohup /kfly/install/kafka/bin/kafka-server-stop.sh &gt;/dev/null  2&gt;&amp;1 &amp;"</span>   </span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"<span class="variable">$host</span> kafka is stopping..."</span>  </span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>
<h3 id="10-3-kafka监控工具的安装"><a href="#10-3-kafka监控工具的安装" class="headerlink" title="10.3 kafka监控工具的安装"></a>10.3 kafka监控工具的安装</h3><h4 id="10-3-1-Kafka-Manager"><a href="#10-3-1-Kafka-Manager" class="headerlink" title="10.3.1. Kafka Manager"></a>10.3.1. Kafka Manager</h4><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kafkaManager它是由雅虎开源的可以监控整个kafka集群相关信息的一个工具。</span><br><span class="line">（<span class="number">1</span>）可以管理几个不同的集群</span><br><span class="line">（<span class="number">2</span>）监控集群的状态(topics, brokers, 副本分布, 分区分布)</span><br><span class="line">（<span class="number">3</span>）创建topic、修改topic相关配置</span><br></pre></td></tr></table></figure>
<ul>
<li><p><a href="https://github.com/yahoo/kafka-manager/releases" target="_blank" rel="noopener">点击下载 https://github.com/yahoo/kafka-manager/releases</a></p>
</li>
<li><p>vim application.conf</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">修改kafka-manager.zkhosts的值，指定kafka集群地址</span></span><br><span class="line">kafka-manager.zkhosts="node01:2181,node02:2181,node03:2181"</span><br></pre></td></tr></table></figure>
</li>
<li><p>4、启动kafka-manager</p>
<ul>
<li>启动zk集群，kafka集群，再使用root用户启动kafka-manager服务。</li>
<li>bin/kafka-manager 默认的端口是9000，可通过 -Dhttp.port，指定端口</li>
<li>-Dconfig.file=conf/application.conf指定配置文件</li>
</ul>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/kafka-manager -Dconfig.<span class="attribute">file</span>=conf/application.conf -Dhttp.<span class="attribute">port</span>=8080 &amp;</span><br></pre></td></tr></table></figure>
</li>
<li><p>5.2. KafkaOffsetMonitor</p>
</li>
</ul>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">该监控是基于一个<span class="selector-tag">jar</span>包的形式运行，部署较为方便。只有监控功能，使用起来也较为安全</span><br><span class="line"></span><br><span class="line">(<span class="number">1</span>)消费者组列表</span><br><span class="line">(<span class="number">2</span>)查看<span class="selector-tag">topic</span>的历史消费信息.</span><br><span class="line">(<span class="number">3</span>)每个<span class="selector-tag">topic</span>的所有<span class="selector-tag">parition</span>列表(topic,pid,offset,logSize,lag,owner)</span><br><span class="line">(<span class="number">4</span>)对<span class="selector-tag">consumer</span>消费情况进行监控,并能列出每个<span class="selector-tag">consumer</span> <span class="selector-tag">offset</span>,滞后数据。</span><br></pre></td></tr></table></figure>
<ul>
<li><p>1、下载安装包 <a href="https://github.com/quantifind/KafkaOffsetMonitor/tags" target="_blank" rel="noopener">下载</a></p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">KafkaOffsetMonitor-assembly-0</span><span class="selector-class">.2</span><span class="selector-class">.0</span><span class="selector-class">.jar</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>2、在服务器上新建一个目录kafka_moitor，把jar包上传到该目录中</p>
</li>
<li><p>3、在kafka_moitor目录下新建一个脚本</p>
<ul>
<li>vim start_kafka_web.sh</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/sh</span></span><br><span class="line">java -cp KafkaOffsetMonitor-assembly-0.2.0.jar com.quantifind.kafka.offsetapp.OffsetGetterWeb --zk node01:2181,node02:2181,node03:2181 --port 8089 --refresh 10.seconds --retain 1.days</span><br></pre></td></tr></table></figure>
</li>
<li><p>4、启动脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup sh start_kafka_web.sh &amp;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="10-3-2-Kafka-Eagle"><a href="#10-3-2-Kafka-Eagle" class="headerlink" title="10.3.2 Kafka Eagle"></a>10.3.2 Kafka Eagle</h4><ul>
<li><p>1、下载Kafka Eagle安装包</p>
<ul>
<li><a href="http://download.smartloli.org/" target="_blank" rel="noopener">http://download.smartloli.org/</a><ul>
<li>kafka-eagle-bin-1.2.3.tar.gz</li>
</ul>
</li>
</ul>
</li>
<li><p>2、解压 </p>
<ul>
<li>tar -zxvf kafka-eagle-bin-1.2.3.tar.gz -C /kkb/install</li>
<li>解压之后进入到kafka-eagle-bin-1.2.3目录中<ul>
<li>得到kafka-eagle-web-1.2.3-bin.tar.gz</li>
<li>然后解压  tar -zxvf kafka-eagle-web-1.2.3-bin.tar.gz</li>
<li>重命名  mv kafka-eagle-web-1.2.3  kafka-eagle-web</li>
</ul>
</li>
</ul>
</li>
<li><p>3、修改配置文件</p>
<ul>
<li><p>进入到conf目录</p>
<ul>
<li>修改system-config.properties</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 填上你的kafka集群信息</span><br><span class="line">kafka.eagle.zk.cluster.alias=cluster1</span><br><span class="line">cluster1.zk.list=node01:2181,node02:2181,node03:2181</span><br><span class="line"></span><br><span class="line"># kafka eagle页面访问端口</span><br><span class="line">kafka.eagle.webui.port=8048</span><br><span class="line"></span><br><span class="line"># kafka sasl authenticate</span><br><span class="line">kafka.eagle.sasl.enable=false</span><br><span class="line">kafka.eagle.sasl.protocol=SASL_PLAINTEXT</span><br><span class="line">kafka.eagle.sasl.mechanism=PLAIN</span><br><span class="line">kafka.eagle.sasl.client=/kfly/install/kafka-eagle-bin-1.2.3/kafka-eagle-web/conf/kafka_client_jaas.conf</span><br><span class="line"></span><br><span class="line">#  添加刚刚导入的ke数据库配置，我这里使用的是mysql</span><br><span class="line">kafka.eagle.driver=com.mysql.jdbc.Driver</span><br><span class="line">kafka.eagle.url=jdbc:mysql://node02:3306/ke?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull</span><br><span class="line">kafka.eagle.username=root</span><br><span class="line">kafka.eagle.password=123456</span><br></pre></td></tr></table></figure>
<ul>
<li>4、配置环境变量</li>
<li>vi /etc/profile</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export KE_HOME=/kfly/install/kafka-eagle-web</span><br><span class="line">export PATH=$PATH:$KE_HOME/bin</span><br></pre></td></tr></table></figure>
<ul>
<li>5、启动kafka-eagle /访问</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sh bin/ke.sh start</span><br><span class="line"><span class="meta">#</span><span class="bash"> 访问 `http://node01:8048/ke`</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 用户名：admin password：123456</span></span><br></pre></td></tr></table></figure>
        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a href="https://blog.sev7e0.site/">大数据施工现场</a></span>
        <span>/</span>
        
        <span><a href="https://wangchujiang.com/linux-command/">linux命令行工具</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script src="/js/gitment.js"></script>
<script>
    var gitment = new Gitment({
        id: '大数据环境搭建',
        owner: 'orchid-ding',
        repo: 'kfly-blog-comment',
        oauth: {
            client_id: '0770cdab79393197b6f5',
            client_secret: '376fb6c7bcd5047718b356712f596b89e490360c',
        },
    })
    gitment.render('comment-container')
</script>




</html>
