<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="天行健、君子以自强不息；地势坤，君子以厚德载物。">
    <meta name="keyword"  content="兰草">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        大数据面试试题汇总 - Kaffir Lily的博客 | Kaffir Lily&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_1598291_q3el2wqimj.css" type="text/css">
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>kfly</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont iconhome"></i>
                    <span>主页</span>
                </a>
            </li>
 	   <li >
                <a href="/"></a>
                    <i class="iconfont iconzhuanti"></i>
                    <span>专题</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>简历</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-Java基础篇"><span class="toc-text">1. Java基础篇</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-语言基础"><span class="toc-text">1.1 语言基础</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-锁"><span class="toc-text">1.2 锁</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-多线程"><span class="toc-text">1.3 多线程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-并发容器（J-U-C）"><span class="toc-text">1.4 并发容器（J.U.C）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-Java进阶篇"><span class="toc-text">2. Java进阶篇</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-JVM"><span class="toc-text">2.1 JVM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-NIO"><span class="toc-text">2.2 NIO</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-RPC"><span class="toc-text">2.3 RPC</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-Linux-基础"><span class="toc-text">3. Linux 基础</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-分布式理论篇"><span class="toc-text">4.分布式理论篇</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-Netty"><span class="toc-text">5. Netty</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6-Hadoop"><span class="toc-text">6. Hadoop</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#6-1-MapReduce"><span class="toc-text">6.1 MapReduce</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-2-HDFS"><span class="toc-text">6.2 HDFS</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-3-Yarn："><span class="toc-text">6.3 Yarn：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#7-Hive"><span class="toc-text">7. Hive</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#8-Hbase"><span class="toc-text">8. Hbase</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#9-Scala"><span class="toc-text">9. Scala</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#10-Spark"><span class="toc-text">10. Spark</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#10-1-Spark-Core"><span class="toc-text">10.1 Spark Core</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-2-Spark-Streaming："><span class="toc-text">10.2 Spark Streaming：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-3-Spark-SQL："><span class="toc-text">10.3 Spark SQL：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-4-Structured-Streaming"><span class="toc-text">10.4 Structured Streaming</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-5-Spark-Mlib："><span class="toc-text">10.5 Spark Mlib：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#11-Kafka"><span class="toc-text">11. Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#11-1-如何提升生产者的吞吐量？"><span class="toc-text">11.1 如何提升生产者的吞吐量？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-2-如何保证Kafka内部数据不丢失？"><span class="toc-text">11.2 如何保证Kafka内部数据不丢失？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-3-积压了百万消息如何处理？"><span class="toc-text">11.3 积压了百万消息如何处理？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-4-生产者遇到了异常如何处理？"><span class="toc-text">11.4 生产者遇到了异常如何处理？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-5-说一下Kafka的HW，LEO的更新机制"><span class="toc-text">11.5 说一下Kafka的HW，LEO的更新机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-6-Zookeeper对于Kafka的作用是什么？"><span class="toc-text">11.6 Zookeeper对于Kafka的作用是什么？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-7-讲一讲Kafka的ack的三种机制"><span class="toc-text">11.7 讲一讲Kafka的ack的三种机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-8-Kafka如何不重复消费数据"><span class="toc-text">11.8 Kafka如何不重复消费数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-9-如何保证同一分区一定有序"><span class="toc-text">11.9 如何保证同一分区一定有序</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#12-Flink"><span class="toc-text">12. Flink</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#13-大数据算法"><span class="toc-text">13. 大数据算法</span></a></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        大数据面试试题汇总
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2019-12-08 16:35:48</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#bigdata" title="bigdata">bigdata</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#meet" title="meet">meet</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <h1 id="1-Java基础篇"><a href="#1-Java基础篇" class="headerlink" title="1. Java基础篇"></a>1. Java基础篇</h1><ul>
<li>语言基础</li>
<li>锁</li>
<li>多线程</li>
<li>并发包中常用的并发容器（JUC）</li>
</ul>
<h2 id="1-1-语言基础"><a href="#1-1-语言基础" class="headerlink" title="1.1 语言基础"></a>1.1 语言基础</h2><ul>
<li><p>Java面向对象</p>
</li>
<li><p>Java语言的三大特性： 封装、继承、多态</p>
</li>
<li><p>Java语言的数据类型</p>
<ul>
<li><p>内置数据类型：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. 在被创建时，在栈上给其划分一块内存，将数值直接存储在栈上。</span></span><br><span class="line"><span class="keyword">int</span> <span class="keyword">byte</span> <span class="keyword">short</span> <span class="keyword">float</span> <span class="keyword">double</span> <span class="keyword">char</span> <span class="keyword">boolean</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>引用数据类型</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 2. 在被创建时，首先要在栈上给其引用（句柄）分配一块内存，而对象的具体信息都存储在堆内存上，然后由栈上面的引用指向堆中对象的地址。</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">interface</span> <span class="title">array</span> <span class="title">enum</span> @<span class="title">interface</span></span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Java的自动类型转换，强制类型转换</p>
</li>
<li><p>String的不可变性、虚拟机的常量池、String.intern() 的底层原理</p>
<ul>
<li><p>String.intern(): </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// String.intern();</span></span><br><span class="line"><span class="comment">// return 一个字符串，内容与此字符串相同，但一定取自具有唯一字符串的池。</span></span><br><span class="line">String a = <span class="string">"a"</span>;</span><br><span class="line">String b = <span class="string">"b"</span>;</span><br><span class="line">String ab = <span class="string">"ab"</span>;</span><br><span class="line">String ab0 = <span class="string">"a"</span> + <span class="string">"b"</span>;</span><br><span class="line">String ab1 = a + b;</span><br><span class="line">String ab2 = <span class="keyword">new</span> String(<span class="string">"ab"</span>);</span><br><span class="line">String ab3 = <span class="keyword">new</span> String(<span class="string">"a"</span>) + <span class="keyword">new</span> String(<span class="string">"b"</span>);</span><br><span class="line"><span class="comment">// 以下结果为。true</span></span><br><span class="line">System.out.println(ab == ab0);</span><br><span class="line">System.out.println(ab == ab1.intern());</span><br><span class="line">System.out.println(ab == ab2.intern());</span><br><span class="line">System.out.println(ab == ab3.intern());</span><br><span class="line">System.out.println(ab2.intern() == ab3.intern());</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>Java 语言中的关键字：<strong>final</strong>、<strong>static</strong>、<strong>transient</strong>、<strong>instanceof</strong>、<strong>volatile</strong>、<strong>synchronized</strong>的底层原理</p>
<ul>
<li><a href="https://blog.csdn.net/Tang_zhihong/article/details/88744343" target="_blank" rel="noopener">查看</a></li>
</ul>
</li>
<li><p>Java 中常用的集合类的实现原理： ArrayList/LinkedList/Vector、SynchronizedList/Vector、HashMap/HashTable/ConcurrentHashMap 互相的区别以及底层实现原理</p>
<ul>
<li><a href="https://crossoverjie.top/JCSprout/#/collections/ArrayList" target="_blank" rel="noopener">查看</a></li>
</ul>
</li>
<li><p>动态代理的实现方式 </p>
<ul>
<li>jdk动态代理：interface 、 InvocationHandler</li>
<li>CGLIB： MethodInterceptor</li>
</ul>
</li>
</ul>
<h2 id="1-2-锁"><a href="#1-2-锁" class="headerlink" title="1.2 锁"></a>1.2 锁</h2><ul>
<li>CAS、乐观锁与悲观锁、数据库相关锁机制、分布式锁、偏向锁、轻量级锁、重量级锁、monitor</li>
<li>锁优化、锁消除、锁粗化、自旋锁、可重入锁、阻塞锁、死锁</li>
<li>死锁的原因</li>
<li>死锁的解决办法</li>
<li>CountDownLatch、CyclicBarrier 和 Semaphore 三个类的使用和原理</li>
</ul>
<h2 id="1-3-多线程"><a href="#1-3-多线程" class="headerlink" title="1.3 多线程"></a>1.3 多线程</h2><ul>
<li>并发和并行的区别 <a href="https://blog.csdn.net/weixin_30363263/article/details/80732156" target="_blank" rel="noopener">点</a></li>
<li>线程与进程的区别   <a href="https://blog.csdn.net/feiBlog/article/details/85397287" target="_blank" rel="noopener">点</a></li>
<li>线程的实现、线程的状态、优先级、线程调度、创建线程的多种方式、守护线程 </li>
<li>自己设计线程池、submit() 和 execute()、线程池原理</li>
<li>为什么不允许使用 Executors 创建线程池 <a href="https://blog.csdn.net/fly910905/article/details/81584675" target="_blank" rel="noopener">点</a></li>
<li>死锁、死锁如何排查、线程安全和内存模型的关系</li>
<li>ThreadLocal 变量</li>
<li>Executor 创建线程池的几种方式：<ul>
<li>newFixedThreadPool(int nThreads)</li>
<li>newCachedThreadPool()</li>
<li>newSingleThreadExecutor()</li>
<li>newScheduledThreadPool(int corePoolSize)</li>
<li>newSingleThreadExecutor()</li>
</ul>
</li>
<li>ThreadPoolExecutor 创建线程池、拒绝策略</li>
<li>线程池关闭的方式</li>
</ul>
<h2 id="1-4-并发容器（J-U-C）"><a href="#1-4-并发容器（J-U-C）" class="headerlink" title="1.4 并发容器（J.U.C）"></a>1.4 并发容器（J.U.C）</h2><ul>
<li>JUC 包中 List 接口的实现类：CopyOnWriteArrayList</li>
<li>JUC 包中 Set 接口的实现类：CopyOnWriteArraySet、ConcurrentSkipListSet</li>
<li>JUC 包中 Map 接口的实现类：ConcurrentHashMap、ConcurrentSkipListMap</li>
<li>JUC包中Queue接口的实现类：ConcurrentLinkedQueue、ConcurrentLinkedDeque、ArrayBlockingQueue、LinkedBlockingQueue、LinkedBlockingDeque</li>
</ul>
<h1 id="2-Java进阶篇"><a href="#2-Java进阶篇" class="headerlink" title="2. Java进阶篇"></a>2. Java进阶篇</h1><h2 id="2-1-JVM"><a href="#2-1-JVM" class="headerlink" title="2.1 JVM"></a>2.1 JVM</h2><ul>
<li><p>JVM内存结构</p>
<figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> 文件格式、运行时数据区：堆、栈、方法区、直接内存、运行时常量池</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>堆和栈区别</p>
<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Java </span>中的对象一定在堆上分配吗？</span><br></pre></td></tr></table></figure>
</li>
<li><p>Java 内存模型</p>
<figure class="highlight d"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">计算机内存模型、缓存一致性、MESI 协议、可见性、原子性、顺序性、happens-before、内存屏障、<span class="keyword">synchronized</span>、<span class="keyword">volatile</span>、<span class="keyword">final</span>、锁</span><br></pre></td></tr></table></figure>
</li>
<li><p>垃圾回收</p>
<figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GC 算法：标记清除、引用计数、复制、标记压缩、分代回收、增量式回收、GC 参数、对象存活的判定、垃圾收集器（CMS、G1、ZGC、<span class="built_in">Epsilon</span>）</span><br></pre></td></tr></table></figure>
</li>
<li><p>JVM 参数及调优</p>
  <figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">-Xmx</span>、<span class="selector-tag">-Xmn</span>、<span class="selector-tag">-Xms</span>、<span class="selector-tag">Xss</span>、<span class="selector-tag">-XX</span><span class="selector-pseudo">:SurvivorRatio</span>、<span class="selector-tag">-XX</span><span class="selector-pseudo">:PermSize</span>、<span class="selector-tag">-XX</span><span class="selector-pseudo">:MaxPermSize</span>、<span class="selector-tag">-XX</span><span class="selector-pseudo">:MaxTenuringThreshold</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Java 对象模型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oop-klass、对象头</span><br></pre></td></tr></table></figure>
</li>
<li><p>HotSpot</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">即时编译器、编译优化</span><br></pre></td></tr></table></figure>
</li>
<li><p>虚拟机性能监控与故障处理工具</p>
<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">jps、jstack、jmap、jstat、jconsole、 </span><span class="keyword">jinfo、 </span><span class="keyword">jhat、javap、btrace、TProfiler、Arthas</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>类加载机制</p>
<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classLoader、类加载过程、双亲委派（破坏双亲委派）、模块化（<span class="keyword">jboss </span>modules、osgi、<span class="keyword">jigsaw）</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="2-2-NIO"><a href="#2-2-NIO" class="headerlink" title="2.2 NIO"></a>2.2 NIO</h2><ul>
<li>用户空间以及内核空间</li>
<li>Linux 网络 I/O 模型：阻塞 I/O (Blocking I/O)、非阻塞 I/O (Non-Blocking I/O)、I/O 复用（I/O Multiplexing)、信号驱动的 I/O (Signal Driven I/O)、异步 I/O</li>
<li>灵拷贝（ZeroCopy）</li>
<li>BIO 与 NIO 对比</li>
<li>缓冲区 Buffer</li>
<li>通道 Channel</li>
<li>反应堆</li>
<li>选择器</li>
<li>AIO</li>
</ul>
<h2 id="2-3-RPC"><a href="#2-3-RPC" class="headerlink" title="2.3 RPC"></a>2.3 RPC</h2><ul>
<li>RPC 的原理编程模型</li>
<li>常用的 RPC 框架：Thrift、Dubbo、SpringCloud</li>
<li>RPC 的应用场景和与消息队列的差别</li>
<li>RPC 核心技术点：服务暴露、远程代理对象、通信、序列化</li>
</ul>
<h1 id="3-Linux-基础"><a href="#3-Linux-基础" class="headerlink" title="3. Linux 基础"></a>3. Linux 基础</h1><ul>
<li>了解 Linux 的常用命令</li>
<li>远程登录</li>
<li>上传下载</li>
<li>系统目录</li>
<li>文件和目录操作</li>
<li>Linux 下的权限体系</li>
<li>压缩和打包</li>
<li>用户和组</li>
<li>Shell 脚本的编写</li>
<li>管道操作</li>
</ul>
<h1 id="4-分布式理论篇"><a href="#4-分布式理论篇" class="headerlink" title="4.分布式理论篇"></a>4.分布式理论篇</h1><ul>
<li>分布式中的一些基本概念：集群（Cluster）、负载均衡（Load Balancer）等</li>
<li>分布式系统理论基础： 一致性、2PC 和 3PC</li>
<li>分布式系统理论基础：CAP</li>
<li>分布式系统理论基础：时间、时钟和事件顺序</li>
<li>分布式系统理论进阶：Paxos</li>
<li>分布式系统理论进阶：Raft、Zab</li>
<li>分布式系统理论进阶：选举、多数派和租约</li>
<li>分布式锁的解决方案</li>
<li>分布式事务的解决方案</li>
<li>分布式 ID 生成器解决方案</li>
</ul>
<h1 id="5-Netty"><a href="#5-Netty" class="headerlink" title="5. Netty"></a>5. Netty</h1><ul>
<li><p>Netty 三层网络架构：Reactor 通信调度层、职责链 PipeLine、业务逻辑处理层</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>. Reactor通信调度层: 该层的主要职责就是监听网络的连接和读写操作，负责将网络层的数据读取到内存缓冲区中，然后触发各种网络事件，例如连接创建、连接激活、读事件、写事件等，将这些事件触发到Pipeline中，再由Pipeline充当的职责链来进行后续的处理</span><br><span class="line"><span class="number">2</span>. 职责链Pipeline层。负责事件在职责链中有序的向前（后）传播，同时负责动态的编排职责链。Pipeline可以选择监听和处理自己关心的事件</span><br><span class="line"><span class="number">3</span>. 业务逻辑处理层，一般可分为两类：</span><br><span class="line">		<span class="selector-tag">a</span>. 纯粹的业务逻辑处理，例如日志、订单处理。</span><br><span class="line">		<span class="selector-tag">b</span>. 应用层协议管理，例如HTTP(S)协议、FTP协议等。</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>Netty 的线程调度模型</p>
</li>
<li><p>序列化方式</p>
</li>
<li><p>链路有效性检测</p>
</li>
<li><p>流量整形</p>
</li>
<li><p>优雅停机策略</p>
</li>
<li><p>Netty 对 SSL/TLS 的支持</p>
</li>
<li><p>Netty 的源码质量极高，推荐对部分的核心代码进行阅读：</p>
</li>
<li><p>Netty 的 Buffer</p>
</li>
<li><p>Netty 的 Reactor</p>
</li>
<li><p>Netty 的 Pipeline</p>
</li>
<li><p>Netty 的 Handler 综述</p>
</li>
<li><p>Netty 的 ChannelHandler</p>
</li>
<li><p>Netty 的 LoggingHandler</p>
</li>
<li><p>Netty 的 TimeoutHandler</p>
</li>
<li><p>Netty 的 CodecHandler</p>
</li>
<li><p>Netty 的 MessageToByteEncoder</p>
</li>
</ul>
<h1 id="6-Hadoop"><a href="#6-Hadoop" class="headerlink" title="6. Hadoop"></a>6. Hadoop</h1><h2 id="6-1-MapReduce"><a href="#6-1-MapReduce" class="headerlink" title="6.1 MapReduce"></a>6.1 MapReduce</h2><ul>
<li>掌握 MapReduce 的工作原理</li>
<li>能用 MapReduce 手写代码实现简单的 WordCount 或者 TopN 算法</li>
<li>掌握 MapReduce Combiner 和 Partitioner的作用</li>
<li>熟悉 Hadoop 集群的搭建过程，并且能解决常见的错误</li>
<li>熟悉 Hadoop 集群的扩容过程和常见的坑</li>
<li>如何解决 MapReduce 的数据倾斜</li>
<li>Shuffle 原理和减少 Shuffle 的方法</li>
</ul>
<h2 id="6-2-HDFS"><a href="#6-2-HDFS" class="headerlink" title="6.2 HDFS"></a>6.2 HDFS</h2><ul>
<li>十分熟悉 HDFS 的架构图和读写流程</li>
<li>十分熟悉 HDFS 的配置</li>
<li>熟悉 DataNode 和 NameNode 的作用</li>
<li>NameNode 的 HA 搭建和配置，Fsimage 和 EditJournal 的作用的场景</li>
<li>HDFS 操作文件的常用命令</li>
<li>HDFS 的安全模式</li>
</ul>
<h2 id="6-3-Yarn："><a href="#6-3-Yarn：" class="headerlink" title="6.3 Yarn："></a>6.3 Yarn：</h2><ul>
<li>Yarn 的产生背景和架构</li>
<li>Yarn 中的角色划分和各自的作用</li>
<li>Yarn 的配置和常用的资源调度策略</li>
<li>Yarn 进行一次任务资源调度的过程</li>
</ul>
<h1 id="7-Hive"><a href="#7-Hive" class="headerlink" title="7. Hive"></a>7. Hive</h1><blockquote>
<p>Hive 是一个数据仓库基础工具，在 Hadoop 中用来处理结构化数据。它架构在 Hadoop 之上，总归为大数据，并使得查询和分析方便。Hive 是应用最广泛的 OLAP 框架。Hive SQL 也是我们进行 SQL 开发用的最多的框架。</p>
</blockquote>
<ul>
<li>HiveSQL 的原理：我们都知道 HiveSQL 会被翻译成 MapReduce 任务执行，那么一条 SQL 是如何翻译成 MapReduce 的？</li>
<li>Hive 和普通关系型数据库有什么区别？</li>
<li>Hive 支持哪些数据格式</li>
<li>Hive 在底层是如何存储 NULL 的</li>
<li>HiveSQL 支持的几种排序各代表什么意思（Sort By/Order By/Cluster By/Distrbute By）</li>
<li>Hive 的动态分区</li>
<li>HQL 和 SQL 有哪些常见的区别</li>
<li>Hive 中的内部表和外部表的区别</li>
<li>Hive 表进行关联查询如何解决长尾和数据倾斜问题</li>
<li>HiveSQL 的优化（系统参数调整、SQL 语句优化）</li>
</ul>
<h1 id="8-Hbase"><a href="#8-Hbase" class="headerlink" title="8. Hbase"></a>8. Hbase</h1><blockquote>
<p>HBase 本质上是一个数据模型，类似于谷歌的大表设计，可以提供快速随机访问海量结构化数据。它利用了 Hadoop 的文件系统（HDFS）提供的容错能力。</p>
<p>它是 Hadoop 的生态系统，提供对数据的随机实时读/写访问，是 Hadoop 文件系统的一部分。</p>
<p>我们可以直接或通过 HBase 的存储 HDFS 数据。使用 HBase 在 HDFS 读取消费/随机访问数据。 HBase 在 Hadoop 的文件系统之上，并提供了读写访问。</p>
<p>HBase 是一个面向列的数据库，在表中它由行排序。表模式定义只能列族，也就是键值对。一个表有多个列族以及每一个列族可以有任意数量的列。后续列的值连续地存储在磁盘上。表中的每个单元格值都具有时间戳。总之，在一个 HBase：表是行的集合、行是列族的集合、列族是列的集合、列是键值对的集合。</p>
</blockquote>
<ul>
<li>Hbase 的架构和原理  </li>
<li>Hbase 的读写流程</li>
<li>Hbase 有没有并发问题？Hbase 如何实现自己的 MVVC 的？</li>
<li>Hbase 中几个重要的概念：HMaster、RegionServer、WAL 机制、MemStore</li>
<li>Hbase 在进行表设计过程中如何进行列族和 RowKey 的设计</li>
<li>Hbase 的数据热点问题发现和解决办法</li>
<li>提高 Hbase 的读写性能的通用做法</li>
<li>HBase 中 RowFilter 和 BloomFilter 的原理</li>
<li>Hbase API 中常见的比较器</li>
<li>Hbase 的预分区</li>
<li>Hbase 的 Compaction</li>
<li>Hbase 集群中 HRegionServer 宕机如何解决</li>
</ul>
<h1 id="9-Scala"><a href="#9-Scala" class="headerlink" title="9. Scala"></a>9. Scala</h1><h1 id="10-Spark"><a href="#10-Spark" class="headerlink" title="10. Spark"></a>10. Spark</h1><blockquote>
<p>Spark 是专门为大数据处理设计的通用计算引擎，是一个实现快速通用的集群计算平台。它是由加州大学伯克利分校 AMP 实验室开发的通用内存并行计算框架，用来构建大型的、低延迟的数据分析应用程序。它扩展了广泛使用的 MapReduce 计算模型。高效的支撑更多计算模式，包括交互式查询和流处理。Spark 的一个主要特点是能够在内存中进行计算，即使依赖磁盘进行复杂的运算，Spark 依然比 MapReduce 更加高效。</p>
<p>Spark 生态包含了：Spark Core、Spark Streaming、Spark SQL、Structured Streming 和机器学习相关的库等。</p>
</blockquote>
<h2 id="10-1-Spark-Core"><a href="#10-1-Spark-Core" class="headerlink" title="10.1 Spark Core"></a>10.1 Spark Core</h2><ul>
<li>Spark的集群搭建和集群架构（Spark 集群中的角色）👌</li>
<li>Spark Cluster 和 Client 模式的区别</li>
<li>Spark 的弹性分布式数据集 RDD 👌 <ul>
<li>spark 的rdd是什么，rdd的特性是什么，以及它的五大属性 👌</li>
<li>常见的算子操作map/mapPartitions 和 foreach 和 foreachPartitions是什么 👌</li>
</ul>
</li>
<li>Spark DAG（有向无环图）</li>
<li>掌握 Spark RDD 编程的算子 API（Transformation 和 Action 算子）</li>
<li>RDD 的依赖关系，什么是宽依赖和窄依赖</li>
<li>RDD 的血缘机制</li>
<li>Spark 核心的运算机制</li>
<li>Spark 的任务调度和资源调度</li>
<li>Spark 的 CheckPoint 和容错</li>
<li>Spark 的通信机制</li>
<li>Spark Shuffle 原理和过程</li>
</ul>
<h2 id="10-2-Spark-Streaming："><a href="#10-2-Spark-Streaming：" class="headerlink" title="10.2 Spark Streaming："></a>10.2 Spark Streaming：</h2><ul>
<li>原理剖析（源码级别）和运行机制</li>
<li>Spark Dstream 及其 API 操作</li>
<li>Spark Streaming 消费 Kafka 的两种方式</li>
<li>Spark 消费 Kafka 消息的 Offset 处理</li>
<li>数据倾斜的处理方案</li>
<li>Spark Streaming 的算子调优</li>
<li>并行度和广播变量</li>
<li>Shuffle 调优</li>
</ul>
<h2 id="10-3-Spark-SQL："><a href="#10-3-Spark-SQL：" class="headerlink" title="10.3 Spark SQL："></a>10.3 Spark SQL：</h2><ul>
<li>Spark SQL 的原理和运行机制</li>
<li>Catalyst 的整体架构</li>
<li><p>Spark SQL 的 DataFrame</p>
</li>
<li><p>Spark SQL 的优化策略：内存列式存储和内存缓存表、列存储压缩、逻辑查询优化、Join 的优化</p>
</li>
</ul>
<h2 id="10-4-Structured-Streaming"><a href="#10-4-Structured-Streaming" class="headerlink" title="10.4 Structured Streaming"></a>10.4 Structured Streaming</h2><blockquote>
<p>Spark 从 2.3.0 版本开始支持 Structured Streaming，它是一个建立在 Spark SQL 引擎之上可扩展且容错的流处理引擎，统一了批处理和流处理。正是 Structured Streaming 的加入使得 Spark 在统一流、批处理方面能和 Flink 分庭抗礼。</p>
</blockquote>
<ul>
<li>Structured Streaming 的模型</li>
<li>Structured Streaming 的结果输出模式</li>
<li>事件时间（Event-time）和延迟数据（Late Data）</li>
<li>窗口操作</li>
<li>水印</li>
<li>容错和数据恢复</li>
</ul>
<h2 id="10-5-Spark-Mlib："><a href="#10-5-Spark-Mlib：" class="headerlink" title="10.5 Spark Mlib："></a>10.5 Spark Mlib：</h2><blockquote>
<p>本部分是 Spark 对机器学习支持的部分，我们学有余力的同学可以了解一下 Spark 对常用的分类、回归、聚类、协同过滤、降维以及底层的优化原语等算法和工具。可以尝试自己使用 Spark Mlib 做一些简单的算法应用</p>
</blockquote>
<h1 id="11-Kafka"><a href="#11-Kafka" class="headerlink" title="11. Kafka"></a>11. Kafka</h1><blockquote>
<p>Kafka 是最初由 Linkedin 公司开发，是一个分布式、支持分区的（partition）、多副本的（replica）的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于 Hadoop 的批处理系统、低延迟的实时系统、Spark 流式处理引擎，Nginx 日志、访问日志，消息服务等等，用 Scala 语言编写，Linkedin 于 2010 年贡献给了 Apache 基金会并成为顶级开源项目。</p>
<p>Kafka 或者类似 Kafka 各个公司自己造的消息’轮子’已经是大数据领域消息中间件的事实标准。目前 Kafka 已经更新到了 2.x 版本，支持了类似 KafkaSQL 等功能，Kafka 不满足单纯的消息中间件，也正朝着平台化的方向演进。</p>
</blockquote>
<h4 id="11-1-如何提升生产者的吞吐量？"><a href="#11-1-如何提升生产者的吞吐量？" class="headerlink" title="11.1 如何提升生产者的吞吐量？"></a>11.1 如何提升生产者的吞吐量？</h4><p>1）buffer.memory：设置发送消息的缓冲区，默认值是33554432，就是32MB<br>如果发送消息出去的速度小于写入消息进去的速度，就会导致缓冲区写满，此时生产消息就会阻塞住，所以说这里就应该多做一些压测，尽可能保证说这块缓冲区不会被写满导致生产行为被阻塞住</p>
<pre><code>  Long startTime=System.currentTime();
  producer.send(record, new Callback() {
  @Override
    public void onCompletion(RecordMetadata metadata, Exception exception) {
        if(exception == null) {
            // 消息发送成功
            System.out.println(&quot;消息发送成功&quot;);  
        } else {
            // 消息发送失败，需要重新发送
        }
    }
});
Long endTime=System.currentTime();
If(endTime - startTime &gt; 100){//说明内存被压满了
 说明有问题
 }        
</code></pre><p>2）compression.type，默认是none，不压缩，但是也可以使用lz4压缩，效率还是不错的，压缩之后可以减小数据量，提升吞吐量，但是会加大producer端的cpu开销。<br>3）batch.size，设置meigebatch的大小，如果batch太小，会导致频繁网络请求，吞吐量下降；如果batch太大，会导致一条消息需要等待很久才能被发送出去，而且会让内存缓冲区有很大压力，过多数据缓冲在内存里<br>默认值是：16384，就是16kb，也就是一个batch满了16kb就发送出去，一般在实际生产环境，这个batch的值可以增大一些来提升吞吐量，可以自己压测一下。<br>4）linger.ms，这个值默认是0，意思就是消息必须立即被发送，但是这是不对的，一般设置一个100毫秒之类的，这样的话就是说，这个消息被发送出去后进入一个batch，如果100毫秒内，这个batch满了16kb，自然就会发送出去。但是如果100毫秒内，batch没满，那么也必须把消息发送出去了，不能让消息的发送延迟时间太长，也避免给内存造成过大的一个压力。</p>
<h4 id="11-2-如何保证Kafka内部数据不丢失？"><a href="#11-2-如何保证Kafka内部数据不丢失？" class="headerlink" title="11.2 如何保证Kafka内部数据不丢失？"></a>11.2 如何保证Kafka内部数据不丢失？</h4><p>如果要回答这个问题的话，要从三个角度去回答：Producer，consumer，broker。</p>
<p>==<strong>producer</strong>==</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">acks参数：</span><br><span class="line">acks = <span class="number">0</span></span><br><span class="line">	生产者发送消息之后 不需要等待服务端的任何响应，它不管消息有没有发送成功，如果发送过程中遇到了异常，导致broker端没有收到消息，消息也就丢失了。实际上它只是把消息发送到了socketBuffer(缓存)中，而socketBuffer什么时候被提交到broker端并不关心，它不担保broker端是否收到了消息，但是这样的配置对retry是不起作用的，因为producer端都不知道是否发生了错误，而且对于offset的获取永远都是<span class="number">-1</span>，因为broker端可能还没有开始写数据。这样不保险的操作为什么还有这样的配置？kafka对于收集海量数据，如果在收集某一项日志时是允许数据量有一定丢失的话，是可以用这种配置来收集日志。</span><br><span class="line">acks = <span class="number">1</span>(默认值)</span><br><span class="line">	生产者发送消息之后，只要分区的leader副本成功写入消息，那么它就会收到来自服务端的成功响应。其实就是消息只发给了leader leader收到消息后会返回ack到producer端。如果消息无法写入leader时(选举、宕机等情况时)，生产都会收到一个错误的响应，为了避免消息丢失，生产者可以选择重发消息，如果消息成功写入，在被其它副本同步数据时leader　　崩溃,那么此条数据还是会丢失，因为新选举的leader是没有收到这条消息，ack设置为<span class="number">1</span>是消息可靠性和吞吐量折中的方案。</span><br><span class="line">acks = all (或<span class="number">-1</span>)</span><br><span class="line">	生产者在发送消息之后，需要等待ISR中所有的副本都成功写入消息之后才能够收到来自服务端的成功响应，在配置环境相同的情况下此种配置可以达到最强的可靠性。即：在发送消息时，需要leader 向fllow 同步完数据之后，也就是ISR队列中所有的broker全部保存完这条消息后，才会向ack发送消息，表示发送成功。</span><br><span class="line"></span><br><span class="line">retry参数：</span><br><span class="line">在kafka中错误分为<span class="number">2</span>种，一种是可恢复的，另一种是不可恢复的。</span><br><span class="line">　　可恢复性的错误：</span><br><span class="line">　　　　　　如遇到在leader的选举、网络的抖动等这些异常时，如果我们在这个时候配置的retries大于<span class="number">0</span>的，也就是可以进行重试操作，那么等到leader选举完成后、网络稳定后，这些异常就会消息，错误也就可以恢复，数据再次重发时就会正常发送到broker端。需要注意retries(重试)之间的时间间隔，以确保在重试时可恢复性错误都已恢复。</span><br><span class="line">　　不可恢复性的错误：</span><br><span class="line">　　　　　　如：超过了发送消息的最大值(max.request.size)时，这种错误是不可恢复的，如果不做处理，那么数据就会丢失，因此我们需要注意在发生异常时把这些消息写入到DB、缓存本地文件中等等，把这些不成功的数据记录下来，等错误修复后，再把这些数据发送到broker端。</span><br><span class="line">　　　　　　　　　　</span><br><span class="line">配置方案</span><br><span class="line"><span class="number">1.</span>高可用型</span><br><span class="line">　　配置：acks = all，retries &gt; <span class="number">0</span> retry.backoff.ms=<span class="number">100</span>(毫秒) (并根据实际情况设置retry可能恢复的间隔时间)</span><br><span class="line">　　优点：这样保证了producer端每发送一条消息都要成功，如果不成功并将消息缓存起来，等异常恢复后再次发送。</span><br><span class="line">　　缺点：这样保证了高可用，但是这会导致集群的吞吐量不是很高，因为数据发送到broker之后，leader要将数据同步到fllower上，如果网络带宽、不稳定等情况时，ack响应时间会更长</span><br><span class="line">　　</span><br><span class="line"><span class="number">2.</span>折中型</span><br><span class="line">　　配置：acks = <span class="number">1</span>  retries &gt; <span class="number">0</span> retries 时间间隔设置 (并根据实际情况设置retries可能恢复的间隔时间)</span><br><span class="line">　　优点：保证了消息的可靠性和吞吐量，是个折中的方案</span><br><span class="line">　　缺点：性能处于<span class="number">2</span>者中间</span><br><span class="line">　　</span><br><span class="line"><span class="number">3.</span>高吞吐型 </span><br><span class="line">　　配置：acks = <span class="number">0</span></span><br><span class="line">　　优点：可以相对容忍一些数据的丢失，吞吐量大，可以接收大量请求</span><br><span class="line">　　缺点：不知道发送的消息是 否成功</span><br></pre></td></tr></table></figure>
<p>==<strong>Consumer</strong>==</p>
<figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">group</span>.id:</span><br><span class="line">	consumer <span class="keyword">group</span>分组的一个id，消费者隶属的消费组名称。在kafka中只允许消息只能被某个组里面的一个consumer端消费，如果为空，则会报异常。对于一个新的consumer加入到消费时，肯定会隶属于哪个组，只有这样才能消费数据</span><br><span class="line"><span class="keyword">auto</span>.offset.reset = earliest(最早) /latest(最晚)</span><br><span class="line">	从何处开始进行消费　　当一个新加入的consumer要进行消费数据，如果这个consumer是做数据分析工作的，是需要以前的历史数据那就需要从最早的位置消费数据，如果仅仅是查看消费情况，那可以从最晚位置开始消费数据</span><br><span class="line">enable.<span class="keyword">auto</span>.commit = <span class="literal">true</span>/<span class="literal">false</span>(默认<span class="literal">true</span>)　</span><br><span class="line">	是否开启自动提交消费位移的功能,默认开启.　　当设置为<span class="literal">true</span>时，意味着由kafka的consumer端自己间隔一定的时间会自动提交offset，如果设置成了fasle，也就是由客户端(自己写代码)来提交，那就还得控制提交的时间间隔<span class="keyword">auto</span>.commit.interval.msauto.commit.interval.ms</span><br><span class="line">	当enable.<span class="keyword">auto</span>.commit设置为<span class="literal">true</span>时才生效，表示开启自动提交消费位移功能时自动提交消费位移的时间间隔。</span><br></pre></td></tr></table></figure>
<p>配置方案</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在consumer消费阶段，对<span class="built_in">offset</span>的处理，关系到是否丢失数据，是否重复消费数据，因此，我们把处理好<span class="built_in">offset</span>就可以做到exactly-once &amp;&amp; <span class="keyword">at</span>-least-once(只消费一次)数据。当enable.auto.commit=<span class="literal">true</span>时　　　　表示由kafka的consumer端自动提交<span class="built_in">offset</span>,当你在pull(拉取)<span class="number">30</span>条数据，在处理到第<span class="number">20</span>条时自动提交了<span class="built_in">offset</span>,但是在处理<span class="number">21</span>条的时候出现了异常，当你再次pull数据时，由于之前是自动提交的<span class="built_in">offset</span>，所以是从<span class="number">30</span>条之后开始拉取数据，这也就意味着<span class="number">21</span><span class="number">-30</span>条的数据发生了丢失。</span><br><span class="line"></span><br><span class="line">当enable.auto.commit=<span class="literal">false</span>时，由于上面的情况可知自动提交<span class="built_in">offset</span>时，如果处理数据失败就会发生数据丢失的情况。那我们设置成手动提交。当设置成<span class="literal">false</span>时，由于是手动提交的，可以处理一条提交一条，也可以处理一批，提交一批，由于consumer在消费数据时是按一个batch来的，当pull了<span class="number">30</span>条数据时，如果我们处理一条，提交一个<span class="built_in">offset</span>，这样会严重影响消费的能力，那就需要我们来按一批来处理，或者设置一个累加器，处理一条加<span class="number">1</span>，如果在处理数据时发生了异常，那就把当前处理失败的<span class="built_in">offset</span>进行提交(放在finally代码块中)注意一定要确保<span class="built_in">offset</span>的正确性，当下次再次消费的时候就可以从提交的<span class="built_in">offset</span>处进行再次消费。</span><br></pre></td></tr></table></figure>
<p>==<strong>Broker</strong>==</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span><span class="selector-class">.replication-factor</span> &gt;=<span class="number">2</span></span><br><span class="line">在创建topic时会通过replication-factor来创建副本的个数，它提高了kafka的高可用性，同时，它允许n-<span class="number">1</span>台broker挂掉，设置好合理的副本因子对kafka整体性能是非常有帮助的，通常是<span class="number">3</span>个，极限是<span class="number">5</span>个，如果多了也会影响开销。</span><br><span class="line"></span><br><span class="line"><span class="number">2</span><span class="selector-class">.min</span><span class="selector-class">.insync</span><span class="selector-class">.replicas</span> = <span class="number">2</span></span><br><span class="line">分区ISR队列集合中最少有多少个副本，默认值是<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="number">3</span><span class="selector-class">.unclean</span><span class="selector-class">.leander</span><span class="selector-class">.election</span><span class="selector-class">.enable</span> = false 　　　　</span><br><span class="line">是否允许从ISR队列中选举leader副本，默认值是false,如果设置成true,则可能会造成数据丢失。</span><br></pre></td></tr></table></figure>
<h4 id="11-3-积压了百万消息如何处理？"><a href="#11-3-积压了百万消息如何处理？" class="headerlink" title="11.3 积压了百万消息如何处理？"></a>11.3 积压了百万消息如何处理？</h4><p>据我了解，在使用消息队列遇到的问题中，消息积压这个问题，应该是最常遇到的问题了，并且，这个问题还不太好解决。我们都知道，消息积压的直接原因，一定是系统中的某个部分出现了性能问题，来不及处理上游发送的消息，才会导致消息积压。所以，我们先来分析下，在使用消息队列时，如何来优化代码的性能，避免出现消息积压。然后再来看看，如果你的线上系统出现了消息积压，该如何进行紧急处理，最大程度地避免消息积压对业务的影响。</p>
<ol>
<li><p>最大程度避免消息积压</p>
<p>生产者</p>
<p>​    提升吞吐量</p>
<p>消费者</p>
<p>​    扩容，扩分区</p>
<p>​    增加consumer</p>
</li>
<li><p>如何处理消息积压</p>
<p>日常系统正常运转的时候，没有积压或者只有少量积压很快就消费掉了，但是某一个时刻，突然就开始积压消息并且积压持续上涨。这种情况下需要你在短时间内找到消息积压的原因，迅速解决问题才不至于影响业务。导致突然积压的原因肯定是多种多样的，不同的系统、不同的情况有不同的原因，不能一概而论。但是，我们排查消息积压原因，是有一些相对固定而且比较有效的方法的。能导致积压突然增加，最粗粒度的原因，只有两种：要么是发送变快了，要么是消费变慢了。大部分消息队列都内置了监控的功能，只要通过监控数据，很容易确定是哪种原因。如果是单位时间发送的消息增多，比如说是赶上大促或者抢购，短时间内不太可能优化消费端的代码来提升消费性能，唯一的方法是通过扩容消费端的实例数来提升总体的消费能力。如果短时间内没有足够的服务器资源进行扩容，没办法的办法是，将系统降级，通过关闭一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。还有一种不太常见的情况，你通过监控发现，无论是发送消息的速度还是消费消息的速度和原来都没什么变化，这时候你需要检查一下你的消费端，是不是消费失败导致的一条消息反复消费这种情况比较多，这种情况也会拖慢整个系统的消费速度。如果监控到消费变慢了，你需要检查你的消费实例，分析一下是什么原因导致消费变慢。优先检查一下日志是否有大量的消费错误，如果没有错误的话，可以通过打印堆栈信息，看一下你的消费线程是不是卡在什么地方不动了，比如触发了死锁或者卡在等待某些资源上了。</p>
</li>
</ol>
<h4 id="11-4-生产者遇到了异常如何处理？"><a href="#11-4-生产者遇到了异常如何处理？" class="headerlink" title="11.4 生产者遇到了异常如何处理？"></a>11.4 生产者遇到了异常如何处理？</h4><ol>
<li>添加重试功能和重试时间间隔</li>
<li>对于重试也失败了任务进行特殊处理</li>
</ol>
<h4 id="11-5-说一下Kafka的HW，LEO的更新机制"><a href="#11-5-说一下Kafka的HW，LEO的更新机制" class="headerlink" title="11.5 说一下Kafka的HW，LEO的更新机制"></a>11.5 说一下Kafka的HW，LEO的更新机制</h4><p><img src="assets/HW和LEO的更新-8199995.png" alt="HW和LEO的更新"></p>
<h4 id="11-6-Zookeeper对于Kafka的作用是什么？"><a href="#11-6-Zookeeper对于Kafka的作用是什么？" class="headerlink" title="11.6 Zookeeper对于Kafka的作用是什么？"></a>11.6 Zookeeper对于Kafka的作用是什么？</h4><p>Kafka集群中有一个broker会被选举为Controller，负责管理集群broker的上下线，所有topic的分区副本分配和leader选举等工作。Controller的管理工作都是依赖于Zookeeper的</p>
<p>注：参考Kafka核心原理的Kafka的集群管理机制</p>
<h4 id="11-7-讲一讲Kafka的ack的三种机制"><a href="#11-7-讲一讲Kafka的ack的三种机制" class="headerlink" title="11.7 讲一讲Kafka的ack的三种机制"></a>11.7 讲一讲Kafka的ack的三种机制</h4><p>acks参数，其实是控制发送出去的消息的持久化机制的<br>1）如果acks=0，那么producer根本不管写入broker的消息到底成功没有，发送一条消息出去，立马就可以发送下一条消息，这是吞吐量最高的方式，但是可能消息都丢失了，你也不知道的，但是说实话，你如果真是那种实时数据流分析的业务和场景，就是仅仅分析一些数据报表，丢几条数据影响不大的。会让你的发送吞吐量会提升很多，你发送弄一个batch出，不需要等待人家leader写成功，直接就可以发送下一个batch了，吞吐量很大的，哪怕是偶尔丢一点点数据，实时报表，折线图，饼图。</p>
<p>2）acks=all，或者acks=-1：这个leader写入成功以后，必须等待其他ISR中的副本都写入成功，才可以返回响应说这条消息写入成功了，此时你会收到一个回调通知</p>
<p>3）acks=1：只要leader写入成功，就认为消息成功了，默认给这个其实就比较合适的，还是可能会导致数据丢失的，如果刚写入leader，leader就挂了，此时数据必然丢了，其他的follower没收到数据副本，变成leader</p>
<h4 id="11-8-Kafka如何不重复消费数据"><a href="#11-8-Kafka如何不重复消费数据" class="headerlink" title="11.8 Kafka如何不重复消费数据"></a>11.8 Kafka如何不重复消费数据</h4><ol>
<li><p>保存并查询</p>
<p>给每个消息都设置一个独一无二的key,消费的时候把这些key记录下来，然后每次消费的时候都查询一下，看这个key是否消费过，如果没有消费过才消费。</p>
</li>
<li><p>幂等</p>
<p>幂等（Idempotence） 本来是一个数学上的概念，它是这样定义的：如果一个函数 f(x) 满足：f(f(x)) = f(x)，则函数 f(x) 满足幂等性。这个概念被拓展到计算机领域，被用来描述一个操作、方法或者服务。一个幂等操作的特点是，其任意多次执行所产生的影响均与一次执行的影响相同。一个幂等的方法，使用同样的参数，对它进行多次调用和一次调用，对系统产生的影响是一样的。所以，对于幂等的方法，不用担心重复执行会对系统造成任何改变。我们举个例子来说明一下。在不考虑并发的情况下，“将账户 X 的余额设置为 100 元”，执行一次后对系统的影响是，账户 X 的余额变成了 100 元。只要提供的参数 100 元不变，那即使再执行多少次，账户 X 的余额始终都是 100 元，不会变化，这个操作就是一个幂等的操作。再举一个例子，“将账户 X 的余额加 100 元”，这个操作它就不是幂等的，每执行一次，账户余额就会增加 100 元，执行多次和执行一次对系统的影响（也就是账户的余额）是不一样的。如果我们系统消费消息的业务逻辑具备幂等性，那就不用担心消息重复的问题了，因为同一条消息，消费一次和消费多次对系统的影响是完全一样的。也就可以认为，消费多次等于消费一次。从对系统的影响结果来说：At least once + 幂等消费 = Exactly once</p>
</li>
</ol>
<p>   那么如何实现幂等操作呢？最好的方式就是，从业务逻辑设计上入手，将消费的业务逻辑设计成具备幂等性的操作。但是，不是所有的业务都能设计成天然幂等的，这里就需要一些方法和技巧来实现幂等。下面我给你介绍几种常用的设计幂等操作的方法：1. 利用数据库的唯一约束实现幂等例如我们刚刚提到的那个不具备幂等特性的转账的例子：将账户 X 的余额加 100 元。在这个例子中，我们可以通过改造业务逻辑，让它具备幂等性。首先，我们可以限定，对于每个转账单每个账户只可以执行一次变更操作，在分布式系统中，这个限制实现的方法非常多，最简单的是我们在数据库中建一张转账流水表，这个表有三个字段：转账单 ID、账户 ID 和变更金额，然后给转账单 ID 和账户 ID 这两个字段联合起来创建一个唯一约束，这样对于相同的转账单 ID 和账户 ID，表里至多只能存在一条记录。这样，我们消费消息的逻辑可以变为：“在转账流水表中增加一条转账记录，然后再根据转账记录，异步操作更新用户余额即可。”在转账流水表增加一条转账记录这个操作中，由于我们在这个表中预先定义了“账户 ID 转账单 ID”的唯一约束，对于同一个转账单同一个账户只能插入一条记录，后续重复的插入操作都会失败，这样就实现了一个幂等的操作。我们只要写一个 SQL，正确地实现它就可以了。基于这个思路，不光是可以使用关系型数据库，只要是支持类似“INSERT IF NOT EXIST”语义的存储类系统都可以用于实现幂等，比如，你可以用 Redis 的 SETNX 命令来替代数据库中的唯一约束，来实现幂等消费。</p>
<ol start="3">
<li><p>为更新的数据设置前置条件</p>
<p>为更新的数据设置前置条件另外一种实现幂等的思路是，给数据变更设置一个前置条件，如果满足条件就更新数据，否则拒绝更新数据，在更新数据的时候，同时变更前置条件中需要判断的数据。这样，重复执行这个操作时，由于第一次更新数据的时候已经变更了前置条件中需要判断的数据，不满足前置条件，则不会重复执行更新数据操作。比如，刚刚我们说过，“将账户 X 的余额增加 100 元”这个操作并不满足幂等性，我们可以把这个操作加上一个前置条件，变为：“如果账户 X 当前的余额为 500 元，将余额加 100 元”，这个操作就具备了幂等性。对应到消息队列中的使用时，可以在发消息时在消息体中带上当前的余额，在消费的时候进行判断数据库中，当前余额是否与消息中的余额相等，只有相等才执行变更操作。但是，如果我们要更新的数据不是数值，或者我们要做一个比较复杂的更新操作怎么办？用什么作为前置判断条件呢？更加通用的方法是，给你的数据增加一个版本号属性，每次更数据前，比较当前数据的版本号是否和消息中的版本号一致，如果不一致就拒绝更新数据，更新数据的同时将版本号 +1，一样可以实现幂等更新</p>
</li>
</ol>
<h4 id="11-9-如何保证同一分区一定有序"><a href="#11-9-如何保证同一分区一定有序" class="headerlink" title="11.9 如何保证同一分区一定有序"></a>11.9 如何保证同一分区一定有序</h4><p>两种方案：<br>方案一，kafka topic 只设置一个partition分区<br>方案二，producer将消息发送到指定partition分区<br>解析：<br>方案一：kafka默认保证同一个partition分区内的消息是有序的，则可以设置topic只使用一个分区，这样消息就是全局有序，缺点是只能被consumer group里的一个消费者消费，降低了性能，不适用高并发的情况<br>方案二：既然kafka默认保证同一个partition分区内的消息是有序的，则producer可以在发送消息时可以指定需要保证顺序的几条消息发送到同一个分区，这样消费者消费时，消息就是有序。</p>
<p>但是个时候还有个问题就是消息重试的时候会让消息顺序打乱，所以还需要设置这个参数：<br>max.in.flight.requests.per.connection 默认值5，设置为1</p>
<ul>
<li>Kafka 的特性和使用场景</li>
<li>Kafka 中的一些概念：Leader、Broker、Producer、Consumer、Topic、Group、Offset、Partition、ISR</li>
<li>Kafka 的整体架构</li>
<li>Kafka 选举策略</li>
<li>Kafka 读取和写入消息过程中都发生了什么</li>
<li>Kakfa 如何进行数据同步（ISR）</li>
<li>Kafka 实现分区消息顺序性的原理</li>
<li>消费者和消费组的关系</li>
<li>消费 Kafka 消息的 Best Practice（最佳实践）是怎样的</li>
<li>Kafka 如何保证消息投递的可靠性和幂等性</li>
<li>Kafka 消息的事务性是如何实现的</li>
<li>如何管理 Kafka 消息的 Offset</li>
<li>Kafka 的文件存储机制</li>
<li>Kafka 是如何支持 Exactly-once 语义的</li>
<li>通常 Kafka 还会要求和 RocketMQ 等消息中间件进行比较</li>
</ul>
<h1 id="12-Flink"><a href="#12-Flink" class="headerlink" title="12. Flink"></a>12. Flink</h1><blockquote>
<p>Apache Flink（以下简称 Flink）项目是大数据处理领域最近冉冉升起的一颗新星，其不同于其他大数据项目的诸多特性吸引了越来越多人的关注。尤其是 2019 年初 Blink 开源将 Flink 的关注度提升到了前所未有的程度。</p>
</blockquote>
<ul>
<li>Flink 集群的搭建</li>
<li>Flink 的架构原理</li>
<li>Flink 的编程模型</li>
<li>Flink 集群的 HA 配置</li>
<li>Flink DataSet 和 DataSteam API</li>
<li>序列化</li>
<li>Flink 累加器</li>
<li>状态 State 的管理和恢复</li>
<li>窗口和时间</li>
<li>并行度</li>
<li>Flink 和消息中间件 Kafka 的结合</li>
<li>Flink Table 和 SQL 的原理和用法</li>
</ul>
<h1 id="13-大数据算法"><a href="#13-大数据算法" class="headerlink" title="13. 大数据算法"></a>13. 大数据算法</h1><ul>
<li>两个超大文件找共同出现的单词</li>
<li>海量数据求 TopN</li>
<li>海量数据找出不重复的数据</li>
<li>布隆过滤器</li>
<li>bit-map</li>
<li>堆</li>
<li>字典树</li>
<li>倒排索引</li>
</ul>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a href="https://blog.sev7e0.site/">大数据施工现场</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




</html>
