<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="天行健、君子以自强不息；地势坤，君子以厚德载物。">
    <meta name="keyword"  content="兰草">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        深入理解Spark Streaming流量控制及反压机制 - kfly的博客 | kfly&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_1598291_q3el2wqimj.css" type="text/css">
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>kfly</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont iconhome"></i>
                    <span>主页</span>
                </a>
            </li>
 	   <li >
                <a href="/spec/">
                    <i class="iconfont iconzhuanti"></i>
                    <span>专题</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>简历</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#反压机制"><span class="toc-text">反压机制</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#接收数据的两种方式"><span class="toc-text">接收数据的两种方式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Receiver-Stream"><span class="toc-text">Receiver Stream</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Direct-Stream"><span class="toc-text">Direct Stream</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark-Streaming-反压机制"><span class="toc-text">Spark Streaming 反压机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#基于PID机制的速率估算器"><span class="toc-text">基于PID机制的速率估算器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RateController"><span class="toc-text">RateController</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RateController两个子类"><span class="toc-text">RateController两个子类</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#ReceiverRateController"><span class="toc-text">ReceiverRateController</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#通过RPC发布流量阈值"><span class="toc-text">通过RPC发布流量阈值</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#DirectKafkaRateController"><span class="toc-text">DirectKafkaRateController</span></a></li></ol></li></ol></li></ol></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        深入理解Spark Streaming流量控制及反压机制
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2019-12-12 12:54:30</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#spark" title="spark">spark</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#反压" title="反压">反压</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <h1 id="反压机制"><a href="#反压机制" class="headerlink" title="反压机制"></a>反压机制</h1><blockquote>
<p>Spark Streaming 作为基于 <strong>微批次</strong>（micro-batch）的流处理框架，其流量的理想状态就是官方文档中所说的 “batches of data should be processed as fast as they are being generated”，即每一批次的处理时长 batchprocesstime 需要小于（但是又比较接近）我们设定的批次间隔 batchinterval。如果 batchprocesstime &gt; batchinterval，说明程序的处理能力不足，积累的数据越来越多，最终会造成 Executor 内存溢出。如果 batchprocesstime &lt;&lt; batch_interval ，说明系统有很长时间是空闲的，应该适当提升流量。</p>
</blockquote>
<h2 id="接收数据的两种方式"><a href="#接收数据的两种方式" class="headerlink" title="接收数据的两种方式"></a>接收数据的两种方式</h2><h3 id="Receiver-Stream"><a href="#Receiver-Stream" class="headerlink" title="Receiver Stream"></a>Receiver Stream</h3><ul>
<li>Spark Streaming 通过 Executor 里的 Receiver 组件源源不断地接收外部数据，并通过 BlockManager 将外部数据转化为 Spark 中的块进行存储。Spark Streaming 中Receiver方式机制的简单框图如下所示。</li>
</ul>
<p><img src="https://kflys.gitee.io/upic/2020/04/07/uPic/spark%E5%8F%8D%E5%8E%8B/assets/image-20200407155624244.png" alt="image-20200407155624244"></p>
<ul>
<li>要限制 Receiver 接收数据的速率，可以在 SparkConf 中设置配置项 <code>spark.streaming.receiver.maxRate</code>，单位为数据条数/秒。</li>
</ul>
<p>这两种方式的优点是设置非常简单，只需要通过实际业务的吞吐量估算一下使批次间隔和处理耗时基本达到平衡的速率就可以了。缺点是一旦业务量发生变化，就只能手动修改参数并重启 Streaming 程序。另外，人为估计的参数毕竟有可能不准，设置得太激进或太保守都不好</p>
<h3 id="Direct-Stream"><a href="#Direct-Stream" class="headerlink" title="Direct Stream"></a>Direct Stream</h3><ul>
<li>如果采用的是基于 Direct Stream 方式的 Kafka 连接，不经过 Receiver，就得设置配置项 <code>spark.streaming.kafka.maxRatePerPartition</code> 来限流，单位是每分区的数据条数/秒。</li>
</ul>
<h2 id="Spark-Streaming-反压机制"><a href="#Spark-Streaming-反压机制" class="headerlink" title="Spark Streaming 反压机制"></a>Spark Streaming 反压机制</h2><ul>
<li>以上两种通过参数控制非常方便，但是一旦业务量发生改变只能手动修改配置文件并重启程序。 所以在Spark 1.5加入了动态流量控制方案。能够根据当前系统的处理速度智能地调节流量阈值，名为 <strong>反压（back pressure）机制</strong>。</li>
<li>控制反压机制的配置文件如下：</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>默认值</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>spark.streaming.backpressure.enabled</td>
<td>false</td>
<td>是否启用反压机制</td>
</tr>
<tr>
<td>spark.streaming.backpressure.initialRate</td>
<td>无</td>
<td>初始最大接收速率。只适用于Receiver Stream，不适用于Direct Stream。</td>
</tr>
<tr>
<td>spark.streaming.backpressure.rateEstimator</td>
<td>pid</td>
<td>速率控制器,Spark 默认只支持此控制器，可自定义。</td>
</tr>
<tr>
<td>spark.streaming.backpressure.pid.proportional</td>
<td>1.0</td>
<td>只能为非负值。当前速率与最后一批速率之间的差值对总控制信号贡献的权重。用默认值即可。</td>
</tr>
<tr>
<td>spark.streaming.backpressure.pid.integral</td>
<td>0.2</td>
<td>只能为非负值。比例误差累积对总控制信号贡献的权重。用默认值即可</td>
</tr>
<tr>
<td>spark.streaming.backpressure.pid.derived</td>
<td>0</td>
<td>只能为非负值。比例误差变化对总控制信号贡献的权重。用默认值即可</td>
</tr>
<tr>
<td>spark.streaming.backpressure.pid.minRate</td>
<td>100</td>
<td>只能为正数，最小速率</td>
</tr>
</tbody>
</table>
<h3 id="基于PID机制的速率估算器"><a href="#基于PID机制的速率估算器" class="headerlink" title="基于PID机制的速率估算器"></a>基于PID机制的速率估算器</h3><ul>
<li><code>org.apache.spark.streaming.scheduler.rate.RateEstimator</code>是一个很短的特征，其中只给出了计算流量阈值的方法 compute() 的定义。它还有一个伴生对象用于创建速率估算器的实例，其中写出了更多关于反压机制的配置参数。</li>
</ul>
<pre><code class="scala">// 速率估算器
private[streaming] trait RateEstimator extends Serializable {
  def compute(
      time: Long,
      elements: Long,
      processingDelay: Long,
      schedulingDelay: Long): Option[Double]
}
// 半生对象
object RateEstimator {
  def create(conf: SparkConf, batchInterval: Duration): RateEstimator =
    conf.get(&quot;spark.streaming.backpressure.rateEstimator&quot;, &quot;pid&quot;) match {
      case &quot;pid&quot; =&gt;
        val proportional = conf.getDouble(&quot;spark.streaming.backpressure.pid.proportional&quot;, 1.0)
        val integral = conf.getDouble(&quot;spark.streaming.backpressure.pid.integral&quot;, 0.2)
        val derived = conf.getDouble(&quot;spark.streaming.backpressure.pid.derived&quot;, 0.0)
        val minRate = conf.getDouble(&quot;spark.streaming.backpressure.pid.minRate&quot;, 100)
        new PIDRateEstimator(batchInterval.milliseconds, proportional, integral, derived, minRate)
      case estimator =&gt;
        throw new IllegalArgumentException(s&quot;Unknown rate estimator: $estimator&quot;)
    }
}
</code></pre>
<ul>
<li>RateEstimator 的唯一实现类是 PIDRateEstimator，亦即 <code>spark.streaming.backpressure.rateEstimator</code> 配置项的值只能为 pid。</li>
</ul>
<pre><code class="scala">private[streaming] class PIDRateEstimator(
    batchIntervalMillis: Long,
    proportional: Double,
    integral: Double,
    derivative: Double,
    minRate: Double
  ) extends RateEstimator with Logging {

  private var firstRun: Boolean = true
  private var latestTime: Long = -1L
  private var latestRate: Double = -1D
  private var latestError: Double = -1L

  require(
    batchIntervalMillis &gt; 0,
    s&quot;Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.&quot;)
  require(
    proportional &gt;= 0,
    s&quot;Proportional term $proportional in PIDRateEstimator should be &gt;= 0.&quot;)
  require(
    integral &gt;= 0,
    s&quot;Integral term $integral in PIDRateEstimator should be &gt;= 0.&quot;)
  require(
    derivative &gt;= 0,
    s&quot;Derivative term $derivative in PIDRateEstimator should be &gt;= 0.&quot;)
  require(
    minRate &gt; 0,
    s&quot;Minimum rate in PIDRateEstimator should be &gt; 0&quot;)

  logInfo(s&quot;Created PIDRateEstimator with proportional = $proportional, integral = $integral, &quot; +
    s&quot;derivative = $derivative, min rate = $minRate&quot;)

  def compute(
      time: Long, // in milliseconds
      numElements: Long,
      processingDelay: Long, // in milliseconds
      schedulingDelay: Long // in milliseconds
    ): Option[Double] = {
    logTrace(s&quot;\ntime = $time, # records = $numElements, &quot; +
      s&quot;processing time = $processingDelay, scheduling delay = $schedulingDelay&quot;)
    this.synchronized {
      if (time &gt; latestTime &amp;&amp; numElements &gt; 0 &amp;&amp; processingDelay &gt; 0) {
        val delaySinceUpdate = (time - latestTime).toDouble / 1000
        val processingRate = numElements.toDouble / processingDelay * 1000
        val error = latestRate - processingRate
        val historicalError = schedulingDelay.toDouble * processingRate / batchIntervalMillis
        val dError = (error - latestError) / delaySinceUpdate
        val newRate = (latestRate - proportional * error -
                                    integral * historicalError -
                                    derivative * dError).max(minRate)
        logTrace(s&quot;&quot;&quot;
            | latestRate = $latestRate, error = $error
            | latestError = $latestError, historicalError = $historicalError
            | delaySinceUpdate = $delaySinceUpdate, dError = $dError
            &quot;&quot;&quot;.stripMargin)
        latestTime = time
        if (firstRun) {
          latestRate = processingRate
          latestError = 0D
          firstRun = false
          logTrace(&quot;First run, rate estimation skipped&quot;)
          None
        } else {
          latestRate = newRate
          latestError = error
          logTrace(s&quot;New rate = $newRate&quot;)
          Some(newRate)
        }
      } else {
        logTrace(&quot;Rate estimation skipped&quot;)
        None
      }
    }
  }
}
</code></pre>
<ul>
<li>PIDRateEstimator 充分运用了工控领域中常见的 PID 控制器的思想。所谓 PID 控制器，即比例（Proportional）-积分（Integral）-微分（Derivative）控制器，本质上是一种反馈回路（loop feedback）。它把收集到的数据和一个设定值（setpoint）进行比较，然后用它们之间的差计算新的输入值，该输入值可以让系统数据尽量接近或者达到设定值。</li>
</ul>
<p><img src="https://kflys.gitee.io/upic/2020/04/07/uPic/spark%E5%8F%8D%E5%8E%8B/assets/image-20200407162210511.png" alt="image-20200407162210511"></p>
<p><img src="https://kflys.gitee.io/upic/2020/04/07/uPic/spark%E5%8F%8D%E5%8E%8B/assets/image-20200407162234229.png" alt="image-20200407162234229"></p>
<ul>
<li><p>其中 e(t) 代表误差，即设定值与回授值之间的差。也就是说，比例单元对应当前误差，积分单元对应过去累积误差，而微分单元对应将来误差。控制三个单元的增益因子分别为 Kp、Ki、Kd。</p>
</li>
<li><p>回到 PIDRateEstimator 的源码来，对应以上的式子，我们可以得知：</p>
<ul>
<li>处理速率的设定值其实就是上一批次的处理速率 latestRate，回授值就是这一批次的速率 processingRate，误差 error 自然就是两者之差。</li>
<li>过去累积误差在这里体现为调度时延的过程中数据积压的速度，也就是schedulingDelay * processingRate / batchInterval。</li>
<li>将来误差就是上面算出的error对时间微分的结果。</li>
</ul>
</li>
<li><p>将上面三者综合起来，就可以根据 Spark Streaming 在上一批次以及这一批次的处理速率，估算出一个合适的用于下一批次的流量阈值。比例增益 Kp 由 <code>spark.streaming.backpressure.pid.proportional</code> 控制，默认值 1.0；积分增益 Ki 由 <code>spark.streaming.backpressure.pid.integral</code> 控制，默认值0.2；微分增益Kd由 <code>spark.streaming.backpressure.pid.derived</code>控制，默认值0.0。</p>
<h3 id="RateController"><a href="#RateController" class="headerlink" title="RateController"></a>RateController</h3></li>
<li><p>动态流量控制器,类<code>org.apache.spark.streaming.scheduler.RateController</code>是动态流量控制器的核心。</p>
</li>
</ul>
<pre><code class="scala">private[streaming] abstract class RateController(val streamUID: Int, rateEstimator: RateEstimator) extends StreamingListener  // 抽象类继承自 StreamingListener 特征，表示它是一个 Streaming 监听器。
with Serializable {
  // 监听 StreamingListenerBatchCompleted 事件，该事件表示一个批次已经处理完成。
  override def onBatchCompleted(batchCompleted: StreamingListenerBatchCompleted) {
    val elements = batchCompleted.batchInfo.streamIdToInputInfo

    for {
      // 处理完成的时间戳 processingEndTime
      processingEnd &lt;- batchCompleted.batchInfo.processingEndTime
      // 实际处理时长 processingDelay（从批次的第一个 job 开始处理到最后一个job处理完成经过的时间）
      workDelay &lt;- batchCompleted.batchInfo.processingDelay
      // 调度时延schedulingDelay（从批次被提交给 Streaming JobScheduler 到第一个 job 开始处理经过的时间）。
      waitDelay &lt;- batchCompleted.batchInfo.schedulingDelay
      // 批次输入数据的条数 numRecords。
      elems &lt;- elements.get(streamUID).map(_.numRecords)
    } computeAndPublish(processingEnd, elems, workDelay, waitDelay)
  }
}
</code></pre>
<h4 id="RateController两个子类"><a href="#RateController两个子类" class="headerlink" title="RateController两个子类"></a>RateController两个子类</h4><ul>
<li>两个子类分别对应两种数据接收方式。Receiver 和 Direct</li>
</ul>
<h5 id="ReceiverRateController"><a href="#ReceiverRateController" class="headerlink" title="ReceiverRateController"></a>ReceiverRateController</h5><ul>
<li><p>通过 RateController 的子类 ReceiverRateController 实现的 publish() 抽象方法可知，新的流量阈值是发布给了 ReceiverTracker。</p>
<pre><code class="scala">/**
   * A RateController that sends the new rate to receivers, via the receiver tracker.
   */
private[streaming] class ReceiverRateController(id: Int, estimator: RateEstimator)
extends RateController(id, estimator) {
  override def publish(rate: Long): Unit =
  ssc.scheduler.receiverTracker.sendRateUpdate(id, rate)
}
</code></pre>
</li>
</ul>
<h6 id="通过RPC发布流量阈值"><a href="#通过RPC发布流量阈值" class="headerlink" title="通过RPC发布流量阈值"></a>通过RPC发布流量阈值</h6><ul>
<li><p>回来看 ReceiverTracker，顾名思义，它负责追踪 Receiver 的状态。其 sendRateUpdate() 方法如下</p>
<pre><code class="scala">// 1. endpoint 是 RPC 端点的引用。具体来说，是 ReceiverTrackerEndpoint 的引用
private var endpoint: RpcEndpointRef = null

/** Update a receiver&#39;s maximum ingestion rate */
def sendRateUpdate(streamUID: Int, newRate: Long): Unit = synchronized {
  if (isTrackerStarted) {
    // 2. endpoint 将流 ID 与新的流量阈值包装在 UpdateReceiverRateLimit 消息中发送过去。
    endpoint.send(UpdateReceiverRateLimit(streamUID, newRate))
  }
}
</code></pre>
</li>
<li><p>ReceiverTrackerEndpoint 收到这条消息后，会再将其包装为 UpdateRateLimit 消息并发送给 Receiver 注册时的 RPC 端点（位于 ReceiverSupervisorImpl 类中）。</p>
</li>
<li>ReceiverTrackerEndpoint 收到这条消息后，会再将其包装为 UpdateRateLimit 消息并发送给 Receiver 注册时的 RPC 端点（位于 ReceiverSupervisorImpl 类中）。</li>
</ul>
<pre><code class="scala">/** RpcEndpointRef for receiving messages from the ReceiverTracker in the driver */
private val endpoint = env.rpcEnv.setupEndpoint(
  &quot;Receiver-&quot; + streamId + &quot;-&quot; + System.currentTimeMillis(), new ThreadSafeRpcEndpoint {
    override val rpcEnv: RpcEnv = env.rpcEnv

    override def receive: PartialFunction[Any, Unit] = {
      case StopReceiver =&gt;
      logInfo(&quot;Received stop signal&quot;)
      ReceiverSupervisorImpl.this.stop(&quot;Stopped by driver&quot;, None)
      case CleanupOldBlocks(threshTime) =&gt;
      logDebug(&quot;Received delete old batch signal&quot;)
      cleanupOldBlocks(threshTime)
      case UpdateRateLimit(eps) =&gt;
      logInfo(s&quot;Received a new rate limit: $eps.&quot;)
      // 1. 收到该消息之后调用了 BlockGenerator.updateRate() 方法。
      registeredBlockGenerators.asScala.foreach { bg =&gt;
        bg.updateRate(eps)
      }
    }
  })
</code></pre>
<pre><code class="scala">// 2. BlockGenerator 是 RateLimiter 的子类，它负责将收到的流数据转化成块存储。updateRate() 方法是在 RateLimiter 抽象类中实现的。
private[streaming] class BlockGenerator(
    listener: BlockGeneratorListener,
    receiverId: Int,
    conf: SparkConf,
    clock: Clock = new SystemClock()
  ) extends RateLimiter(conf) with Logging {}
</code></pre>
<pre><code class="scala">// 这里接住了guava的RateLimiter
import com.google.common.util.concurrent.{RateLimiter =&gt; GuavaRateLimiter}

private[receiver] abstract class RateLimiter(conf: SparkConf) extends Logging {
  // treated as an upper limit
  private val maxRateLimit = conf.getLong(&quot;spark.streaming.receiver.maxRate&quot;, Long.MaxValue)
  private lazy val rateLimiter = GuavaRateLimiter.create(getInitialRateLimit().toDouble)
  def waitToPush() {
    rateLimiter.acquire()
  }
  /**
   * Return the current rate limit. If no limit has been set so far, it returns {{{Long.MaxValue}}}.
   */
  def getCurrentLimit: Long = rateLimiter.getRate.toLong

  /**
   * Set the rate limit to `newRate`. The new rate will not exceed the maximum rate configured by
   * {{{spark.streaming.receiver.maxRate}}}, even if `newRate` is higher than that.
   *
   * @param newRate A new rate in records per second. It has no effect if it&#39;s 0 or negative.
   */
  // 3. 更细Rate
  private[receiver] def updateRate(newRate: Long): Unit =
    if (newRate &gt; 0) {
      if (maxRateLimit &gt; 0) {
        rateLimiter.setRate(newRate.min(maxRateLimit))
      } else {
        rateLimiter.setRate(newRate)
      }
    }
  /**
   * Get the initial rateLimit to initial rateLimiter
   */
  private def getInitialRateLimit(): Long = {
    math.min(conf.getLong(&quot;spark.streaming.backpressure.initialRate&quot;, maxRateLimit), maxRateLimit)
  }
}
</code></pre>
<p><img src="https://kflys.gitee.io/upic/2020/04/07/uPic/spark%E5%8F%8D%E5%8E%8B/assets/image-20200407164947975.png" alt="image-20200407164947975"></p>
<h5 id="DirectKafkaRateController"><a href="#DirectKafkaRateController" class="headerlink" title="DirectKafkaRateController"></a>DirectKafkaRateController</h5><ul>
<li>DirectKafkaRateController只继承了RateController，并未在 publish() 加过多的内容，我们主要看一下<code>DirectKafkaInputDStream</code>这个类。</li>
</ul>
<pre><code class="scala">private[spark] class DirectKafkaInputDStream[K, V](
    _ssc: StreamingContext,
    locationStrategy: LocationStrategy,
    consumerStrategy: ConsumerStrategy[K, V],
    ppc: PerPartitionConfig
  ) extends InputDStream[ConsumerRecord[K, V]](_ssc) with Logging with CanCommitOffsets 

  /**
   * Asynchronously maintains &amp; sends new rate limits to the receiver through the receiver tracker.
   异步，通过ReceiverTracker发送新的速率限制
   */
  override protected[streaming] val rateController: Option[RateController] = {
    if (RateController.isBackPressureEnabled(ssc.conf)) {
      Some(new DirectKafkaRateController(id,
        RateEstimator.create(ssc.conf, context.graph.batchDuration)))
    } else {
      None
    }
  }
    // 主要实现在这里
  protected[streaming] def maxMessagesPerPartition(
    offsets: Map[TopicPartition, Long]): Option[Map[TopicPartition, Long]] = {
    //   调用RateController 的 def getLatestRate(): Long = rateLimit.get()获取rateLimiter    
    val estimatedRateLimit = rateController.map(_.getLatestRate())

    // calculate a per-partition rate limit based on current lag
    val effectiveRateLimitPerPartition = estimatedRateLimit.filter(_ &gt; 0) match {
      case Some(rate) =&gt;
          // offset range的消息量 totalLag
        val lagPerPartition = offsets.map { case (tp, offset) =&gt;
          tp -&gt; Math.max(offset - currentOffsets(tp), 0)
        }
        val totalLag = lagPerPartition.values.sum

        lagPerPartition.map { case (tp, lag) =&gt;
          // 设置的maxRatePerPartition
          val maxRateLimitPerPartition = ppc.maxRatePerPartition(tp)
          val backpressureRate = Math.round(lag / totalLag.toFloat * rate)
          tp -&gt; (if (maxRateLimitPerPartition &gt; 0) {
             // 有效速率=取设置的maxRatePerPartition和预估的速率最小值
            Math.min(backpressureRate, maxRateLimitPerPartition)} else backpressureRate)
        }
      case None =&gt; offsets.map { case (tp, offset) =&gt; tp -&gt; ppc.maxRatePerPartition(tp) }
    }

    if (effectiveRateLimitPerPartition.values.sum &gt; 0) {
      val secsPerBatch = context.graph.batchDuration.milliseconds.toDouble / 1000
      Some(effectiveRateLimitPerPartition.map {
        case (tp, limit) =&gt; tp -&gt; (secsPerBatch * limit).toLong
      })
    } else {
      None
    }
  }
  /**
   * A RateController to retrieve the rate from RateEstimator.
   * 实现RateController抽象类，并未具体实现publish方法，主要用来取回rate数据
   */
  private[streaming] class DirectKafkaRateController(id: Int, estimator: RateEstimator)
    extends RateController(id, estimator) {
    override def publish(rate: Long): Unit = ()
  }
}
</code></pre>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a href="https://blog.sev7e0.site/">大数据施工现场</a></span>
        <span>/</span>
        
        <span><a href="https://wangchujiang.com/linux-command/">linux命令</a></span>
        <span>/</span>
        
        <span><a href="http://redisdoc.com/">Redis命令</a></span>
        <span>/</span>
        
        <span><a href="https://github.com/orchid-ding">github</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script src="/js/gitment.js"></script>
<script>
    var gitment = new Gitment({
        id: '深入理解Spark Streaming流量控制及反压机制',
        owner: 'orchid-ding',
        repo: 'kfly-blog-comment',
        oauth: {
            client_id: '0770cdab79393197b6f5',
            client_secret: '376fb6c7bcd5047718b356712f596b89e490360c',
        },
    })
    gitment.render('comment-container')
</script>




</html>
