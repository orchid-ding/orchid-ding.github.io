<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="天行健、君子以自强不息；地势坤，君子以厚德载物。">
    <meta name="keyword"  content="兰草">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        kfly的博客 | kfly&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_1598291_q3el2wqimj.css" type="text/css">
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>kfly</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont iconhome"></i>
                    <span>主页</span>
                </a>
            </li>
 	   <li >
                <a href="/spec/">
                    <i class="iconfont iconzhuanti"></i>
                    <span>专题</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>简历</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#数据存储原理"><span class="toc-text">数据存储原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#读数据流程"><span class="toc-text">读数据流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#写数据流程"><span class="toc-text">写数据流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#flush、compact机制"><span class="toc-text">flush、compact机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Flush触发条件"><span class="toc-text">Flush触发条件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Flush的流程"><span class="toc-text">Flush的流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Compact合并机制"><span class="toc-text">Compact合并机制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#minor-compaction"><span class="toc-text">minor compaction</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#major-compaction"><span class="toc-text">major compaction</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#region-拆分机制"><span class="toc-text">region 拆分机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#表的预分区"><span class="toc-text">表的预分区</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#region-合并"><span class="toc-text">region 合并</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HBase集成MapReduce"><span class="toc-text">HBase集成MapReduce</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HBase集成Hive"><span class="toc-text">HBase集成Hive</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#对比"><span class="toc-text">对比</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#拷贝jar包"><span class="toc-text">拷贝jar包</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#修改hive-site-xml"><span class="toc-text">修改hive-site.xml</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#修改hive-env-sh"><span class="toc-text">修改hive-env.sh</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hive建表同步到hbase"><span class="toc-text">hive建表同步到hbase</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hive外部表映射HBase表模型"><span class="toc-text">hive外部表映射HBase表模型</span></a></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2019-03-13 14:46:15</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#hbase" title="hbase">hbase</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#hbase与hive" title="hbase与hive">hbase与hive</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#hbase与mapreduce" title="hbase与mapreduce">hbase与mapreduce</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <h2 id="数据存储原理"><a href="#数据存储原理" class="headerlink" title="数据存储原理"></a>数据存储原理</h2><p><img src="http://kflys.gitee.io/upic/2020/04/01/uPic/hbase/assets/hbase%E5%AD%98%E5%82%A8%E6%9E%B6%E6%9E%84.png?lastModify=1573631775" alt="hbase存储架构"></p>
<p><img src="http://kflys.gitee.io/upic/2020/04/01/uPic/hbase/assets/hbase_data_storage-1565601156263.png?lastModify=1573631775" alt="img"></p>
<ul>
<li>一个HRegionServer会负责管理很多个region</li>
<li>一个<strong>==region==</strong>包含很多个==store==<ul>
<li>一个<strong>==列族==</strong>就划分成一个<strong>==store==</strong></li>
<li>如果一个表中只有1个列族，那么每一个region中只有一个store</li>
<li>如果一个表中有N个列族，那么每一个region中有N个store</li>
</ul>
</li>
<li>==一个store==里面只有==一个memstore==<ul>
<li>memstore是一块<strong>内存区域</strong>，写入的数据会先写入memstore进行缓冲，然后再把数据刷到磁盘</li>
</ul>
</li>
<li>一个store里面有很多个<strong>==StoreFile==</strong>, 最后数据是以很多个<strong>==HFile==</strong>这种数据结构的文件保存在HDFS上<ul>
<li>StoreFile是HFile的抽象对象，如果说到StoreFile就等于HFile</li>
<li>==每次memstore刷写数据到磁盘，就生成对应的一个新的HFile文件出来==</li>
</ul>
</li>
</ul>
<p><img src="http://kflys.gitee.io/upic/2020/04/01/uPic/hbase/assets/region.png?lastModify=1573631775" alt="region"></p>
<h2 id="读数据流程"><a href="#读数据流程" class="headerlink" title="读数据流程"></a>读数据流程</h2><p><img src="http://kflys.gitee.io/upic/2020/04/01/uPic/hbase/assets/hbase%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B.png?lastModify=1573631775" alt="img"></p>
<blockquote>
<p>说明：HBase集群，只有一张meta表，此表只有一个region，该region数据保存在一个HRegionServer上</p>
</blockquote>
<ul>
<li>1、客户端首先与zk进行连接；从zk找到meta表的region位置，即meta表的数据存储在某一HRegionServer上；客户端与此HRegionServer建立连接，然后读取meta表中的数据；meta表中存储了所有用户表的region信息，我们可以通过<code>scan  &#39;hbase:meta&#39;</code>来查看meta表信息</li>
<li>2、根据要查询的namespace、表名和rowkey信息。找到写入数据对应的region信息</li>
<li>3、找到这个region对应的regionServer，然后发送请求</li>
<li>4、查找并定位到对应的region</li>
<li>5、先从memstore查找数据，如果没有，再从BlockCache上读取<ul>
<li>HBase上Regionserver的内存分为两个部分<ul>
<li>一部分作为Memstore，主要用来写；</li>
<li>另外一部分作为BlockCache，主要用于读数据；</li>
</ul>
</li>
</ul>
</li>
<li>6、如果BlockCache中也没有找到，再到StoreFile上进行读取<ul>
<li>从storeFile中读取到数据之后，不是直接把结果数据返回给客户端，而是把数据先写入到BlockCache中，目的是为了加快后续的查询；然后在返回结果给客户端。</li>
</ul>
</li>
</ul>
<h2 id="写数据流程"><a href="#写数据流程" class="headerlink" title="写数据流程"></a>写数据流程</h2><p><img src="http://kflys.gitee.io/upic/2020/04/01/uPic/hbase/assets/hbase%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B.png?lastModify=1573631775" alt="img"></p>
<ul>
<li>1、客户端首先从zk找到meta表的region位置，然后读取meta表中的数据，meta表中存储了用户表的region信息</li>
<li>2、根据namespace、表名和rowkey信息。找到写入数据对应的region信息</li>
<li>3、找到这个region对应的regionServer，然后发送请求</li>
<li>4、把数据分别写到HLog（write ahead log）和memstore各一份</li>
<li>5、memstore达到阈值后把数据刷到磁盘，生成storeFile文件</li>
<li>6、删除HLog中的历史数据</li>
</ul>
<pre><code>补充：
HLog（write ahead log）：
  也称为WAL意为Write ahead log，类似mysql中的binlog,用来做灾难恢复时用，HLog记录数据的所有变更,一旦数据修改，就可以从log中进行恢复。
</code></pre><h2 id="flush、compact机制"><a href="#flush、compact机制" class="headerlink" title="flush、compact机制"></a>flush、compact机制</h2><p><img src="http://kflys.gitee.io/upic/2020/04/01/uPic/hbase/assets/hbase-split-compaction.png" style="zoom:50%;"></p>
<h3 id="Flush触发条件"><a href="#Flush触发条件" class="headerlink" title="Flush触发条件"></a>Flush触发条件</h3><ul>
<li>memstore级别限制</li>
</ul>
<pre><code class="xml">&lt;!--
    当Region中任意一个MemStore的大小达到了上限（hbase.hregion.memstore.flush.size，默认128MB），会触发Memstore刷新。
--&gt;
&lt;property&gt;
    &lt;name&gt;hbase.hregion.memstore.flush.size&lt;/name&gt;
    &lt;value&gt;134217728&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<ul>
<li>region级别限制</li>
</ul>
<pre><code class="xml">&lt;!--
    当Region中所有Memstore的大小总和达到了上限（hbase.hregion.memstore.block.multiplier * hbase.hregion.memstore.flush.size，默认 2* 128M = 256M），会触发memstore刷新。
--&gt;
&lt;property&gt;
    &lt;name&gt;hbase.hregion.memstore.flush.size&lt;/name&gt;
    &lt;value&gt;134217728&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hbase.hregion.memstore.block.multiplier&lt;/name&gt;
    &lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;   
</code></pre>
<ul>
<li>Region Server级别限制</li>
</ul>
<pre><code class="xml">&lt;!--
  - 当一个Region Server中所有Memstore的大小总和超过低水位阈值hbase.regionserver.global.memstore.size.lower.limit*hbase.regionserver.global.memstore.size（前者默认值0.95），RegionServer开始强制flush；
  - 先Flush Memstore最大的Region，再执行次大的，依次执行；
  - 如写入速度大于flush写出的速度，导致总MemStore大小超过高水位阈值hbase.regionserver.global.memstore.size（默认为JVM内存的40%），此时RegionServer会阻塞更新并强制执行flush，直到总MemStore大小低于低水位阈值
--&gt;
&lt;property&gt;
    &lt;name&gt;hbase.regionserver.global.memstore.size.lower.limit&lt;/name&gt;
    &lt;value&gt;0.95&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hbase.regionserver.global.memstore.size&lt;/name&gt;
    &lt;value&gt;0.4&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<ul>
<li><p>HLog数量上限</p>
<ul>
<li>当一个Region Server中HLog数量达到上限（可通过参数hbase.regionserver.maxlogs配置）时，系统会选取最早的一个 HLog对应的一个或多个Region进行flush</li>
</ul>
</li>
<li><p>定期刷新Memstore</p>
<ul>
<li>默认周期为1小时，确保Memstore不会长时间没有持久化。为避免所有的MemStore在同一时间都进行flush导致的问题，定期的flush操作有20000左右的随机延时。</li>
</ul>
</li>
<li><p>手动flush</p>
<ul>
<li>用户可以通过shell命令<code>flush ‘tablename’</code>或者<code>flush ‘region name’</code>分别对一个表或者一个Region进行flush。</li>
</ul>
</li>
</ul>
<h3 id="Flush的流程"><a href="#Flush的流程" class="headerlink" title="Flush的流程"></a>Flush的流程</h3><ul>
<li><p>为了减少flush过程对读写的影响，将整个flush过程分为三个阶段：</p>
<ul>
<li><p>prepare阶段：遍历当前Region中所有的Memstore，将Memstore中当前数据集CellSkipListSet做一个<strong>快照snapshot</strong>；然后再新建一个CellSkipListSet。后期写入的数据都会写入新的CellSkipListSet中。prepare阶段需要加一把updateLock对<strong>写请求阻塞</strong>，结束之后会释放该锁。因为此阶段没有任何费时操作，因此持锁时间很短。</p>
</li>
<li><p>flush阶段：遍历所有Memstore，将prepare阶段生成的snapshot持久化为<strong>临时文件</strong>，临时文件会统一放到目录.tmp下。这个过程因为涉及到磁盘IO操作，因此相对比较耗时。</p>
</li>
<li>commit阶段：遍历所有Memstore，将flush阶段生成的临时文件移到指定的ColumnFamily目录下，针对HFile生成对应的storefile和Reader，把storefile添加到HStore的storefiles列表中，最后再<strong>清空</strong>prepare阶段生成的snapshot。</li>
</ul>
</li>
</ul>
<h3 id="Compact合并机制"><a href="#Compact合并机制" class="headerlink" title="Compact合并机制"></a>Compact合并机制</h3><ul>
<li>hbase为了==防止小文件过多==，以保证查询效率，hbase需要在必要的时候将这些小的store file合并成相对较大的store file，这个过程就称之为compaction。</li>
</ul>
<h4 id="minor-compaction"><a href="#minor-compaction" class="headerlink" title="minor compaction"></a>minor compaction</h4><ul>
<li><p>在将Store中多个HFile合并为一个HFile</p>
<p>在这个过程中会选取一些小的、相邻的StoreFile将他们合并成一个更大的StoreFile，对于超过了TTL的数据、更新的数据、删除的数据仅仅只是做了标记。并没有进行物理删除，一次Minor Compaction的结果是更少并且更大的StoreFile。这种合并的触发频率很高。</p>
</li>
<li><p>minor compaction触发条件由以下几个参数共同决定：</p>
</li>
</ul>
<pre><code class="xml">&lt;!--表示至少需要三个满足条件的store file时，minor compaction才会启动--&gt;
&lt;property&gt;
    &lt;name&gt;hbase.hstore.compactionThreshold&lt;/name&gt;
    &lt;value&gt;3&lt;/value&gt;
&lt;/property&gt;

&lt;!--表示一次minor compaction中最多选取10个store file--&gt;
&lt;property&gt;
    &lt;name&gt;hbase.hstore.compaction.max&lt;/name&gt;
    &lt;value&gt;10&lt;/value&gt;
&lt;/property&gt;

&lt;!--默认值为128m,
表示文件大小小于该值的store file 一定会加入到minor compaction的store file中
--&gt;
&lt;property&gt;
    &lt;name&gt;hbase.hstore.compaction.min.size&lt;/name&gt;
    &lt;value&gt;134217728&lt;/value&gt;
&lt;/property&gt;

&lt;!--默认值为LONG.MAX_VALUE，
表示文件大小大于该值的store file 一定会被minor compaction排除--&gt;
&lt;property&gt;
    &lt;name&gt;hbase.hstore.compaction.max.size&lt;/name&gt;
    &lt;value&gt;9223372036854775807&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<h4 id="major-compaction"><a href="#major-compaction" class="headerlink" title="major compaction"></a>major compaction</h4><ul>
<li><p>合并Store中所有的HFile为一个HFile</p>
<p>将所有的StoreFile合并成一个StoreFile，这个过程还会清理三类无意义数据：被删除的数据、TTL过期数据、版本号超过设定版本号的数据。合并频率比较低，默认7天执行一次，并且性能消耗非常大，建议生产关闭(设置为0)，在应用空闲时间手动触发。一般可以是手动控制进行合并，防止出现在业务高峰期。</p>
</li>
<li><p>major compaction触发时间条件</p>
<pre><code class="xml">&lt;!--默认值为7天进行一次大合并，--&gt;
&lt;property&gt;
    &lt;name&gt;hbase.hregion.majorcompaction&lt;/name&gt;
    &lt;value&gt;604800000&lt;/value&gt;
&lt;/property&gt;
</code></pre>
</li>
<li><p>手动触发</p>
<pre><code class="ruby">##使用major_compact命令
major_compact tableName
</code></pre>
</li>
</ul>
<h2 id="region-拆分机制"><a href="#region-拆分机制" class="headerlink" title="region 拆分机制"></a>region 拆分机制</h2><ul>
<li><p>region中存储的是大量的rowkey数据 ,当region中的数据条数过多的时候,直接影响查询效率.当region过大的时候.hbase会拆分region , 这也是Hbase的一个优点 .</p>
</li>
<li><p>HBase的region split策略一共有以下几种：</p>
</li>
</ul>
<ul>
<li><p>1、<strong>ConstantSizeRegionSplitPolicy</strong></p>
<ul>
<li>0.94版本前默认切分策略</li>
</ul>
</li>
<li><p>当region大小大于某个阈值(hbase.hregion.max.filesize=10G)之后就会触发切分，一个region等分为2个region。</p>
<ul>
<li>但是在生产线上这种切分策略却有相当大的弊端：切分策略对于大表和小表没有明显的区分。阈值(hbase.hregion.max.filesize)设置较大对大表比较友好，但是小表就有可能不会触发分裂，极端情况下可能就1个，这对业务来说并不是什么好事。如果设置较小则对小表友好，但一个大表就会在整个集群产生大量的region，这对于集群的管理、资源使用、failover来说都不是一件好事。</li>
</ul>
</li>
<li><p>2、<strong>IncreasingToUpperBoundRegionSplitPolicy</strong></p>
<ul>
<li>0.94版本~2.0版本默认切分策略</li>
</ul>
<ul>
<li><p>切分策略稍微有点复杂，总体看和ConstantSizeRegionSplitPolicy思路相同，一个region大小大于设置阈值就会触发切分。但是这个阈值并不像ConstantSizeRegionSplitPolicy是一个固定的值，而是会在一定条件下不断调整，调整规则和region所属表在当前regionserver上的region个数有关系.</p>
</li>
<li><p>region split的计算公式是：<br>regioncount^3 <em> 128M </em> 2，当region达到该size的时候进行split<br>例如：<br>第一次split：1^3 <em> 256 = 256MB<br>第二次split：2^3 </em> 256 = 2048MB<br>第三次split：3^3 <em> 256 = 6912MB<br>第四次split：4^3 </em> 256 = 16384MB &gt; 10GB，因此取较小的值10GB<br>后面每次split的size都是10GB了</p>
</li>
</ul>
</li>
<li><p>3、<strong>SteppingSplitPolicy</strong></p>
<ul>
<li>2.0版本默认切分策略</li>
</ul>
<ul>
<li>这种切分策略的切分阈值又发生了变化，相比 IncreasingToUpperBoundRegionSplitPolicy 简单了一些，依然和待分裂region所属表在当前regionserver上的region个数有关系，如果region个数等于1，<br>切分阈值为flush size * 2，否则为MaxRegionFileSize。这种切分策略对于大集群中的大表、小表会比 IncreasingToUpperBoundRegionSplitPolicy 更加友好，小表不会再产生大量的小region，而是适可而止。</li>
</ul>
</li>
<li><p>4、<strong>KeyPrefixRegionSplitPolicy</strong></p>
<ul>
<li>根据rowKey的前缀对数据进行分组，这里是指定rowKey的前多少位作为前缀，比如rowKey都是16位的，指定前5位是前缀，那么前5位相同的rowKey在进行region split的时候会分到相同的region中。</li>
</ul>
</li>
<li><p>5、<strong>DelimitedKeyPrefixRegionSplitPolicy</strong></p>
<ul>
<li>保证相同前缀的数据在同一个region中，例如rowKey的格式为：userid_eventtype_eventid，指定的delimiter为 _ ，则split的的时候会确保userid相同的数据在同一个region中。</li>
</ul>
</li>
</ul>
<ul>
<li>6、<strong>DisabledRegionSplitPolicy</strong><ul>
<li>不启用自动拆分, 需要指定手动拆分</li>
</ul>
</li>
</ul>
<h2 id="表的预分区"><a href="#表的预分区" class="headerlink" title="表的预分区"></a>表的预分区</h2><ul>
<li>当一个table刚被创建的时候，Hbase默认的分配一个region给table。也就是说这个时候，所有的读写请求都会访问到同一个regionServer的同一个region中，这个时候就达不到负载均衡的效果了，集群中的其他regionServer就可能会处于比较空闲的状态。<ul>
<li>解决这个问题可以用<strong>pre-splitting</strong>,在创建table的时候就配置好，生成多个region。</li>
</ul>
</li>
<li><p>为何要预分区？</p>
<ul>
<li>增加数据读写效率</li>
<li>负载均衡，防止数据倾斜</li>
<li>方便集群容灾调度region</li>
<li>优化Map数量</li>
</ul>
</li>
<li><p>每一个region维护着startRow与endRowKey，如果加入的数据符合某个region维护的rowKey范围，则该数据交给这个region维护。</p>
</li>
</ul>
<pre><code class="ruby">-- 创建表，指定预分区
create &#39;person&#39;,&#39;info1&#39;,&#39;info2&#39;,SPLITS =&gt; [&#39;1000&#39;,&#39;2000&#39;,&#39;3000&#39;,&#39;4000&#39;]

-- 根据文件内容预分区
cat /kfly/install/split.txt
  aaa
  bbb
  ccc
  ddd
create &#39;student&#39;,&#39;info&#39;,SPLITS_FILE =&gt; &#39;/kfly/install/split.txt&#39;
</code></pre>
<ul>
<li><p>HexStringSplit 算法</p>
<ul>
<li>HexStringSplit会将数据从“00000000”到“FFFFFFFF”之间的数据长度按照<strong>n等分</strong>之后算出每一段的其实rowkey和结束rowkey，以此作为拆分点。</li>
</ul>
<pre><code class="ruby">create &#39;mytable&#39;, &#39;base_info&#39;,&#39; extra_info&#39;, {NUMREGIONS =&gt; 15, SPLITALGO =&gt; &#39;HexStringSplit&#39;}
</code></pre>
</li>
</ul>
<p><img src="http://kflys.gitee.io/upic/2020/04/01/uPic/hbase/assets/hbasePreSplit.png" alt="hbasePreSplit" style="zoom:50%;"></p>
<h2 id="region-合并"><a href="#region-合并" class="headerlink" title="region 合并"></a>region 合并</h2><ul>
<li>Region的合并不是为了性能,  而是出于维护的目的 .</li>
<li>比如删除了大量的数据 ,这个时候每个Region都变得很小 ,存储多个Region就浪费了 ,这个时候可以把Region合并起来，进而可以减少一些Region服务器节点 </li>
<li><p>通过Merge类冷合并Region</p>
<ul>
<li><p>执行合并前，==需要先关闭hbase集群==</p>
</li>
<li><p>创建一张hbase表：</p>
</li>
</ul>
</li>
</ul>
<pre><code class="ruby">create &#39;test&#39;,&#39;info1&#39;,SPLITS =&gt; [&#39;1000&#39;,&#39;2000&#39;,&#39;3000&#39;]
</code></pre>
<ul>
<li>查看表region</li>
</ul>
<p><img src="http://kflys.gitee.io/upic/2020/04/01/uPic/hbase/assets/testRegion.png" alt="testRegion"></p>
<ul>
<li>需求：</li>
</ul>
<ul>
<li>这里通过org.apache.hadoop.hbase.util.Merge类来实现，不需要进入hbase shell，直接执行（==<strong>需要先关闭hbase集群</strong>==）：</li>
</ul>
<pre><code class="shell">  # 需要把test表中的2个region数据进行合并：test,,1565940912661.62d28d7d20f18debd2e7dac093bc09d8.  test,1000,1565940912661.5b6f9e8dad3880bcc825826d12e81436.

  hbase org.apache.hadoop.hbase.util.Merge test test,,1565940912661.62d28d7d20f18debd2e7dac093bc09d8. test,1000,1565940912661.5b6f9e8dad3880bcc825826d12e81436.
</code></pre>
<ul>
<li>成功后界面观察</li>
</ul>
<p><img src="http://kflys.gitee.io/upic/2020/04/01/uPic/hbase/assets/testMerge.png" alt="testMerge"></p>
<ul>
<li><p>通过online_merge热合并Region</p>
<ul>
<li><p>==不需要关闭hbase集群==，在线进行合并</p>
</li>
<li><p>与冷合并不同的是，online_merge的传参是Region的hash值，而Region的hash值就是Region名称的最后那段在两个.之间的字符串部分。</p>
</li>
<li><p>需求：需要把test表中的2个region数据进行合并：<br>test,2000,1565940912661.c2212a3956b814a6f0d57a90983a8515.<br>test,3000,1565940912661.553dd4db667814cf2f050561167ca030.</p>
</li>
<li><p>需要进入hbase shell：</p>
</li>
</ul>
<pre><code class="ruby">merge_region &#39;c2212a3956b814a6f0d57a90983a8515&#39;,&#39;553dd4db667814cf2f050561167ca030&#39;
</code></pre>
<ul>
<li>成功后观察界面</li>
</ul>
</li>
</ul>
<p><img src="http://kflys.gitee.io/upic/2020/04/01/uPic/hbase/assets/online_merge.png" alt="online_merge"></p>
<h2 id="HBase集成MapReduce"><a href="#HBase集成MapReduce" class="headerlink" title="HBase集成MapReduce"></a>HBase集成MapReduce</h2><ul>
<li><p>HBase表中的数据最终都是存储在HDFS上，HBase天生的支持MR的操作，我们可以通过MR直接处理HBase表中的数据，并且MR可以将处理后的结果直接存储到HBase表中。</p>
<ul>
<li>参考地址：&lt;<a href="http://hbase.apache.org/book.html#mapreduce" target="_blank" rel="noopener">http://hbase.apache.org/book.html#mapreduce</a></li>
</ul>
</li>
<li><p>需求：==读取HBase当中myuser这张表的数据，将数据写入到另外一张myuser2表里面去==</p>
</li>
</ul>
<pre><code class="xml"> &lt;dependency&gt;
   &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
   &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;
   &lt;version&gt;2.6.0-mr1-cdh5.14.2&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
  &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;
  &lt;artifactId&gt;hbase-client&lt;/artifactId&gt;
  &lt;version&gt;1.2.0-cdh5.14.2&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
  &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;
  &lt;artifactId&gt;hbase-server&lt;/artifactId&gt;
  &lt;version&gt;1.2.0-cdh5.14.2&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<pre><code class="java">class HBaseMapper extends TableMapper&lt;Text,Put&gt;{
  protected void map(ImmutableBytesWritable key, Result value, Context context){
    // key get rowKey
    // result -&gt; put
    context.write(new Text(rowkey),put);
  }
}
class HbaseReducer extends TableReducer&lt;Text,Put,ImmutableBytesWritable&gt;{
  protected void reduce(Text key, Iterable&lt;Put&gt; values, Context context){
    for (Put put : values) {
      context.write(null,put);
    }
  }
}
public static void main(String[] args){
        Configuration conf = new Configuration();
        Scan scan = new Scan();
        Job job = Job.getInstance(conf);
        job.setJarByClass(HBaseMR.class);
        //使用TableMapReduceUtil 工具类来初始化我们的mapper
      TableMapReduceUtil.initTableMapperJob(
                                            TableName.valueOf(args[0]),
                                            scan,
                                            HBaseMapper.class,
                                            Text.class,
                                            Put.class,
                                            job
                                                                              );
        //使用TableMapReduceUtil 工具类来初始化我们的reducer
        TableMapReduceUtil.initTableReducerJob(
                                                                      args[1],
                                                                      HbaseReducer.class,
                                                                      job);
        //设置reduce task个数
        job.setNumReduceTasks(1);
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
</code></pre>
<pre><code class="shell"># 打成jar包提交到集群中运行
hadoop jar hbase_java_api-1.0-SNAPSHOT.jar com.kaikeba.HBaseMR t1 t2
</code></pre>
<ul>
<li><p>需求</p>
<ul>
<li>==通过bulkload的方式批量加载数据到HBase表中==</li>
<li>==将我们hdfs上面的这个路径/hbase/input/user.txt的数据文件，转换成HFile格式，然后load到myuser2这张表里面去==</li>
</ul>
</li>
<li><p>知识点描述</p>
<ul>
<li>加载数据到HBase当中去的方式多种多样，我们可以使用HBase的javaAPI或者使用sqoop将我们的数据写入或者导入到HBase当中去，但是这些方式不是慢就是在导入的过程的占用Region资源导致效率低下</li>
<li>我们也可以通过MR的程序，将我们的数据直接转换成HBase的最终存储格式HFile，然后直接load数据到HBase当中去即可</li>
</ul>
</li>
<li><p>HBase数据正常写流程回顾</p>
<p><img src="http://kflys.gitee.io/upic/2020/04/01/uPic/hbase/assets/hbase-write.png" alt="hbase-write"></p>
</li>
<li><p>bulkload方式的处理示意图</p>
</li>
</ul>
<p><img src="http://kflys.gitee.io/upic/2020/04/01/uPic/hbase/assets/bulkload.png" alt=""></p>
<ul>
<li><p>好处</p>
<ul>
<li>导入过程不占用Region资源</li>
<li>能快速导入海量的数据</li>
<li>节省内存</li>
</ul>
</li>
<li><p>==1、开发生成HFile文件的代码==</p>
</li>
</ul>
<pre><code class="java">// 1. map阶段
context.write(new ImmutableBytesWritable(Bytes.toBytes(split[0])),put);

// 2. main job
Configuration conf = HBaseConfiguration.create();
Connection connection = ConnectionFactory.createConnection(conf);
job.setMapOutputKeyClass(ImmutableBytesWritable.class);
job.setMapOutputValueClass(Put.class);
//指定输出的类型HFileOutputFormat2
job.setOutputFormatClass(HFileOutputFormat2.class);
HFileOutputFormat2
  .configureIncrementalLoad(
                            job,
                            table,                                                       
                            conn.getRegionLocator(TableName.valueOf(&quot;t4&quot;))
                                                            );
// 3. 加载数据使用java Api
Table table = connection.getTable(tableName);
//构建LoadIncrementalHFiles加载HFile文件
LoadIncrementalHFiles load = new LoadIncrementalHFiles(configuration);
load.doBulkLoad(new Path(&quot;hdfs://node01:8020/hbase/output_file&quot;);

// 加载数据命令加载,先将hbase的jar包添加到hadoop的classpath路径下
export HBASE_HOME=/kfly/install/hbase-1.2.0-cdh5.14.2/
export HADOOP_HOME=/kfly/install/hadoop-2.6.0/
export HADOOP_CLASSPATH=`${HBASE_HOME}/bin/hbase mapredcp`

yarn jar /kfly/install/hbase-1.2.0-cdh5.14.2/lib/hbase-server-1.2.0-cdh5.14.2.jar   completebulkload /hbase/output_hfile myuser2
</code></pre>
<pre><code class="shell">hadoop jar hbase_java_api-1.0-SNAPSHOT.jar com.kaikeba.HBaseLoad
</code></pre>
<h2 id="HBase集成Hive"><a href="#HBase集成Hive" class="headerlink" title="HBase集成Hive"></a>HBase集成Hive</h2><ul>
<li>Hive提供了与HBase的集成，使得能够在HBase表上使用hive sql 语句进行查询、插入操作以及进行Join和Union等复杂查询，同时也可以将hive表中的数据映射到Hbase中</li>
</ul>
<h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><ul>
<li><p>Hive</p>
<ul>
<li><p>数据仓库</p>
<ul>
<li>​    Hive的本质其实就相当于将HDFS中已经存储的文件在Mysql中做了一个双射关系，以方便使用HQL去管理查询。</li>
</ul>
</li>
<li><p>用于数据分析、清洗                </p>
<ul>
<li>​    Hive适用于离线的数据分析和清洗，延迟较高</li>
</ul>
</li>
<li><p>基于HDFS、MapReduce</p>
<ul>
<li>​    Hive存储的数据依旧在DataNode上，编写的HQL语句终将是转换为MapReduce代码执行。（不要钻不需要执行MapReduce代码的情况的牛角尖）</li>
</ul>
</li>
</ul>
</li>
<li><p>HBase</p>
<ul>
<li><p>数据库</p>
<ul>
<li>是一种面向列存储的非关系型数据库。</li>
</ul>
</li>
<li><p>用于存储结构化和非结构话的数据</p>
<ul>
<li>适用于单表非关系型数据的存储，不适合做关联查询，类似JOIN等操作。</li>
</ul>
</li>
<li><p>基于HDFS</p>
<ul>
<li>数据持久化存储的体现形式是Hfile，存放于DataNode中，被ResionServer以region的形式进行管理。</li>
</ul>
</li>
<li><p>延迟较低，接入在线业务使用</p>
<ul>
<li>面对大量的企业数据，HBase可以直线单表大量数据的存储，同时提供了高效的数据访问速度。</li>
</ul>
</li>
</ul>
</li>
<li><p>Hive和Hbase是两种基于Hadoop的不同技术，Hive是一种类SQL的引擎，并且运行MapReduce任务，Hbase是一种在Hadoop之上的NoSQL 的Key/vale数据库。这两种工具是可以同时使用的。就像用Google来搜索，用FaceBook进行社交一样，Hive可以用来进行统计查询，HBase可以用来进行实时查询，数据也可以从Hive写到HBase，或者从HBase写回Hive。</p>
</li>
</ul>
<h4 id="拷贝jar包"><a href="#拷贝jar包" class="headerlink" title="拷贝jar包"></a>拷贝jar包</h4><ul>
<li><p>将我们HBase的五个jar包拷贝到hive的lib目录下</p>
</li>
<li><p>hbase的jar包都在/kfly/install/hbase-1.2.0-cdh5.14.2/lib</p>
</li>
<li><p>我们需要拷贝五个jar包名字如下</p>
</li>
</ul>
<pre><code>hbase-client-1.2.0-cdh5.14.2.jar                  
hbase-hadoop2-compat-1.2.0-cdh5.14.2.jar 
hbase-hadoop-compat-1.2.0-cdh5.14.2.jar  
hbase-it-1.2.0-cdh5.14.2.jar    
hbase-server-1.2.0-cdh5.14.2.jar
</code></pre><ul>
<li>我们直接在node03执行以下命令，通过创建软连接的方式来进行jar包的依赖</li>
</ul>
<pre><code class="shell">ln -s /kfly/install/hbase-1.2.0-cdh5.14.2/lib/hbase-client-1.2.0-cdh5.14.2.jar              /kfly/install/hive-1.1.0-cdh5.14.2/lib/hbase-client-1.2.0-cdh5.14.2.jar   
</code></pre>
<h4 id="修改hive-site-xml"><a href="#修改hive-site-xml" class="headerlink" title="修改hive-site.xml"></a>修改hive-site.xml</h4><ul>
<li>添加以下两个属性的配置</li>
</ul>
<pre><code class="xml">&lt;property&gt;
        &lt;name&gt;hive.zookeeper.quorum&lt;/name&gt;
        &lt;value&gt;node01,node02,node03&lt;/value&gt;
&lt;/property&gt;
 &lt;property&gt;
        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
        &lt;value&gt;node01,node02,node03&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<h4 id="修改hive-env-sh"><a href="#修改hive-env-sh" class="headerlink" title="修改hive-env.sh"></a>修改hive-env.sh</h4><pre><code>export HADOOP_HOME=/export/servers/hadoop-2.6.0
export HBASE_HOME=/export/servers/hbase-1.2.0-cdh5.14.2
export HIVE_CONF_DIR=/export/servers/hive-1.1.0-cdh5.14.2/conf
</code></pre><h3 id="hive建表同步到hbase"><a href="#hive建表同步到hbase" class="headerlink" title="hive建表同步到hbase"></a>hive建表同步到hbase</h3><pre><code class="mysql">-- hive当中建表
create external table if not exists course.score(id int,cname string,score int) row format delimited fields terminated by &#39;\t&#39; stored as textfile ;
-- 加载数据到hive
load data local inpath &#39;/kfly/doc/hive-hbase.txt&#39; into table score;
-- 创建hive管理表与HBase映射
create table course.hbase_score(id int,cname string,score int) stored by &#39;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#39;  with serdeproperties(&quot;hbase.columns.mapping&quot; = &quot;cf:name,cf:score&quot;) tblproperties(&quot;hbase.table.name&quot; = &quot;hbase_score&quot;);
</code></pre>
<h3 id="hive外部表映射HBase表模型"><a href="#hive外部表映射HBase表模型" class="headerlink" title="hive外部表映射HBase表模型"></a>hive外部表映射HBase表模型</h3><pre><code class="sql">-- 创建一张hbase表
create &#39;hbase_hive_score&#39;,{ NAME =&gt;&#39;cf&#39;}
-- 建立hive的外部表，映射HBase当中的表以及字段
CREATE external TABLE course.hbase2hive(id int, name string, score int) STORED BY &#39;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#39; WITH SERDEPROPERTIES (&quot;hbase.columns.mapping&quot; = &quot;:key,cf:name,cf:score&quot;) TBLPROPERTIES(&quot;hbase.table.name&quot; =&quot;hbase_hive_score&quot;);
</code></pre>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a href="https://blog.sev7e0.site/">大数据施工现场</a></span>
        <span>/</span>
        
        <span><a href="https://wangchujiang.com/linux-command/">linux命令行工具</a></span>
        <span>/</span>
        
        <span><a href="https://github.com/orchid-ding">github</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script src="/js/gitment.js"></script>
<script>
    var gitment = new Gitment({
        id: '',
        owner: 'orchid-ding',
        repo: 'kfly-blog-comment',
        oauth: {
            client_id: '0770cdab79393197b6f5',
            client_secret: '376fb6c7bcd5047718b356712f596b89e490360c',
        },
    })
    gitment.render('comment-container')
</script>




</html>
