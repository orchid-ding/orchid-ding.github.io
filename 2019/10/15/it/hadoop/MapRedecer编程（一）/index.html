<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="天行健、君子以自强不息；地势坤，君子以厚德载物。">
    <meta name="keyword"  content="兰草">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        MapRedecer编程（一） - kfly的博客 | kfly&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_1598291_q3el2wqimj.css" type="text/css">
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>kfly</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont iconhome"></i>
                    <span>主页</span>
                </a>
            </li>
 	   <li >
                <a href="/spec/">
                    <i class="iconfont iconzhuanti"></i>
                    <span>专题</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>简历</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#MapReduce编程模型"><span class="toc-text">MapReduce编程模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#一、知识要点"><span class="toc-text">一、知识要点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-MapReduce编程模型"><span class="toc-text">1. MapReduce编程模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-Map阶段"><span class="toc-text">1.1 Map阶段</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-Reduce阶段"><span class="toc-text">1.2 Reduce阶段</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-Map-amp-Reduce"><span class="toc-text">1.3 Map&amp;Reduce</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-MapReduce编程示例"><span class="toc-text">2. MapReduce编程示例</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-MapReduce原理图"><span class="toc-text">2.1 MapReduce原理图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-MR中key的作用"><span class="toc-text">2.2 MR中key的作用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-MR参考代码"><span class="toc-text">2.4 MR参考代码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-5-集群运行"><span class="toc-text">2.5 集群运行</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-6-总结"><span class="toc-text">2.6 总结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-WEB-UI查看结果"><span class="toc-text">3. WEB UI查看结果</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-Yarn"><span class="toc-text">3.1 Yarn</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-HDFS结果"><span class="toc-text">3.2 HDFS结果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-Shuffle"><span class="toc-text">4. Shuffle</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-shuffle简图"><span class="toc-text">4.1 shuffle简图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-shuffle细节图"><span class="toc-text">4.2 shuffle细节图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-map端"><span class="toc-text">4.3 map端</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-reduce端"><span class="toc-text">4.4 reduce端</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-5-总结"><span class="toc-text">4.5 总结</span></a></li></ol></li></ol></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        MapRedecer编程（一）
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2019-10-15 23:11:32</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#hadoop" title="hadoop">hadoop</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#MapReduce" title="MapReduce">MapReduce</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <h1 id="MapReduce编程模型"><a href="#MapReduce编程模型" class="headerlink" title="MapReduce编程模型"></a>MapReduce编程模型</h1><h2 id="一、知识要点"><a href="#一、知识要点" class="headerlink" title="一、知识要点"></a>一、知识要点</h2><h3 id="1-MapReduce编程模型"><a href="#1-MapReduce编程模型" class="headerlink" title="1. MapReduce编程模型"></a>1. MapReduce编程模型</h3><ul>
<li><p>Hadoop架构图</p>
<p>Hadoop由HDFS分布式存储、<strong>MapReduce分布式计算</strong>、Yarn资源调度三部分组成</p>
</li>
</ul>
<p><img src="assets/Image201906191834-1562922704761.png" alt=""></p>
<ul>
<li>MapReduce是采用一种<strong>分而治之</strong>的思想设计出来的分布式计算框架</li>
<li>MapReduce由两个阶段组成：<ul>
<li>Map阶段（切分成一个个小的任务）</li>
<li>Reduce阶段（汇总小任务的结果）</li>
</ul>
</li>
<li>那什么是分而治之呢？<ul>
<li>比如一复杂、计算量大、耗时长的的任务，暂且称为“大任务”；</li>
<li>此时使用单台服务器无法计算或较短时间内计算出结果时，可将此大任务切分成一个个小的任务，小任务分别在不同的服务器上<strong>并行</strong>的执行</li>
<li>最终再汇总每个小任务的结果</li>
</ul>
</li>
</ul>
<p><img src="assets/Image201906251747.png" alt=""></p>
<h4 id="1-1-Map阶段"><a href="#1-1-Map阶段" class="headerlink" title="1.1 Map阶段"></a>1.1 Map阶段</h4><ul>
<li>map阶段有一个关键的map()函数；</li>
<li>此函数的输入是<strong>键值对</strong></li>
<li>输出是一系列<strong>键值对</strong>，输出写入<strong>本地磁盘</strong>。</li>
</ul>
<h4 id="1-2-Reduce阶段"><a href="#1-2-Reduce阶段" class="headerlink" title="1.2 Reduce阶段"></a>1.2 Reduce阶段</h4><ul>
<li><p>reduce阶段有一个关键的函数reduce()函数</p>
</li>
<li><p>此函数的输入也是键值对（即map的输出（kv对））</p>
</li>
<li><p>输出也是一系列键值对，结果最终写入HDFS</p>
</li>
</ul>
<h4 id="1-3-Map-amp-Reduce"><a href="#1-3-Map-amp-Reduce" class="headerlink" title="1.3 Map&amp;Reduce"></a>1.3 Map&amp;Reduce</h4><p><img src="assets/Image201906251807.png" alt=""></p>
<h3 id="2-MapReduce编程示例"><a href="#2-MapReduce编程示例" class="headerlink" title="2. MapReduce编程示例"></a>2. MapReduce编程示例</h3><ul>
<li>以<strong>MapReduce的词频统计</strong>为例：统计一批英文文章当中，每个单词出现的总次数</li>
</ul>
<h4 id="2-1-MapReduce原理图"><a href="#2-1-MapReduce原理图" class="headerlink" title="2.1 MapReduce原理图"></a>2.1 MapReduce原理图</h4><p><img src="assets/Image201906271715.png" alt=""></p>
<ul>
<li>Map阶段<ul>
<li>假设MR的输入文件“<strong>Gone With The Wind</strong>”有三个block；block1、block2、block3 </li>
<li>MR编程时，每个block对应一个分片split</li>
<li>每一个split对应一个map任务（map task）</li>
<li>如图共3个map任务（map1、map2、map3）；这3个任务的逻辑一样，所以以第一个map任务（map1）为例分析 </li>
<li>map1读取block1的数据；一次读取block1的一行数据；<ul>
<li>产生键值对(key/value)，作为map()的参数传入，调用map()；</li>
<li>假设当前所读行是第一行</li>
<li>将当前所读行的行首相对于当前block开始处的字节偏移量作为key（0）</li>
<li>当前行的内容作为value（Dear Bear River）</li>
</ul>
</li>
<li>map()内<ul>
<li>(按需求，写业务代码)，将value当前行内容按空格切分，得到三个单词Dear | Bear | River</li>
<li>将每个单词变成键值对，输出出去(Dear, 1) | (Bear, 1) | (River, 1)；最终结果写入map任务所在节点的本地磁盘中（内里还有细节，讲到shuffle时，再细细展开）</li>
<li>block的第一行的数据被处理完后，接着处理第二行；逻辑同上</li>
<li>当map任务将当前block中所有的数据全部处理完后，此map任务即运行结束</li>
</ul>
</li>
<li>其它的每一个map任务都是如上逻辑，不再赘述</li>
</ul>
</li>
<li>Reduce阶段<ul>
<li>reduce任务（reduce task）的个数由自己写的程序编程指定，main()内的job.setNumReduceTasks(4)指定reduce任务是4个（reduce1、reduce2、reduce3、reduce4）</li>
<li>每一个reduce任务的逻辑一下，所以以第一个reduce任务（reduce1）为例分析</li>
<li>map1任务完成后，reduce1通过网络，连接到map1，将map1输出结果中属于reduce1的分区的数据，通过网络获取到reduce1端（拷贝阶段）</li>
<li>同样也如此连接到map2、map3获取结果</li>
<li>最终reduce1端获得4个(Dear, 1)键值对；由于key键相同，它们分到同一组；</li>
<li>4个(Dear, 1)键值对，转换成[Dear, Iterable(1, 1, 1, )]，作为两个参数传入reduce()</li>
<li>在reduce()内部，计算Dear的总数为4，并将(Dear, 4)作为键值对输出</li>
<li>每个reduce任务最终输出文件（内里还有细节，讲到shuffle时，再细细展开），文件写入到HDFS</li>
</ul>
</li>
</ul>
<h4 id="2-2-MR中key的作用"><a href="#2-2-MR中key的作用" class="headerlink" title="2.2 MR中key的作用"></a>2.2 MR中key的作用</h4><ul>
<li><font color="red"><strong>MapReduce编程中，key有特殊的作用</strong></font>

<ul>
<li><p><strong>①数据中，若要针对某个值进行分组、聚合时，需将此值作为MR中的reduce的输入的key</strong></p>
</li>
<li><p><strong>如当前的词频统计例子，按单词进行分组，每组中对出现次数做聚合（计算总和）；所以需要将每个单词作为reduce输入的key，MapReduce框架自动按照单词分组，进而求出每组即每个单词的总次数</strong></p>
<p><img src="/Users/dingchuangshi/Documents/Java大数据课件/三期课件/第九章MapReduce课件/20191014-MR-第一次/assets/Image201910141101.png" alt=""></p>
</li>
<li><p><strong>②另外，key还具有可排序的特性，因为MR中的key类需要实现WritableComparable接口；而此接口又继承Comparable接口（可查看源码）</strong></p>
</li>
<li><p><strong>MR编程时，要充分利用以上两点；结合实际业务需求，设置合适的key</strong></p>
<p><img src="/Users/dingchuangshi/Documents/Java大数据课件/三期课件/第九章MapReduce课件/20191014-MR-第一次/assets/Image201908221717.png" alt=""></p>
<p><img src="/Users/dingchuangshi/Documents/Java大数据课件/三期课件/第九章MapReduce课件/20191014-MR-第一次/assets/Image201908221718.png" alt=""></p>
</li>
</ul>
</li>
</ul>
<h4 id="2-4-MR参考代码"><a href="#2-4-MR参考代码" class="headerlink" title="2.4 MR参考代码"></a>2.4 MR参考代码</h4><p><strong>2.4.1 Mapper代码</strong></p>
<pre><code class="java">package com.kaikeba.hadoop.wordcount;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

/**
 * 类Mapper&lt;LongWritable, Text, Text, IntWritable&gt;的四个泛型分别表示
 * map方法的输入的键的类型kin、值的类型vin；输出的键的类型kout、输出的值的类型vout
 * kin指的是当前所读行行首相对于split分片开头的字节偏移量,所以是long类型，对应序列化类型LongWritable
 * vin指的是当前所读行，类型是String，对应序列化类型Text
 * kout根据需求，输出键指的是单词，类型是String，对应序列化类型是Text
 * vout根据需求，输出值指的是单词的个数，1，类型是int，对应序列化类型是IntWritable
 *
 */
public class WordCountMap extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {

    /**
     * 处理分片split中的每一行的数据；针对每行数据，会调用一次map方法
     * 在一次map方法调用时，从一行数据中，获得一个个单词word，再将每个单词word变成键值对形式(word, 1)输出出去
     * 输出的值最终写到本地磁盘中
     * @param key 当前所读行行首相对于split分片开头的字节偏移量
     * @param value  当前所读行
     * @param context
     * @throws IOException
     * @throws InterruptedException
     */
    public void map(LongWritable key, Text value, Context context)
            throws IOException, InterruptedException {
        //当前行的示例数据(单词间空格分割)：Dear Bear River
        //取得当前行的数据
        String line = value.toString();
        //按照\t进行分割，得到当前行所有单词
        String[] words = line.split(&quot;\t&quot;);

        for (String word : words) {
            //将每个单词word变成键值对形式(word, 1)输出出去
            //同样，输出前，要将kout, vout包装成对应的可序列化类型，如String对应Text，int对应IntWritable
            context.write(new Text(word), new IntWritable(1));
        }
    }
}

</code></pre>
<p><strong>2.4.2 Reducer代码</strong></p>
<pre><code class="java">package com.kaikeba.hadoop.wordcount;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;

/**
 *
 * Reducer&lt;Text, IntWritable, Text, IntWritable&gt;的四个泛型分别表示
 * reduce方法的输入的键的类型kin、输入值的类型vin；输出的键的类型kout、输出的值的类型vout
 * 注意：因为map的输出作为reduce的输入，所以此处的kin、vin类型分别与map的输出的键类型、值类型相同
 * kout根据需求，输出键指的是单词，类型是String，对应序列化类型是Text
 * vout根据需求，输出值指的是每个单词的总个数，类型是int，对应序列化类型是IntWritable
 *
 */
public class WordCountReduce extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    /**
     *
     * key相同的一组kv对，会调用一次reduce方法
     * 如reduce task汇聚了众多的键值对，有key是hello的键值对，也有key是spark的键值对，如下
     * (hello, 1)
     * (hello, 1)
     * (hello, 1)
     * (hello, 1)
     * ...
     * (spark, 1)
     * (spark, 1)
     * (spark, 1)
     *
     * 其中，key是hello的键值对被分成一组；merge成[hello, Iterable(1,1,1,1)]，调用一次reduce方法
     * 同样，key是spark的键值对被分成一组；merge成[spark, Iterable(1,1,1)]，再调用一次reduce方法
     *
     * @param key 当前组的key
     * @param values 当前组中，所有value组成的可迭代集和
     * @param context reduce上下文环境对象
     * @throws IOException
     * @throws InterruptedException
     */
    public void reduce(Text key, Iterable&lt;IntWritable&gt; values,
                          Context context) throws IOException, InterruptedException {
        //定义变量，用于累计当前单词出现的次数
        int sum = 0;

        for (IntWritable count : values) {
            //从count中获得值，累加到sum中
            sum += count.get();
        }

        //将单词、单词次数，分别作为键值对，输出
        context.write(key, new IntWritable(sum));// 输出最终结果
    };
}
</code></pre>
<p><strong>2.4.3 Main程序入口</strong></p>
<pre><code class="java">package com.kaikeba.hadoop.wordcount;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import java.io.IOException;

/**
 *
 * MapReduce程序入口
 * 注意：
 *  导包时，不要导错了；
 *  另外，map\reduce相关的类，使用mapreduce包下的，是新API，如org.apache.hadoop.mapreduce.Job;；
 */
public class WordCountMain {
    //若在IDEA中本地执行MR程序，需要将mapred-site.xml中的mapreduce.framework.name值修改成local
    //参数 c:/test/README.txt c:/test/wc
    public static void main(String[] args) throws IOException,
            ClassNotFoundException, InterruptedException {

        //判断一下，输入参数是否是两个，分别表示输入路径、输出路径
       if (args.length != 2 || args == null) {
            System.out.println(&quot;please input Path!&quot;);
            System.exit(0);
        }

        Configuration configuration = new Configuration();
        //configuration.set(&quot;mapreduce.framework.name&quot;,&quot;local&quot;);


        //告诉程序，要运行的jar包在哪
        //configuration.set(&quot;mapreduce.job.jar&quot;,&quot;/home/hadoop/IdeaProjects/Hadoop/target/com.kaikeba.hadoop-1.0-SNAPSHOT.jar&quot;);

        //调用getInstance方法，生成job实例
        Job job = Job.getInstance(configuration, WordCountMain.class.getSimpleName());

        //设置job的jar包，如果参数指定的类包含在一个jar包中，则此jar包作为job的jar包； 参数class跟主类在一个工程即可；一般设置成主类
//        job.setJarByClass(WordCountMain.class);
        job.setJarByClass(WordCountMain.class);

        //通过job设置输入/输出格式
        //MR的默认输入格式是TextInputFormat，输出格式是TextOutputFormat；所以下两行可以注释掉
//        job.setInputFormatClass(TextInputFormat.class);
//        job.setOutputFormatClass(TextOutputFormat.class);

        //设置输入/输出路径
        FileInputFormat.setInputPaths(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));

        //设置处理Map阶段的自定义的类
        job.setMapperClass(WordCountMap.class);
        //设置map combine类，减少网路传出量
        job.setCombinerClass(WordCountReduce.class);
        //设置处理Reduce阶段的自定义的类
        job.setReducerClass(WordCountReduce.class);
        //注意：如果map、reduce的输出的kv对类型一致，直接设置reduce的输出的kv对就行；如果不一样，需要分别设置map, reduce的输出的kv类型
        //注意：此处设置的map输出的key/value类型，一定要与自定义map类输出的kv对类型一致；否则程序运行报错
//        job.setMapOutputKeyClass(Text.class);
//        job.setMapOutputValueClass(IntWritable.class);

        //设置reduce task最终输出key/value的类型
        //注意：此处设置的reduce输出的key/value类型，一定要与自定义reduce类输出的kv对类型一致；否则程序运行报错
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        // 提交作业
        job.waitForCompletion(true);

    }
}
</code></pre>
<blockquote>
<p>程序运行有两种方式，分别是windows本地运行、集群运行，依次演示</p>
</blockquote>
<h4 id="2-5-集群运行"><a href="#2-5-集群运行" class="headerlink" title="2.5 集群运行"></a>2.5 集群运行</h4><ul>
<li>用maven插件打jar包；①点击Maven，②双击package打包</li>
</ul>
<pre><code class="shell">[hadoop@node01 ~]$ hadoop jar com.kaikeba.hadoop-1.0-SNAPSHOT.jar com.kaikeba.hadoop.wordcount.WordCountMain /README.txt /wordcount01
</code></pre>
<blockquote>
<p>说明：</p>
<p>com.kaikeba.hadoop-1.0-SNAPSHOT.jar是jar包名</p>
<p>com.kaikeba.hadoop.wordcount.WordCountMain是包含main方法的类的全限定名</p>
<p>/NOTICE.txt和/wordcount是main方法的两个参数，表示输入路径、输出路径</p>
</blockquote>
<p><img src="assets/hadoop jar.gif" alt=""></p>
<ul>
<li>确认结果</li>
</ul>
<pre><code class="shell">[hadoop@node01 ~]$ hadoop fs -ls /wordcount01
</code></pre>
<p><img src="assets/Image201908221620.png" alt=""></p>
<h4 id="2-6-总结"><a href="#2-6-总结" class="headerlink" title="2.6 总结"></a>2.6 总结</h4><ul>
<li>MR分为两个阶段：map阶段、reduce阶段</li>
<li>MR输入的文件有几个block，就会生成几个map任务</li>
<li>MR的reduce任务的个数，由程序中编程指定：job.setNumReduceTasks(4)</li>
<li>map任务<ul>
<li>map任务中map()一次读取block的一行数据，以kv对的形式输入map()</li>
<li>map()的输出作为reduce()的输入</li>
</ul>
</li>
<li>reduce任务<ul>
<li>reduce任务通过网络将各执行完成的map任务输出结果中，属于自己的数据取过来</li>
<li>key相同的键值对作为一组，调用一次reduce()</li>
<li>reduce任务生成一个结果文件</li>
<li>文件写入HDFS</li>
</ul>
</li>
</ul>
<h3 id="3-WEB-UI查看结果"><a href="#3-WEB-UI查看结果" class="headerlink" title="3. WEB UI查看结果"></a>3. WEB UI查看结果</h3><h4 id="3-1-Yarn"><a href="#3-1-Yarn" class="headerlink" title="3.1 Yarn"></a>3.1 Yarn</h4><blockquote>
<p>node01是resourcemanager所在节点主机名，根据自己的实际情况修改主机名</p>
</blockquote>
<p>浏览器访问url地址：<a href="http://node01:8088" target="_blank" rel="noopener">http://node01:8088</a></p>
<p><img src="assets/Image201908221638.png" alt=""></p>
<h4 id="3-2-HDFS结果"><a href="#3-2-HDFS结果" class="headerlink" title="3.2 HDFS结果"></a>3.2 HDFS结果</h4><p>浏览器输入URL：<a href="http://node01:50070" target="_blank" rel="noopener">http://node01:50070</a></p>
<p>①点击下拉框；②浏览文件系统；③输入根目录，查看hdfs根路径中的内容</p>
<p><img src="assets/Image201908221639.png" alt=""></p>
<h3 id="4-Shuffle"><a href="#4-Shuffle" class="headerlink" title="4. Shuffle"></a>4. Shuffle</h3><ul>
<li>shuffle主要指的是map端的输出作为reduce端输入的过程</li>
</ul>
<h4 id="4-1-shuffle简图"><a href="#4-1-shuffle简图" class="headerlink" title="4.1 shuffle简图"></a>4.1 shuffle简图</h4><p><img src="assets/Image201905231409.png" alt=""></p>
<h4 id="4-2-shuffle细节图"><a href="#4-2-shuffle细节图" class="headerlink" title="4.2 shuffle细节图"></a>4.2 shuffle细节图</h4><p><img src="assets/Image201906280906.png" alt=""></p>
<ul>
<li><p>分区用到了分区器，默认分区器是HashPartitioner</p>
<p>源码：</p>
<pre><code class="java">public class HashPartitioner&lt;K2, V2&gt; implements Partitioner&lt;K2, V2&gt; {

  public void configure(JobConf job) {}

  /** Use {@link Object#hashCode()} to partition. */
  public int getPartition(K2 key, V2 value,
                          int numReduceTasks) {
    return (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks;
  }

}
</code></pre>
</li>
</ul>
<h4 id="4-3-map端"><a href="#4-3-map端" class="headerlink" title="4.3 map端"></a>4.3 map端</h4><ul>
<li>每个map任务都有一个对应的环形内存缓冲区；输出是kv对，先写入到环形缓冲区（默认大小100M），当内容占据80%缓冲区空间后，由一个后台线程将缓冲区中的数据溢出写到一个磁盘文件</li>
<li>在溢出写的过程中，map任务可以继续向环形缓冲区写入数据；但是若写入速度大于溢出写的速度，最终造成100m占满后，map任务会暂停向环形缓冲区中写数据的过程；只执行溢出写的过程；直到环形缓冲区的数据全部溢出写到磁盘，才恢复向缓冲区写入</li>
<li>后台线程溢写磁盘过程，有以下几个步骤：<ul>
<li>先对每个溢写的kv对做分区；分区的个数由MR程序的reduce任务数决定；默认使用HashPartitioner计算当前kv对属于哪个分区；计算公式：(key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks</li>
<li>每个分区中，根据kv对的key做内存中排序；</li>
<li>若设置了map端本地聚合combiner，则对每个分区中，排好序的数据做combine操作；</li>
<li>若设置了对map输出压缩的功能，会对溢写数据压缩</li>
</ul>
</li>
<li>随着不断的向环形缓冲区中写入数据，会多次触发溢写（每当环形缓冲区写满100m），本地磁盘最终会生成多个溢出文件</li>
<li>合并溢写文件：在map task完成之前，所有溢出文件会被合并成一个大的溢出文件；且是已分区、已排序的输出文件</li>
<li>小细节：<ul>
<li>在合并溢写文件时，如果至少有3个溢写文件，并且设置了map端combine的话，会在合并的过程中触发combine操作；</li>
<li>但是若只有2个或1个溢写文件，则不触发combine操作（因为combine操作，本质上是一个reduce，需要启动JVM虚拟机，有一定的开销）</li>
</ul>
</li>
</ul>
<h4 id="4-4-reduce端"><a href="#4-4-reduce端" class="headerlink" title="4.4 reduce端"></a>4.4 reduce端</h4><ul>
<li><p>reduce task会在每个map task运行完成后，通过HTTP获得map task输出中，属于自己的分区数据（许多kv对）</p>
</li>
<li><p>如果map输出数据比较小，先保存在reduce的jvm内存中，否则直接写入reduce磁盘</p>
</li>
<li><p>一旦内存缓冲区达到阈值（默认0.66）或map输出数的阈值（默认1000），则触发<strong>归并merge</strong>，结果写到本地磁盘</p>
</li>
<li><p>若MR编程指定了combine，在归并过程中会执行combine操作</p>
</li>
<li><p>随着溢出写的文件的增多，后台线程会将它们合并大的、排好序的文件</p>
</li>
<li><p>reduce task将所有map task复制完后，将合并磁盘上所有的溢出文件</p>
</li>
<li><p>默认一次合并10个</p>
</li>
<li><p>最后一批合并，部分数据来自内存，部分来自磁盘上的文件</p>
</li>
<li><p>进入“归并、排序、分组阶段”</p>
</li>
<li><p>每组数据调用一次reduce方法</p>
</li>
<li><p>参考文件《<strong>reduce端merge 排序 分组.txt</strong>》</p>
</li>
</ul>
<h4 id="4-5-总结"><a href="#4-5-总结" class="headerlink" title="4.5 总结"></a>4.5 总结</h4><ul>
<li>map端<ul>
<li>map()输出结果先写入环形缓冲区</li>
<li>缓冲区100M；写满80M后，开始溢出写磁盘文件</li>
<li>此过程中，会进行分区、排序、combine（可选）、压缩（可选）</li>
<li>map任务完成前，会将多个小的溢出文件，合并成一个大的溢出文件（已分区、排序）</li>
</ul>
</li>
<li>reduce端<ul>
<li>拷贝阶段：reduce任务通过http将map任务属于自己的分区数据拉取过来</li>
<li>开始merge及溢出写磁盘文件</li>
<li>所有map任务的分区全部拷贝过来后，进行阶段合并、排序、分组阶段</li>
<li>每组数据调用一次reduce()</li>
<li>结果写入HDFS</li>
</ul>
</li>
</ul>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a href="https://blog.sev7e0.site/">大数据施工现场</a></span>
        <span>/</span>
        
        <span><a href="https://wangchujiang.com/linux-command/">linux命令行工具</a></span>
        <span>/</span>
        
        <span><a href="https://github.com/orchid-ding">github</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script src="/js/gitment.js"></script>
<script>
    var gitment = new Gitment({
        id: 'MapRedecer编程（一）',
        owner: 'orchid-ding',
        repo: 'kfly-blog-comment',
        oauth: {
            client_id: '0770cdab79393197b6f5',
            client_secret: '376fb6c7bcd5047718b356712f596b89e490360c',
        },
    })
    gitment.render('comment-container')
</script>




</html>
