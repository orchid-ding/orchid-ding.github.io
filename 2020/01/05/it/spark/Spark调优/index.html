<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="天行健、君子以自强不息；地势坤，君子以厚德载物。">
    <meta name="keyword"  content="兰草">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        Spark调优 - Kaffir Lily的博客 | Kaffir Lily&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_1598291_q3el2wqimj.css" type="text/css">
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>kfly</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont iconhome"></i>
                    <span>主页</span>
                </a>
            </li>
 	   <li >
                <a href="/spec/">
                    <i class="iconfont iconzhuanti"></i>
                    <span>专题</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>简历</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Spark调优"><span class="toc-text">Spark调优</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-分配更多的资源"><span class="toc-text">1. 分配更多的资源</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-分配哪些资源"><span class="toc-text">1.1 分配哪些资源</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-在哪里可以设置这些资源"><span class="toc-text">1.2 在哪里可以设置这些资源</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-参数调节到多大，算是最大"><span class="toc-text">1.3 参数调节到多大，算是最大</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-为什么调大资源以后性能可以提升"><span class="toc-text">1.4 为什么调大资源以后性能可以提升</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-提高并行度"><span class="toc-text">2. 提高并行度</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-Spark的并行度指的是什么"><span class="toc-text">2.1 Spark的并行度指的是什么</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-如何提高并行度"><span class="toc-text">2.2 如何提高并行度</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-1-可以设置task的数量"><span class="toc-text">2.2.1 可以设置task的数量</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-2-如何设置task数量来提高并行度"><span class="toc-text">2.2.2 如何设置task数量来提高并行度</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-3-给RDD重新设置partition的数量"><span class="toc-text">2.2.3 给RDD重新设置partition的数量</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-4-提高sparksql运行的task数量"><span class="toc-text">2.2.4 提高sparksql运行的task数量</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-RDD的重用和持久化"><span class="toc-text">3. RDD的重用和持久化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-实际开发遇到的情况说明"><span class="toc-text">3.1 实际开发遇到的情况说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-如何对rdd进行持久化"><span class="toc-text">3.2 如何对rdd进行持久化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-rdd持久化的时可以采用序列化"><span class="toc-text">3.3 rdd持久化的时可以采用序列化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-广播变量的使用"><span class="toc-text">4.  广播变量的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-场景描述"><span class="toc-text">4.1 场景描述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-广播变量引入"><span class="toc-text">4.2 广播变量引入</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-使用广播变量后的性能分析"><span class="toc-text">4.3 使用广播变量后的性能分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-广播变量使用注意事项"><span class="toc-text">4.4 广播变量使用注意事项</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-5-如何使用广播变量"><span class="toc-text">4.5 如何使用广播变量</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-尽量避免使用shuffle类算子"><span class="toc-text">5. 尽量避免使用shuffle类算子</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-shuffle描述"><span class="toc-text">5.1 shuffle描述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-哪些算子操作会产生shuffle"><span class="toc-text">5.2 哪些算子操作会产生shuffle</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-如何避免产生shuffle"><span class="toc-text">5.3 如何避免产生shuffle</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-4-使用map-side预聚合的shuffle操作"><span class="toc-text">5.4 使用map-side预聚合的shuffle操作</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-使用高性能的算子"><span class="toc-text">6. 使用高性能的算子</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#6-1-使用reduceByKey-aggregateByKey替代groupByKey"><span class="toc-text">6.1 使用reduceByKey/aggregateByKey替代groupByKey</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-2-使用mapPartitions替代普通map"><span class="toc-text">6.2 使用mapPartitions替代普通map</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-3-使用foreachPartitions替代foreach"><span class="toc-text">6.3 使用foreachPartitions替代foreach</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-4-使用filter之后进行coalesce操作"><span class="toc-text">6.4 使用filter之后进行coalesce操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-5-使用repartitionAndSortWithinPartitions替代repartition与sort类操作"><span class="toc-text">6.5 使用repartitionAndSortWithinPartitions替代repartition与sort类操作</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-使用Kryo优化序列化性能"><span class="toc-text">7. 使用Kryo优化序列化性能</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#7-1-spark序列化介绍"><span class="toc-text">7.1 spark序列化介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-2-Kryo序列化启用后生效的地方"><span class="toc-text">7.2 Kryo序列化启用后生效的地方</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-3-如何开启Kryo序列化机制"><span class="toc-text">7.3 如何开启Kryo序列化机制</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-使用fastutil优化数据格式"><span class="toc-text">8. 使用fastutil优化数据格式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-fastutil介绍"><span class="toc-text">8.1 fastutil介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-2-fastutil好处"><span class="toc-text">8.2 fastutil好处</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-3-Spark中应用fastutil的场景和使用"><span class="toc-text">8.3 Spark中应用fastutil的场景和使用</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#8-3-1-算子函数使用了外部变量"><span class="toc-text">8.3.1 算子函数使用了外部变量</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#8-3-2-算子函数里使用了比较大的集合Map-List"><span class="toc-text">8.3.2 算子函数里使用了比较大的集合Map/List</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#8-3-3-fastutil的使用"><span class="toc-text">8.3.3 fastutil的使用</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-调节数据本地化等待时长"><span class="toc-text">9. 调节数据本地化等待时长</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#9-1-本地化级别"><span class="toc-text">9.1 本地化级别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-2-数据本地化等待时长"><span class="toc-text">9.2 数据本地化等待时长</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-3-如何调节参数并且测试"><span class="toc-text">9.3 如何调节参数并且测试</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-基于Spark内存模型调优"><span class="toc-text">10. 基于Spark内存模型调优</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#10-1-spark中executor内存划分"><span class="toc-text">10.1 spark中executor内存划分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-2-spark的内存模型"><span class="toc-text">10.2 spark的内存模型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#10-2-1-静态内存模型"><span class="toc-text">10.2.1 静态内存模型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#10-2-2-统一内存模型"><span class="toc-text">10.2.2 统一内存模型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#10-2-3-任务提交脚本参考"><span class="toc-text">10.2.3 任务提交脚本参考</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#10-2-4-个人经验"><span class="toc-text">10.2.4 个人经验</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-数据倾斜原理和现象分析"><span class="toc-text">11.  数据倾斜原理和现象分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#11-1-数据倾斜概述"><span class="toc-text">11.1 数据倾斜概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-2-数据倾斜发生时的现象"><span class="toc-text">11.2 数据倾斜发生时的现象</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-3-数据倾斜发生的原理"><span class="toc-text">11.3 数据倾斜发生的原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-4-数据倾斜如何定位原因"><span class="toc-text">11.4 数据倾斜如何定位原因</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-5-数据倾斜原因总结"><span class="toc-text">11.5 数据倾斜原因总结</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-6-数据倾斜的后果"><span class="toc-text">11.6 数据倾斜的后果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-spark中数据倾斜的解决方案"><span class="toc-text">12. spark中数据倾斜的解决方案</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案一：使用Hive-ETL预处理数据"><span class="toc-text">解决方案一：使用Hive ETL预处理数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案二：过滤少数导致倾斜的key"><span class="toc-text">解决方案二：过滤少数导致倾斜的key</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案三：提高shuffle操作的并行度-效果差"><span class="toc-text">解决方案三：提高shuffle操作的并行度(效果差)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案四：两阶段聚合（局部聚合-全局聚合）"><span class="toc-text">解决方案四：两阶段聚合（局部聚合+全局聚合）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案五：将reduce-join转为map-join"><span class="toc-text">解决方案五：将reduce join转为map join</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案六：采样倾斜key并分拆join操作"><span class="toc-text">解决方案六：采样倾斜key并分拆join操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案七：使用随机前缀和扩容RDD进行join"><span class="toc-text">解决方案七：使用随机前缀和扩容RDD进行join</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案八：把上面的几种数据倾斜的解决方案综合的灵活运行"><span class="toc-text">解决方案八：把上面的几种数据倾斜的解决方案综合的灵活运行</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-Shuffle调优"><span class="toc-text">13. Shuffle调优</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#13-1-什么时候发生shuffle"><span class="toc-text">13.1 什么时候发生shuffle</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-2-Shuffle的核心组件"><span class="toc-text">13.2 Shuffle的核心组件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-3-Shuffle组件调度"><span class="toc-text">13.3 Shuffle组件调度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-4-Shuffle原理剖析"><span class="toc-text">13.4 Shuffle原理剖析</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#13-4-1-MapOutputTracker"><span class="toc-text">13.4.1 MapOutputTracker</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#13-4-2-ShuffleWriter"><span class="toc-text">13.4.2 ShuffleWriter</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#13-4-3-ShuffleReader"><span class="toc-text">13.4.3 ShuffleReader</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-4-4-Spark-Shuffle参数调优"><span class="toc-text">3.4.4 Spark Shuffle参数调优</span></a></li></ol></li></ol></li></ol></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        Spark调优
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2020-01-05 12:55:30</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#调优" title="调优">调优</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#spark" title="spark">spark</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <h1 id="Spark调优"><a href="#Spark调优" class="headerlink" title="Spark调优"></a>Spark调优</h1><h3 id="1-分配更多的资源"><a href="#1-分配更多的资源" class="headerlink" title="1. 分配更多的资源"></a>1. 分配更多的资源</h3><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">分配更多的资源：</span><br><span class="line">	它是性能优化调优的王道，就是增加和分配更多的资源，这对于性能和速度上的提升是显而易见的，</span><br><span class="line">	基本上，在一定范围之内，增加资源与性能的提升，是成正比的；写完了一个复杂的spark作业之后，进行性能调优的时候，首先第一步，就是要来调节最优的资源配置；</span><br><span class="line">	在这个基础之上，如果说你的spark作业，能够分配的资源达到了你的能力范围的顶端之后，无法再分配更多的资源了，公司资源有限；那么才是考虑去做后面的这些性能调优的点。</span><br><span class="line"></span><br><span class="line">相关问题：</span><br><span class="line">（<span class="number">1</span>）分配哪些资源？</span><br><span class="line">（<span class="number">2</span>）在哪里可以设置这些资源？</span><br><span class="line">（<span class="number">3</span>）剖析为什么分配这些资源之后，性能可以得到提升？</span><br></pre></td></tr></table></figure>
<h4 id="1-1-分配哪些资源"><a href="#1-1-分配哪些资源" class="headerlink" title="1.1 分配哪些资源"></a>1.1 分配哪些资源</h4><figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">executor-<span class="keyword">memory</span>、executor-cores、driver-<span class="keyword">memory</span></span><br></pre></td></tr></table></figure>
<h4 id="1-2-在哪里可以设置这些资源"><a href="#1-2-在哪里可以设置这些资源" class="headerlink" title="1.2 在哪里可以设置这些资源"></a>1.2 在哪里可以设置这些资源</h4><figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">在实际的生产环境中，提交spark任务时，使用spark-submit shell脚本，在里面调整对应的参数。</span><br><span class="line"> 	</span><br><span class="line"> 提交任务的脚本:</span><br><span class="line"> spark-submit \</span><br><span class="line"> -<span class="ruby">-master <span class="symbol">spark:</span>/<span class="regexp">/node1:7077 \</span></span></span><br><span class="line"><span class="ruby"> --<span class="class"><span class="keyword">class</span> <span class="title">cn</span>.<span class="title">itcast</span>.<span class="title">WordCount</span> \</span></span></span><br><span class="line"><span class="ruby"> --num-executors <span class="number">3</span> \    配置executor的数量</span></span><br><span class="line"><span class="ruby"> --driver-memory <span class="number">1</span>g \   配置driver的内存（影响不大）</span></span><br><span class="line"><span class="ruby"> --executor-memory <span class="number">1</span>g \ 配置每一个executor的内存大小</span></span><br><span class="line"><span class="ruby"> --executor-cores <span class="number">3</span> \   配置每一个executor的cpu个数</span></span><br><span class="line"><span class="ruby"> /export/servers/wordcount.jar</span></span><br></pre></td></tr></table></figure>
<h4 id="1-3-参数调节到多大，算是最大"><a href="#1-3-参数调节到多大，算是最大" class="headerlink" title="1.3 参数调节到多大，算是最大"></a>1.3 参数调节到多大，算是最大</h4><ul>
<li>==Standalone模式==</li>
</ul>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">先计算出公司spark集群上的所有资源 每台节点的内存大小和cpu核数，</span><br><span class="line">比如：一共有<span class="number">20</span>台worker节点，每台节点<span class="number">8</span>g内存，<span class="number">10</span>个cpu。</span><br><span class="line">实际任务在给定资源的时候，可以给<span class="number">20</span>个executor、每个executor的内存<span class="number">8</span>g、每个executor的使用的cpu个数<span class="number">10</span>。</span><br></pre></td></tr></table></figure>
<ul>
<li>==Yarn模式==</li>
</ul>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">先计算出yarn集群的所有大小，比如一共<span class="number">500</span>g内存，<span class="number">100</span>个cpu；</span><br><span class="line">这个时候可以分配的最大资源，比如给定<span class="number">50</span>个executor、每个executor的内存大小<span class="number">10</span>g,每个executor使用的cpu个数为<span class="number">2</span>。</span><br></pre></td></tr></table></figure>
<ul>
<li>使用原则</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在资源比较充足的情况下，尽可能的使用更多的计算资源，尽量去调节到最大的大小</span><br></pre></td></tr></table></figure>
<h4 id="1-4-为什么调大资源以后性能可以提升"><a href="#1-4-为什么调大资源以后性能可以提升" class="headerlink" title="1.4 为什么调大资源以后性能可以提升"></a>1.4 为什么调大资源以后性能可以提升</h4><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/spark性能优化--分配资源.png" alt="spark性能优化--分配资源"></p>
<h3 id="2-提高并行度"><a href="#2-提高并行度" class="headerlink" title="2. 提高并行度"></a>2. 提高并行度</h3><h4 id="2-1-Spark的并行度指的是什么"><a href="#2-1-Spark的并行度指的是什么" class="headerlink" title="2.1 Spark的并行度指的是什么"></a>2.1 Spark的并行度指的是什么</h4><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark作业中，各个stage的<span class="keyword">task</span>的数量，也就代表了spark作业在各个阶段stage的并行度！</span><br><span class="line">   当分配完所能分配的最大资源了，然后对应资源去调节程序的并行度，如果并行度没有与资源相匹配，那么导致你分配下去的资源都浪费掉了。同时并行运行，还可以让每个<span class="keyword">task</span>要处理的数量变少（很简单的原理。合理设置并行度，可以充分利用集群资源，减少每个<span class="keyword">task</span>处理数据量，而增加性能加快运行速度。）</span><br></pre></td></tr></table></figure>
<h4 id="2-2-如何提高并行度"><a href="#2-2-如何提高并行度" class="headerlink" title="2.2 如何提高并行度"></a>2.2 如何提高并行度</h4><h5 id="2-2-1-可以设置task的数量"><a href="#2-2-1-可以设置task的数量" class="headerlink" title="2.2.1 可以设置task的数量"></a>2.2.1 可以设置task的数量</h5><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">至少设置成与spark Application 的总cpu core 数量相同。</span><br><span class="line">最理想情况，<span class="number">150</span>个core，分配<span class="number">150</span>task，一起运行，差不多同一时间运行完毕</span><br><span class="line">官方推荐，task数量，设置成spark Application 总cpu core数量的<span class="number">2</span>~<span class="number">3</span>倍 。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">比如<span class="number">150</span>个cpu core ，基本设置task数量为<span class="number">300</span>~<span class="number">500.</span> 与理想情况不同的，有些task会运行快一点，比如<span class="number">50</span>s就完了，有些task 可能会慢一点，要一分半才运行完，所以如果你的task数量，刚好设置的跟cpu core 数量相同，可能会导致资源的浪费。</span><br><span class="line">因为比如<span class="number">150</span>个task中<span class="number">10</span>个先运行完了，剩余<span class="number">140</span>个还在运行，但是这个时候，就有<span class="number">10</span>个cpu core空闲出来了，导致浪费。如果设置<span class="number">2</span>~<span class="number">3</span>倍，那么一个task运行完以后，另外一个task马上补上来，尽量让cpu core不要空闲。同时尽量提升spark运行效率和速度。提升性能。</span><br></pre></td></tr></table></figure>
<h5 id="2-2-2-如何设置task数量来提高并行度"><a href="#2-2-2-如何设置task数量来提高并行度" class="headerlink" title="2.2.2 如何设置task数量来提高并行度"></a>2.2.2 如何设置task数量来提高并行度</h5><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">设置参数spark.defalut.parallelism  </span><br><span class="line">   默认是没有值的，如果设置了值为<span class="number">10</span>，它会在shuffle的过程才会起作用。</span><br><span class="line">   比如 val rdd2 = rdd1.reduceByKey(<span class="literal">_</span>+<span class="literal">_</span>) </span><br><span class="line">   此时rdd2的分区数就是<span class="number">10</span></span><br><span class="line">   </span><br><span class="line">可以通过在构建SparkConf对象的时候设置，例如：</span><br><span class="line">   <span class="keyword">new</span> <span class="type">SparkConf</span>().<span class="keyword">set</span>(<span class="string">"spark.defalut.parallelism"</span>,<span class="string">"500"</span>)</span><br></pre></td></tr></table></figure>
<h5 id="2-2-3-给RDD重新设置partition的数量"><a href="#2-2-3-给RDD重新设置partition的数量" class="headerlink" title="2.2.3 给RDD重新设置partition的数量"></a>2.2.3 给RDD重新设置partition的数量</h5><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">使用rdd.repartition 来重新分区，该方法会生成一个新的rdd，使其分区数变大。</span><br><span class="line">此时由于一个partition对应一个<span class="keyword">task</span>，那么对应的<span class="keyword">task</span>个数越多，通过这种方式也可以提高并行度。</span><br></pre></td></tr></table></figure>
<h5 id="2-2-4-提高sparksql运行的task数量"><a href="#2-2-4-提高sparksql运行的task数量" class="headerlink" title="2.2.4 提高sparksql运行的task数量"></a>2.2.4 提高sparksql运行的task数量</h5><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">通过设置参数 spark<span class="selector-class">.sql</span><span class="selector-class">.shuffle</span><span class="selector-class">.partitions</span>=<span class="number">500</span>  默认为<span class="number">200</span>；</span><br><span class="line">可以适当增大，来提高并行度。 比如设置为 spark<span class="selector-class">.sql</span><span class="selector-class">.shuffle</span><span class="selector-class">.partitions</span>=<span class="number">500</span></span><br></pre></td></tr></table></figure>
<h3 id="3-RDD的重用和持久化"><a href="#3-RDD的重用和持久化" class="headerlink" title="3. RDD的重用和持久化"></a>3. RDD的重用和持久化</h3><h4 id="3-1-实际开发遇到的情况说明"><a href="#3-1-实际开发遇到的情况说明" class="headerlink" title="3.1 实际开发遇到的情况说明"></a>3.1 实际开发遇到的情况说明</h4><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/rdd重用1.png" alt="rdd重用1"></p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">如上图所示的计算逻辑：</span><br><span class="line">（<span class="number">1</span>）当第一次使用rdd2做相应的算子操作得到rdd3的时候，就会从rdd1开始计算，先读取HDFS上的文件，然后对rdd1做对应的算子操作得到rdd2,再由rdd2计算之后得到rdd3。同样为了计算得到rdd4，前面的逻辑会被重新计算。</span><br><span class="line"></span><br><span class="line">（<span class="number">3</span>）默认情况下多次对一个rdd执行算子操作，去获取不同的rdd，都会对这个rdd及之前的父rdd全部重新计算一次。</span><br><span class="line">这种情况在实际开发代码的时候会经常遇到，但是我们一定要避免一个rdd重复计算多次，否则会导致性能急剧降低。</span><br><span class="line"></span><br><span class="line">总结：可以把多次使用到的rdd，也就是公共rdd进行持久化，避免后续需要，再次重新计算，提升效率。</span><br></pre></td></tr></table></figure>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/rdd重用2.png" alt="rdd重用2"></p>
<h4 id="3-2-如何对rdd进行持久化"><a href="#3-2-如何对rdd进行持久化" class="headerlink" title="3.2 如何对rdd进行持久化"></a>3.2 如何对rdd进行持久化</h4><ul>
<li>可以调用rdd的cache或者persist方法。</li>
</ul>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">（1）<span class="selector-tag">cache</span>方法默认是把数据持久化到内存中 ，例如：<span class="selector-tag">rdd</span><span class="selector-class">.cache</span> ，其本质还是调用了<span class="selector-tag">persist</span>方法</span><br><span class="line">（2）<span class="selector-tag">persist</span>方法中有丰富的缓存级别，这些缓存级别都定义在<span class="selector-tag">StorageLevel</span>这个<span class="selector-tag">object</span>中，可以结合实际的应用场景合理的设置缓存级别。例如： <span class="selector-tag">rdd</span><span class="selector-class">.persist</span>(<span class="selector-tag">StorageLevel</span><span class="selector-class">.MEMORY_ONLY</span>),这是<span class="selector-tag">cache</span>方法的实现。</span><br></pre></td></tr></table></figure>
<h4 id="3-3-rdd持久化的时可以采用序列化"><a href="#3-3-rdd持久化的时可以采用序列化" class="headerlink" title="3.3 rdd持久化的时可以采用序列化"></a>3.3 rdd持久化的时可以采用序列化</h4><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">（1）如果正常将数据持久化在内存中，那么可能会导致内存的占用过大，这样的话，也许会导致<span class="selector-tag">OOM</span>内存溢出。</span><br><span class="line">（2）当纯内存无法支撑公共<span class="selector-tag">RDD</span>数据完全存放的时候，就优先考虑使用序列化的方式在纯内存中存储。将<span class="selector-tag">RDD</span>的每个<span class="selector-tag">partition</span>的数据，序列化成一个字节数组；序列化后，大大减少内存的空间占用。</span><br><span class="line">（3）序列化的方式，唯一的缺点就是，在获取数据的时候，需要反序列化。但是可以减少占用的空间和便于网络传输</span><br><span class="line">（4）如果序列化纯内存方式，还是导致<span class="selector-tag">OOM</span>，内存溢出；就只能考虑磁盘的方式，内存+磁盘的普通方式（无序列化）。</span><br><span class="line">（5）为了数据的高可靠性，而且内存充足，可以使用双副本机制，进行持久化</span><br><span class="line">	持久化的双副本机制，持久化后的一个副本，因为机器宕机了，副本丢了，就还是得重新计算一次；</span><br><span class="line">	持久化的每个数据单元，存储一份副本，放在其他节点上面，从而进行容错；</span><br><span class="line">	一个副本丢了，不用重新计算，还可以使用另外一份副本。这种方式，仅仅针对你的内存资源极度充足。</span><br><span class="line">	 比如: <span class="selector-tag">StorageLevel</span><span class="selector-class">.MEMORY_ONLY_2</span></span><br></pre></td></tr></table></figure>
<h3 id="4-广播变量的使用"><a href="#4-广播变量的使用" class="headerlink" title="4.  广播变量的使用"></a>4.  广播变量的使用</h3><h4 id="4-1-场景描述"><a href="#4-1-场景描述" class="headerlink" title="4.1 场景描述"></a>4.1 场景描述</h4><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在实际工作中可能会遇到这样的情况，由于要处理的数据量非常大，这个时候可能会在一个stage中出现大量的<span class="keyword">task</span>，比如有<span class="number">1000</span>个<span class="keyword">task</span>，这些<span class="keyword">task</span>都需要一份相同的数据来处理业务，这份数据的大小为<span class="number">100</span>M，该数据会拷贝<span class="number">1000</span>份副本，通过网络传输到各个<span class="keyword">task</span>中去，给<span class="keyword">task</span>使用。这里会涉及大量的网络传输开销，同时至少需要的内存为<span class="number">1000</span>*<span class="number">100</span>M=<span class="number">100</span>G，这个内存开销是非常大的。不必要的内存的消耗和占用，就导致了你在进行RDD持久化到内存，也许就没法完全在内存中放下；就只能写入磁盘，最后导致后续的操作在磁盘IO上消耗性能；这对于spark任务处理来说就是一场灾难。</span><br><span class="line"></span><br><span class="line">   由于内存开销比较大，<span class="keyword">task</span>在创建对象的时候，可能会出现堆内存放不下所有对象，就会导致频繁的垃圾回收器的回收GC。GC的时候一定是会导致工作线程停止，也就是导致Spark暂停工作那么一点时间。频繁GC的话，对Spark作业的运行的速度会有相当可观的影响。</span><br></pre></td></tr></table></figure>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/task共享数据.png" alt="task共享数据"></p>
<h4 id="4-2-广播变量引入"><a href="#4-2-广播变量引入" class="headerlink" title="4.2 广播变量引入"></a>4.2 广播变量引入</h4><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Spark中分布式执行的代码需要传递到各个executor的<span class="keyword">task</span>上运行。对于一些只读、固定的数据,每次都需要Driver广播到各个<span class="keyword">Task</span>上，这样效率低下。广播变量允许将变量只广播给各个executor。该executor上的各个<span class="keyword">task</span>再从所在节点的BlockManager(负责管理某个executor对应的内存和磁盘上的数据)获取变量，而不是从Driver获取变量，从而提升了效率。</span><br></pre></td></tr></table></figure>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/广播变量.png" alt="广播变量"></p>
<figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">广播变量，初始的时候，就在Drvier上有一份副本。通过在Driver把共享数据转换成广播变量。</span><br><span class="line"></span><br><span class="line">	<span class="keyword">task</span>在运行的时候，想要使用广播变量中的数据，此时首先会在自己本地的Executor对应的BlockManager中，尝试获取变量副本；如果本地没有，那么就从Driver远程拉取广播变量副本，并保存在本地的BlockManager中；</span><br><span class="line">	</span><br><span class="line">	此后这个executor上的<span class="keyword">task</span>，都会直接使用本地的BlockManager中的副本。那么这个时候所有该executor中的<span class="keyword">task</span>都会使用这个广播变量的副本。也就是说一个executor只需要在第一个<span class="keyword">task</span>启动时，获得一份广播变量数据，之后的<span class="keyword">task</span>都从本节点的BlockManager中获取相关数据。</span><br><span class="line"></span><br><span class="line">	executor的BlockManager除了从driver上拉取，也可能从其他节点的BlockManager上拉取变量副本，网络距离越近越好。</span><br></pre></td></tr></table></figure>
<h4 id="4-3-使用广播变量后的性能分析"><a href="#4-3-使用广播变量后的性能分析" class="headerlink" title="4.3 使用广播变量后的性能分析"></a>4.3 使用广播变量后的性能分析</h4><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">比如一个任务需要<span class="number">50</span>个executor，<span class="number">1000</span>个task，共享数据为<span class="number">100</span>M。</span><br><span class="line">(<span class="number">1</span>)在不使用广播变量的情况下，<span class="number">1000</span>个task，就需要该共享数据的<span class="number">1000</span>个副本，也就是说有<span class="number">1000</span>份数需要大量的网络传输和内存开销存储。耗费的内存大小<span class="number">1000</span>*<span class="number">100</span>=<span class="number">100</span>G.</span><br><span class="line"></span><br><span class="line">(<span class="number">2</span>)使用了广播变量后，<span class="number">50</span>个executor就只需要<span class="number">50</span>个副本数据，而且不一定都是从Driver传输到每个节点，还可能是就近从最近的节点的executor的blockmanager上拉取广播变量副本，网络传输速度大大增加；内存开销 <span class="number">50</span>*<span class="number">100</span>M=<span class="number">5</span>G</span><br><span class="line"></span><br><span class="line">总结：</span><br><span class="line">	不使用广播变量的内存开销为<span class="number">100</span>G，使用后的内存开销<span class="number">5</span>G，这里就相差了<span class="number">20</span>倍左右的网络传输性能损耗和内存开销，使用广播变量后对于性能的提升和影响，还是很可观的。</span><br><span class="line">	</span><br><span class="line">	广播变量的使用不一定会对性能产生决定性的作用。比如运行<span class="number">30</span>分钟的spark作业，可能做了广播变量以后，速度快了<span class="number">2</span>分钟，或者<span class="number">5</span>分钟。但是一点一滴的调优，积少成多。最后还是会有效果的。</span><br></pre></td></tr></table></figure>
<h4 id="4-4-广播变量使用注意事项"><a href="#4-4-广播变量使用注意事项" class="headerlink" title="4.4 广播变量使用注意事项"></a>4.4 广播变量使用注意事项</h4><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">（<span class="number">1</span>）能不能将一个RDD使用广播变量广播出去？</span><br><span class="line"></span><br><span class="line">       不能，因为RDD是不存储数据的。可以将RDD的结果广播出去。</span><br><span class="line"></span><br><span class="line">（<span class="number">2</span>）广播变量只能在<span class="built_in">Driver</span>端定义，不能在Executor端定义。</span><br><span class="line"></span><br><span class="line">（<span class="number">3</span>）在<span class="built_in">Driver</span>端可以修改广播变量的值，在Executor端无法修改广播变量的值。</span><br><span class="line"></span><br><span class="line">（<span class="number">4</span>）如果executor端用到了<span class="built_in">Driver</span>的变量，如果不使用广播变量在Executor有多少task就有多少<span class="built_in">Driver</span>端的变量副本。</span><br><span class="line"></span><br><span class="line">（<span class="number">5</span>）如果Executor端用到了<span class="built_in">Driver</span>的变量，如果使用广播变量在每个Executor中只有一份<span class="built_in">Driver</span>端的变量副本。</span><br></pre></td></tr></table></figure>
<h4 id="4-5-如何使用广播变量"><a href="#4-5-如何使用广播变量" class="headerlink" title="4.5 如何使用广播变量"></a>4.5 如何使用广播变量</h4><ul>
<li>例如</li>
</ul>
<figure class="highlight vbscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">1</span>) 通过sparkContext的broadcast方法把数据转换成广播变量，类型为Broadcast，</span><br><span class="line">	val broadcastArray: Broadcast[<span class="built_in">Array</span>[<span class="built_in">Int</span>]] = sc.broadcast(<span class="built_in">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>))</span><br><span class="line">	</span><br><span class="line">(<span class="number">2</span>) 然后executor上的BlockManager就可以拉取该广播变量的副本获取具体的数据。</span><br><span class="line">		获取广播变量中的值可以通过调用其value方法</span><br><span class="line">	 val <span class="built_in">array</span>: <span class="built_in">Array</span>[<span class="built_in">Int</span>] = broadcastArray.value</span><br></pre></td></tr></table></figure>
<h3 id="5-尽量避免使用shuffle类算子"><a href="#5-尽量避免使用shuffle类算子" class="headerlink" title="5. 尽量避免使用shuffle类算子"></a>5. 尽量避免使用shuffle类算子</h3><h4 id="5-1-shuffle描述"><a href="#5-1-shuffle描述" class="headerlink" title="5.1 shuffle描述"></a>5.1 shuffle描述</h4><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">spark中的shuffle涉及到数据要进行大量的网络传输，下游阶段的<span class="keyword">task</span>任务需要通过网络拉取上阶段<span class="keyword">task</span>的输出数据，shuffle过程，简单来说，就是将分布在集群中多个节点上的同一个key，拉取到同一个节点上，进行聚合或<span class="keyword">join</span>等操作。比如reduceByKey、<span class="keyword">join</span>等算子，都会触发shuffle操作。</span><br><span class="line"></span><br><span class="line">如果有可能的话，要尽量避免使用shuffle类算子。</span><br><span class="line">因为Spark作业运行过程中，最消耗性能的地方就是shuffle过程。</span><br></pre></td></tr></table></figure>
<h4 id="5-2-哪些算子操作会产生shuffle"><a href="#5-2-哪些算子操作会产生shuffle" class="headerlink" title="5.2 哪些算子操作会产生shuffle"></a>5.2 哪些算子操作会产生shuffle</h4><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark程序在开发的过程中使用reduceByKey、<span class="keyword">join</span>、distinct、repartition等算子操作，这里都会产生shuffle，由于shuffle这一块是非常耗费性能的，实际开发中尽量使用<span class="built_in">map</span>类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。</span><br></pre></td></tr></table></figure>
<h4 id="5-3-如何避免产生shuffle"><a href="#5-3-如何避免产生shuffle" class="headerlink" title="5.3 如何避免产生shuffle"></a>5.3 如何避免产生shuffle</h4><ul>
<li>小案例</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//错误的做法：</span></span><br><span class="line"><span class="comment">// 传统的join操作会导致shuffle操作。</span></span><br><span class="line"><span class="comment">// 因为两个RDD中，相同的key都需要通过网络拉取到一个节点上，由一个task进行join操作。</span></span><br><span class="line"><span class="keyword">val</span> rdd3 = rdd1.join(rdd2)</span><br><span class="line">    </span><br><span class="line"><span class="comment">//正确的做法：</span></span><br><span class="line"><span class="comment">// Broadcast+map的join操作，不会导致shuffle操作。</span></span><br><span class="line"><span class="comment">// 使用Broadcast将一个数据量较小的RDD作为广播变量。</span></span><br><span class="line"><span class="keyword">val</span> rdd2Data = rdd2.collect()</span><br><span class="line"><span class="keyword">val</span> rdd2DataBroadcast = sc.broadcast(rdd2Data)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在rdd1.map算子中，可以从rdd2DataBroadcast中，获取rdd2的所有数据。</span></span><br><span class="line"><span class="comment">// 然后进行遍历，如果发现rdd2中某条数据的key与rdd1的当前数据的key是相同的，那么就判定可以进行join。</span></span><br><span class="line"><span class="comment">// 此时就可以根据自己需要的方式，将rdd1当前数据与rdd2中可以连接的数据，拼接在一起（String或Tuple）。</span></span><br><span class="line"><span class="keyword">val</span> rdd3 = rdd1.map(rdd2DataBroadcast...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注意，以上操作，建议仅仅在rdd2的数据量比较少（比如几百M，或者一两G）的情况下使用。</span></span><br><span class="line"><span class="comment">// 因为每个Executor的内存中，都会驻留一份rdd2的全量数据。</span></span><br></pre></td></tr></table></figure>
<h4 id="5-4-使用map-side预聚合的shuffle操作"><a href="#5-4-使用map-side预聚合的shuffle操作" class="headerlink" title="5.4 使用map-side预聚合的shuffle操作"></a>5.4 使用map-side预聚合的shuffle操作</h4><ul>
<li>map-side预聚合</li>
</ul>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">如果因为业务需要，一定要使用shuffle操作，无法用<span class="built_in">map</span>类的算子来替代，那么尽量使用可以<span class="built_in">map</span>-side预聚合的算子。</span><br><span class="line"></span><br><span class="line">所谓的<span class="built_in">map</span>-side预聚合，说的是在每个节点本地对相同的<span class="built_in">key</span>进行一次聚合操作，类似于MapReduce中的本地combiner。</span><br><span class="line"><span class="built_in">map</span>-side预聚合之后，每个节点本地就只会有一条相同的<span class="built_in">key</span>，因为多条相同的<span class="built_in">key</span>都被聚合起来了。其他节点在拉取所有节点上的相同<span class="built_in">key</span>时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销。</span><br><span class="line">通常来说，在可能的情况下，建议使用reduceByKey或者aggregateByKey算子来替代掉groupByKey算子。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同<span class="built_in">key</span>进行预聚合。</span><br><span class="line">而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差。</span><br><span class="line"></span><br><span class="line">比如如下两幅图，就是典型的例子，分别基于reduceByKey和groupByKey进行单词计数。其中第一张图是groupByKey的原理图，可以看到，没有进行任何本地聚合时，所有数据都会在集群节点之间传输；第二张图是reduceByKey的原理图，可以看到，每个节点本地的相同<span class="built_in">key</span>数据，都进行了预聚合，然后才传输到其他节点上进行全局聚合。</span><br></pre></td></tr></table></figure>
<ul>
<li>==groupByKey进行单词计数原理==</li>
</ul>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/groupByKey.png" alt="1577080609633"></p>
<ul>
<li>==reduceByKey单词计数原理==</li>
</ul>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/reduceByKey.png" alt="1577080686083"></p>
<h3 id="6-使用高性能的算子"><a href="#6-使用高性能的算子" class="headerlink" title="6. 使用高性能的算子"></a>6. 使用高性能的算子</h3><h4 id="6-1-使用reduceByKey-aggregateByKey替代groupByKey"><a href="#6-1-使用reduceByKey-aggregateByKey替代groupByKey" class="headerlink" title="6.1 使用reduceByKey/aggregateByKey替代groupByKey"></a>6.1 使用reduceByKey/aggregateByKey替代groupByKey</h4><ul>
<li>reduceByKey/aggregateByKey 可以进行预聚合操作，减少数据的传输量，提升性能</li>
<li>groupByKey 不会进行预聚合操作，进行数据的全量拉取，性能比较低</li>
</ul>
<h4 id="6-2-使用mapPartitions替代普通map"><a href="#6-2-使用mapPartitions替代普通map" class="headerlink" title="6.2 使用mapPartitions替代普通map"></a>6.2 使用mapPartitions替代普通map</h4><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mapPartitions类的算子，一次函数调用会处理一个<span class="built_in">partition</span>所有的数据，而不是一次函数调用处理一条，性能相对来说会高一些。</span><br><span class="line">但是有的时候，使用mapPartitions会出现OOM（内存溢出）的问题。因为单次函数调用就要处理掉一个<span class="built_in">partition</span>所有的数据，如果内存不够，垃圾回收时是无法回收掉太多对象的，很可能出现OOM异常。所以使用这类操作时要慎重！</span><br></pre></td></tr></table></figure>
<h4 id="6-3-使用foreachPartitions替代foreach"><a href="#6-3-使用foreachPartitions替代foreach" class="headerlink" title="6.3 使用foreachPartitions替代foreach"></a>6.3 使用foreachPartitions替代foreach</h4><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原理类似于“使用mapPartitions替代<span class="built_in">map</span>”，也是一次函数调用处理一个<span class="built_in">partition</span>的所有数据，而不是一次函数调用处理一条数据。</span><br><span class="line">在实践中发现，foreachPartitions类的算子，对性能的提升还是很有帮助的。比如在foreach函数中，将RDD中所有数据写MySQL，那么如果是普通的foreach算子，就会一条数据一条数据地写，每次函数调用可能就会创建一个数据库连接，此时就势必会频繁地创建和销毁数据库连接，性能是非常低下；	但是如果用foreachPartitions算子一次性处理一个<span class="built_in">partition</span>的数据，那么对于每个<span class="built_in">partition</span>，只要创建一个数据库连接即可，然后执行批量插入操作，此时性能是比较高的。实践中发现，对于<span class="number">1</span>万条左右的数据量写MySQL，性能可以提升<span class="number">30</span><span class="symbol">%</span>以上。</span><br></pre></td></tr></table></figure>
<h4 id="6-4-使用filter之后进行coalesce操作"><a href="#6-4-使用filter之后进行coalesce操作" class="headerlink" title="6.4 使用filter之后进行coalesce操作"></a>6.4 使用filter之后进行coalesce操作</h4><figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">通常对一个RDD执行<span class="keyword">filter</span>算子过滤掉RDD中较多数据后（比如<span class="number">30</span>%以上的数据），建议使用coalesce算子，手动减少RDD的<span class="keyword">partition</span>数量，将RDD中的数据压缩到更少的<span class="keyword">partition</span>中去。</span><br><span class="line">因为<span class="keyword">filter</span>之后，RDD的每个<span class="keyword">partition</span>中都会有很多数据被过滤掉，此时如果照常进行后续的计算，其实每个task处理的<span class="keyword">partition</span>中的数据量并不是很多，有一点资源浪费，而且此时处理的task越多，可能速度反而越慢。</span><br><span class="line">因此用coalesce减少<span class="keyword">partition</span>数量，将RDD中的数据压缩到更少的<span class="keyword">partition</span>之后，只要使用更少的task即可处理完所有的<span class="keyword">partition</span>。在某些场景下，对于性能的提升会有一定的帮助。</span><br></pre></td></tr></table></figure>
<h4 id="6-5-使用repartitionAndSortWithinPartitions替代repartition与sort类操作"><a href="#6-5-使用repartitionAndSortWithinPartitions替代repartition与sort类操作" class="headerlink" title="6.5 使用repartitionAndSortWithinPartitions替代repartition与sort类操作"></a>6.5 使用repartitionAndSortWithinPartitions替代repartition与sort类操作</h4><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">repartitionAndSortWithinPartitions是Spark官网推荐的一个算子，官方建议，如果需要在repartition重分区之后，还要进行排序，建议直接使用repartitionAndSortWithinPartitions算子。</span><br><span class="line">因为该算子可以一边进行重分区的shuffle操作，一边进行排序。shuffle与<span class="keyword">sort</span>两个操作同时进行，比先shuffle再<span class="keyword">sort</span>来说，性能可能是要高的。</span><br></pre></td></tr></table></figure>
<h3 id="7-使用Kryo优化序列化性能"><a href="#7-使用Kryo优化序列化性能" class="headerlink" title="7. 使用Kryo优化序列化性能"></a>7. 使用Kryo优化序列化性能</h3><h4 id="7-1-spark序列化介绍"><a href="#7-1-spark序列化介绍" class="headerlink" title="7.1 spark序列化介绍"></a>7.1 spark序列化介绍</h4><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">	Spark在进行任务计算的时候，会涉及到数据跨进程的网络传输、数据的持久化，这个时候就需要对数据进行序列化。Spark默认采用<span class="keyword">Java的序列化器。默认java序列化的优缺点如下:</span></span><br><span class="line"><span class="keyword">其好处：</span></span><br><span class="line"><span class="keyword">	</span>处理起来方便，不需要我们手动做其他操作，只是在使用一个对象和变量的时候，需要实现Serializble接口。</span><br><span class="line">其缺点：</span><br><span class="line">	默认的序列化机制的效率不高，序列化的速度比较慢；序列化以后的数据，占用的内存空间相对还是比较大。</span><br><span class="line"></span><br><span class="line">Spark支持使用Kryo序列化机制。Kryo序列化机制，比默认的<span class="keyword">Java序列化机制，速度要快，序列化后的数据要更小，大概是Java序列化机制的1/10。所以Kryo序列化优化以后，可以让网络传输的数据变少；在集群中耗费的内存资源大大减少。</span></span><br></pre></td></tr></table></figure>
<h4 id="7-2-Kryo序列化启用后生效的地方"><a href="#7-2-Kryo序列化启用后生效的地方" class="headerlink" title="7.2 Kryo序列化启用后生效的地方"></a>7.2 Kryo序列化启用后生效的地方</h4><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Kryo序列化机制，一旦启用以后，会生效的几个地方：</span><br><span class="line">（<span class="number">1</span>）算子函数中使用到的外部变量</span><br><span class="line">	算子中的外部变量可能来着与driver需要涉及到网络传输，就需要用到序列化。</span><br><span class="line">	    最终可以优化网络传输的性能，优化集群中内存的占用和消耗</span><br><span class="line">		</span><br><span class="line">（<span class="number">2</span>）持久化RDD时进行序列化，StorageLevel.MEMORY_ONLY_SER</span><br><span class="line">	将rdd持久化时，对应的存储级别里，需要用到序列化。</span><br><span class="line">	    最终可以优化内存的占用和消耗；持久化RDD占用的内存越少，<span class="keyword">task</span>执行的时候，创建的对象，就不至于频繁的占满内存，频繁发生GC。</span><br><span class="line">		</span><br><span class="line">（<span class="number">3</span>）	产生shuffle的地方，也就是宽依赖</span><br><span class="line">	下游的stage中的<span class="keyword">task</span>，拉取上游stage中的<span class="keyword">task</span>产生的结果数据，跨网络传输，需要用到序列化。最终可以优化网络传输的性能</span><br></pre></td></tr></table></figure>
<h4 id="7-3-如何开启Kryo序列化机制"><a href="#7-3-如何开启Kryo序列化机制" class="headerlink" title="7.3 如何开启Kryo序列化机制"></a>7.3 如何开启Kryo序列化机制</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建SparkConf对象。</span></span><br><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(...).setAppName(...)</span><br><span class="line"><span class="comment">// 设置序列化器为KryoSerializer。</span></span><br><span class="line">conf.set(<span class="string">"spark.serializer"</span>, <span class="string">"org.apache.spark.serializer.KryoSerializer"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册要序列化的自定义类型。</span></span><br><span class="line">conf.registerKryoClasses(<span class="type">Array</span>(classOf[<span class="type">MyClass1</span>], classOf[<span class="type">MyClass2</span>]))</span><br></pre></td></tr></table></figure>
<h3 id="8-使用fastutil优化数据格式"><a href="#8-使用fastutil优化数据格式" class="headerlink" title="8. 使用fastutil优化数据格式"></a>8. 使用fastutil优化数据格式</h3><h4 id="8-1-fastutil介绍"><a href="#8-1-fastutil介绍" class="headerlink" title="8.1 fastutil介绍"></a>8.1 fastutil介绍</h4><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fastutil是扩展了Java标准集合框架（<span class="built_in">Map</span>、<span class="built_in">List</span>、<span class="built_in">Set</span>；HashMap、ArrayList、HashSet）的类库，提供了特殊类型的<span class="built_in">map</span>、<span class="built_in">set</span>、<span class="built_in">list</span>和<span class="built_in">queue</span>；</span><br><span class="line"></span><br><span class="line">fastutil能够提供更小的内存占用，更快的存取速度；我们使用fastutil提供的集合类，来替代自己平时使用的JDK的原生的<span class="built_in">Map</span>、<span class="built_in">List</span>、<span class="built_in">Set</span>.</span><br></pre></td></tr></table></figure>
<h4 id="8-2-fastutil好处"><a href="#8-2-fastutil好处" class="headerlink" title="8.2 fastutil好处"></a>8.2 fastutil好处</h4><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fastutil集合类，可以减小内存的占用，并且在进行集合的遍历、根据索引（或者<span class="built_in">key</span>）获取元素的值和设置元素的值的时候，提供更快的存取速度；</span><br></pre></td></tr></table></figure>
<h4 id="8-3-Spark中应用fastutil的场景和使用"><a href="#8-3-Spark中应用fastutil的场景和使用" class="headerlink" title="8.3 Spark中应用fastutil的场景和使用"></a>8.3 Spark中应用fastutil的场景和使用</h4><h5 id="8-3-1-算子函数使用了外部变量"><a href="#8-3-1-算子函数使用了外部变量" class="headerlink" title="8.3.1 算子函数使用了外部变量"></a>8.3.1 算子函数使用了外部变量</h5><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">（<span class="number">1</span>）你可以使用Broadcast广播变量优化；</span><br><span class="line"></span><br><span class="line">（<span class="number">2</span>）可以使用Kryo序列化类库，提升序列化性能和效率；</span><br><span class="line"></span><br><span class="line">（<span class="number">3</span>）如果外部变量是某种比较大的集合，那么可以考虑使用fastutil改写外部变量；</span><br><span class="line"></span><br><span class="line">首先从源头上就减少内存的占用(fastutil)，通过广播变量进一步减少内存占用，再通过Kryo序列化类库进一步减少内存占用。</span><br></pre></td></tr></table></figure>
<h5 id="8-3-2-算子函数里使用了比较大的集合Map-List"><a href="#8-3-2-算子函数里使用了比较大的集合Map-List" class="headerlink" title="8.3.2 算子函数里使用了比较大的集合Map/List"></a>8.3.2 算子函数里使用了比较大的集合Map/List</h5><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">在你的算子函数里，也就是<span class="keyword">task</span>要执行的计算逻辑里面，如果有逻辑中，出现，要创建比较大的Map、List等集合，</span><br><span class="line">可能会占用较大的内存空间，而且可能涉及到消耗性能的遍历、存取等集合操作； </span><br><span class="line">那么此时，可以考虑将这些集合类型使用fastutil类库重写，</span><br><span class="line"></span><br><span class="line">使用了fastutil集合类以后，就可以在一定程度上，减少<span class="keyword">task</span>创建出来的集合类型的内存占用。 </span><br><span class="line">避免executor内存频繁占满，频繁唤起GC，导致性能下降。</span><br></pre></td></tr></table></figure>
<h5 id="8-3-3-fastutil的使用"><a href="#8-3-3-fastutil的使用" class="headerlink" title="8.3.3 fastutil的使用"></a>8.3.3 fastutil的使用</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">第一步：在pom.xml中引用fastutil的包</span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>fastutil<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>fastutil<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.0.9<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">第二步：平时使用List （Integer）的替换成IntList即可。 </span><br><span class="line">	List<span class="tag">&lt;<span class="name">Integer</span>&gt;</span>的list对应的到fastutil就是IntList类型</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">使用说明：</span><br><span class="line">基本都是类似于IntList的格式，前缀就是集合的元素类型； </span><br><span class="line">特殊的就是Map，Int2IntMap，代表了key-value映射的元素类型。</span><br></pre></td></tr></table></figure>
<h3 id="9-调节数据本地化等待时长"><a href="#9-调节数据本地化等待时长" class="headerlink" title="9. 调节数据本地化等待时长"></a>9. 调节数据本地化等待时长</h3><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Spark在Driver上对Application的每一个stage的<span class="keyword">task</span>进行分配之前，都会计算出每个<span class="keyword">task</span>要计算的是哪个分片数据，RDD的某个partition；Spark的<span class="keyword">task</span>分配算法，优先会希望每个<span class="keyword">task</span>正好分配到它要计算的数据所在的节点，这样的话就不用在网络间传输数据；</span><br><span class="line"></span><br><span class="line">但是通常来说，有时事与愿违，可能<span class="keyword">task</span>没有机会分配到它的数据所在的节点，为什么呢，可能那个节点的计算资源和计算能力都满了；所以这种时候，通常来说，Spark会等待一段时间，默认情况下是<span class="number">3</span>秒（不是绝对的，还有很多种情况，对不同的本地化级别，都会去等待），到最后实在是等待不了了，就会选择一个比较差的本地化级别，比如说将<span class="keyword">task</span>分配到距离要计算的数据所在节点比较近的一个节点，然后进行计算。</span><br></pre></td></tr></table></figure>
<h4 id="9-1-本地化级别"><a href="#9-1-本地化级别" class="headerlink" title="9.1 本地化级别"></a>9.1 本地化级别</h4><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">（<span class="number">1</span>）PROCESS_LOCAL：进程本地化</span><br><span class="line">	代码和数据在同一个进程中，也就是在同一个executor中；计算数据的<span class="keyword">task</span>由executor执行，数据在executor的BlockManager中；性能最好</span><br><span class="line">（<span class="number">2</span>）NODE_LOCAL：节点本地化</span><br><span class="line">	代码和数据在同一个节点中；比如说数据作为一个HDFS block块，就在节点上，而<span class="keyword">task</span>在节点上某个executor中运行；或者是数据和<span class="keyword">task</span>在一个节点上的不同executor中；数据需要在进程间进行传输；性能其次</span><br><span class="line">（<span class="number">3</span>）RACK_LOCAL：机架本地化	</span><br><span class="line">	数据和<span class="keyword">task</span>在一个机架的两个节点上；数据需要通过网络在节点之间进行传输； 性能比较差</span><br><span class="line">（<span class="number">4</span>）	<span class="keyword">ANY</span>：无限制</span><br><span class="line">	数据和<span class="keyword">task</span>可能在集群中的任何地方，而且不在一个机架中；性能最差</span><br></pre></td></tr></table></figure>
<h4 id="9-2-数据本地化等待时长"><a href="#9-2-数据本地化等待时长" class="headerlink" title="9.2 数据本地化等待时长"></a>9.2 数据本地化等待时长</h4><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark<span class="selector-class">.locality</span><span class="selector-class">.wait</span>，默认是<span class="number">3s</span></span><br><span class="line">首先采用最佳的方式，等待<span class="number">3s</span>后降级,还是不行，继续降级...,最后还是不行，只能够采用最差的。</span><br></pre></td></tr></table></figure>
<h4 id="9-3-如何调节参数并且测试"><a href="#9-3-如何调节参数并且测试" class="headerlink" title="9.3 如何调节参数并且测试"></a>9.3 如何调节参数并且测试</h4><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">修改spark<span class="selector-class">.locality</span><span class="selector-class">.wait</span>参数，默认是<span class="number">3s</span>，可以增加</span><br><span class="line"></span><br><span class="line">下面是每个数据本地化级别的等待时间，默认都是跟spark<span class="selector-class">.locality</span><span class="selector-class">.wait</span>时间相同，</span><br><span class="line">默认都是<span class="number">3s</span>(可查看spark官网对应参数说明，如下图所示)</span><br><span class="line">spark<span class="selector-class">.locality</span><span class="selector-class">.wait</span><span class="selector-class">.node</span></span><br><span class="line">spark<span class="selector-class">.locality</span><span class="selector-class">.wait</span><span class="selector-class">.process</span></span><br><span class="line">spark<span class="selector-class">.locality</span><span class="selector-class">.wait</span><span class="selector-class">.rack</span></span><br></pre></td></tr></table></figure>
<p><img src="/Users/dingchuangshi/Documents/hexo-kfly-blog/source/_posts/it/spark/http://kfly.top/picture/kfly-top/Spark调优/assets/data-local-spark.png" alt="data-local-spark"></p>
<figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">在代码中设置：</span><br><span class="line"><span class="literal">new</span> SparkConf().<span class="built_in">set</span>(<span class="string">"spark.locality.wait"</span>,<span class="string">"10"</span>)</span><br><span class="line"></span><br><span class="line">然后把程序提交到spark集群中运行，注意观察日志，spark作业的运行日志，推荐大家在测试的时候，先用client模式，在本地就直接可以看到比较全的日志。 </span><br><span class="line">日志里面会显示，starting task <span class="params">...</span>. PROCESS <span class="built_in">LOCAL</span>、NODE <span class="built_in">LOCAL</span><span class="params">...</span>..</span><br><span class="line">例如：</span><br><span class="line">Starting task <span class="number">0.0</span> <span class="keyword">in</span> stage <span class="number">1.0</span> (TID <span class="number">2</span>, <span class="number">192.168</span><span class="number">.200</span><span class="number">.102</span>, partition <span class="number">0</span>, NODE_LOCAL, <span class="number">5254</span> <span class="built_in">bytes</span>)</span><br><span class="line"></span><br><span class="line">观察大部分task的数据本地化级别 </span><br><span class="line">如果大多都是PROCESS_LOCAL，那就不用调节了。如果是发现，好多的级别都是NODE_LOCAL、ANY，那么最好就去调节一下数据本地化的等待时长。应该是要反复调节，每次调节完以后，再来运行，观察日志 </span><br><span class="line">看看大部分的task的本地化级别有没有提升；看看整个spark作业的运行时间有没有缩短。</span><br><span class="line"></span><br><span class="line">注意注意：</span><br><span class="line">在调节参数、运行任务的时候，别本末倒置，本地化级别倒是提升了， 但是因为大量的等待时长，spark作业的运行时间反而增加了，那就还是不要调节了。</span><br></pre></td></tr></table></figure>
<h3 id="10-基于Spark内存模型调优"><a href="#10-基于Spark内存模型调优" class="headerlink" title="10. 基于Spark内存模型调优"></a>10. 基于Spark内存模型调优</h3><h4 id="10-1-spark中executor内存划分"><a href="#10-1-spark中executor内存划分" class="headerlink" title="10.1 spark中executor内存划分"></a>10.1 spark中executor内存划分</h4><ul>
<li>Executor的内存主要分为三块<ul>
<li>第一块是让task执行我们自己编写的代码时使用；</li>
<li>第二块是让task通过shuffle过程拉取了上一个stage的task的输出后，进行聚合等操作时使用</li>
<li>第三块是让RDD缓存时使用</li>
</ul>
</li>
</ul>
<h4 id="10-2-spark的内存模型"><a href="#10-2-spark的内存模型" class="headerlink" title="10.2 spark的内存模型"></a>10.2 spark的内存模型</h4><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在<span class="selector-tag">spark1</span><span class="selector-class">.6</span>版本以前 <span class="selector-tag">spark</span>的<span class="selector-tag">executor</span>使用的静态内存模型，但是在<span class="selector-tag">spark1</span><span class="selector-class">.6</span>开始，多增加了一个统一内存模型。</span><br><span class="line">通过<span class="selector-tag">spark</span><span class="selector-class">.memory</span><span class="selector-class">.useLegacyMode</span> 这个参数去配置</span><br><span class="line">		默认这个值是<span class="selector-tag">false</span>，代表用的是新的动态内存模型；</span><br><span class="line">		如果想用以前的静态内存模型，那么就要把这个值改为<span class="selector-tag">true</span>。</span><br></pre></td></tr></table></figure>
<h5 id="10-2-1-静态内存模型"><a href="#10-2-1-静态内存模型" class="headerlink" title="10.2.1 静态内存模型"></a>10.2.1 静态内存模型</h5><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1570604272790.png" alt="1570604272790"></p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">实际上就是把我们的一个executor分成了三部分，</span><br><span class="line">	一部分是Storage内存区域，</span><br><span class="line">	一部分是execution区域，</span><br><span class="line">	还有一部分是其他区域。如果使用的静态内存模型，那么用这几个参数去控制：</span><br><span class="line">	</span><br><span class="line">spark<span class="selector-class">.storage</span><span class="selector-class">.memoryFraction</span>：默认<span class="number">0.6</span></span><br><span class="line">spark<span class="selector-class">.shuffle</span><span class="selector-class">.memoryFraction</span>：默认<span class="number">0.2</span>  </span><br><span class="line">所以第三部分就是<span class="number">0.2</span></span><br><span class="line"></span><br><span class="line">如果我们cache数据量比较大，或者是我们的广播变量比较大，</span><br><span class="line">	那我们就把spark<span class="selector-class">.storage</span><span class="selector-class">.memoryFraction</span>这个值调大一点。</span><br><span class="line">	但是如果我们代码里面没有广播变量，也没有cache，shuffle又比较多，那我们要把spark<span class="selector-class">.shuffle</span><span class="selector-class">.memoryFraction</span> 这值调大。</span><br></pre></td></tr></table></figure>
<ul>
<li>静态内存模型的缺点</li>
</ul>
<figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我们配置好了Storage内存区域和<span class="keyword">execution</span>区域后，我们的一个任务假设<span class="keyword">execution</span>内存不够用了，但是它的Storage内存区域是空闲的，两个之间不能互相借用，不够灵活，所以才出来我们新的统一内存模型。</span><br></pre></td></tr></table></figure>
<h5 id="10-2-2-统一内存模型"><a href="#10-2-2-统一内存模型" class="headerlink" title="10.2.2 统一内存模型"></a>10.2.2 统一内存模型</h5><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/image2018-11-1_16-39-33.png" alt="img"></p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">	动态内存模型先是预留了300<span class="selector-tag">m</span>内存，防止内存溢出。动态内存模型把整体内存分成了两部分，</span><br><span class="line">由这个参数表示<span class="selector-tag">spark</span><span class="selector-class">.memory</span><span class="selector-class">.fraction</span> 这个指的默认值是0<span class="selector-class">.6</span> 代表另外的一部分是0<span class="selector-class">.4</span>,</span><br><span class="line"></span><br><span class="line">然后<span class="selector-tag">spark</span><span class="selector-class">.memory</span><span class="selector-class">.fraction</span> 这部分又划分成为两个小部分。这两小部分共占整体内存的0<span class="selector-class">.6</span> .这两部分其实就是：<span class="selector-tag">Storage</span>内存和<span class="selector-tag">execution</span>内存。由<span class="selector-tag">spark</span><span class="selector-class">.memory</span><span class="selector-class">.storageFraction</span> 这个参数去调配，因为两个共占0<span class="selector-class">.6</span>。如果<span class="selector-tag">spark</span><span class="selector-class">.memory</span><span class="selector-class">.storageFraction</span>这个值配的是0<span class="selector-class">.5</span>,那说明这0<span class="selector-class">.6</span>里面 <span class="selector-tag">storage</span>占了0<span class="selector-class">.5</span>，也就是<span class="selector-tag">execution</span>占了0<span class="selector-class">.3</span> 。</span><br></pre></td></tr></table></figure>
<ul>
<li><p>统一内存模型有什么特点呢?</p>
<figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Storage内存和<span class="keyword">execution</span>内存 可以相互借用。不用像静态内存模型那样死板，但是是有规则的</span><br></pre></td></tr></table></figure>
<ul>
<li><p>==场景一==</p>
<ul>
<li><p>Execution使用的时候发现内存不够了，然后就会把storage的内存里的数据驱逐到磁盘上。</p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1570604662552.png" alt="1570604662552"></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>==场景二==<ul>
<li>一开始execution的内存使用得不多，但是storage使用的内存多，所以storage就借用了execution的内存，但是后来execution也要需要内存了，这个时候就会把storage的内存里的数据写到磁盘上，腾出内存空间。</li>
</ul>
</li>
</ul>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1570604675176.png" alt="1570604675176"></p>
<figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">为什么受伤的都是storage呢？</span><br><span class="line"></span><br><span class="line">是因为<span class="keyword">execution</span>里面的数据是马上就要用的，而storage里的数据不一定马上就要用。</span><br></pre></td></tr></table></figure>
<h5 id="10-2-3-任务提交脚本参考"><a href="#10-2-3-任务提交脚本参考" class="headerlink" title="10.2.3 任务提交脚本参考"></a>10.2.3 任务提交脚本参考</h5><ul>
<li>以下是一份spark-submit命令的示例，大家可以参考一下，并根据自己的实际情况进行调节</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit \</span><br><span class="line">  --master yarn-cluster \</span><br><span class="line">  --num-executors 100 \</span><br><span class="line">  --executor-memory 6G \</span><br><span class="line">  --executor-cores 4 \</span><br><span class="line">  --driver-memory 1G \</span><br><span class="line">  --conf spark.default.parallelism=1000 \</span><br><span class="line">  --conf spark.storage.memoryFraction=0.5 \</span><br><span class="line">  --conf spark.shuffle.memoryFraction=0.3 \</span><br></pre></td></tr></table></figure>
<h5 id="10-2-4-个人经验"><a href="#10-2-4-个人经验" class="headerlink" title="10.2.4 个人经验"></a>10.2.4 个人经验</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">java.lang.OutOfMemoryError</span><br><span class="line">ExecutorLostFailure</span><br><span class="line">Executor exit code 为143</span><br><span class="line">executor lost</span><br><span class="line">hearbeat time out</span><br><span class="line">shuffle file lost</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果遇到以上问题，很有可能就是内存除了问题，可以先尝试增加内存。如果还是解决不了，那么请听下一次数据倾斜调优的课。</span></span><br></pre></td></tr></table></figure>
<h3 id="11-数据倾斜原理和现象分析"><a href="#11-数据倾斜原理和现象分析" class="headerlink" title="11.  数据倾斜原理和现象分析"></a>11.  数据倾斜原理和现象分析</h3><h4 id="11-1-数据倾斜概述"><a href="#11-1-数据倾斜概述" class="headerlink" title="11.1 数据倾斜概述"></a>11.1 数据倾斜概述</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">有的时候，我们可能会遇到大数据计算中一个最棘手的问题——数据倾斜，此时Spark作业的性能会比期望差很多。</span><br><span class="line">数据倾斜调优，就是使用各种技术方案解决不同类型的数据倾斜问题，以保证Spark作业的性能。</span><br></pre></td></tr></table></figure>
<h4 id="11-2-数据倾斜发生时的现象"><a href="#11-2-数据倾斜发生时的现象" class="headerlink" title="11.2 数据倾斜发生时的现象"></a>11.2 数据倾斜发生时的现象</h4><ul>
<li><p>（1）绝大多数task执行得都非常快，但个别task执行极慢</p>
<figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">	你的大部分的<span class="keyword">task</span>，都执行的特别快，很快就执行完了，剩下几个<span class="keyword">task</span>，执行的特别特别慢，</span><br><span class="line">前面的<span class="keyword">task</span>，一般<span class="number">10</span>s可以执行完<span class="number">5</span>个；最后发现某个<span class="keyword">task</span>，要执行<span class="number">1</span>个小时，<span class="number">2</span>个小时才能执行完一个<span class="keyword">task</span>。</span><br><span class="line">	</span><br><span class="line">	这个时候就出现数据倾斜了。</span><br><span class="line">这种方式还算好的，因为虽然老牛拉破车一样，非常慢，但是至少还能跑。</span><br></pre></td></tr></table></figure>
</li>
<li><p>（2）绝大数task执行很快，有的task直接报OOM (Jvm Out Of Memory) 异常</p>
<figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">运行的时候，其他<span class="keyword">task</span>都很快执行完了，也没什么特别的问题；但是有的<span class="keyword">task</span>，就是会突然间报了一个OOM，JVM <span class="keyword">Out</span> <span class="keyword">Of</span> Memory，内存溢出了，<span class="keyword">task</span> failed，<span class="keyword">task</span> lost，resubmitting <span class="keyword">task</span>等日志异常信息。反复执行几次都到了某个<span class="keyword">task</span>就是跑不通，最后就挂掉。</span><br><span class="line">  </span><br><span class="line">某个<span class="keyword">task</span>就直接OOM，那么基本上也是因为数据倾斜了，<span class="keyword">task</span>分配的数量实在是太大了！！！所以内存放不下，然后你的<span class="keyword">task</span>每处理一条数据，还要创建大量的对象。内存爆掉了。</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="11-3-数据倾斜发生的原理"><a href="#11-3-数据倾斜发生的原理" class="headerlink" title="11.3 数据倾斜发生的原理"></a>11.3 数据倾斜发生的原理</h4><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/数据倾斜.png" alt="数据倾斜"></p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">如上图所示：</span><br><span class="line">	在进行任务计算shuffle操作的时候，第一个task和第二个task各分配到了<span class="number">1</span>万条数据；需要<span class="number">5</span>分钟计算完毕；第一个和第二个task，可能同时在<span class="number">5</span>分钟内都运行完了；第三个task要<span class="number">98</span>万条数据，<span class="number">98</span> * <span class="number">5</span> = <span class="number">490</span>分钟 = <span class="number">8</span>个小时；</span><br><span class="line">	本来另外两个task很快就运行完毕了（<span class="number">5</span>分钟），第三个task数据量比较大，要<span class="number">8</span>个小时才能运行完，就导致整个spark作业，也得<span class="number">8</span>个小时才能运行完。最终导致整个spark任务计算特别慢。</span><br></pre></td></tr></table></figure>
<h4 id="11-4-数据倾斜如何定位原因"><a href="#11-4-数据倾斜如何定位原因" class="headerlink" title="11.4 数据倾斜如何定位原因"></a>11.4 数据倾斜如何定位原因</h4><ul>
<li><p>主要是根据log日志信息去定位</p>
<figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">数据倾斜只会发生在shuffle过程中。这里给大家罗列一些常用的并且可能会触发shuffle操作的算子：<span class="keyword">distinct</span>、groupByKey、reduceByKey、aggregateByKey、<span class="keyword">join</span>、cogroup、repartition等。</span><br><span class="line">出现数据倾斜时，可能就是你的代码中使用了这些算子中的某一个所导致的。因为某个或者某些<span class="keyword">key</span>对应的数据，远远的高于其他的<span class="keyword">key</span>。</span><br></pre></td></tr></table></figure>
</li>
<li><p>分析定位逻辑</p>
<figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">由于代码中有大量的shuffle操作，一个job会划分成很多个stage，首先要看的，就是数据倾斜发生在第几个stage中。</span><br><span class="line">可以在任务运行的过程中，观察任务的UI界面，可以观察到每一个stage中运行的<span class="keyword">task</span>的数据量，从而进一步确定是不是<span class="keyword">task</span>分配的数据不均匀导致了数据倾斜。</span><br><span class="line">比如下图中，倒数第三列显示了每个<span class="keyword">task</span>的运行时间。明显可以看到，有的<span class="keyword">task</span>运行特别快，只需要几秒钟就可以运行完;而有的<span class="keyword">task</span>运行特别慢，需要几分钟才能运行完，此时单从运行时间上看就已经能够确定发生数据倾斜了。</span><br><span class="line">此外，倒数第一列显示了每个<span class="keyword">task</span>处理的数据量，明显可以看到，运行时间特别短的<span class="keyword">task</span>只需要处理几百KB的数据即可，而运行时间特别长的<span class="keyword">task</span>需要处理几千KB的数据，处理的数据量差了<span class="number">10</span>倍。此时更加能够确定是发生了数据倾斜。</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/20170308091203159.png" alt="20170308091203159"></p>
<p><strong>某个task莫名其妙内存溢出的情况</strong></p>
<figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">这种情况下去定位出问题的代码就比较容易了。我们建议直接看yarn-client模式下本地<span class="keyword">log</span>的异常栈，或者是通过YARN查看yarn-<span class="keyword">cluster</span>模式下的<span class="keyword">log</span>中的异常栈。一般来说，通过异常栈信息就可以定位到你的代码中哪一行发生了内存溢出。然后在那行代码附近找找，一般也会有shuffle类算子，此时很可能就是这个算子导致了数据倾斜。</span><br><span class="line">但是大家要注意的是，不能单纯靠偶然的内存溢出就判定发生了数据倾斜。因为自己编写的代码的bug，以及偶然出现的数据异常，也可能会导致内存溢出。因此还是要按照上面所讲的方法，通过Spark Web UI查看报错的那个stage的各个task的运行时间以及分配的数据量，才能确定是否是由于数据倾斜才导致了这次内存溢出。</span><br></pre></td></tr></table></figure>
<p><strong>查看导致数据倾斜的key的数据分布情况</strong></p>
<figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">	知道了数据倾斜发生在哪里之后，通常需要分析一下那个执行了shuffle操作并且导致了数据倾斜的RDD/Hive表，查看一下其中<span class="keyword">key</span>的分布情况。这主要是为之后选择哪一种技术方案提供依据。针对不同的<span class="keyword">key</span>分布与不同的shuffle算子组合起来的各种情况，可能需要选择不同的技术方案来解决。</span><br><span class="line">此时根据你执行操作的情况不同，可以有很多种查看<span class="keyword">key</span>分布的方式：</span><br><span class="line">	如果是Spark SQL中的<span class="keyword">group</span> <span class="keyword">by</span>、<span class="keyword">join</span>语句导致的数据倾斜，那么就查询一下SQL中使用的表的<span class="keyword">key</span>分布情况。</span><br><span class="line">	如果是对Spark RDD执行shuffle算子导致的数据倾斜，那么可以在Spark作业中加入查看<span class="keyword">key</span>分布的代码，比如RDD.countByKey()。然后对统计出来的各个<span class="keyword">key</span>出现的次数，collect/<span class="keyword">take</span>到客户端打印一下，就可以看到<span class="keyword">key</span>的分布情况。</span><br><span class="line">	举例来说，对于上面所说的单词计数程序，如果确定了是stage1的reduceByKey算子导致了数据倾斜，那么就应该看看进行reduceByKey操作的RDD中的<span class="keyword">key</span>分布情况，在这个例子中指的就是pairs RDD。如下示例，我们可以先对pairs采样<span class="number">10</span>%的样本数据，然后使用countByKey算子统计出每个<span class="keyword">key</span>出现的次数，最后在客户端遍历和打印样本数据中各个<span class="keyword">key</span>的出现次数。</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sampledPairs = pairs.sample(<span class="literal">false</span>, <span class="number">0.1</span>)</span><br><span class="line"><span class="keyword">val</span> sampledWordCounts = sampledPairs.countByKey()</span><br><span class="line">sampledWordCounts.foreach(println(_))</span><br><span class="line"></span><br><span class="line"><span class="comment">//sample算子时用来抽样用的，其有3个参数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//withReplacement：表示抽出样本后是否在放回去，true表示会放回去，这也就意味着抽出的样本可能有重复</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//fraction ：抽出多少，这是一个double类型的参数,0-1之间，eg:0.3表示抽出30%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//seed：表示一个种子，根据这个seed随机抽取，一般情况下只用前两个参数就可以，那么这个参数是干嘛的呢，这个参数一般用于调试，有时候不知道是程序出问题还是数据出了问题，就可以将这个参数设置为定值</span></span><br></pre></td></tr></table></figure>
<h4 id="11-5-数据倾斜原因总结"><a href="#11-5-数据倾斜原因总结" class="headerlink" title="11.5 数据倾斜原因总结"></a>11.5 数据倾斜原因总结</h4><ul>
<li><p>数据本身问题</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">（<span class="number">1</span>）、<span class="type">key</span>本身分布不均衡（包括大量的<span class="type">key</span>为空）</span><br><span class="line">（<span class="number">2</span>）、<span class="type">key</span>的设置不合理</span><br></pre></td></tr></table></figure>
</li>
<li><p>spark使用不当的问题</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">（<span class="number">1</span>）、shuffle时的并发度不够</span><br><span class="line">（<span class="number">2</span>）、计算方式有误</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="11-6-数据倾斜的后果"><a href="#11-6-数据倾斜的后果" class="headerlink" title="11.6 数据倾斜的后果"></a>11.6 数据倾斜的后果</h4><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">（<span class="number">1</span>）spark中的stage的执行时间受限于最后那个执行完成的<span class="keyword">task</span>,因此运行缓慢的任务会拖垮整个程序的运行速度（分布式程序运行的速度是由最慢的那个<span class="keyword">task</span>决定的）。</span><br><span class="line"></span><br><span class="line">（<span class="number">2</span>）过多的数据在同一个<span class="keyword">task</span>中运行，将会把executor内存撑爆，导致OOM内存溢出。</span><br></pre></td></tr></table></figure>
<h3 id="12-spark中数据倾斜的解决方案"><a href="#12-spark中数据倾斜的解决方案" class="headerlink" title="12. spark中数据倾斜的解决方案"></a>12. spark中数据倾斜的解决方案</h3><h4 id="解决方案一：使用Hive-ETL预处理数据"><a href="#解决方案一：使用Hive-ETL预处理数据" class="headerlink" title="解决方案一：使用Hive ETL预处理数据"></a>解决方案一：使用Hive ETL预处理数据</h4><p><font color="red">方案适用场景</font>：导致数据倾斜的是Hive表。如果该Hive表中的数据本身很不均匀(比如某个key对应了100万数据，其他key才对应了10条数据)，而且业务场景需要频繁使用Spark对Hive表执行某个分析操作，那么比较适合使用这种技术方案。</p>
<p><font color="red">方案实现思路</font>：此时可以评估一下，是否可以通过Hive来进行数据预处理(即通过Hive ETL预先对数据按照key进行聚合，或者是预先和其他表进行join)，然后在Spark作业中针对的数据源就不是原来的Hive表了，而是预处理后的Hive表。此时由于数据已经预先进行过聚合或join操作了，那么在Spark作业中也就不需要使用原先的shuffle类算子执行这类操作了。</p>
<p><font color="red">方案实现原理</font>：这种方案从根源上解决了数据倾斜，因为彻底避免了在Spark中执行shuffle类算子，那么肯定就不会有数据倾斜的问题了。但是这里也要提醒一下大家，这种方式属于治标不治本。因为毕竟数据本身就存在分布不均匀的问题，所以Hive ETL中进行group by或者join等shuffle操作时，还是会出现数据倾斜，导致Hive ETL的速度很慢。我们只是把数据倾斜的发生提前到了Hive ETL中，避免Spark程序发生数据倾斜而已。</p>
<p><font color="red">方案优点</font>：实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，Spark作业的性能会大幅度提升。</p>
<p><font color="red">方案缺点</font>：治标不治本，Hive ETL中还是会发生数据倾斜。</p>
<p><font color="red">方案实践经验</font>：在一些Java系统与Spark结合使用的项目中，会出现Java代码频繁调用Spark作业的场景，而且对Spark作业的执行性能要求很高，就比较适合使用这种方案。将数据倾斜提前到上游的Hive ETL，每天仅执行一次，只有那一次是比较慢的，而之后每次Java调用Spark作业时，执行速度都会很快，能够提供更好的用户体验。</p>
<p><font color="red">项目实践经验</font>：有一个交互式用户行为分析系统中使用了这种方案，该系统主要是允许用户通过Java Web系统提交数据分析统计任务，后端通过Java提交Spark作业进行数据分析统计。要求Spark作业速度必须要快，尽量在10分钟以内，否则速度太慢，用户体验会很差。所以我们将有些Spark作业的shuffle操作提前到了Hive ETL中，从而让Spark直接使用预处理的Hive中间表，尽可能地减少Spark的shuffle操作，大幅度提升了性能，将部分作业的性能提升了6倍以上。</p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/交互式用户行为分析系统.png" alt="交互式用户行为分析系统"></p>
<h4 id="解决方案二：过滤少数导致倾斜的key"><a href="#解决方案二：过滤少数导致倾斜的key" class="headerlink" title="解决方案二：过滤少数导致倾斜的key"></a>解决方案二：过滤少数导致倾斜的key</h4><p>　　<font color="red">方案适用场景</font>：如果发现导致倾斜的key就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。<br>　　<font color="red">方案实现思路</font>：如果我们判断那少数几个数据量特别多的key，对作业的执行和计算结果不是特别重要的话，那么干脆就直接过滤掉那少数几个key。比如，在Spark SQL中可以使用where子句过滤掉这些key或者在Spark Core中对RDD执行filter算子过滤掉这些key。如果需要每次作业执行时，动态判定哪些key的数据量最多然后再进行过滤，那么可以使用sample算子对RDD进行采样，然后计算出每个key的数量，取数据量最多的key过滤掉即可。<br>　　<font color="red">方案实现原理</font>：将导致数据倾斜的key给过滤掉之后，这些key就不会参与计算了，自然不可能产生数据倾斜。<br>　　<font color="red">方案优点</font>：实现简单，而且效果也很好，可以完全规避掉数据倾斜。<br>　　<font color="red">方案缺点</font>：适用场景不多，大多数情况下，导致倾斜的key还是很多的，并不是只有少数几个。<br>　　<font color="red">方案实践经验</font>：在项目中我们也采用过这种方案解决数据倾斜。有一次发现某一天Spark作业在运行的时候突然OOM了，追查之后发现，是Hive表中的某一个key在那天数据异常，导致数据量暴增。因此就采取每次执行前先进行采样，计算出样本中数据量最大的几个key之后，直接在程序中将那些key给过滤掉。</p>
<h4 id="解决方案三：提高shuffle操作的并行度-效果差"><a href="#解决方案三：提高shuffle操作的并行度-效果差" class="headerlink" title="解决方案三：提高shuffle操作的并行度(效果差)"></a>解决方案三：提高shuffle操作的并行度(效果差)</h4><p>　　　<font color="red">方案适用场景</font>：如果我们必须要对数据倾斜迎难而上，那么建议优先使用这种方案，因为这是处理数据倾斜最简单的一种方案。<br>　　　<font color="red">方案实现思路</font>：在对RDD执行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个shuffle算子执行时shuffle read task的数量。对于Spark SQL中的shuffle类语句，比如group by、join等，需要设置一个参数，即spark.sql.shuffle.partitions，该参数代表了shuffle read task的并行度，该值默认是200，对于很多场景来说都有点过小。<br>　　　<font color="red">方案实现原理</font>：增加shuffle read task的数量，可以让原本分配给一个task的多个key分配给多个task，从而让每个task处理比原来更少的数据。举例来说，如果原本有5个key，每个key对应10条数据，这5个key都是分配给一个task的，那么这个task就要处理50条数据。而增加了shuffle read task以后，每个task就分配到一个key，即每个task就处理10条数据，那么自然每个task的执行时间都会变短了。具体原理如下图所示。<br>　　　<font color="red">方案优点</font>：实现起来比较简单，可以有效缓解和减轻数据倾斜的影响。<br>　　　<font color="red">方案缺点</font>：只是缓解了数据倾斜而已，没有彻底根除问题，根据实践经验来看，其效果有限。<br>　　　<font color="red">方案实践经验</font>：该方案通常无法彻底解决数据倾斜，因为如果出现一些极端情况，比如某个key对应的数据量有100万，那么无论你的task数量增加到多少，这个对应着100万数据的key肯定还是会分配到一个task中去处理，因此注定还是会发生数据倾斜的。所以这种方案只能说是在发现数据倾斜时尝试使用的第一种手段，尝试去用最简单的方法缓解数据倾斜而已，或者是和其他方案结合起来使用。</p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1570609831990.png" alt="1570609831990"></p>
<h4 id="解决方案四：两阶段聚合（局部聚合-全局聚合）"><a href="#解决方案四：两阶段聚合（局部聚合-全局聚合）" class="headerlink" title="解决方案四：两阶段聚合（局部聚合+全局聚合）"></a>解决方案四：两阶段聚合（局部聚合+全局聚合）</h4><p>　　<font color="red">方案适用场景</font>：对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时，比较适用这种方案。<br>　　<font color="red">方案实现思路</font>：这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。<br>　　<font color="red">方案实现原理</font>：将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。具体原理见下图。<br>　　<font color="red">方案优点</font>：对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。<br>　　<font color="red">方案缺点</font>：仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//案例</span></span><br><span class="line"><span class="comment">//  如果使用reduceByKey因为数据倾斜造成运行失败的问题。具体操作流程如下:</span></span><br><span class="line"><span class="comment">//    (1) 将原始的 key 转化为  随机值 + key  (随机值 = Random.nextInt)</span></span><br><span class="line"><span class="comment">//    (2) 对数据进行 reduceByKey(func)</span></span><br><span class="line"><span class="comment">//    (3) 将 key + 随机值转成 key</span></span><br><span class="line"><span class="comment">//    (4) 再对数据进行 reduceByKey(func)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCountAggTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[2]"</span>).setAppName(<span class="string">"WordCount"</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="keyword">val</span> array = <span class="type">Array</span>(<span class="string">"you you"</span>,<span class="string">"you you"</span>,<span class="string">"you you"</span>,</span><br><span class="line">      <span class="string">"you you"</span>,</span><br><span class="line">      <span class="string">"you you"</span>,</span><br><span class="line">      <span class="string">"you you"</span>,</span><br><span class="line">      <span class="string">"you you"</span>,</span><br><span class="line">      <span class="string">"jump jump"</span>)</span><br><span class="line">    <span class="keyword">val</span> rdd = sc.parallelize(array,<span class="number">8</span>)</span><br><span class="line">    rdd.flatMap( line =&gt; line.split(<span class="string">" "</span>))</span><br><span class="line">      .map(word =&gt;&#123;</span><br><span class="line">        <span class="keyword">val</span> prefix = (<span class="keyword">new</span> util.<span class="type">Random</span>).nextInt(<span class="number">3</span>)</span><br><span class="line">        (prefix+<span class="string">"_"</span>+word,<span class="number">1</span>)</span><br><span class="line">      &#125;).reduceByKey(_+_)</span><br><span class="line">       .map( wc =&gt;&#123;</span><br><span class="line">         <span class="keyword">val</span> newWord=wc._1.split(<span class="string">"_"</span>)(<span class="number">1</span>)</span><br><span class="line">         <span class="keyword">val</span> count=wc._2</span><br><span class="line">         (newWord,count)</span><br><span class="line">       &#125;).reduceByKey(_+_)</span><br><span class="line">      .foreach( wc =&gt;&#123;</span><br><span class="line">        println(<span class="string">"单词："</span>+wc._1 + <span class="string">" 次数："</span>+wc._2)</span><br><span class="line">      &#125;)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">注：我们这儿使用的是reduceByKey天然的有调优的效果，如果这儿是groupBykey那么发生数据倾斜的概率就会更大，更严重。</span><br></pre></td></tr></table></figure>
<h4 id="解决方案五：将reduce-join转为map-join"><a href="#解决方案五：将reduce-join转为map-join" class="headerlink" title="解决方案五：将reduce join转为map join"></a>解决方案五：将reduce join转为map join</h4><p>　　<font color="red">方案适用场景</font>：在对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小（比如几百M或者一两G），比较适用此方案。<br>　　<font color="red">方案实现思路</font>：不使用join算子进行连接操作，而使用Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作，彻底避免数据倾斜的发生和出现。将较小RDD中的数据直接通过collect算子拉取到Driver端的内存中来，然后对其创建一个Broadcast变量；接着对另外一个RDD执行map类算子，在算子函数内，从Broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比对，如果连接key相同的话，那么就将两个RDD的数据用你需要的方式连接起来。<br>　　<font color="red">方案实现原理</font>：普通的join是会走shuffle过程的，而一旦shuffle，就相当于会将相同key的数据拉取到一个shuffle read task中再进行join，此时就是reduce join。但是如果一个RDD是比较小的，则可以采用广播小RDD全量数据+map算子来实现与join同样的效果，也就是map join，此时就不会发生shuffle操作，也就不会发生数据倾斜。具体原理如下图所示。<br>　　<font color="red">方案优点</font>：对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜。<br>　　<font color="red">方案缺点</font>：适用场景较少，因为这个方案只适用于一个大表和一个小表的情况。毕竟我们需要将小表进行广播，此时会比较消耗内存资源，driver和每个Executor内存中都会驻留一份小RDD的全量数据。如果我们广播出去的RDD数据比较大，比如10G以上，那么就可能发生内存溢出了。因此并不适合两个都是大表的情况。</p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/reduce joinz转换为map join .png" alt="reduce joinz转换为map join "></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">MapJoinTest</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[2]"</span>).setAppName(<span class="string">"WordCount"</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="keyword">val</span> lista=<span class="type">Array</span>(</span><br><span class="line">      <span class="type">Tuple2</span>(<span class="string">"001"</span>,<span class="string">"令狐冲"</span>),</span><br><span class="line">      <span class="type">Tuple2</span>(<span class="string">"002"</span>,<span class="string">"任盈盈"</span>)</span><br><span class="line">    )</span><br><span class="line">     <span class="comment">//数据量小一点</span></span><br><span class="line">    <span class="keyword">val</span> listb=<span class="type">Array</span>(</span><br><span class="line">      <span class="type">Tuple2</span>(<span class="string">"001"</span>,<span class="string">"一班"</span>),</span><br><span class="line">      <span class="type">Tuple2</span>(<span class="string">"002"</span>,<span class="string">"二班"</span>)</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">val</span> listaRDD = sc.parallelize(lista)</span><br><span class="line">    <span class="keyword">val</span> listbRDD = sc.parallelize(listb)</span><br><span class="line">    <span class="comment">//val result: RDD[(String, (String, String))] = listaRDD.join(listbRDD)</span></span><br><span class="line">     <span class="comment">//设置广播变量</span></span><br><span class="line">    <span class="keyword">val</span> listbBoradcast = sc.broadcast(listbRDD.collect())</span><br><span class="line">    listaRDD.map(  tuple =&gt;&#123;</span><br><span class="line">      <span class="keyword">val</span> key = tuple._1</span><br><span class="line">      <span class="keyword">val</span> name = tuple._2</span><br><span class="line">      <span class="keyword">val</span> map = listbBoradcast.value.toMap</span><br><span class="line">      <span class="keyword">val</span> className = map.get(key)</span><br><span class="line">      (key,(name,className))</span><br><span class="line">    &#125;).foreach( tuple =&gt;&#123;</span><br><span class="line">      println(<span class="string">"班级号"</span>+tuple._1 + <span class="string">" 姓名："</span>+tuple._2._1 + <span class="string">" 班级名："</span>+tuple._2._2.get)</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="解决方案六：采样倾斜key并分拆join操作"><a href="#解决方案六：采样倾斜key并分拆join操作" class="headerlink" title="解决方案六：采样倾斜key并分拆join操作"></a>解决方案六：采样倾斜key并分拆join操作</h4><p>　　<font color="red">方案适用场景</font>：两个RDD/Hive表进行join的时候，如果数据量都比较大，无法采用“解决方案五”，那么此时可以看一下两个RDD/Hive表中的key分布情况。如果出现数据倾斜，是因为其中某一个RDD/Hive表中的少数几个key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀，那么采用这个解决方案是比较合适的。<br>　　<font color="red">方案实现思路</font>：<br>　　1、对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个key的数量，计算出来数据量最大的是哪几个key。<br>　　2、然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀，而不会导致倾斜的大部分key形成另外一个RDD。<br>　　3、接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀，不会导致倾斜的大部分key也形成另外一个RDD。<br>　　4、再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，==此时就可以将原先相同的key打散成n份，分散到多个task中去进行join了。==<br>　　5、而另外两个普通的RDD就照常join即可。<br>　　6、最后将两次join的结果使用union算子合并起来即可，就是最终的join结果。<br>　　<font color="red">方案实现原理</font>：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，可以将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。<br>　　<font color="red">方案优点</font>：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，采用该方式可以用最有效的方式打散key进行join。而且只需要针对少数倾斜key对应的数据进行扩容n倍，不需要对全量数据进行扩容。避免了占用过多内存。<br>　　<font color="red">方案缺点</font>：如果导致倾斜的key特别多的话，比如成千上万个key都导致数据倾斜，那么这种方式也不适合。</p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/随机前缀和扩容RDD.png" alt="随机前缀和扩容RDD"></p>
<h4 id="解决方案七：使用随机前缀和扩容RDD进行join"><a href="#解决方案七：使用随机前缀和扩容RDD进行join" class="headerlink" title="解决方案七：使用随机前缀和扩容RDD进行join"></a>解决方案七：使用随机前缀和扩容RDD进行join</h4><p>　　<font color="red">方案适用场景</font>：如果在进行join操作时，RDD中有大量的key导致数据倾斜，那么进行分拆key也没什么意义，此时就只能使用这一种方案来解决问题了。<br>　　<font color="red">方案实现思路</font>：<br>　　1、该方案的实现思路基本和“解决方案六”类似，首先查看RDD/Hive表中的数据分布情况，找到那个造成数据倾斜的RDD/Hive表，比如有多个key都对应了超过1万条数据。<br>　　2、然后将该RDD的每条数据都打上一个n以内的随机前缀。<br>　　3、同时对另外一个正常的RDD进行扩容，将每条数据都扩容成n条数据，扩容出来的每条数据都依次打上一个0~n的前缀。<br>　　4、最后将两个处理后的RDD进行join即可。<br>　　方案实现原理：将原先一样的key通过附加随机前缀变成不一样的key，然后就可以将这些处理后的“不同key”分散到多个task中去处理，而不是让一个task处理大量的相同key。该方案与“解决方案六”的不同之处就在于，上一种方案是尽量只对少数倾斜key对应的数据进行特殊处理，由于处理过程需要扩容RDD，因此上一种方案扩容RDD后对内存的占用并不大；而这一种方案是针对有大量倾斜key的情况，没法将部分key拆分出来进行单独处理，因此只能对整个RDD进行数据扩容，对内存资源要求很高。<br>　　<font color="red">方案优点</font>：对join类型的数据倾斜基本都可以处理，而且效果也相对比较显著，性能提升效果非常不错。<br>　　<font color="red">方案缺点</font>：该方案更多的是缓解数据倾斜，而不是彻底避免数据倾斜。而且需要对整个RDD进行扩容，对内存资源要求很高。<br>　　<font color="red">方案实践经验</font>：曾经开发一个数据需求的时候，发现一个join导致了数据倾斜。优化之前，作业的执行时间大约是60分钟左右；使用该方案优化之后，执行时间缩短到10分钟左右，性能提升了6倍。</p>
<h4 id="解决方案八：把上面的几种数据倾斜的解决方案综合的灵活运行"><a href="#解决方案八：把上面的几种数据倾斜的解决方案综合的灵活运行" class="headerlink" title="解决方案八：把上面的几种数据倾斜的解决方案综合的灵活运行"></a>解决方案八：把上面的几种数据倾斜的解决方案综合的灵活运行</h4><h3 id="13-Shuffle调优"><a href="#13-Shuffle调优" class="headerlink" title="13. Shuffle调优"></a>13. Shuffle调优</h3><h4 id="13-1-什么时候发生shuffle"><a href="#13-1-什么时候发生shuffle" class="headerlink" title="13.1 什么时候发生shuffle"></a>13.1 什么时候发生shuffle</h4><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567231926304.png" alt="1567231926304"></p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567232029615.png" alt="1567232029615"></p>
<h4 id="13-2-Shuffle的核心组件"><a href="#13-2-Shuffle的核心组件" class="headerlink" title="13.2 Shuffle的核心组件"></a>13.2 Shuffle的核心组件</h4><p>碰到ShuffleDenpendency就进行stage的划分，ShuffleMapStage: 为shuffle提供数据的中间stage，ResultStage: 为一个action操作计算结果的stage。</p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567232245246.png" alt="1567232245246"></p>
<h4 id="13-3-Shuffle组件调度"><a href="#13-3-Shuffle组件调度" class="headerlink" title="13.3 Shuffle组件调度"></a>13.3 Shuffle组件调度</h4><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567232408746.png" alt="1567232408746"></p>
<h4 id="13-4-Shuffle原理剖析"><a href="#13-4-Shuffle原理剖析" class="headerlink" title="13.4 Shuffle原理剖析"></a>13.4 Shuffle原理剖析</h4><h5 id="13-4-1-MapOutputTracker"><a href="#13-4-1-MapOutputTracker" class="headerlink" title="13.4.1 MapOutputTracker"></a>13.4.1 MapOutputTracker</h5><p>解决的一个问题是resut task如何知道从哪个Executor去拉取Shuffle data</p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567232849493.png" alt="1567232849493"></p>
<h5 id="13-4-2-ShuffleWriter"><a href="#13-4-2-ShuffleWriter" class="headerlink" title="13.4.2 ShuffleWriter"></a>13.4.2 ShuffleWriter</h5><p><strong>（1）HashShuffleWriter</strong></p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567232923386.png" alt="1567232923386"></p>
<p>特点：根据Hash分区，分区数是m * n 个。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> counts: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] </span><br><span class="line">	= wordCount.reduceByKey(<span class="keyword">new</span> <span class="type">HashPartitioner</span>(<span class="number">2</span>), (x, y) =&gt; x + y)</span><br></pre></td></tr></table></figure>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567233073556.png" alt="1567233073556"></p>
<p><strong>（2）SortShuffleWriter</strong></p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567233308867.png" alt="1567233308867"></p>
<p>特点：</p>
<p>a、文件数量为m</p>
<p>b、如果需要排序或者需要combine，那么每一个partition数据排序要自己实现。（SortShuffleWriter里的sort指的是对partition的分区号进行排序）</p>
<p>c、数据先放在内存,内存不够则写到磁盘中,最后再全部写到磁盘。</p>
<p><strong>（3）BypassMergeSortShuffleWriter</strong></p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567234608013.png" alt="1567234608013"></p>
<p>这种模式同时具有HashShuffleWriter和SortShuffleter的特点。因为其实HashShufflerWriter的性能不错，但是如果task数太多的话，性能话下降，所以Spark在task数较少的时候自动使用了这种模式，一开始还是像HashShufflerWriter那种生成多个文件，但是最后会把多个文件合并成一个文件。然后下游来读取文件。默认map的分区需要小于spark.shuffle.sort.bypassMergeThreshold(默认是200),因为如何分区数太多，产生的小文件就会很多性能就会下降。</p>
<h5 id="13-4-3-ShuffleReader"><a href="#13-4-3-ShuffleReader" class="headerlink" title="13.4.3 ShuffleReader"></a>13.4.3 ShuffleReader</h5><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567235022607.png" alt="1567235022607"></p>
<h5 id="3-4-4-Spark-Shuffle参数调优"><a href="#3-4-4-Spark-Shuffle参数调优" class="headerlink" title="3.4.4 Spark Shuffle参数调优"></a>3.4.4 Spark Shuffle参数调优</h5><p>==spark.shuffle.file.buffer==</p>
<ul>
<li>默认值：32k</li>
<li>参数说明：该参数用于设置shuffle write task的BufferedOutputStream的buffer缓冲大小。将数据写到磁盘文件之前，会先写入buffer缓冲中，待缓冲写满之后，才会溢写到磁盘。</li>
<li>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如64k），从而减少shuffle write过程中溢写磁盘文件的次数，也就可以减少磁盘IO次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。</li>
</ul>
<p>==spark.reducer.maxSizeInFlight==</p>
<ul>
<li>默认值：48m</li>
<li>参数说明：该参数用于设置shuffle read task的buffer缓冲大小，而这个buffer缓冲决定了每次能够拉取多少数据。</li>
<li>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如96m），从而减少拉取数据的次数，也就可以减少网络传输的次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。</li>
</ul>
<p>==spark.shuffle.io.maxRetries==</p>
<ul>
<li>默认值：3</li>
<li>参数说明：shuffle read task从shuffle write task所在节点拉取属于自己的数据时，如果因为网络异常导致拉取失败，是会自动进行重试的。该参数就代表了可以重试的最大次数。如果在指定次数之内拉取还是没有成功，就可能会导致作业执行失败。</li>
<li>调优建议：对于那些包含了特别耗时的shuffle操作的作业，建议增加重试最大次数（比如60次），以避免由于JVM的full gc或者网络不稳定等因素导致的数据拉取失败。在实践中发现，对于针对超大数据量（数十亿~上百亿）的shuffle过程，调节该参数可以大幅度提升稳定性。</li>
</ul>
<p>==spark.shuffle.io.retryWait==</p>
<ul>
<li>默认值：5s</li>
<li>参数说明：具体解释同上，该参数代表了每次重试拉取数据的等待间隔，默认是5s。</li>
<li>调优建议：建议加大间隔时长（比如60s），以增加shuffle操作的稳定性。</li>
</ul>
<p>==spark.shuffle.memoryFraction==（Spark1.6是这个参数，1.6以后参数变了，具体参考上一讲Spark内存模型知识）</p>
<ul>
<li>默认值：0.2</li>
<li>参数说明：该参数代表了Executor内存中，分配给shuffle read task进行聚合操作的内存比例，默认是20%。</li>
<li>调优建议：在资源参数调优中讲解过这个参数。如果内存充足，而且很少使用持久化操作，建议调高这个比例，给shuffle read的聚合操作更多内存，以避免由于内存不足导致聚合过程中频繁读写磁盘。在实践中发现，合理调节该参数可以将性能提升10%左右。</li>
</ul>
<p>==spark.shuffle.manager==</p>
<ul>
<li>默认值：sort</li>
<li>参数说明：该参数用于设置ShuffleManager的类型。Spark 1.5以后，有三个可选项：hash、sort和tungsten-sort。HashShuffleManager是Spark 1.2以前的默认选项，但是Spark 1.2以及之后的版本默认都是SortShuffleManager了。Spark1.6以后把hash方式给移除了，tungsten-sort与sort类似，但是使用了tungsten计划中的堆外内存管理机制，内存使用效率更高。</li>
<li>调优建议：由于SortShuffleManager默认会对数据进行排序，因此如果你的业务逻辑中需要该排序机制的话，则使用默认的SortShuffleManager就可以；而如果你的业务逻辑不需要对数据进行排序，那么建议参考后面的几个参数调优，通过bypass机制或优化的HashShuffleManager来避免排序操作，同时提供较好的磁盘读写性能。这里要注意的是，tungsten-sort要慎用，因为之前发现了一些相应的bug。</li>
</ul>
<p>==spark.shuffle.sort.bypassMergeThreshold==</p>
<ul>
<li>默认值：200</li>
<li>参数说明：当ShuffleManager为SortShuffleManager时，如果shuffle read task的数量小于这个阈值（默认是200），则shuffle write过程中不会进行排序操作，而是直接按照未经优化的HashShuffleManager的方式去写数据，但是最后会将每个task产生的所有临时磁盘文件都合并成一个文件，并会创建单独的索引文件。</li>
<li>调优建议：当你使用SortShuffleManager时，如果的确不需要排序操作，那么建议将这个参数调大一些，大于shuffle read task的数量。那么此时就会自动启用bypass机制，map-side就不会进行排序了，减少了排序的性能开销。但是这种方式下，依然会产生大量的磁盘文件，因此shuffle write性能有待提高。</li>
</ul>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a href="https://blog.sev7e0.site/">大数据施工现场</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script src="/js/gitment.js"></script>
<script>
    var gitment = new Gitment({
        id: 'Spark调优',
        owner: 'orchid-ding',
        repo: 'kfly-blog-comment',
        oauth: {
            client_id: '0770cdab79393197b6f5',
            client_secret: '376fb6c7bcd5047718b356712f596b89e490360c',
        },
    })
    gitment.render('comment-container')
</script>




</html>
