<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="天行健、君子以自强不息；地势坤，君子以厚德载物。">
    <meta name="keyword"  content="兰草">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        Spark调优 - kfly的博客 | kfly&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_1598291_q3el2wqimj.css" type="text/css">
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>kfly</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont iconhome"></i>
                    <span>主页</span>
                </a>
            </li>
 	   <li >
                <a href="/spec/">
                    <i class="iconfont iconzhuanti"></i>
                    <span>专题</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>简历</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Spark调优"><span class="toc-text">Spark调优</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-分配更多的资源"><span class="toc-text">1. 分配更多的资源</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-分配哪些资源"><span class="toc-text">1.1 分配哪些资源</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-在哪里可以设置这些资源"><span class="toc-text">1.2 在哪里可以设置这些资源</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-参数调节到多大，算是最大"><span class="toc-text">1.3 参数调节到多大，算是最大</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-为什么调大资源以后性能可以提升"><span class="toc-text">1.4 为什么调大资源以后性能可以提升</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-提高并行度"><span class="toc-text">2. 提高并行度</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-Spark的并行度指的是什么"><span class="toc-text">2.1 Spark的并行度指的是什么</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-如何提高并行度"><span class="toc-text">2.2 如何提高并行度</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-1-可以设置task的数量"><span class="toc-text">2.2.1 可以设置task的数量</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-2-如何设置task数量来提高并行度"><span class="toc-text">2.2.2 如何设置task数量来提高并行度</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-3-给RDD重新设置partition的数量"><span class="toc-text">2.2.3 给RDD重新设置partition的数量</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-4-提高sparksql运行的task数量"><span class="toc-text">2.2.4 提高sparksql运行的task数量</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-RDD的重用和持久化"><span class="toc-text">3. RDD的重用和持久化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-实际开发遇到的情况说明"><span class="toc-text">3.1 实际开发遇到的情况说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-如何对rdd进行持久化"><span class="toc-text">3.2 如何对rdd进行持久化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-rdd持久化的时可以采用序列化"><span class="toc-text">3.3 rdd持久化的时可以采用序列化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-广播变量的使用"><span class="toc-text">4.  广播变量的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-场景描述"><span class="toc-text">4.1 场景描述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-广播变量引入"><span class="toc-text">4.2 广播变量引入</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-使用广播变量后的性能分析"><span class="toc-text">4.3 使用广播变量后的性能分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-广播变量使用注意事项"><span class="toc-text">4.4 广播变量使用注意事项</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-5-如何使用广播变量"><span class="toc-text">4.5 如何使用广播变量</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-尽量避免使用shuffle类算子"><span class="toc-text">5. 尽量避免使用shuffle类算子</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-shuffle描述"><span class="toc-text">5.1 shuffle描述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-哪些算子操作会产生shuffle"><span class="toc-text">5.2 哪些算子操作会产生shuffle</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-如何避免产生shuffle"><span class="toc-text">5.3 如何避免产生shuffle</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-4-使用map-side预聚合的shuffle操作"><span class="toc-text">5.4 使用map-side预聚合的shuffle操作</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-使用高性能的算子"><span class="toc-text">6. 使用高性能的算子</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#6-1-使用reduceByKey-aggregateByKey替代groupByKey"><span class="toc-text">6.1 使用reduceByKey/aggregateByKey替代groupByKey</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-2-使用mapPartitions替代普通map"><span class="toc-text">6.2 使用mapPartitions替代普通map</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-3-使用foreachPartitions替代foreach"><span class="toc-text">6.3 使用foreachPartitions替代foreach</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-4-使用filter之后进行coalesce操作"><span class="toc-text">6.4 使用filter之后进行coalesce操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-5-使用repartitionAndSortWithinPartitions替代repartition与sort类操作"><span class="toc-text">6.5 使用repartitionAndSortWithinPartitions替代repartition与sort类操作</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-使用Kryo优化序列化性能"><span class="toc-text">7. 使用Kryo优化序列化性能</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#7-1-spark序列化介绍"><span class="toc-text">7.1 spark序列化介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-2-Kryo序列化启用后生效的地方"><span class="toc-text">7.2 Kryo序列化启用后生效的地方</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-3-如何开启Kryo序列化机制"><span class="toc-text">7.3 如何开启Kryo序列化机制</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-使用fastutil优化数据格式"><span class="toc-text">8. 使用fastutil优化数据格式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-fastutil介绍"><span class="toc-text">8.1 fastutil介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-2-fastutil好处"><span class="toc-text">8.2 fastutil好处</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-3-Spark中应用fastutil的场景和使用"><span class="toc-text">8.3 Spark中应用fastutil的场景和使用</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#8-3-1-算子函数使用了外部变量"><span class="toc-text">8.3.1 算子函数使用了外部变量</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#8-3-2-算子函数里使用了比较大的集合Map-List"><span class="toc-text">8.3.2 算子函数里使用了比较大的集合Map/List</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#8-3-3-fastutil的使用"><span class="toc-text">8.3.3 fastutil的使用</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-调节数据本地化等待时长"><span class="toc-text">9. 调节数据本地化等待时长</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#9-1-本地化级别"><span class="toc-text">9.1 本地化级别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-2-数据本地化等待时长"><span class="toc-text">9.2 数据本地化等待时长</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-3-如何调节参数并且测试"><span class="toc-text">9.3 如何调节参数并且测试</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-基于Spark内存模型调优"><span class="toc-text">10. 基于Spark内存模型调优</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#10-1-spark中executor内存划分"><span class="toc-text">10.1 spark中executor内存划分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-2-spark的内存模型"><span class="toc-text">10.2 spark的内存模型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#10-2-1-静态内存模型"><span class="toc-text">10.2.1 静态内存模型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#10-2-2-统一内存模型"><span class="toc-text">10.2.2 统一内存模型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#10-2-3-任务提交脚本参考"><span class="toc-text">10.2.3 任务提交脚本参考</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#10-2-4-个人经验"><span class="toc-text">10.2.4 个人经验</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-数据倾斜原理和现象分析"><span class="toc-text">11.  数据倾斜原理和现象分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#11-1-数据倾斜概述"><span class="toc-text">11.1 数据倾斜概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-2-数据倾斜发生时的现象"><span class="toc-text">11.2 数据倾斜发生时的现象</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-3-数据倾斜发生的原理"><span class="toc-text">11.3 数据倾斜发生的原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-4-数据倾斜如何定位原因"><span class="toc-text">11.4 数据倾斜如何定位原因</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-5-数据倾斜原因总结"><span class="toc-text">11.5 数据倾斜原因总结</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-6-数据倾斜的后果"><span class="toc-text">11.6 数据倾斜的后果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-spark中数据倾斜的解决方案"><span class="toc-text">12. spark中数据倾斜的解决方案</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案一：使用Hive-ETL预处理数据"><span class="toc-text">解决方案一：使用Hive ETL预处理数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案二：过滤少数导致倾斜的key"><span class="toc-text">解决方案二：过滤少数导致倾斜的key</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案三：提高shuffle操作的并行度-效果差"><span class="toc-text">解决方案三：提高shuffle操作的并行度(效果差)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案四：两阶段聚合（局部聚合-全局聚合）"><span class="toc-text">解决方案四：两阶段聚合（局部聚合+全局聚合）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案五：将reduce-join转为map-join"><span class="toc-text">解决方案五：将reduce join转为map join</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案六：采样倾斜key并分拆join操作"><span class="toc-text">解决方案六：采样倾斜key并分拆join操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案七：使用随机前缀和扩容RDD进行join"><span class="toc-text">解决方案七：使用随机前缀和扩容RDD进行join</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案八：把上面的几种数据倾斜的解决方案综合的灵活运行"><span class="toc-text">解决方案八：把上面的几种数据倾斜的解决方案综合的灵活运行</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-Shuffle调优"><span class="toc-text">13. Shuffle调优</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#13-1-什么时候发生shuffle"><span class="toc-text">13.1 什么时候发生shuffle</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-2-Shuffle的核心组件"><span class="toc-text">13.2 Shuffle的核心组件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-3-Shuffle组件调度"><span class="toc-text">13.3 Shuffle组件调度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-4-Shuffle原理剖析"><span class="toc-text">13.4 Shuffle原理剖析</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#13-4-1-MapOutputTracker"><span class="toc-text">13.4.1 MapOutputTracker</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#13-4-2-ShuffleWriter"><span class="toc-text">13.4.2 ShuffleWriter</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#13-4-3-ShuffleReader"><span class="toc-text">13.4.3 ShuffleReader</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-4-4-Spark-Shuffle参数调优"><span class="toc-text">3.4.4 Spark Shuffle参数调优</span></a></li></ol></li></ol></li></ol></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        Spark调优
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2020-01-05 12:55:30</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#spark" title="spark">spark</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#调优" title="调优">调优</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <h1 id="Spark调优"><a href="#Spark调优" class="headerlink" title="Spark调优"></a>Spark调优</h1><h3 id="1-分配更多的资源"><a href="#1-分配更多的资源" class="headerlink" title="1. 分配更多的资源"></a>1. 分配更多的资源</h3><pre><code>分配更多的资源：
    它是性能优化调优的王道，就是增加和分配更多的资源，这对于性能和速度上的提升是显而易见的，
    基本上，在一定范围之内，增加资源与性能的提升，是成正比的；写完了一个复杂的spark作业之后，进行性能调优的时候，首先第一步，就是要来调节最优的资源配置；
    在这个基础之上，如果说你的spark作业，能够分配的资源达到了你的能力范围的顶端之后，无法再分配更多的资源了，公司资源有限；那么才是考虑去做后面的这些性能调优的点。

相关问题：
（1）分配哪些资源？
（2）在哪里可以设置这些资源？
（3）剖析为什么分配这些资源之后，性能可以得到提升？
</code></pre><h4 id="1-1-分配哪些资源"><a href="#1-1-分配哪些资源" class="headerlink" title="1.1 分配哪些资源"></a>1.1 分配哪些资源</h4><pre><code>executor-memory、executor-cores、driver-memory
</code></pre><h4 id="1-2-在哪里可以设置这些资源"><a href="#1-2-在哪里可以设置这些资源" class="headerlink" title="1.2 在哪里可以设置这些资源"></a>1.2 在哪里可以设置这些资源</h4><pre><code>在实际的生产环境中，提交spark任务时，使用spark-submit shell脚本，在里面调整对应的参数。

 提交任务的脚本:
 spark-submit \
 --master spark://node1:7077 \
 --class cn.itcast.WordCount \
 --num-executors 3 \    配置executor的数量
 --driver-memory 1g \   配置driver的内存（影响不大）
 --executor-memory 1g \ 配置每一个executor的内存大小
 --executor-cores 3 \   配置每一个executor的cpu个数
 /export/servers/wordcount.jar

</code></pre><h4 id="1-3-参数调节到多大，算是最大"><a href="#1-3-参数调节到多大，算是最大" class="headerlink" title="1.3 参数调节到多大，算是最大"></a>1.3 参数调节到多大，算是最大</h4><ul>
<li>==Standalone模式==</li>
</ul>
<pre><code>     先计算出公司spark集群上的所有资源 每台节点的内存大小和cpu核数，
     比如：一共有20台worker节点，每台节点8g内存，10个cpu。
     实际任务在给定资源的时候，可以给20个executor、每个executor的内存8g、每个executor的使用的cpu个数10。
</code></pre><ul>
<li>==Yarn模式==</li>
</ul>
<pre><code>     先计算出yarn集群的所有大小，比如一共500g内存，100个cpu；
     这个时候可以分配的最大资源，比如给定50个executor、每个executor的内存大小10g,每个executor使用的cpu个数为2。
</code></pre><ul>
<li>使用原则</li>
</ul>
<pre><code>在资源比较充足的情况下，尽可能的使用更多的计算资源，尽量去调节到最大的大小
</code></pre><h4 id="1-4-为什么调大资源以后性能可以提升"><a href="#1-4-为什么调大资源以后性能可以提升" class="headerlink" title="1.4 为什么调大资源以后性能可以提升"></a>1.4 为什么调大资源以后性能可以提升</h4><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/spark性能优化--分配资源.png" alt="spark性能优化--分配资源"></p>
<h3 id="2-提高并行度"><a href="#2-提高并行度" class="headerlink" title="2. 提高并行度"></a>2. 提高并行度</h3><h4 id="2-1-Spark的并行度指的是什么"><a href="#2-1-Spark的并行度指的是什么" class="headerlink" title="2.1 Spark的并行度指的是什么"></a>2.1 Spark的并行度指的是什么</h4><pre><code> spark作业中，各个stage的task的数量，也就代表了spark作业在各个阶段stage的并行度！
    当分配完所能分配的最大资源了，然后对应资源去调节程序的并行度，如果并行度没有与资源相匹配，那么导致你分配下去的资源都浪费掉了。同时并行运行，还可以让每个task要处理的数量变少（很简单的原理。合理设置并行度，可以充分利用集群资源，减少每个task处理数据量，而增加性能加快运行速度。）
</code></pre><h4 id="2-2-如何提高并行度"><a href="#2-2-如何提高并行度" class="headerlink" title="2.2 如何提高并行度"></a>2.2 如何提高并行度</h4><h5 id="2-2-1-可以设置task的数量"><a href="#2-2-1-可以设置task的数量" class="headerlink" title="2.2.1 可以设置task的数量"></a>2.2.1 可以设置task的数量</h5><pre><code>    至少设置成与spark Application 的总cpu core 数量相同。
    最理想情况，150个core，分配150task，一起运行，差不多同一时间运行完毕
    官方推荐，task数量，设置成spark Application 总cpu core数量的2~3倍 。


    比如150个cpu core ，基本设置task数量为300~500. 与理想情况不同的，有些task会运行快一点，比如50s就完了，有些task 可能会慢一点，要一分半才运行完，所以如果你的task数量，刚好设置的跟cpu core 数量相同，可能会导致资源的浪费。
    因为比如150个task中10个先运行完了，剩余140个还在运行，但是这个时候，就有10个cpu core空闲出来了，导致浪费。如果设置2~3倍，那么一个task运行完以后，另外一个task马上补上来，尽量让cpu core不要空闲。同时尽量提升spark运行效率和速度。提升性能。
</code></pre><h5 id="2-2-2-如何设置task数量来提高并行度"><a href="#2-2-2-如何设置task数量来提高并行度" class="headerlink" title="2.2.2 如何设置task数量来提高并行度"></a>2.2.2 如何设置task数量来提高并行度</h5><pre><code>设置参数spark.defalut.parallelism  
   默认是没有值的，如果设置了值为10，它会在shuffle的过程才会起作用。
   比如 val rdd2 = rdd1.reduceByKey(_+_) 
   此时rdd2的分区数就是10

可以通过在构建SparkConf对象的时候设置，例如：
   new SparkConf().set(&quot;spark.defalut.parallelism&quot;,&quot;500&quot;)
</code></pre><h5 id="2-2-3-给RDD重新设置partition的数量"><a href="#2-2-3-给RDD重新设置partition的数量" class="headerlink" title="2.2.3 给RDD重新设置partition的数量"></a>2.2.3 给RDD重新设置partition的数量</h5><pre><code>使用rdd.repartition 来重新分区，该方法会生成一个新的rdd，使其分区数变大。
此时由于一个partition对应一个task，那么对应的task个数越多，通过这种方式也可以提高并行度。
</code></pre><h5 id="2-2-4-提高sparksql运行的task数量"><a href="#2-2-4-提高sparksql运行的task数量" class="headerlink" title="2.2.4 提高sparksql运行的task数量"></a>2.2.4 提高sparksql运行的task数量</h5><pre><code>通过设置参数 spark.sql.shuffle.partitions=500  默认为200；
可以适当增大，来提高并行度。 比如设置为 spark.sql.shuffle.partitions=500
</code></pre><h3 id="3-RDD的重用和持久化"><a href="#3-RDD的重用和持久化" class="headerlink" title="3. RDD的重用和持久化"></a>3. RDD的重用和持久化</h3><h4 id="3-1-实际开发遇到的情况说明"><a href="#3-1-实际开发遇到的情况说明" class="headerlink" title="3.1 实际开发遇到的情况说明"></a>3.1 实际开发遇到的情况说明</h4><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/rdd重用1.png" alt="rdd重用1"></p>
<pre><code>如上图所示的计算逻辑：
（1）当第一次使用rdd2做相应的算子操作得到rdd3的时候，就会从rdd1开始计算，先读取HDFS上的文件，然后对rdd1做对应的算子操作得到rdd2,再由rdd2计算之后得到rdd3。同样为了计算得到rdd4，前面的逻辑会被重新计算。

（3）默认情况下多次对一个rdd执行算子操作，去获取不同的rdd，都会对这个rdd及之前的父rdd全部重新计算一次。
这种情况在实际开发代码的时候会经常遇到，但是我们一定要避免一个rdd重复计算多次，否则会导致性能急剧降低。

总结：可以把多次使用到的rdd，也就是公共rdd进行持久化，避免后续需要，再次重新计算，提升效率。
</code></pre><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/rdd重用2.png" alt="rdd重用2"></p>
<h4 id="3-2-如何对rdd进行持久化"><a href="#3-2-如何对rdd进行持久化" class="headerlink" title="3.2 如何对rdd进行持久化"></a>3.2 如何对rdd进行持久化</h4><ul>
<li>可以调用rdd的cache或者persist方法。</li>
</ul>
<pre><code>（1）cache方法默认是把数据持久化到内存中 ，例如：rdd.cache ，其本质还是调用了persist方法
（2）persist方法中有丰富的缓存级别，这些缓存级别都定义在StorageLevel这个object中，可以结合实际的应用场景合理的设置缓存级别。例如： rdd.persist(StorageLevel.MEMORY_ONLY),这是cache方法的实现。
</code></pre><h4 id="3-3-rdd持久化的时可以采用序列化"><a href="#3-3-rdd持久化的时可以采用序列化" class="headerlink" title="3.3 rdd持久化的时可以采用序列化"></a>3.3 rdd持久化的时可以采用序列化</h4><pre><code>（1）如果正常将数据持久化在内存中，那么可能会导致内存的占用过大，这样的话，也许会导致OOM内存溢出。
（2）当纯内存无法支撑公共RDD数据完全存放的时候，就优先考虑使用序列化的方式在纯内存中存储。将RDD的每个partition的数据，序列化成一个字节数组；序列化后，大大减少内存的空间占用。
（3）序列化的方式，唯一的缺点就是，在获取数据的时候，需要反序列化。但是可以减少占用的空间和便于网络传输
（4）如果序列化纯内存方式，还是导致OOM，内存溢出；就只能考虑磁盘的方式，内存+磁盘的普通方式（无序列化）。
（5）为了数据的高可靠性，而且内存充足，可以使用双副本机制，进行持久化
    持久化的双副本机制，持久化后的一个副本，因为机器宕机了，副本丢了，就还是得重新计算一次；
    持久化的每个数据单元，存储一份副本，放在其他节点上面，从而进行容错；
    一个副本丢了，不用重新计算，还可以使用另外一份副本。这种方式，仅仅针对你的内存资源极度充足。
     比如: StorageLevel.MEMORY_ONLY_2
</code></pre><h3 id="4-广播变量的使用"><a href="#4-广播变量的使用" class="headerlink" title="4.  广播变量的使用"></a>4.  广播变量的使用</h3><h4 id="4-1-场景描述"><a href="#4-1-场景描述" class="headerlink" title="4.1 场景描述"></a>4.1 场景描述</h4><pre><code>    在实际工作中可能会遇到这样的情况，由于要处理的数据量非常大，这个时候可能会在一个stage中出现大量的task，比如有1000个task，这些task都需要一份相同的数据来处理业务，这份数据的大小为100M，该数据会拷贝1000份副本，通过网络传输到各个task中去，给task使用。这里会涉及大量的网络传输开销，同时至少需要的内存为1000*100M=100G，这个内存开销是非常大的。不必要的内存的消耗和占用，就导致了你在进行RDD持久化到内存，也许就没法完全在内存中放下；就只能写入磁盘，最后导致后续的操作在磁盘IO上消耗性能；这对于spark任务处理来说就是一场灾难。

    由于内存开销比较大，task在创建对象的时候，可能会出现堆内存放不下所有对象，就会导致频繁的垃圾回收器的回收GC。GC的时候一定是会导致工作线程停止，也就是导致Spark暂停工作那么一点时间。频繁GC的话，对Spark作业的运行的速度会有相当可观的影响。

</code></pre><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/task共享数据.png" alt="task共享数据"></p>
<h4 id="4-2-广播变量引入"><a href="#4-2-广播变量引入" class="headerlink" title="4.2 广播变量引入"></a>4.2 广播变量引入</h4><pre><code>    Spark中分布式执行的代码需要传递到各个executor的task上运行。对于一些只读、固定的数据,每次都需要Driver广播到各个Task上，这样效率低下。广播变量允许将变量只广播给各个executor。该executor上的各个task再从所在节点的BlockManager(负责管理某个executor对应的内存和磁盘上的数据)获取变量，而不是从Driver获取变量，从而提升了效率。
</code></pre><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/广播变量.png" alt="广播变量"></p>
<pre><code>广播变量，初始的时候，就在Drvier上有一份副本。通过在Driver把共享数据转换成广播变量。

    task在运行的时候，想要使用广播变量中的数据，此时首先会在自己本地的Executor对应的BlockManager中，尝试获取变量副本；如果本地没有，那么就从Driver远程拉取广播变量副本，并保存在本地的BlockManager中；

    此后这个executor上的task，都会直接使用本地的BlockManager中的副本。那么这个时候所有该executor中的task都会使用这个广播变量的副本。也就是说一个executor只需要在第一个task启动时，获得一份广播变量数据，之后的task都从本节点的BlockManager中获取相关数据。

    executor的BlockManager除了从driver上拉取，也可能从其他节点的BlockManager上拉取变量副本，网络距离越近越好。
</code></pre><h4 id="4-3-使用广播变量后的性能分析"><a href="#4-3-使用广播变量后的性能分析" class="headerlink" title="4.3 使用广播变量后的性能分析"></a>4.3 使用广播变量后的性能分析</h4><pre><code>比如一个任务需要50个executor，1000个task，共享数据为100M。
(1)在不使用广播变量的情况下，1000个task，就需要该共享数据的1000个副本，也就是说有1000份数需要大量的网络传输和内存开销存储。耗费的内存大小1000*100=100G.

(2)使用了广播变量后，50个executor就只需要50个副本数据，而且不一定都是从Driver传输到每个节点，还可能是就近从最近的节点的executor的blockmanager上拉取广播变量副本，网络传输速度大大增加；内存开销 50*100M=5G

总结：
    不使用广播变量的内存开销为100G，使用后的内存开销5G，这里就相差了20倍左右的网络传输性能损耗和内存开销，使用广播变量后对于性能的提升和影响，还是很可观的。

    广播变量的使用不一定会对性能产生决定性的作用。比如运行30分钟的spark作业，可能做了广播变量以后，速度快了2分钟，或者5分钟。但是一点一滴的调优，积少成多。最后还是会有效果的。
</code></pre><h4 id="4-4-广播变量使用注意事项"><a href="#4-4-广播变量使用注意事项" class="headerlink" title="4.4 广播变量使用注意事项"></a>4.4 广播变量使用注意事项</h4><pre><code>（1）能不能将一个RDD使用广播变量广播出去？

       不能，因为RDD是不存储数据的。可以将RDD的结果广播出去。

（2）广播变量只能在Driver端定义，不能在Executor端定义。

（3）在Driver端可以修改广播变量的值，在Executor端无法修改广播变量的值。

（4）如果executor端用到了Driver的变量，如果不使用广播变量在Executor有多少task就有多少Driver端的变量副本。

（5）如果Executor端用到了Driver的变量，如果使用广播变量在每个Executor中只有一份Driver端的变量副本。
</code></pre><h4 id="4-5-如何使用广播变量"><a href="#4-5-如何使用广播变量" class="headerlink" title="4.5 如何使用广播变量"></a>4.5 如何使用广播变量</h4><ul>
<li>例如</li>
</ul>
<pre><code>(1) 通过sparkContext的broadcast方法把数据转换成广播变量，类型为Broadcast，
    val broadcastArray: Broadcast[Array[Int]] = sc.broadcast(Array(1,2,3,4,5,6))

(2) 然后executor上的BlockManager就可以拉取该广播变量的副本获取具体的数据。
        获取广播变量中的值可以通过调用其value方法
     val array: Array[Int] = broadcastArray.value
</code></pre><h3 id="5-尽量避免使用shuffle类算子"><a href="#5-尽量避免使用shuffle类算子" class="headerlink" title="5. 尽量避免使用shuffle类算子"></a>5. 尽量避免使用shuffle类算子</h3><h4 id="5-1-shuffle描述"><a href="#5-1-shuffle描述" class="headerlink" title="5.1 shuffle描述"></a>5.1 shuffle描述</h4><pre><code>    spark中的shuffle涉及到数据要进行大量的网络传输，下游阶段的task任务需要通过网络拉取上阶段task的输出数据，shuffle过程，简单来说，就是将分布在集群中多个节点上的同一个key，拉取到同一个节点上，进行聚合或join等操作。比如reduceByKey、join等算子，都会触发shuffle操作。

    如果有可能的话，要尽量避免使用shuffle类算子。
    因为Spark作业运行过程中，最消耗性能的地方就是shuffle过程。

</code></pre><h4 id="5-2-哪些算子操作会产生shuffle"><a href="#5-2-哪些算子操作会产生shuffle" class="headerlink" title="5.2 哪些算子操作会产生shuffle"></a>5.2 哪些算子操作会产生shuffle</h4><pre><code>    spark程序在开发的过程中使用reduceByKey、join、distinct、repartition等算子操作，这里都会产生shuffle，由于shuffle这一块是非常耗费性能的，实际开发中尽量使用map类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。
</code></pre><h4 id="5-3-如何避免产生shuffle"><a href="#5-3-如何避免产生shuffle" class="headerlink" title="5.3 如何避免产生shuffle"></a>5.3 如何避免产生shuffle</h4><ul>
<li>小案例</li>
</ul>
<pre><code class="scala">//错误的做法：
// 传统的join操作会导致shuffle操作。
// 因为两个RDD中，相同的key都需要通过网络拉取到一个节点上，由一个task进行join操作。
val rdd3 = rdd1.join(rdd2)

//正确的做法：
// Broadcast+map的join操作，不会导致shuffle操作。
// 使用Broadcast将一个数据量较小的RDD作为广播变量。
val rdd2Data = rdd2.collect()
val rdd2DataBroadcast = sc.broadcast(rdd2Data)

// 在rdd1.map算子中，可以从rdd2DataBroadcast中，获取rdd2的所有数据。
// 然后进行遍历，如果发现rdd2中某条数据的key与rdd1的当前数据的key是相同的，那么就判定可以进行join。
// 此时就可以根据自己需要的方式，将rdd1当前数据与rdd2中可以连接的数据，拼接在一起（String或Tuple）。
val rdd3 = rdd1.map(rdd2DataBroadcast...)

// 注意，以上操作，建议仅仅在rdd2的数据量比较少（比如几百M，或者一两G）的情况下使用。
// 因为每个Executor的内存中，都会驻留一份rdd2的全量数据。
</code></pre>
<h4 id="5-4-使用map-side预聚合的shuffle操作"><a href="#5-4-使用map-side预聚合的shuffle操作" class="headerlink" title="5.4 使用map-side预聚合的shuffle操作"></a>5.4 使用map-side预聚合的shuffle操作</h4><ul>
<li>map-side预聚合</li>
</ul>
<pre><code>    如果因为业务需要，一定要使用shuffle操作，无法用map类的算子来替代，那么尽量使用可以map-side预聚合的算子。

    所谓的map-side预聚合，说的是在每个节点本地对相同的key进行一次聚合操作，类似于MapReduce中的本地combiner。
    map-side预聚合之后，每个节点本地就只会有一条相同的key，因为多条相同的key都被聚合起来了。其他节点在拉取所有节点上的相同key时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销。
    通常来说，在可能的情况下，建议使用reduceByKey或者aggregateByKey算子来替代掉groupByKey算子。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合。
    而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差。

    比如如下两幅图，就是典型的例子，分别基于reduceByKey和groupByKey进行单词计数。其中第一张图是groupByKey的原理图，可以看到，没有进行任何本地聚合时，所有数据都会在集群节点之间传输；第二张图是reduceByKey的原理图，可以看到，每个节点本地的相同key数据，都进行了预聚合，然后才传输到其他节点上进行全局聚合。
</code></pre><ul>
<li>==groupByKey进行单词计数原理==</li>
</ul>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/groupByKey.png" alt="1577080609633"></p>
<ul>
<li>==reduceByKey单词计数原理==</li>
</ul>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/reduceByKey.png" alt="1577080686083"></p>
<h3 id="6-使用高性能的算子"><a href="#6-使用高性能的算子" class="headerlink" title="6. 使用高性能的算子"></a>6. 使用高性能的算子</h3><h4 id="6-1-使用reduceByKey-aggregateByKey替代groupByKey"><a href="#6-1-使用reduceByKey-aggregateByKey替代groupByKey" class="headerlink" title="6.1 使用reduceByKey/aggregateByKey替代groupByKey"></a>6.1 使用reduceByKey/aggregateByKey替代groupByKey</h4><ul>
<li>reduceByKey/aggregateByKey 可以进行预聚合操作，减少数据的传输量，提升性能</li>
<li>groupByKey 不会进行预聚合操作，进行数据的全量拉取，性能比较低</li>
</ul>
<h4 id="6-2-使用mapPartitions替代普通map"><a href="#6-2-使用mapPartitions替代普通map" class="headerlink" title="6.2 使用mapPartitions替代普通map"></a>6.2 使用mapPartitions替代普通map</h4><pre><code>    mapPartitions类的算子，一次函数调用会处理一个partition所有的数据，而不是一次函数调用处理一条，性能相对来说会高一些。
    但是有的时候，使用mapPartitions会出现OOM（内存溢出）的问题。因为单次函数调用就要处理掉一个partition所有的数据，如果内存不够，垃圾回收时是无法回收掉太多对象的，很可能出现OOM异常。所以使用这类操作时要慎重！
</code></pre><h4 id="6-3-使用foreachPartitions替代foreach"><a href="#6-3-使用foreachPartitions替代foreach" class="headerlink" title="6.3 使用foreachPartitions替代foreach"></a>6.3 使用foreachPartitions替代foreach</h4><pre><code>    原理类似于“使用mapPartitions替代map”，也是一次函数调用处理一个partition的所有数据，而不是一次函数调用处理一条数据。
    在实践中发现，foreachPartitions类的算子，对性能的提升还是很有帮助的。比如在foreach函数中，将RDD中所有数据写MySQL，那么如果是普通的foreach算子，就会一条数据一条数据地写，每次函数调用可能就会创建一个数据库连接，此时就势必会频繁地创建和销毁数据库连接，性能是非常低下；    但是如果用foreachPartitions算子一次性处理一个partition的数据，那么对于每个partition，只要创建一个数据库连接即可，然后执行批量插入操作，此时性能是比较高的。实践中发现，对于1万条左右的数据量写MySQL，性能可以提升30%以上。
</code></pre><h4 id="6-4-使用filter之后进行coalesce操作"><a href="#6-4-使用filter之后进行coalesce操作" class="headerlink" title="6.4 使用filter之后进行coalesce操作"></a>6.4 使用filter之后进行coalesce操作</h4><pre><code>    通常对一个RDD执行filter算子过滤掉RDD中较多数据后（比如30%以上的数据），建议使用coalesce算子，手动减少RDD的partition数量，将RDD中的数据压缩到更少的partition中去。
    因为filter之后，RDD的每个partition中都会有很多数据被过滤掉，此时如果照常进行后续的计算，其实每个task处理的partition中的数据量并不是很多，有一点资源浪费，而且此时处理的task越多，可能速度反而越慢。
    因此用coalesce减少partition数量，将RDD中的数据压缩到更少的partition之后，只要使用更少的task即可处理完所有的partition。在某些场景下，对于性能的提升会有一定的帮助。
</code></pre><h4 id="6-5-使用repartitionAndSortWithinPartitions替代repartition与sort类操作"><a href="#6-5-使用repartitionAndSortWithinPartitions替代repartition与sort类操作" class="headerlink" title="6.5 使用repartitionAndSortWithinPartitions替代repartition与sort类操作"></a>6.5 使用repartitionAndSortWithinPartitions替代repartition与sort类操作</h4><pre><code>    repartitionAndSortWithinPartitions是Spark官网推荐的一个算子，官方建议，如果需要在repartition重分区之后，还要进行排序，建议直接使用repartitionAndSortWithinPartitions算子。
    因为该算子可以一边进行重分区的shuffle操作，一边进行排序。shuffle与sort两个操作同时进行，比先shuffle再sort来说，性能可能是要高的。
</code></pre><h3 id="7-使用Kryo优化序列化性能"><a href="#7-使用Kryo优化序列化性能" class="headerlink" title="7. 使用Kryo优化序列化性能"></a>7. 使用Kryo优化序列化性能</h3><h4 id="7-1-spark序列化介绍"><a href="#7-1-spark序列化介绍" class="headerlink" title="7.1 spark序列化介绍"></a>7.1 spark序列化介绍</h4><pre><code>    Spark在进行任务计算的时候，会涉及到数据跨进程的网络传输、数据的持久化，这个时候就需要对数据进行序列化。Spark默认采用Java的序列化器。默认java序列化的优缺点如下:
其好处：
    处理起来方便，不需要我们手动做其他操作，只是在使用一个对象和变量的时候，需要实现Serializble接口。
其缺点：
    默认的序列化机制的效率不高，序列化的速度比较慢；序列化以后的数据，占用的内存空间相对还是比较大。

Spark支持使用Kryo序列化机制。Kryo序列化机制，比默认的Java序列化机制，速度要快，序列化后的数据要更小，大概是Java序列化机制的1/10。所以Kryo序列化优化以后，可以让网络传输的数据变少；在集群中耗费的内存资源大大减少。

</code></pre><h4 id="7-2-Kryo序列化启用后生效的地方"><a href="#7-2-Kryo序列化启用后生效的地方" class="headerlink" title="7.2 Kryo序列化启用后生效的地方"></a>7.2 Kryo序列化启用后生效的地方</h4><pre><code>Kryo序列化机制，一旦启用以后，会生效的几个地方：
（1）算子函数中使用到的外部变量
    算子中的外部变量可能来着与driver需要涉及到网络传输，就需要用到序列化。
        最终可以优化网络传输的性能，优化集群中内存的占用和消耗

（2）持久化RDD时进行序列化，StorageLevel.MEMORY_ONLY_SER
    将rdd持久化时，对应的存储级别里，需要用到序列化。
        最终可以优化内存的占用和消耗；持久化RDD占用的内存越少，task执行的时候，创建的对象，就不至于频繁的占满内存，频繁发生GC。

（3）    产生shuffle的地方，也就是宽依赖
    下游的stage中的task，拉取上游stage中的task产生的结果数据，跨网络传输，需要用到序列化。最终可以优化网络传输的性能


</code></pre><h4 id="7-3-如何开启Kryo序列化机制"><a href="#7-3-如何开启Kryo序列化机制" class="headerlink" title="7.3 如何开启Kryo序列化机制"></a>7.3 如何开启Kryo序列化机制</h4><pre><code class="scala">// 创建SparkConf对象。
val conf = new SparkConf().setMaster(...).setAppName(...)
// 设置序列化器为KryoSerializer。
conf.set(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;)

// 注册要序列化的自定义类型。
conf.registerKryoClasses(Array(classOf[MyClass1], classOf[MyClass2]))
</code></pre>
<h3 id="8-使用fastutil优化数据格式"><a href="#8-使用fastutil优化数据格式" class="headerlink" title="8. 使用fastutil优化数据格式"></a>8. 使用fastutil优化数据格式</h3><h4 id="8-1-fastutil介绍"><a href="#8-1-fastutil介绍" class="headerlink" title="8.1 fastutil介绍"></a>8.1 fastutil介绍</h4><pre><code>fastutil是扩展了Java标准集合框架（Map、List、Set；HashMap、ArrayList、HashSet）的类库，提供了特殊类型的map、set、list和queue；

fastutil能够提供更小的内存占用，更快的存取速度；我们使用fastutil提供的集合类，来替代自己平时使用的JDK的原生的Map、List、Set.
</code></pre><h4 id="8-2-fastutil好处"><a href="#8-2-fastutil好处" class="headerlink" title="8.2 fastutil好处"></a>8.2 fastutil好处</h4><pre><code>fastutil集合类，可以减小内存的占用，并且在进行集合的遍历、根据索引（或者key）获取元素的值和设置元素的值的时候，提供更快的存取速度；
</code></pre><h4 id="8-3-Spark中应用fastutil的场景和使用"><a href="#8-3-Spark中应用fastutil的场景和使用" class="headerlink" title="8.3 Spark中应用fastutil的场景和使用"></a>8.3 Spark中应用fastutil的场景和使用</h4><h5 id="8-3-1-算子函数使用了外部变量"><a href="#8-3-1-算子函数使用了外部变量" class="headerlink" title="8.3.1 算子函数使用了外部变量"></a>8.3.1 算子函数使用了外部变量</h5><pre><code>（1）你可以使用Broadcast广播变量优化；

（2）可以使用Kryo序列化类库，提升序列化性能和效率；

（3）如果外部变量是某种比较大的集合，那么可以考虑使用fastutil改写外部变量；

首先从源头上就减少内存的占用(fastutil)，通过广播变量进一步减少内存占用，再通过Kryo序列化类库进一步减少内存占用。
</code></pre><h5 id="8-3-2-算子函数里使用了比较大的集合Map-List"><a href="#8-3-2-算子函数里使用了比较大的集合Map-List" class="headerlink" title="8.3.2 算子函数里使用了比较大的集合Map/List"></a>8.3.2 算子函数里使用了比较大的集合Map/List</h5><pre><code>在你的算子函数里，也就是task要执行的计算逻辑里面，如果有逻辑中，出现，要创建比较大的Map、List等集合，
可能会占用较大的内存空间，而且可能涉及到消耗性能的遍历、存取等集合操作； 
那么此时，可以考虑将这些集合类型使用fastutil类库重写，

使用了fastutil集合类以后，就可以在一定程度上，减少task创建出来的集合类型的内存占用。 
避免executor内存频繁占满，频繁唤起GC，导致性能下降。
</code></pre><h5 id="8-3-3-fastutil的使用"><a href="#8-3-3-fastutil的使用" class="headerlink" title="8.3.3 fastutil的使用"></a>8.3.3 fastutil的使用</h5><pre><code>第一步：在pom.xml中引用fastutil的包
    &lt;dependency&gt;
      &lt;groupId&gt;fastutil&lt;/groupId&gt;
      &lt;artifactId&gt;fastutil&lt;/artifactId&gt;
      &lt;version&gt;5.0.9&lt;/version&gt;
    &lt;/dependency&gt;

第二步：平时使用List （Integer）的替换成IntList即可。 
    List&lt;Integer&gt;的list对应的到fastutil就是IntList类型


使用说明：
基本都是类似于IntList的格式，前缀就是集合的元素类型； 
特殊的就是Map，Int2IntMap，代表了key-value映射的元素类型。
</code></pre><h3 id="9-调节数据本地化等待时长"><a href="#9-调节数据本地化等待时长" class="headerlink" title="9. 调节数据本地化等待时长"></a>9. 调节数据本地化等待时长</h3><pre><code>    Spark在Driver上对Application的每一个stage的task进行分配之前，都会计算出每个task要计算的是哪个分片数据，RDD的某个partition；Spark的task分配算法，优先会希望每个task正好分配到它要计算的数据所在的节点，这样的话就不用在网络间传输数据；

    但是通常来说，有时事与愿违，可能task没有机会分配到它的数据所在的节点，为什么呢，可能那个节点的计算资源和计算能力都满了；所以这种时候，通常来说，Spark会等待一段时间，默认情况下是3秒（不是绝对的，还有很多种情况，对不同的本地化级别，都会去等待），到最后实在是等待不了了，就会选择一个比较差的本地化级别，比如说将task分配到距离要计算的数据所在节点比较近的一个节点，然后进行计算。

</code></pre><h4 id="9-1-本地化级别"><a href="#9-1-本地化级别" class="headerlink" title="9.1 本地化级别"></a>9.1 本地化级别</h4><pre><code>（1）PROCESS_LOCAL：进程本地化
    代码和数据在同一个进程中，也就是在同一个executor中；计算数据的task由executor执行，数据在executor的BlockManager中；性能最好
（2）NODE_LOCAL：节点本地化
    代码和数据在同一个节点中；比如说数据作为一个HDFS block块，就在节点上，而task在节点上某个executor中运行；或者是数据和task在一个节点上的不同executor中；数据需要在进程间进行传输；性能其次
（3）RACK_LOCAL：机架本地化    
    数据和task在一个机架的两个节点上；数据需要通过网络在节点之间进行传输； 性能比较差
（4）    ANY：无限制
    数据和task可能在集群中的任何地方，而且不在一个机架中；性能最差

</code></pre><h4 id="9-2-数据本地化等待时长"><a href="#9-2-数据本地化等待时长" class="headerlink" title="9.2 数据本地化等待时长"></a>9.2 数据本地化等待时长</h4><pre><code>spark.locality.wait，默认是3s
首先采用最佳的方式，等待3s后降级,还是不行，继续降级...,最后还是不行，只能够采用最差的。

</code></pre><h4 id="9-3-如何调节参数并且测试"><a href="#9-3-如何调节参数并且测试" class="headerlink" title="9.3 如何调节参数并且测试"></a>9.3 如何调节参数并且测试</h4><pre><code>修改spark.locality.wait参数，默认是3s，可以增加

下面是每个数据本地化级别的等待时间，默认都是跟spark.locality.wait时间相同，
默认都是3s(可查看spark官网对应参数说明，如下图所示)
spark.locality.wait.node
spark.locality.wait.process
spark.locality.wait.rack

</code></pre><p><img src="/Users/dingchuangshi/Documents/hexo-kfly-blog/source/_posts/it/spark/http://kfly.top/picture/kfly-top/Spark调优/assets/data-local-spark.png" alt="data-local-spark"></p>
<pre><code>在代码中设置：
new SparkConf().set(&quot;spark.locality.wait&quot;,&quot;10&quot;)

然后把程序提交到spark集群中运行，注意观察日志，spark作业的运行日志，推荐大家在测试的时候，先用client模式，在本地就直接可以看到比较全的日志。 
日志里面会显示，starting task .... PROCESS LOCAL、NODE LOCAL.....
例如：
Starting task 0.0 in stage 1.0 (TID 2, 192.168.200.102, partition 0, NODE_LOCAL, 5254 bytes)

观察大部分task的数据本地化级别 
如果大多都是PROCESS_LOCAL，那就不用调节了。如果是发现，好多的级别都是NODE_LOCAL、ANY，那么最好就去调节一下数据本地化的等待时长。应该是要反复调节，每次调节完以后，再来运行，观察日志 
看看大部分的task的本地化级别有没有提升；看看整个spark作业的运行时间有没有缩短。

注意注意：
在调节参数、运行任务的时候，别本末倒置，本地化级别倒是提升了， 但是因为大量的等待时长，spark作业的运行时间反而增加了，那就还是不要调节了。
</code></pre><h3 id="10-基于Spark内存模型调优"><a href="#10-基于Spark内存模型调优" class="headerlink" title="10. 基于Spark内存模型调优"></a>10. 基于Spark内存模型调优</h3><h4 id="10-1-spark中executor内存划分"><a href="#10-1-spark中executor内存划分" class="headerlink" title="10.1 spark中executor内存划分"></a>10.1 spark中executor内存划分</h4><ul>
<li>Executor的内存主要分为三块<ul>
<li>第一块是让task执行我们自己编写的代码时使用；</li>
<li>第二块是让task通过shuffle过程拉取了上一个stage的task的输出后，进行聚合等操作时使用</li>
<li>第三块是让RDD缓存时使用</li>
</ul>
</li>
</ul>
<h4 id="10-2-spark的内存模型"><a href="#10-2-spark的内存模型" class="headerlink" title="10.2 spark的内存模型"></a>10.2 spark的内存模型</h4><pre><code>    在spark1.6版本以前 spark的executor使用的静态内存模型，但是在spark1.6开始，多增加了一个统一内存模型。
    通过spark.memory.useLegacyMode 这个参数去配置
            默认这个值是false，代表用的是新的动态内存模型；
            如果想用以前的静态内存模型，那么就要把这个值改为true。
</code></pre><h5 id="10-2-1-静态内存模型"><a href="#10-2-1-静态内存模型" class="headerlink" title="10.2.1 静态内存模型"></a>10.2.1 静态内存模型</h5><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1570604272790.png" alt="1570604272790"></p>
<pre><code>实际上就是把我们的一个executor分成了三部分，
    一部分是Storage内存区域，
    一部分是execution区域，
    还有一部分是其他区域。如果使用的静态内存模型，那么用这几个参数去控制：

spark.storage.memoryFraction：默认0.6
spark.shuffle.memoryFraction：默认0.2  
所以第三部分就是0.2

如果我们cache数据量比较大，或者是我们的广播变量比较大，
    那我们就把spark.storage.memoryFraction这个值调大一点。
    但是如果我们代码里面没有广播变量，也没有cache，shuffle又比较多，那我们要把spark.shuffle.memoryFraction 这值调大。
</code></pre><ul>
<li>静态内存模型的缺点</li>
</ul>
<pre><code>我们配置好了Storage内存区域和execution区域后，我们的一个任务假设execution内存不够用了，但是它的Storage内存区域是空闲的，两个之间不能互相借用，不够灵活，所以才出来我们新的统一内存模型。
</code></pre><h5 id="10-2-2-统一内存模型"><a href="#10-2-2-统一内存模型" class="headerlink" title="10.2.2 统一内存模型"></a>10.2.2 统一内存模型</h5><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/image2018-11-1_16-39-33.png" alt="img"></p>
<pre><code>    动态内存模型先是预留了300m内存，防止内存溢出。动态内存模型把整体内存分成了两部分，
由这个参数表示spark.memory.fraction 这个指的默认值是0.6 代表另外的一部分是0.4,

然后spark.memory.fraction 这部分又划分成为两个小部分。这两小部分共占整体内存的0.6 .这两部分其实就是：Storage内存和execution内存。由spark.memory.storageFraction 这个参数去调配，因为两个共占0.6。如果spark.memory.storageFraction这个值配的是0.5,那说明这0.6里面 storage占了0.5，也就是execution占了0.3 。
</code></pre><ul>
<li><p>统一内存模型有什么特点呢?</p>
<pre><code>Storage内存和execution内存 可以相互借用。不用像静态内存模型那样死板，但是是有规则的
</code></pre></li>
</ul>
<ul>
<li><p>==场景一==</p>
<ul>
<li><p>Execution使用的时候发现内存不够了，然后就会把storage的内存里的数据驱逐到磁盘上。</p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1570604662552.png" alt="1570604662552"></p>
</li>
</ul>
</li>
</ul>
<ul>
<li>==场景二==<ul>
<li>一开始execution的内存使用得不多，但是storage使用的内存多，所以storage就借用了execution的内存，但是后来execution也要需要内存了，这个时候就会把storage的内存里的数据写到磁盘上，腾出内存空间。</li>
</ul>
</li>
</ul>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1570604675176.png" alt="1570604675176"></p>
<pre><code>为什么受伤的都是storage呢？

是因为execution里面的数据是马上就要用的，而storage里的数据不一定马上就要用。    
</code></pre><h5 id="10-2-3-任务提交脚本参考"><a href="#10-2-3-任务提交脚本参考" class="headerlink" title="10.2.3 任务提交脚本参考"></a>10.2.3 任务提交脚本参考</h5><ul>
<li>以下是一份spark-submit命令的示例，大家可以参考一下，并根据自己的实际情况进行调节</li>
</ul>
<pre><code class="shell">./bin/spark-submit \
  --master yarn-cluster \
  --num-executors 100 \
  --executor-memory 6G \
  --executor-cores 4 \
  --driver-memory 1G \
  --conf spark.default.parallelism=1000 \
  --conf spark.storage.memoryFraction=0.5 \
  --conf spark.shuffle.memoryFraction=0.3 \
</code></pre>
<h5 id="10-2-4-个人经验"><a href="#10-2-4-个人经验" class="headerlink" title="10.2.4 个人经验"></a>10.2.4 个人经验</h5><pre><code class="shell">java.lang.OutOfMemoryError
ExecutorLostFailure
Executor exit code 为143
executor lost
hearbeat time out
shuffle file lost

# 如果遇到以上问题，很有可能就是内存除了问题，可以先尝试增加内存。如果还是解决不了，那么请听下一次数据倾斜调优的课。
</code></pre>
<h3 id="11-数据倾斜原理和现象分析"><a href="#11-数据倾斜原理和现象分析" class="headerlink" title="11.  数据倾斜原理和现象分析"></a>11.  数据倾斜原理和现象分析</h3><h4 id="11-1-数据倾斜概述"><a href="#11-1-数据倾斜概述" class="headerlink" title="11.1 数据倾斜概述"></a>11.1 数据倾斜概述</h4><pre><code>    有的时候，我们可能会遇到大数据计算中一个最棘手的问题——数据倾斜，此时Spark作业的性能会比期望差很多。
    数据倾斜调优，就是使用各种技术方案解决不同类型的数据倾斜问题，以保证Spark作业的性能。
</code></pre><h4 id="11-2-数据倾斜发生时的现象"><a href="#11-2-数据倾斜发生时的现象" class="headerlink" title="11.2 数据倾斜发生时的现象"></a>11.2 数据倾斜发生时的现象</h4><ul>
<li><p>（1）绝大多数task执行得都非常快，但个别task执行极慢</p>
<pre><code>    你的大部分的task，都执行的特别快，很快就执行完了，剩下几个task，执行的特别特别慢，
前面的task，一般10s可以执行完5个；最后发现某个task，要执行1个小时，2个小时才能执行完一个task。

    这个时候就出现数据倾斜了。
这种方式还算好的，因为虽然老牛拉破车一样，非常慢，但是至少还能跑。
</code></pre></li>
<li><p>（2）绝大数task执行很快，有的task直接报OOM (Jvm Out Of Memory) 异常</p>
<pre><code>    运行的时候，其他task都很快执行完了，也没什么特别的问题；但是有的task，就是会突然间报了一个OOM，JVM Out Of Memory，内存溢出了，task failed，task lost，resubmitting task等日志异常信息。反复执行几次都到了某个task就是跑不通，最后就挂掉。

    某个task就直接OOM，那么基本上也是因为数据倾斜了，task分配的数量实在是太大了！！！所以内存放不下，然后你的task每处理一条数据，还要创建大量的对象。内存爆掉了。
</code></pre></li>
</ul>
<h4 id="11-3-数据倾斜发生的原理"><a href="#11-3-数据倾斜发生的原理" class="headerlink" title="11.3 数据倾斜发生的原理"></a>11.3 数据倾斜发生的原理</h4><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/数据倾斜.png" alt="数据倾斜"></p>
<pre><code>如上图所示：
    在进行任务计算shuffle操作的时候，第一个task和第二个task各分配到了1万条数据；需要5分钟计算完毕；第一个和第二个task，可能同时在5分钟内都运行完了；第三个task要98万条数据，98 * 5 = 490分钟 = 8个小时；
    本来另外两个task很快就运行完毕了（5分钟），第三个task数据量比较大，要8个小时才能运行完，就导致整个spark作业，也得8个小时才能运行完。最终导致整个spark任务计算特别慢。
</code></pre><h4 id="11-4-数据倾斜如何定位原因"><a href="#11-4-数据倾斜如何定位原因" class="headerlink" title="11.4 数据倾斜如何定位原因"></a>11.4 数据倾斜如何定位原因</h4><ul>
<li><p>主要是根据log日志信息去定位</p>
<pre><code>    数据倾斜只会发生在shuffle过程中。这里给大家罗列一些常用的并且可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。
    出现数据倾斜时，可能就是你的代码中使用了这些算子中的某一个所导致的。因为某个或者某些key对应的数据，远远的高于其他的key。
</code></pre></li>
<li><p>分析定位逻辑</p>
<pre><code>    由于代码中有大量的shuffle操作，一个job会划分成很多个stage，首先要看的，就是数据倾斜发生在第几个stage中。
    可以在任务运行的过程中，观察任务的UI界面，可以观察到每一个stage中运行的task的数据量，从而进一步确定是不是task分配的数据不均匀导致了数据倾斜。
    比如下图中，倒数第三列显示了每个task的运行时间。明显可以看到，有的task运行特别快，只需要几秒钟就可以运行完;而有的task运行特别慢，需要几分钟才能运行完，此时单从运行时间上看就已经能够确定发生数据倾斜了。
    此外，倒数第一列显示了每个task处理的数据量，明显可以看到，运行时间特别短的task只需要处理几百KB的数据即可，而运行时间特别长的task需要处理几千KB的数据，处理的数据量差了10倍。此时更加能够确定是发生了数据倾斜。
</code></pre></li>
</ul>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/20170308091203159.png" alt="20170308091203159"></p>
<p><strong>某个task莫名其妙内存溢出的情况</strong></p>
<pre><code>    这种情况下去定位出问题的代码就比较容易了。我们建议直接看yarn-client模式下本地log的异常栈，或者是通过YARN查看yarn-cluster模式下的log中的异常栈。一般来说，通过异常栈信息就可以定位到你的代码中哪一行发生了内存溢出。然后在那行代码附近找找，一般也会有shuffle类算子，此时很可能就是这个算子导致了数据倾斜。
    但是大家要注意的是，不能单纯靠偶然的内存溢出就判定发生了数据倾斜。因为自己编写的代码的bug，以及偶然出现的数据异常，也可能会导致内存溢出。因此还是要按照上面所讲的方法，通过Spark Web UI查看报错的那个stage的各个task的运行时间以及分配的数据量，才能确定是否是由于数据倾斜才导致了这次内存溢出。
</code></pre><p><strong>查看导致数据倾斜的key的数据分布情况</strong></p>
<pre><code>    知道了数据倾斜发生在哪里之后，通常需要分析一下那个执行了shuffle操作并且导致了数据倾斜的RDD/Hive表，查看一下其中key的分布情况。这主要是为之后选择哪一种技术方案提供依据。针对不同的key分布与不同的shuffle算子组合起来的各种情况，可能需要选择不同的技术方案来解决。
此时根据你执行操作的情况不同，可以有很多种查看key分布的方式：
    如果是Spark SQL中的group by、join语句导致的数据倾斜，那么就查询一下SQL中使用的表的key分布情况。
    如果是对Spark RDD执行shuffle算子导致的数据倾斜，那么可以在Spark作业中加入查看key分布的代码，比如RDD.countByKey()。然后对统计出来的各个key出现的次数，collect/take到客户端打印一下，就可以看到key的分布情况。
    举例来说，对于上面所说的单词计数程序，如果确定了是stage1的reduceByKey算子导致了数据倾斜，那么就应该看看进行reduceByKey操作的RDD中的key分布情况，在这个例子中指的就是pairs RDD。如下示例，我们可以先对pairs采样10%的样本数据，然后使用countByKey算子统计出每个key出现的次数，最后在客户端遍历和打印样本数据中各个key的出现次数。
</code></pre><pre><code class="scala">val sampledPairs = pairs.sample(false, 0.1)
val sampledWordCounts = sampledPairs.countByKey()
sampledWordCounts.foreach(println(_))

//sample算子时用来抽样用的，其有3个参数

//withReplacement：表示抽出样本后是否在放回去，true表示会放回去，这也就意味着抽出的样本可能有重复

//fraction ：抽出多少，这是一个double类型的参数,0-1之间，eg:0.3表示抽出30%

//seed：表示一个种子，根据这个seed随机抽取，一般情况下只用前两个参数就可以，那么这个参数是干嘛的呢，这个参数一般用于调试，有时候不知道是程序出问题还是数据出了问题，就可以将这个参数设置为定值
</code></pre>
<h4 id="11-5-数据倾斜原因总结"><a href="#11-5-数据倾斜原因总结" class="headerlink" title="11.5 数据倾斜原因总结"></a>11.5 数据倾斜原因总结</h4><ul>
<li><p>数据本身问题</p>
<pre><code>（1）、key本身分布不均衡（包括大量的key为空）
（2）、key的设置不合理
</code></pre></li>
<li><p>spark使用不当的问题</p>
<pre><code>（1）、shuffle时的并发度不够
（2）、计算方式有误    
</code></pre></li>
</ul>
<h4 id="11-6-数据倾斜的后果"><a href="#11-6-数据倾斜的后果" class="headerlink" title="11.6 数据倾斜的后果"></a>11.6 数据倾斜的后果</h4><pre><code>（1）spark中的stage的执行时间受限于最后那个执行完成的task,因此运行缓慢的任务会拖垮整个程序的运行速度（分布式程序运行的速度是由最慢的那个task决定的）。

（2）过多的数据在同一个task中运行，将会把executor内存撑爆，导致OOM内存溢出。
</code></pre><h3 id="12-spark中数据倾斜的解决方案"><a href="#12-spark中数据倾斜的解决方案" class="headerlink" title="12. spark中数据倾斜的解决方案"></a>12. spark中数据倾斜的解决方案</h3><h4 id="解决方案一：使用Hive-ETL预处理数据"><a href="#解决方案一：使用Hive-ETL预处理数据" class="headerlink" title="解决方案一：使用Hive ETL预处理数据"></a>解决方案一：使用Hive ETL预处理数据</h4><p><font color="red">方案适用场景</font>：导致数据倾斜的是Hive表。如果该Hive表中的数据本身很不均匀(比如某个key对应了100万数据，其他key才对应了10条数据)，而且业务场景需要频繁使用Spark对Hive表执行某个分析操作，那么比较适合使用这种技术方案。</p>
<p><font color="red">方案实现思路</font>：此时可以评估一下，是否可以通过Hive来进行数据预处理(即通过Hive ETL预先对数据按照key进行聚合，或者是预先和其他表进行join)，然后在Spark作业中针对的数据源就不是原来的Hive表了，而是预处理后的Hive表。此时由于数据已经预先进行过聚合或join操作了，那么在Spark作业中也就不需要使用原先的shuffle类算子执行这类操作了。</p>
<p><font color="red">方案实现原理</font>：这种方案从根源上解决了数据倾斜，因为彻底避免了在Spark中执行shuffle类算子，那么肯定就不会有数据倾斜的问题了。但是这里也要提醒一下大家，这种方式属于治标不治本。因为毕竟数据本身就存在分布不均匀的问题，所以Hive ETL中进行group by或者join等shuffle操作时，还是会出现数据倾斜，导致Hive ETL的速度很慢。我们只是把数据倾斜的发生提前到了Hive ETL中，避免Spark程序发生数据倾斜而已。</p>
<p><font color="red">方案优点</font>：实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，Spark作业的性能会大幅度提升。</p>
<p><font color="red">方案缺点</font>：治标不治本，Hive ETL中还是会发生数据倾斜。</p>
<p><font color="red">方案实践经验</font>：在一些Java系统与Spark结合使用的项目中，会出现Java代码频繁调用Spark作业的场景，而且对Spark作业的执行性能要求很高，就比较适合使用这种方案。将数据倾斜提前到上游的Hive ETL，每天仅执行一次，只有那一次是比较慢的，而之后每次Java调用Spark作业时，执行速度都会很快，能够提供更好的用户体验。</p>
<p><font color="red">项目实践经验</font>：有一个交互式用户行为分析系统中使用了这种方案，该系统主要是允许用户通过Java Web系统提交数据分析统计任务，后端通过Java提交Spark作业进行数据分析统计。要求Spark作业速度必须要快，尽量在10分钟以内，否则速度太慢，用户体验会很差。所以我们将有些Spark作业的shuffle操作提前到了Hive ETL中，从而让Spark直接使用预处理的Hive中间表，尽可能地减少Spark的shuffle操作，大幅度提升了性能，将部分作业的性能提升了6倍以上。</p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/交互式用户行为分析系统.png" alt="交互式用户行为分析系统"></p>
<h4 id="解决方案二：过滤少数导致倾斜的key"><a href="#解决方案二：过滤少数导致倾斜的key" class="headerlink" title="解决方案二：过滤少数导致倾斜的key"></a>解决方案二：过滤少数导致倾斜的key</h4><p>　　<font color="red">方案适用场景</font>：如果发现导致倾斜的key就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。<br>　　<font color="red">方案实现思路</font>：如果我们判断那少数几个数据量特别多的key，对作业的执行和计算结果不是特别重要的话，那么干脆就直接过滤掉那少数几个key。比如，在Spark SQL中可以使用where子句过滤掉这些key或者在Spark Core中对RDD执行filter算子过滤掉这些key。如果需要每次作业执行时，动态判定哪些key的数据量最多然后再进行过滤，那么可以使用sample算子对RDD进行采样，然后计算出每个key的数量，取数据量最多的key过滤掉即可。<br>　　<font color="red">方案实现原理</font>：将导致数据倾斜的key给过滤掉之后，这些key就不会参与计算了，自然不可能产生数据倾斜。<br>　　<font color="red">方案优点</font>：实现简单，而且效果也很好，可以完全规避掉数据倾斜。<br>　　<font color="red">方案缺点</font>：适用场景不多，大多数情况下，导致倾斜的key还是很多的，并不是只有少数几个。<br>　　<font color="red">方案实践经验</font>：在项目中我们也采用过这种方案解决数据倾斜。有一次发现某一天Spark作业在运行的时候突然OOM了，追查之后发现，是Hive表中的某一个key在那天数据异常，导致数据量暴增。因此就采取每次执行前先进行采样，计算出样本中数据量最大的几个key之后，直接在程序中将那些key给过滤掉。</p>
<h4 id="解决方案三：提高shuffle操作的并行度-效果差"><a href="#解决方案三：提高shuffle操作的并行度-效果差" class="headerlink" title="解决方案三：提高shuffle操作的并行度(效果差)"></a>解决方案三：提高shuffle操作的并行度(效果差)</h4><p>　　　<font color="red">方案适用场景</font>：如果我们必须要对数据倾斜迎难而上，那么建议优先使用这种方案，因为这是处理数据倾斜最简单的一种方案。<br>　　　<font color="red">方案实现思路</font>：在对RDD执行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个shuffle算子执行时shuffle read task的数量。对于Spark SQL中的shuffle类语句，比如group by、join等，需要设置一个参数，即spark.sql.shuffle.partitions，该参数代表了shuffle read task的并行度，该值默认是200，对于很多场景来说都有点过小。<br>　　　<font color="red">方案实现原理</font>：增加shuffle read task的数量，可以让原本分配给一个task的多个key分配给多个task，从而让每个task处理比原来更少的数据。举例来说，如果原本有5个key，每个key对应10条数据，这5个key都是分配给一个task的，那么这个task就要处理50条数据。而增加了shuffle read task以后，每个task就分配到一个key，即每个task就处理10条数据，那么自然每个task的执行时间都会变短了。具体原理如下图所示。<br>　　　<font color="red">方案优点</font>：实现起来比较简单，可以有效缓解和减轻数据倾斜的影响。<br>　　　<font color="red">方案缺点</font>：只是缓解了数据倾斜而已，没有彻底根除问题，根据实践经验来看，其效果有限。<br>　　　<font color="red">方案实践经验</font>：该方案通常无法彻底解决数据倾斜，因为如果出现一些极端情况，比如某个key对应的数据量有100万，那么无论你的task数量增加到多少，这个对应着100万数据的key肯定还是会分配到一个task中去处理，因此注定还是会发生数据倾斜的。所以这种方案只能说是在发现数据倾斜时尝试使用的第一种手段，尝试去用最简单的方法缓解数据倾斜而已，或者是和其他方案结合起来使用。</p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1570609831990.png" alt="1570609831990"></p>
<h4 id="解决方案四：两阶段聚合（局部聚合-全局聚合）"><a href="#解决方案四：两阶段聚合（局部聚合-全局聚合）" class="headerlink" title="解决方案四：两阶段聚合（局部聚合+全局聚合）"></a>解决方案四：两阶段聚合（局部聚合+全局聚合）</h4><p>　　<font color="red">方案适用场景</font>：对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时，比较适用这种方案。<br>　　<font color="red">方案实现思路</font>：这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。<br>　　<font color="red">方案实现原理</font>：将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。具体原理见下图。<br>　　<font color="red">方案优点</font>：对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。<br>　　<font color="red">方案缺点</font>：仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案。</p>
<pre><code class="scala">//案例
//  如果使用reduceByKey因为数据倾斜造成运行失败的问题。具体操作流程如下:
//    (1) 将原始的 key 转化为  随机值 + key  (随机值 = Random.nextInt)
//    (2) 对数据进行 reduceByKey(func)
//    (3) 将 key + 随机值转成 key
//    (4) 再对数据进行 reduceByKey(func)

object WordCountAggTest {
  def main(args: Array[String]): Unit = {
    val conf = new SparkConf().setMaster(&quot;local[2]&quot;).setAppName(&quot;WordCount&quot;)
    val sc = new SparkContext(conf)
    val array = Array(&quot;you you&quot;,&quot;you you&quot;,&quot;you you&quot;,
      &quot;you you&quot;,
      &quot;you you&quot;,
      &quot;you you&quot;,
      &quot;you you&quot;,
      &quot;jump jump&quot;)
    val rdd = sc.parallelize(array,8)
    rdd.flatMap( line =&gt; line.split(&quot; &quot;))
      .map(word =&gt;{
        val prefix = (new util.Random).nextInt(3)
        (prefix+&quot;_&quot;+word,1)
      }).reduceByKey(_+_)
       .map( wc =&gt;{
         val newWord=wc._1.split(&quot;_&quot;)(1)
         val count=wc._2
         (newWord,count)
       }).reduceByKey(_+_)
      .foreach( wc =&gt;{
        println(&quot;单词：&quot;+wc._1 + &quot; 次数：&quot;+wc._2)
      })

  }
}
注：我们这儿使用的是reduceByKey天然的有调优的效果，如果这儿是groupBykey那么发生数据倾斜的概率就会更大，更严重。
</code></pre>
<h4 id="解决方案五：将reduce-join转为map-join"><a href="#解决方案五：将reduce-join转为map-join" class="headerlink" title="解决方案五：将reduce join转为map join"></a>解决方案五：将reduce join转为map join</h4><p>　　<font color="red">方案适用场景</font>：在对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小（比如几百M或者一两G），比较适用此方案。<br>　　<font color="red">方案实现思路</font>：不使用join算子进行连接操作，而使用Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作，彻底避免数据倾斜的发生和出现。将较小RDD中的数据直接通过collect算子拉取到Driver端的内存中来，然后对其创建一个Broadcast变量；接着对另外一个RDD执行map类算子，在算子函数内，从Broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比对，如果连接key相同的话，那么就将两个RDD的数据用你需要的方式连接起来。<br>　　<font color="red">方案实现原理</font>：普通的join是会走shuffle过程的，而一旦shuffle，就相当于会将相同key的数据拉取到一个shuffle read task中再进行join，此时就是reduce join。但是如果一个RDD是比较小的，则可以采用广播小RDD全量数据+map算子来实现与join同样的效果，也就是map join，此时就不会发生shuffle操作，也就不会发生数据倾斜。具体原理如下图所示。<br>　　<font color="red">方案优点</font>：对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜。<br>　　<font color="red">方案缺点</font>：适用场景较少，因为这个方案只适用于一个大表和一个小表的情况。毕竟我们需要将小表进行广播，此时会比较消耗内存资源，driver和每个Executor内存中都会驻留一份小RDD的全量数据。如果我们广播出去的RDD数据比较大，比如10G以上，那么就可能发生内存溢出了。因此并不适合两个都是大表的情况。</p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/reduce joinz转换为map join .png" alt="reduce joinz转换为map join "></p>
<pre><code class="scala">object MapJoinTest {

  def main(args: Array[String]): Unit = {
    val conf = new SparkConf().setMaster(&quot;local[2]&quot;).setAppName(&quot;WordCount&quot;)
    val sc = new SparkContext(conf)
    val lista=Array(
      Tuple2(&quot;001&quot;,&quot;令狐冲&quot;),
      Tuple2(&quot;002&quot;,&quot;任盈盈&quot;)
    )
     //数据量小一点
    val listb=Array(
      Tuple2(&quot;001&quot;,&quot;一班&quot;),
      Tuple2(&quot;002&quot;,&quot;二班&quot;)
    )
    val listaRDD = sc.parallelize(lista)
    val listbRDD = sc.parallelize(listb)
    //val result: RDD[(String, (String, String))] = listaRDD.join(listbRDD)
     //设置广播变量
    val listbBoradcast = sc.broadcast(listbRDD.collect())
    listaRDD.map(  tuple =&gt;{
      val key = tuple._1
      val name = tuple._2
      val map = listbBoradcast.value.toMap
      val className = map.get(key)
      (key,(name,className))
    }).foreach( tuple =&gt;{
      println(&quot;班级号&quot;+tuple._1 + &quot; 姓名：&quot;+tuple._2._1 + &quot; 班级名：&quot;+tuple._2._2.get)
    })
  }
}
</code></pre>
<h4 id="解决方案六：采样倾斜key并分拆join操作"><a href="#解决方案六：采样倾斜key并分拆join操作" class="headerlink" title="解决方案六：采样倾斜key并分拆join操作"></a>解决方案六：采样倾斜key并分拆join操作</h4><p>　　<font color="red">方案适用场景</font>：两个RDD/Hive表进行join的时候，如果数据量都比较大，无法采用“解决方案五”，那么此时可以看一下两个RDD/Hive表中的key分布情况。如果出现数据倾斜，是因为其中某一个RDD/Hive表中的少数几个key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀，那么采用这个解决方案是比较合适的。<br>　　<font color="red">方案实现思路</font>：<br>　　1、对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个key的数量，计算出来数据量最大的是哪几个key。<br>　　2、然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀，而不会导致倾斜的大部分key形成另外一个RDD。<br>　　3、接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀，不会导致倾斜的大部分key也形成另外一个RDD。<br>　　4、再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，==此时就可以将原先相同的key打散成n份，分散到多个task中去进行join了。==<br>　　5、而另外两个普通的RDD就照常join即可。<br>　　6、最后将两次join的结果使用union算子合并起来即可，就是最终的join结果。<br>　　<font color="red">方案实现原理</font>：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，可以将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。<br>　　<font color="red">方案优点</font>：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，采用该方式可以用最有效的方式打散key进行join。而且只需要针对少数倾斜key对应的数据进行扩容n倍，不需要对全量数据进行扩容。避免了占用过多内存。<br>　　<font color="red">方案缺点</font>：如果导致倾斜的key特别多的话，比如成千上万个key都导致数据倾斜，那么这种方式也不适合。</p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/随机前缀和扩容RDD.png" alt="随机前缀和扩容RDD"></p>
<h4 id="解决方案七：使用随机前缀和扩容RDD进行join"><a href="#解决方案七：使用随机前缀和扩容RDD进行join" class="headerlink" title="解决方案七：使用随机前缀和扩容RDD进行join"></a>解决方案七：使用随机前缀和扩容RDD进行join</h4><p>　　<font color="red">方案适用场景</font>：如果在进行join操作时，RDD中有大量的key导致数据倾斜，那么进行分拆key也没什么意义，此时就只能使用这一种方案来解决问题了。<br>　　<font color="red">方案实现思路</font>：<br>　　1、该方案的实现思路基本和“解决方案六”类似，首先查看RDD/Hive表中的数据分布情况，找到那个造成数据倾斜的RDD/Hive表，比如有多个key都对应了超过1万条数据。<br>　　2、然后将该RDD的每条数据都打上一个n以内的随机前缀。<br>　　3、同时对另外一个正常的RDD进行扩容，将每条数据都扩容成n条数据，扩容出来的每条数据都依次打上一个0~n的前缀。<br>　　4、最后将两个处理后的RDD进行join即可。<br>　　方案实现原理：将原先一样的key通过附加随机前缀变成不一样的key，然后就可以将这些处理后的“不同key”分散到多个task中去处理，而不是让一个task处理大量的相同key。该方案与“解决方案六”的不同之处就在于，上一种方案是尽量只对少数倾斜key对应的数据进行特殊处理，由于处理过程需要扩容RDD，因此上一种方案扩容RDD后对内存的占用并不大；而这一种方案是针对有大量倾斜key的情况，没法将部分key拆分出来进行单独处理，因此只能对整个RDD进行数据扩容，对内存资源要求很高。<br>　　<font color="red">方案优点</font>：对join类型的数据倾斜基本都可以处理，而且效果也相对比较显著，性能提升效果非常不错。<br>　　<font color="red">方案缺点</font>：该方案更多的是缓解数据倾斜，而不是彻底避免数据倾斜。而且需要对整个RDD进行扩容，对内存资源要求很高。<br>　　<font color="red">方案实践经验</font>：曾经开发一个数据需求的时候，发现一个join导致了数据倾斜。优化之前，作业的执行时间大约是60分钟左右；使用该方案优化之后，执行时间缩短到10分钟左右，性能提升了6倍。</p>
<h4 id="解决方案八：把上面的几种数据倾斜的解决方案综合的灵活运行"><a href="#解决方案八：把上面的几种数据倾斜的解决方案综合的灵活运行" class="headerlink" title="解决方案八：把上面的几种数据倾斜的解决方案综合的灵活运行"></a>解决方案八：把上面的几种数据倾斜的解决方案综合的灵活运行</h4><h3 id="13-Shuffle调优"><a href="#13-Shuffle调优" class="headerlink" title="13. Shuffle调优"></a>13. Shuffle调优</h3><h4 id="13-1-什么时候发生shuffle"><a href="#13-1-什么时候发生shuffle" class="headerlink" title="13.1 什么时候发生shuffle"></a>13.1 什么时候发生shuffle</h4><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567231926304.png" alt="1567231926304"></p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567232029615.png" alt="1567232029615"></p>
<h4 id="13-2-Shuffle的核心组件"><a href="#13-2-Shuffle的核心组件" class="headerlink" title="13.2 Shuffle的核心组件"></a>13.2 Shuffle的核心组件</h4><p>碰到ShuffleDenpendency就进行stage的划分，ShuffleMapStage: 为shuffle提供数据的中间stage，ResultStage: 为一个action操作计算结果的stage。</p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567232245246.png" alt="1567232245246"></p>
<h4 id="13-3-Shuffle组件调度"><a href="#13-3-Shuffle组件调度" class="headerlink" title="13.3 Shuffle组件调度"></a>13.3 Shuffle组件调度</h4><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567232408746.png" alt="1567232408746"></p>
<h4 id="13-4-Shuffle原理剖析"><a href="#13-4-Shuffle原理剖析" class="headerlink" title="13.4 Shuffle原理剖析"></a>13.4 Shuffle原理剖析</h4><h5 id="13-4-1-MapOutputTracker"><a href="#13-4-1-MapOutputTracker" class="headerlink" title="13.4.1 MapOutputTracker"></a>13.4.1 MapOutputTracker</h5><p>解决的一个问题是resut task如何知道从哪个Executor去拉取Shuffle data</p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567232849493.png" alt="1567232849493"></p>
<h5 id="13-4-2-ShuffleWriter"><a href="#13-4-2-ShuffleWriter" class="headerlink" title="13.4.2 ShuffleWriter"></a>13.4.2 ShuffleWriter</h5><p><strong>（1）HashShuffleWriter</strong></p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567232923386.png" alt="1567232923386"></p>
<p>特点：根据Hash分区，分区数是m * n 个。</p>
<pre><code class="scala">val counts: RDD[(String, Int)] 
    = wordCount.reduceByKey(new HashPartitioner(2), (x, y) =&gt; x + y)

</code></pre>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567233073556.png" alt="1567233073556"></p>
<p><strong>（2）SortShuffleWriter</strong></p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567233308867.png" alt="1567233308867"></p>
<p>特点：</p>
<p>a、文件数量为m</p>
<p>b、如果需要排序或者需要combine，那么每一个partition数据排序要自己实现。（SortShuffleWriter里的sort指的是对partition的分区号进行排序）</p>
<p>c、数据先放在内存,内存不够则写到磁盘中,最后再全部写到磁盘。</p>
<p><strong>（3）BypassMergeSortShuffleWriter</strong></p>
<p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567234608013.png" alt="1567234608013"></p>
<p>这种模式同时具有HashShuffleWriter和SortShuffleter的特点。因为其实HashShufflerWriter的性能不错，但是如果task数太多的话，性能话下降，所以Spark在task数较少的时候自动使用了这种模式，一开始还是像HashShufflerWriter那种生成多个文件，但是最后会把多个文件合并成一个文件。然后下游来读取文件。默认map的分区需要小于spark.shuffle.sort.bypassMergeThreshold(默认是200),因为如何分区数太多，产生的小文件就会很多性能就会下降。</p>
<h5 id="13-4-3-ShuffleReader"><a href="#13-4-3-ShuffleReader" class="headerlink" title="13.4.3 ShuffleReader"></a>13.4.3 ShuffleReader</h5><p><img src="http://kfly.top/picture/kfly-top/Spark调优/assets/1567235022607.png" alt="1567235022607"></p>
<h5 id="3-4-4-Spark-Shuffle参数调优"><a href="#3-4-4-Spark-Shuffle参数调优" class="headerlink" title="3.4.4 Spark Shuffle参数调优"></a>3.4.4 Spark Shuffle参数调优</h5><p>==spark.shuffle.file.buffer==</p>
<ul>
<li>默认值：32k</li>
<li>参数说明：该参数用于设置shuffle write task的BufferedOutputStream的buffer缓冲大小。将数据写到磁盘文件之前，会先写入buffer缓冲中，待缓冲写满之后，才会溢写到磁盘。</li>
<li>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如64k），从而减少shuffle write过程中溢写磁盘文件的次数，也就可以减少磁盘IO次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。</li>
</ul>
<p>==spark.reducer.maxSizeInFlight==</p>
<ul>
<li>默认值：48m</li>
<li>参数说明：该参数用于设置shuffle read task的buffer缓冲大小，而这个buffer缓冲决定了每次能够拉取多少数据。</li>
<li>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如96m），从而减少拉取数据的次数，也就可以减少网络传输的次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。</li>
</ul>
<p>==spark.shuffle.io.maxRetries==</p>
<ul>
<li>默认值：3</li>
<li>参数说明：shuffle read task从shuffle write task所在节点拉取属于自己的数据时，如果因为网络异常导致拉取失败，是会自动进行重试的。该参数就代表了可以重试的最大次数。如果在指定次数之内拉取还是没有成功，就可能会导致作业执行失败。</li>
<li>调优建议：对于那些包含了特别耗时的shuffle操作的作业，建议增加重试最大次数（比如60次），以避免由于JVM的full gc或者网络不稳定等因素导致的数据拉取失败。在实践中发现，对于针对超大数据量（数十亿~上百亿）的shuffle过程，调节该参数可以大幅度提升稳定性。</li>
</ul>
<p>==spark.shuffle.io.retryWait==</p>
<ul>
<li>默认值：5s</li>
<li>参数说明：具体解释同上，该参数代表了每次重试拉取数据的等待间隔，默认是5s。</li>
<li>调优建议：建议加大间隔时长（比如60s），以增加shuffle操作的稳定性。</li>
</ul>
<p>==spark.shuffle.memoryFraction==（Spark1.6是这个参数，1.6以后参数变了，具体参考上一讲Spark内存模型知识）</p>
<ul>
<li>默认值：0.2</li>
<li>参数说明：该参数代表了Executor内存中，分配给shuffle read task进行聚合操作的内存比例，默认是20%。</li>
<li>调优建议：在资源参数调优中讲解过这个参数。如果内存充足，而且很少使用持久化操作，建议调高这个比例，给shuffle read的聚合操作更多内存，以避免由于内存不足导致聚合过程中频繁读写磁盘。在实践中发现，合理调节该参数可以将性能提升10%左右。</li>
</ul>
<p>==spark.shuffle.manager==</p>
<ul>
<li>默认值：sort</li>
<li>参数说明：该参数用于设置ShuffleManager的类型。Spark 1.5以后，有三个可选项：hash、sort和tungsten-sort。HashShuffleManager是Spark 1.2以前的默认选项，但是Spark 1.2以及之后的版本默认都是SortShuffleManager了。Spark1.6以后把hash方式给移除了，tungsten-sort与sort类似，但是使用了tungsten计划中的堆外内存管理机制，内存使用效率更高。</li>
<li>调优建议：由于SortShuffleManager默认会对数据进行排序，因此如果你的业务逻辑中需要该排序机制的话，则使用默认的SortShuffleManager就可以；而如果你的业务逻辑不需要对数据进行排序，那么建议参考后面的几个参数调优，通过bypass机制或优化的HashShuffleManager来避免排序操作，同时提供较好的磁盘读写性能。这里要注意的是，tungsten-sort要慎用，因为之前发现了一些相应的bug。</li>
</ul>
<p>==spark.shuffle.sort.bypassMergeThreshold==</p>
<ul>
<li>默认值：200</li>
<li>参数说明：当ShuffleManager为SortShuffleManager时，如果shuffle read task的数量小于这个阈值（默认是200），则shuffle write过程中不会进行排序操作，而是直接按照未经优化的HashShuffleManager的方式去写数据，但是最后会将每个task产生的所有临时磁盘文件都合并成一个文件，并会创建单独的索引文件。</li>
<li>调优建议：当你使用SortShuffleManager时，如果的确不需要排序操作，那么建议将这个参数调大一些，大于shuffle read task的数量。那么此时就会自动启用bypass机制，map-side就不会进行排序了，减少了排序的性能开销。但是这种方式下，依然会产生大量的磁盘文件，因此shuffle write性能有待提高。</li>
</ul>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a href="https://blog.sev7e0.site/">大数据施工现场</a></span>
        <span>/</span>
        
        <span><a href="https://wangchujiang.com/linux-command/">linux命令行工具</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script src="/js/gitment.js"></script>
<script>
    var gitment = new Gitment({
        id: 'Spark调优',
        owner: 'orchid-ding',
        repo: 'kfly-blog-comment',
        oauth: {
            client_id: '0770cdab79393197b6f5',
            client_secret: '376fb6c7bcd5047718b356712f596b89e490360c',
        },
    })
    gitment.render('comment-container')
</script>




</html>
