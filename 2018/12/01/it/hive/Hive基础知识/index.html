<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="天行健、君子以自强不息；地势坤，君子以厚德载物。">
    <meta name="keyword"  content="兰草">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        Hive基础知识 - kfly的博客 | kfly&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_1598291_q3el2wqimj.css" type="text/css">
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>kfly</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont iconhome"></i>
                    <span>主页</span>
                </a>
            </li>
 	   <li >
                <a href="/spec/">
                    <i class="iconfont iconzhuanti"></i>
                    <span>专题</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive基础知识"><span class="toc-text">Hive基础知识</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive简介"><span class="toc-text">Hive简介</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#优缺点"><span class="toc-text">优缺点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#架构原理"><span class="toc-text">架构原理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据类型"><span class="toc-text">数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#基本数据类型"><span class="toc-text">基本数据类型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#复合数据类型"><span class="toc-text">复合数据类型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive的DDL操作"><span class="toc-text">Hive的DDL操作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#hive的数据库DDL操作"><span class="toc-text">hive的数据库DDL操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#hive的表DDL操作"><span class="toc-text">hive的表DDL操作</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#hive的分区表"><span class="toc-text">hive的分区表</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#hive的分桶表"><span class="toc-text">hive的分桶表</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive修改表结构"><span class="toc-text">Hive修改表结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据导入"><span class="toc-text">数据导入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据导出"><span class="toc-text">数据导出</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#静态、动态分区"><span class="toc-text">静态、动态分区</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#排序"><span class="toc-text">排序</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive-java-Api"><span class="toc-text">Hive java Api</span></a></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 君子谦谦，温和有礼，有才而不骄，得志而不傲，居于谷而不卑。 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        Hive基础知识
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2018-12-01 16:01:32</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#hive" title="hive">hive</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <h2 id="Hive基础知识"><a href="#Hive基础知识" class="headerlink" title="Hive基础知识"></a>Hive基础知识</h2><h3 id="Hive简介"><a href="#Hive简介" class="headerlink" title="Hive简介"></a>Hive简介</h3><ul>
<li>Hive是什么</li>
</ul>
<p>Hive是基于Hadoop的一个数据仓库工具，==可以将结构化的数据文件映射为一张数据库表==，并提供类SQL查询功能。其本质是将SQL转换为MapReduce的任务进行运算，底层由HDFS来提供数据的存储，说白了hive可以理解为一个将SQL转换为MapReduce的任务的工具，甚至更进一步可以说hive就是一个MapReduce的客户端</p>
<p><img src="http://kflys.gitee.io/upic/2020/03/31/uPic/hive/Snipaste_2019-07-10_23-23-31.png" style="zoom:67%;"></p>
<ul>
<li>Hive与数据库的区别</li>
</ul>
<p><img src="http://kflys.gitee.io/upic/2020/03/31/uPic/hive/2018040319335283.png" alt=""></p>
<ul>
<li>Hive 具有 SQL 数据库的外表，但应用场景完全不同。</li>
<li>==Hive 只适合用来做海量离线数据统计分析，也就是数据仓库==。</li>
</ul>
<h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><ul>
<li><p>==优点==</p>
<ul>
<li><p><strong>操作接口采用类SQL语法</strong>，提供快速开发的能力（简单、容易上手）。</p>
</li>
<li><p><strong>避免了去写MapReduce</strong>，减少开发人员的学习成本。</p>
</li>
<li><p><strong>Hive支持用户自定义函数</strong>，用户可以根据自己的需求来实现自己的函数。</p>
</li>
</ul>
</li>
<li><p>==缺点==</p>
<ul>
<li><strong>Hive 不支持记录级别的增删改操作</strong></li>
<li><strong>Hive 的查询延迟很严重</strong><ul>
<li>hadoop jar  xxxx.jar  xxx.class /input /output<ul>
<li>进行任务的划分，然后进行计算资源的申请</li>
<li>map 0%  reduce 0%</li>
<li>map 10%  reduce 0%</li>
</ul>
</li>
</ul>
</li>
<li><strong>Hive 不支持事务</strong></li>
</ul>
</li>
</ul>
<h4 id="架构原理"><a href="#架构原理" class="headerlink" title="架构原理"></a>架构原理</h4><p><img src="http://kflys.gitee.io/upic/2020/03/31/uPic/hive/2019-07-11_11-08-35.png" style="zoom:50%;"></p>
<ul>
<li>1、用户接口：Client</li>
</ul>
<pre><code class="shell"># CLI（hive shell）、JDBC/ODBC(java访问hive)、WEBUI（浏览器访问hive）
# 第一种 hive Client
bin/hive

# 第二种
nohup  bin/hive --service hiveserver2  &amp;
# 
bin/beeline
beeline&gt; !connect jdbc:hive2://node03:10000
    eg:sql
        bin/hive -e &quot;show databases&quot;
        bin/hive -f hive.sql  # 执行文件 
</code></pre>
<ul>
<li><p>2、元数据：Metastore</p>
<ul>
<li><p>元数据包括：表名、表所属的数据库（默认是default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等；</p>
<ul>
<li>默认存储在自带的derby数据库中，==推荐使用MySQL存储Metastore==</li>
</ul>
</li>
</ul>
</li>
<li><p>3、Hadoop集群</p>
<ul>
<li>使用HDFS进行存储，使用MapReduce进行计算。</li>
</ul>
</li>
<li><p>4、Driver：驱动器</p>
<ul>
<li>解析器（SQL Parser） <ul>
<li>将SQL字符串转换成抽象语法树AST</li>
<li>对AST进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误</li>
</ul>
</li>
<li>编译器（Physical Plan）：将AST编译生成逻辑执行计划</li>
<li>优化器（Query Optimizer）：对逻辑执行计划进行优化</li>
<li>执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于Hive来说默认就是mapreduce任务</li>
</ul>
</li>
</ul>
<p><img src="http://kflys.gitee.io/upic/2020/03/31/uPic/hive/hive1.png" alt="hive1"></p>
<h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><h4 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a>基本数据类型</h4><table>
<thead>
<tr>
<th style="text-align:center">类型名称</th>
<th style="text-align:center">描述</th>
<th style="text-align:center">举例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">boolean</td>
<td style="text-align:center">true/false</td>
<td style="text-align:center">true</td>
</tr>
<tr>
<td style="text-align:center">tinyint</td>
<td style="text-align:center">1字节的有符号整数</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">smallint</td>
<td style="text-align:center">2字节的有符号整数</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">==<strong>int</strong>==</td>
<td style="text-align:center">4字节的有符号整数</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center"><strong>==bigint==</strong></td>
<td style="text-align:center">8字节的有符号整数</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">float</td>
<td style="text-align:center">4字节单精度浮点数</td>
<td style="text-align:center">1.0</td>
</tr>
<tr>
<td style="text-align:center"><strong>==double==</strong></td>
<td style="text-align:center">8字节单精度浮点数</td>
<td style="text-align:center">1.0</td>
</tr>
<tr>
<td style="text-align:center"><strong>==string==</strong></td>
<td style="text-align:center">字符串(不设长度)</td>
<td style="text-align:center">“abc”</td>
</tr>
<tr>
<td style="text-align:center">varchar</td>
<td style="text-align:center">字符串（1-65355长度，超长截断）</td>
<td style="text-align:center">“abc”</td>
</tr>
<tr>
<td style="text-align:center">timestamp</td>
<td style="text-align:center">时间戳</td>
<td style="text-align:center">1563157873</td>
</tr>
<tr>
<td style="text-align:center">date</td>
<td style="text-align:center">日期</td>
<td style="text-align:center">20190715</td>
</tr>
</tbody>
</table>
<h4 id="复合数据类型"><a href="#复合数据类型" class="headerlink" title="复合数据类型"></a>复合数据类型</h4><table>
<thead>
<tr>
<th style="text-align:center">类型名称</th>
<th style="text-align:center">描述</th>
<th style="text-align:center">举例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">array</td>
<td style="text-align:center">一组有序的字段，字段类型必须相同 array(元素1，元素2)  ： array[0]</td>
<td style="text-align:center">Array（1,2,3）</td>
</tr>
<tr>
<td style="text-align:center">map</td>
<td style="text-align:center">一组无序的键值对 map(k1,v1,k2,v2)  ：map[‘a’]</td>
<td style="text-align:center">Map(‘a’,1,’b’,2)</td>
</tr>
<tr>
<td style="text-align:center">struct</td>
<td style="text-align:center">一组命名的字段, col3 struct\&lt;a:string,b:int,c:double> : c.a</td>
<td style="text-align:center">Struct(‘a’,1,2,0)</td>
</tr>
</tbody>
</table>
<h3 id="Hive的DDL操作"><a href="#Hive的DDL操作" class="headerlink" title="Hive的DDL操作"></a>Hive的DDL操作</h3><h4 id="hive的数据库DDL操作"><a href="#hive的数据库DDL操作" class="headerlink" title="hive的数据库DDL操作"></a>hive的数据库DDL操作</h4><pre><code class="sql">-- 1. 创建数据库
hive &gt; create database db_hive;
# 或者
hive &gt; create database if not exists db_hive;

-- 查询数据库    
show databases like &#39;db_hive*&#39;;

-- 查看数据库详情
desc database db_hive;

-- 显示数据库详细信息
desc database extended db_hive;

-- 删除为空的数据库
hive&gt; drop database db_hive;

-- 如果删除的数据库不存在，最好采用if exists 判断数据库是否存在
hive&gt; drop database if exists db_hive;

-- #如果数据库中有表存在，这里需要使用cascade强制删除数据库
hive&gt; drop database if exists db_hive cascade;
</code></pre>
<h4 id="hive的表DDL操作"><a href="#hive的表DDL操作" class="headerlink" title="hive的表DDL操作"></a>hive的表DDL操作</h4><p>官网地址：<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL</a></p>
<pre><code class="sql">-- 通过AS 查询语句完成建表：将子查询的结果存在新表里，有数据 
create table if not exists myhive.stu1 as select id, name from stu;

-- 根据已经存在的表结构创建表
create table if not exists myhive.stu2 like stu;

-- 查询表的类型
desc formatted myhive.stu;

-- eg:external 加上为外部表
create  [external] table if not exists myhive.stu3(id int ,name string)
row format delimited fields terminated by &#39;\t&#39; stored as textfile location       &#39;/user/stu2&#39;;

-- 加载数据 [local]：加上代表本地路径，不加代表hdfs路径
load data [local] inpath &#39;/kfly/install/hivedatas/teacher.csv&#39; into table myhive.teacher;

-- 内部表转换为外部表
alter table stu set tblproperties(&#39;EXTERNAL&#39;=&#39;TRUE&#39;);

-- 注意： 内部表由于删除表的时候会同步删除HDFS的数据文件，所以确定如果一个表仅仅是你独占使用，其他人不适用的时候就可以创建内部表，如果一个表的文件数据，其他人也要使用，那么就创建外部表
-- 一般外部表都是用在数据仓库的ODS层
-- 内部表都是用在数据仓库的DW层
</code></pre>
<h5 id="hive的分区表"><a href="#hive的分区表" class="headerlink" title="hive的分区表"></a>hive的分区表</h5><pre><code class="sql">-- 创建分区表
create table score(s_id string,c_id string, s_score int) partitioned by (month string) row -format delimited fields terminated by &#39;\t&#39;;

-- 创建一个表带多个分区
create table score2 (s_id string,c_id string, s_score int) partitioned by (year string,month string,day string) row format delimited fields terminated by &#39;\t&#39;;

-- 加载数据到分区表
load data  local inpath &#39;/kfly/install/hivedatas/score.csv&#39; into table score partition  (month=&#39;201806&#39;);

-- 展示分区
show  partitions  score;
-- 添加一个 / 多个分区
alter table score add partition(month=&#39;201805&#39;);
alter table score add partition(month=&#39;201804&#39;) partition(month = &#39;201803&#39;);
-- 删除分区
alter table score drop partition(month = &#39;201806&#39;);

-- 进行表的修复,建立我们表与我们数据文件之间的一个关系映射，本地文件数据与元数据之间不同步时执行
msck  repair   table  score4;
</code></pre>
<p><img src="http://kflys.gitee.io/upic/2020/03/31/uPic/hive/2019-07-15_11-35-37.png" alt="2019-07-15_11-35-37" style="zoom:67%;"></p>
<h5 id="hive的分桶表"><a href="#hive的分桶表" class="headerlink" title="hive的分桶表"></a>hive的分桶表</h5><p><img src="http://kflys.gitee.io/upic/2020/03/31/uPic/hive/2019-07-16_17-01-51.png" style="zoom:67%;"></p>
<ul>
<li><p>分桶是相对分区进行更细粒度的划分。</p>
</li>
<li><p>==分桶将整个数据内容安装某列属性值取hash值进行区分，具有相同hash值的数据进入到同一个文件中==</p>
<ul>
<li>比如按照name属性分为3个桶，就是对name属性值的hash值对3取摸，按照取模结果对数据分桶。<ul>
<li>取模结果为==0==的数据记录存放到一个文件</li>
<li>取模结果为==1==的数据记录存放到一个文件</li>
<li>取模结果为==2==的数据记录存放到一个文件</li>
<li>取模结果为==3==的数据记录存放到一个文件</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>==作用==</strong></p>
<ul>
<li>取样sampling更高效。没有分区的话需要扫描整个数据集。</li>
<li><p>提升某些查询操作效率，例如map side join</p>
</li>
<li><p>在创建分桶表之前要执行的命令</p>
<ul>
<li>==set hive.enforce.bucketing=true;==  开启对分桶表的支持</li>
<li>==set mapreduce.job.reduces=4;==      设置与桶相同的reduce个数（默认只有一个reduce）</li>
</ul>
<pre><code class="sql">-- 进入hive客户端然后执行以下命令
use myhive;
set mapreduce.job.reduces=4;  
set hive.enforce.bucketing=true; 
--分桶表
create table myhive.user_buckets_demo(id int, name string)
clustered by(id) 
into 4 buckets 
row format delimited fields terminated by &#39;\t&#39;;

-- 加载数据到普通表 user_demo 中
load data local inpath &#39;/user_bucket.txt&#39;  overwrite into table user_demo; 

-- 在hive客户端当中加载数据
load data local inpath &#39;/user_bucket.txt&#39; into table user_demo;

-- 加载数据到桶表user_buckets_demo中
insert into table user_buckets_demo select * from user_demo;
</code></pre>
</li>
</ul>
</li>
</ul>
<ul>
<li>抽样查询桶表的数据<ul>
<li>tablesample抽样语句，语法：tablesample(bucket  x  out  of  y)<ul>
<li>x表示从第几个桶开始取数据（x 为start y为步长）</li>
<li>y表示桶数的倍数，一共需要从 ==桶数/y==  个桶中取数据</li>
</ul>
</li>
</ul>
</li>
</ul>
<pre><code class="sql">select * from user_buckets_demo tablesample(bucket 1 out of 2)

-- 需要的总桶数=4/2=2个
-- 先从第1个桶中取出数据
-- 再从第1+2=3个桶中取出数据
</code></pre>
<h3 id="Hive修改表结构"><a href="#Hive修改表结构" class="headerlink" title="Hive修改表结构"></a>Hive修改表结构</h3><pre><code class="sql">-- 修改表名称语法
alter table  old_table_name  rename to  new_table_name;
alter table stu3 rename to stu4;
-- 增加列
alter table stu4 add columns(address string);
-- 修改列
alter table stu4 change column address address_id int;

</code></pre>
<h3 id="数据导入"><a href="#数据导入" class="headerlink" title="数据导入"></a>数据导入</h3><pre><code class="sql">-- 数据导入
load data [local] inpath &#39;dataPath&#39; overwrite | into table student [partition (partcol1=val1,…)]; 

insert overwrite table score5 partition(month = &#39;201806&#39;) select s_id,c_id,s_score from score;

-- 查询语句创建表，并加载数据
create table score6 as select * from score;

-- 查询语句中创建表并加载数据（as select）
create external table score (s_id string,c_id string,s_score int) row format delimited fields terminated by &#39;\t&#39; location &#39;/myscore7&#39;;
msck repair table score;

-- 数据导入导出
hive (myhive)&gt; create table teacher2 like teacher;
hive (myhive)&gt; import table teacher2 from &#39;/kfly/teacher&#39;;
</code></pre>
<h3 id="数据导出"><a href="#数据导出" class="headerlink" title="数据导出"></a>数据导出</h3><pre><code class="sql">-- 将查询的结果导出到本地
insert overwrite local directory &#39;/kfly/install/hivedatas/stu&#39; select * from stu;
-- 将查询的结果格式化导出到本地
insert overwrite local directory &#39;/kkb/install/hivedatas/stu2&#39; row format delimited fields terminated by  &#39;,&#39; select * from stu;
-- 将查询的结果导出到HDFS上==(没有local)==
insert overwrite  directory &#39;/kfly/hivedatas/stu&#39;  row format delimited fields terminated by  &#39;,&#39;  select * from stu;

-- shell 命令导出
hive -e &quot;sql语句&quot; &gt;   file
hive -f  sql文件   &gt;    file
bin/hive -e &#39;select * from myhive.stu;&#39; &gt; /kfly/install/hivedatas/student1.txt
-- 导出到hdfs上
export table  myhive.stu to &#39;/kfly/install/hivedatas/stuexport&#39;;
</code></pre>
<h3 id="静态、动态分区"><a href="#静态、动态分区" class="headerlink" title="静态、动态分区"></a>静态、动态分区</h3><pre><code class="sql">-- 静态分区
  create table order_partition(order_number string,order_price  double,order_time string)
  partitioned BY(month string)
  row format delimited fields terminated by &#39;\t&#39;;

  load data local inpath &#39;/kfly/install/hivedatas/order.txt&#39; overwrite into table order_partition partition(month=&#39;2019-03&#39;);

-- 动态分区
--创建普通表
create table t_order(
    order_number string,
    order_price  double, 
    order_time   string
)row format delimited fields terminated by &#39;\t&#39;;
load data local inpath &#39;/kkb/install/hivedatas/order_partition.txt&#39; overwrite into table t_order;

--创建目标分区表
create table order_dynamic_partition(
    order_number string,
    order_price  double    
)partitioned BY(order_time string)
row format delimited fields terminated by &#39;\t&#39;;


-- 要想进行动态分区，需要设置参数
-- 开启动态分区功能
hive&gt; set hive.exec.dynamic.partition=true; 
-- 设置hive为非严格模式
hive&gt; set hive.exec.dynamic.partition.mode=nonstrict; 
hive&gt; insert into table order_dynamic_partition partition(order_time) select order_number,order_price,order_time from t_order;
-- 查看分区
bin/hive&gt;  show partitions order_dynamic_partition;
</code></pre>
<h4 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h4><pre><code class="sql"> -- 全局排序
 order by 

 --局部排序，每个reduce内部进行排序
 sort by    
 set mapreduce.job.reduces=3;

 -- 分区排序,类似MR中partition，==采集hash算法，在map端将查询的结果中hash值相同的结果分发到对应的reduce文件中==。
 distribute by
 -- 当distribute by和sort by字段相同时，可以使用cluster by方式
 cluster by
</code></pre>
<h3 id="Hive-java-Api"><a href="#Hive-java-Api" class="headerlink" title="Hive java Api"></a>Hive java Api</h3><pre><code class="xml"> &lt;dependency&gt;
   &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;
   &lt;artifactId&gt;hive-exec&lt;/artifactId&gt;
   &lt;version&gt;1.1.0-cdh5.14.2&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
  &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;
  &lt;artifactId&gt;hive-jdbc&lt;/artifactId&gt;
  &lt;version&gt;1.1.0-cdh5.14.2&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
  &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;
  &lt;artifactId&gt;hive-cli&lt;/artifactId&gt;
  &lt;version&gt;1.1.0-cdh5.14.2&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
  &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
  &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;
  &lt;version&gt;2.6.0-cdh5.14.2&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<pre><code class="java">Class.forName(&quot;org.apache.hive.jdbc.HiveDriver&quot;);
//获取数据库连接
Connection connection = DriverManager.getConnection(url, &quot;hadoop&quot;,&quot;&quot;);
//定义查询的sql语句
String sql=&quot;select * from stu&quot;;
PreparedStatement ps = connection.prepareStatement(sql);
ResultSet rs = ps.executeQuery();
</code></pre>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a href="https://blog.sev7e0.site/">大数据施工现场</a></span>
        <span>/</span>
        
        <span><a href="https://wangchujiang.com/linux-command/">linux命令</a></span>
        <span>/</span>
        
        <span><a href="http://redisdoc.com/">Redis命令</a></span>
        <span>/</span>
        
        <span><a href="https://github.com/orchid-ding">github</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




</html>
